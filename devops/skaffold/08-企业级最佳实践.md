# 第8章：企业级最佳实践

## 8.1 企业级架构设计

### 8.1.1 多团队协作架构

**企业级Skaffold组织架构：**
```
企业根目录/
├── platform-team/           # 平台团队
│   ├── base-configs/       # 基础配置
│   ├── shared-libraries/   # 共享库
│   └── monitoring/         # 监控配置
├── frontend-team/          # 前端团队
│   ├── app1/              # 应用1
│   ├── app2/              # 应用2
│   └── shared-components/ # 共享组件
├── backend-team/          # 后端团队
│   ├── service1/          # 服务1
│   ├── service2/          # 服务2
│   └── shared-libs/      # 共享库
└── devops/                # DevOps团队
    ├── ci-cd-templates/    # CI/CD模板
    ├── security-policies/ # 安全策略
    └── monitoring-dashboards/ # 监控面板
```

### 8.1.2 配置管理策略

**企业级配置管理：**
```yaml
# 基础配置模板
# base-configs/skaffold-base.yaml
apiVersion: skaffold/v2beta29
kind: Config
metadata:
  name: enterprise-base
  
# 全局构建配置
build:
  local:
    push: false
  artifacts: []
  
# 全局部署配置
deploy:
  kubectl:
    flags:
      global:
        - --validate=true
        - --server-side=true
  
# 全局测试配置
test:
  - image: "*"
    structureTests:
      - ./tests/structure/*.yaml
    
# 全局标签配置
profiles:
  - name: security
    patches:
      - op: add
        path: /build/artifacts/0/docker/secret
        value:
          id: docker-config
          dst: /kaniko/.docker/config.json
```

## 8.2 安全最佳实践

### 8.2.1 镜像安全

**安全镜像构建配置：**
```yaml
# security/skaffold-security.yaml
apiVersion: skaffold/v2beta29
kind: Config
profiles:
  - name: security-hardened
    build:
      artifacts:
        - image: my-app
          docker:
            dockerfile: Dockerfile.security
            target: production
            buildArgs:
              SCAN_ENABLED: "true"
              VULNERABILITY_SCAN: "true"
    
    # 镜像扫描配置
    test:
      - image: "*"
        structureTests:
          - ./security-tests/structure.yaml
        custom:
          - command: "trivy image --exit-code 1 --severity HIGH,CRITICAL {{.IMAGE}}"
          - command: "grype {{.IMAGE}} --fail-on high"
          - command: "docker scout cves {{.IMAGE}}"
    
    # 安全部署配置
    deploy:
      kubectl:
        manifests:
          - k8s/security/
```

### 8.2.2 网络和安全策略

**网络安全配置：**
```yaml
# k8s/security/network-policies.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: deny-all
  namespace: default
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: allow-app-communication
spec:
  podSelector:
    matchLabels:
      app: my-app
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - podSelector:
        matchLabels:
          app: my-app
    ports:
    - protocol: TCP
      port: 8080
  egress:
  - to:
    - podSelector:
        matchLabels:
          app: my-app
    ports:
    - protocol: TCP
      port: 8080
```

## 8.3 性能优化

### 8.3.1 构建性能优化

**高性能构建配置：**
```yaml
# performance/skaffold-performance.yaml
apiVersion: skaffold/v2beta29
kind: Config
profiles:
  - name: optimized-build
    build:
      # 并行构建
      concurrency: 0  # 0表示无限制
      
      artifacts:
        - image: frontend
          docker:
            dockerfile: Dockerfile
            cacheFrom:
              - frontend:latest
              - frontend:{{.BRANCH_NAME}}
            cacheTo:
              - type: registry
                params:
                  mode: max
            
        - image: backend
          docker:
            dockerfile: Dockerfile
            target: production
            
      # 构建缓存优化
      local:
        useBuildkit: true
        concurrency: 3
        
    # 部署优化
    deploy:
      kubectl:
        flags:
          global:
            - --prune-whitelist=apps/v1
            - --prune=true
```

### 8.3.2 资源优化

**资源限制和请求配置：**
```yaml
# k8s/optimization/resource-limits.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
      - name: app
        image: my-app:latest
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        # 健康检查优化
        livenessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
        readinessProbe:
          httpGet:
            path: /ready
            port: 8080
          initialDelaySeconds: 5
          periodSeconds: 5
```

## 8.4 监控和可观测性

### 8.4.1 应用监控

**完整的监控配置：**
```yaml
# monitoring/skaffold-monitoring.yaml
apiVersion: skaffold/v2beta29
kind: Config
profiles:
  - name: with-monitoring
    deploy:
      kubectl:
        manifests:
          - k8s/monitoring/
          - k8s/logging/
    
    # 监控配置
    test:
      - image: "*"
        custom:
          - command: "curl -f http://{{.IMAGE}}:8080/metrics"
          - command: "curl -f http://{{.IMAGE}}:8080/health"

# 监控配置示例
# k8s/monitoring/service-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: my-app-monitor
  labels:
    team: backend
spec:
  selector:
    matchLabels:
      app: my-app
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
```

### 8.4.2 日志管理

**结构化日志配置：**
```yaml
# k8s/logging/fluentd-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: logging
data:
  fluent.conf: |
    <source>
      @type forward
      port 24224
    </source>
    
    <filter **>
      @type record_transformer
      enable_ruby true
      <record>
        pod_name ${record["kubernetes"]["pod_name"]}
        namespace ${record["kubernetes"]["namespace_name"]}
        container_name ${record["kubernetes"]["container_name"]}
      </record>
    </filter>
    
    <match **>
      @type elasticsearch
      host elasticsearch.logging.svc.cluster.local
      port 9200
      index_name fluentd-${time.strftime('%Y.%m.%d')}
      type_name fluentd
    </match>
```

## 8.5 多环境管理

### 8.5.1 环境隔离策略

**多环境配置管理：**
```yaml
# environments/skaffold-environments.yaml
apiVersion: skaffold/v2beta29
kind: Config
profiles:
  - name: development
    patches:
      - op: replace
        path: /deploy/kubectl/manifests
        value:
          - k8s/overlays/development/
      - op: replace
        path: /build/artifacts/0/image
        value: my-app-dev
    
  - name: staging
    patches:
      - op: replace
        path: /deploy/kubectl/manifests
        value:
          - k8s/overlays/staging/
      - op: replace
        path: /build/artifacts/0/image
        value: my-app-staging
      - op: add
        path: /test
        value:
          - image: "*"
            customTests:
              - command: "k6 run --vus 10 --duration 30s tests/load-test.js"
    
  - name: production
    patches:
      - op: replace
        path: /deploy/kubectl/manifests
        value:
          - k8s/overlays/production/
      - op: replace
        path: /build/artifacts/0/image
        value: my-app-prod
      - op: add
        path: /build/artifacts/0/docker/buildArgs
        value:
          PRODUCTION: "true"
          DEBUG: "false"
```

### 8.5.2 环境特定的配置

**环境覆盖配置：**
```yaml
# k8s/overlays/production/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

resources:
- ../../base

patchesStrategicMerge:
- deployment-patch.yaml
- service-patch.yaml
- hpa-patch.yaml

# 生产环境特定配置
namespace: production

commonLabels:
  environment: production
  tier: production

images:
- name: my-app
  newTag: latest
  newName: registry.company.com/my-app

# k8s/overlays/production/deployment-patch.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app
spec:
  replicas: 5
  template:
    spec:
      containers:
      - name: app
        env:
        - name: ENVIRONMENT
          value: "production"
        - name: LOG_LEVEL
          value: "WARN"
        resources:
          requests:
            memory: "256Mi"
            cpu: "200m"
          limits:
            memory: "1Gi"
            cpu: "1"
```

## 8.6 灾难恢复和备份

### 8.6.1 备份策略

**应用备份配置：**
```yaml
# backup/skaffold-backup.yaml
apiVersion: skaffold/v2beta29
kind: Config
profiles:
  - name: backup
    deploy:
      kubectl:
        manifests:
          - k8s/backup/
    
    # 备份验证
    test:
      - image: "*"
        custom:
          - command: "velero backup create {{.TIMESTAMP}}-my-app --include-namespaces default --wait"
          - command: "velero backup describe {{.TIMESTAMP}}-my-app"

# 备份配置示例
# k8s/backup/velero-schedule.yaml
apiVersion: velero.io/v1
kind: Schedule
metadata:
  name: my-app-daily-backup
spec:
  schedule: "0 2 * * *"
  template:
    includedNamespaces:
    - default
    excludedResources:
    - nodes
    - events
    - events.events.k8s.io
    - backups.velero.io
    - restores.velero.io
    ttl: 720h0m0s
```

### 8.6.2 恢复策略

**灾难恢复配置：**
```yaml
# disaster-recovery/skaffold-recovery.yaml
apiVersion: skaffold/v2beta29
kind: Config
profiles:
  - name: disaster-recovery
    deploy:
      kubectl:
        manifests:
          - k8s/recovery/
    
    # 恢复验证
    test:
      - image: "*"
        custom:
          - command: "velero restore create --from-backup latest-my-app --wait"
          - command: "kubectl rollout status deployment/my-app --timeout=300s"

# 恢复配置示例
# k8s/recovery/restore-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: disaster-recovery
spec:
  template:
    spec:
      containers:
      - name: recovery
        image: velero/velero:v1.10.0
        command:
        - /bin/bash
        - -c
        - |
          # 恢复最新备份
          velero restore create --from-backup $(velero backup get -o json | jq -r '.items[0].metadata.name') --wait
          
          # 验证恢复
          kubectl get pods -l app=my-app
        env:
        - name: VELERO_NAMESPACE
          value: velero
      restartPolicy: OnFailure
```

## 8.7 合规性和审计

### 8.7.1 合规性检查

**合规性配置：**
```yaml
# compliance/skaffold-compliance.yaml
apiVersion: skaffold/v2beta29
kind: Config
profiles:
  - name: compliance-check
    test:
      - image: "*"
        custom:
          # 安全合规检查
          - command: "kube-bench --version 1.25"
          - command: "kube-hunter --remote {{.CLUSTER_IP}}"
          - command: "falco --rules /etc/falco/falco_rules.yaml"
          
          # 配置合规检查
          - command: "conftest test k8s/ -p policies/"
          - command: "checkov -d k8s/ --framework kubernetes"
          - command: "kubeaudit all -f k8s/"
    
    # 部署合规配置
    deploy:
      kubectl:
        manifests:
          - k8s/compliance/
```

### 8.7.2 审计日志

**审计配置：**
```yaml
# k8s/compliance/audit-policy.yaml
apiVersion: audit.k8s.io/v1
kind: Policy
rules:
- level: Metadata
  namespaces: ["default"]
  resources:
  - group: ""
    resources: ["pods"]
  - group: "apps"
    resources: ["deployments"]
- level: RequestResponse
  namespaces: ["kube-system"]
  resources:
  - group: ""
    resources: ["secrets"]
```

## 8.8 成本优化

### 8.8.1 资源成本优化

**成本优化配置：**
```yaml
# cost-optimization/skaffold-cost.yaml
apiVersion: skaffold/v2beta29
kind: Config
profiles:
  - name: cost-optimized
    build:
      artifacts:
        - image: my-app
          docker:
            dockerfile: Dockerfile
            # 优化镜像大小
            buildArgs:
              BUILDKIT_SANDBOX_HOSTNAME: docker-container
              BUILDKIT_INLINE_CACHE: 1
    
    # 部署成本优化
    deploy:
      kubectl:
        manifests:
          - k8s/cost-optimization/

# 成本优化配置
# k8s/cost-optimization/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: my-app-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: my-app
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

本章详细介绍了企业级Skaffold的最佳实践，包括安全、性能、监控、多环境管理、灾难恢复、合规性和成本优化等方面的完整配置和策略。