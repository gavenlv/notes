# ç¬¬12ç« ï¼šå®æˆ˜é¡¹ç›®

> **å­¦ä¹ æ—¶é•¿**: 10-12å°æ—¶  
> **éš¾åº¦**: â­â­â­â­â­  
> **é‡è¦æ€§**: â­â­â­â­â­ (ç»¼åˆå®æˆ˜)

## æœ¬ç« ç›®æ ‡

å­¦å®Œæœ¬ç« å,ä½ å°†èƒ½å¤Ÿ:

- âœ… éƒ¨ç½²å®Œæ•´çš„Kubernetesç›‘æ§æ–¹æ¡ˆ
- âœ… æ„å»ºå¾®æœåŠ¡ç›‘æ§ä½“ç³»
- âœ… æ­å»ºå¯è§‚æµ‹æ€§å¹³å°(Prometheus + Grafana + Loki + Jaeger)
- âœ… å®æ–½ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ
- âœ… å¤„ç†çœŸå®åœºæ™¯çš„ç›‘æ§æŒ‘æˆ˜

---

## 12.1 é¡¹ç›®ä¸€ï¼šKuberneteså®Œæ•´ç›‘æ§æ–¹æ¡ˆ

### 12.1.1 æ¶æ„è®¾è®¡

**ç›‘æ§æ ˆç»„ä»¶**:

```
Kubernetes Cluster
â”œâ”€â”€ Prometheus Operator (ç›‘æ§ç¼–æ’)
â”œâ”€â”€ Prometheus (æŒ‡æ ‡é‡‡é›†å’Œå­˜å‚¨)
â”œâ”€â”€ Alertmanager (å‘Šè­¦ç®¡ç†)
â”œâ”€â”€ Grafana (å¯è§†åŒ–)
â”œâ”€â”€ kube-state-metrics (K8sèµ„æºçŠ¶æ€)
â”œâ”€â”€ node-exporter (èŠ‚ç‚¹ç›‘æ§)
â””â”€â”€ åº”ç”¨ Exporters (åº”ç”¨ç›‘æ§)
```

**æ•°æ®æµ**:

```
K8s API Server â”€â”€â”€â”€â”€â”
                    â”œâ”€> kube-state-metrics â”€â”
Kubelet â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
                   â”œâ”€> cAdvisor â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€> Prometheus
Node Exporter â”€â”€â”€â”€â”                         â”‚
                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
åº”ç”¨ /metrics â”€â”€â”€â”€â”˜
```

### 12.1.2 ä½¿ç”¨Prometheus Operatoréƒ¨ç½²

**å®‰è£…Prometheus Operator**:

```bash
# æ·»åŠ Helmä»“åº“
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# å®‰è£…kube-prometheus-stack
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace \
  --set prometheus.prometheusSpec.retention=30d \
  --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=100Gi \
  --set prometheus.prometheusSpec.resources.requests.memory=4Gi \
  --set prometheus.prometheusSpec.resources.requests.cpu=2 \
  --set grafana.persistence.enabled=true \
  --set grafana.persistence.size=10Gi \
  --set alertmanager.persistence.enabled=true \
  --set alertmanager.persistence.size=10Gi
```

**æŸ¥çœ‹éƒ¨ç½²**:

```bash
kubectl get pods -n monitoring
kubectl get svc -n monitoring
```

### 12.1.3 é…ç½®ServiceMonitor

**ç›‘æ§è‡ªå®šä¹‰åº”ç”¨**:

```yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: my-app
  namespace: monitoring
  labels:
    release: prometheus
spec:
  selector:
    matchLabels:
      app: my-app
  endpoints:
    - port: metrics
      interval: 30s
      path: /metrics
  namespaceSelector:
    matchNames:
      - production
```

**å¯¹åº”çš„Service**:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app
  namespace: production
  labels:
    app: my-app
spec:
  selector:
    app: my-app
  ports:
    - name: web
      port: 8080
    - name: metrics
      port: 9090
```

### 12.1.4 PrometheusRuleé…ç½®

**Kuberneteså‘Šè­¦è§„åˆ™**:

```yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kubernetes-alerts
  namespace: monitoring
  labels:
    release: prometheus
spec:
  groups:
    - name: kubernetes.rules
      interval: 30s
      rules:
        # PodçŠ¶æ€å¼‚å¸¸
        - alert: PodNotReady
          expr: sum by (namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown|Failed"}) > 0
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} çŠ¶æ€å¼‚å¸¸"
            description: "Podå¤„äº{{ $labels.phase }}çŠ¶æ€å·²è¶…è¿‡5åˆ†é’Ÿ"
        
        # Podé‡å¯é¢‘ç¹
        - alert: PodCrashLooping
          expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
          for: 5m
          labels:
            severity: critical
          annotations:
            summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} é¢‘ç¹é‡å¯"
            description: "å®¹å™¨{{ $labels.container }}åœ¨15åˆ†é’Ÿå†…é‡å¯äº†{{ $value }}æ¬¡"
        
        # èŠ‚ç‚¹å†…å­˜ä¸è¶³
        - alert: NodeMemoryPressure
          expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "èŠ‚ç‚¹{{ $labels.node }}å†…å­˜å‹åŠ›"
        
        # èŠ‚ç‚¹ç£ç›˜å‹åŠ›
        - alert: NodeDiskPressure
          expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "èŠ‚ç‚¹{{ $labels.node }}ç£ç›˜å‹åŠ›"
        
        # Deploymentå‰¯æœ¬æ•°ä¸è¶³
        - alert: DeploymentReplicasMismatch
          expr: |
            kube_deployment_spec_replicas != kube_deployment_status_replicas_available
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} å‰¯æœ¬æ•°ä¸åŒ¹é…"
            description: "æœŸæœ›{{ $labels.spec_replicas }}ä¸ªå‰¯æœ¬,å½“å‰åªæœ‰{{ $labels.available_replicas }}ä¸ªå¯ç”¨"
        
        # StatefulSetå‰¯æœ¬æ•°ä¸è¶³
        - alert: StatefulSetReplicasMismatch
          expr: |
            kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
          for: 10m
          labels:
            severity: warning
          annotations:
            summary: "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} å‰¯æœ¬æ•°ä¸åŒ¹é…"
        
        # PersistentVolumeClaim Pending
        - alert: PersistentVolumeClaimPending
          expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
          for: 5m
          labels:
            severity: warning
          annotations:
            summary: "PVC {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} å¤„äºPendingçŠ¶æ€"
```

### 12.1.5 Grafana Dashboard

**å¯¼å…¥ç¤¾åŒºDashboard**:

1. è®¿é—®Grafana: `kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80`
2. ç™»å½•(é»˜è®¤admin/prom-operator)
3. å¯¼å…¥Dashboard ID:
   - `3119` - Kubernetes Cluster Monitoring
   - `6417` - Kubernetes Deployment Statefulset Daemonset
   - `10856` - Kubernetes Persistent Volumes
   - `7249` - Kubernetes Cluster (Prometheus)

---

## 12.2 é¡¹ç›®äºŒï¼šå¾®æœåŠ¡ç›‘æ§ä½“ç³»

### 12.2.1 æ¶æ„è®¾è®¡

**å¾®æœåŠ¡æ¶æ„**:

```
API Gateway
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Service                 â”‚
â”‚  Order Service                â”‚
â”‚  Payment Service              â”‚
â”‚  Inventory Service            â”‚
â”‚  Notification Service         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Message Queue (RabbitMQ/Kafka)
Database (MySQL/Redis)
```

**ç›‘æ§å±‚æ¬¡**:

```
ä¸šåŠ¡å±‚: è®¢å•é‡ã€æ”¯ä»˜æˆåŠŸç‡ã€ç”¨æˆ·æ³¨å†Œæ•°
åº”ç”¨å±‚: QPSã€é”™è¯¯ç‡ã€å»¶è¿Ÿã€ååé‡
èµ„æºå±‚: CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œ
åŸºç¡€è®¾æ–½å±‚: K8sé›†ç¾¤ã€èŠ‚ç‚¹ã€å®¹å™¨
```

### 12.2.2 åº”ç”¨ç›‘æ§é›†æˆ

**Goå¾®æœåŠ¡ç¤ºä¾‹**:

```go
package main

import (
    "context"
    "log"
    "net/http"
    "time"

    "github.com/prometheus/client_golang/prometheus"
    "github.com/prometheus/client_golang/prometheus/promhttp"
    "google.golang.org/grpc"
)

var (
    // æœåŠ¡çº§åˆ«æŒ‡æ ‡
    requestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "service_requests_total",
            Help: "æœåŠ¡è¯·æ±‚æ€»æ•°",
        },
        []string{"service", "method", "status"},
    )
    
    requestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "service_request_duration_seconds",
            Help:    "æœåŠ¡è¯·æ±‚å»¶è¿Ÿ",
            Buckets: []float64{0.001, 0.01, 0.1, 0.5, 1, 2, 5, 10},
        },
        []string{"service", "method"},
    )
    
    // ä¸šåŠ¡æŒ‡æ ‡
    ordersCreated = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "orders_created_total",
            Help: "åˆ›å»ºçš„è®¢å•æ•°",
        },
        []string{"service", "status"},
    )
    
    orderAmount = prometheus.NewHistogram(
        prometheus.HistogramOpts{
            Name:    "order_amount",
            Help:    "è®¢å•é‡‘é¢åˆ†å¸ƒ",
            Buckets: []float64{10, 50, 100, 500, 1000, 5000, 10000},
        },
    )
    
    // ä¾èµ–æœåŠ¡æŒ‡æ ‡
    dependencyRequestsTotal = prometheus.NewCounterVec(
        prometheus.CounterOpts{
            Name: "dependency_requests_total",
            Help: "ä¾èµ–æœåŠ¡è¯·æ±‚æ•°",
        },
        []string{"service", "dependency", "status"},
    )
    
    dependencyRequestDuration = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name:    "dependency_request_duration_seconds",
            Help:    "ä¾èµ–æœåŠ¡è¯·æ±‚å»¶è¿Ÿ",
            Buckets: []float64{0.001, 0.01, 0.1, 0.5, 1, 2, 5},
        },
        []string{"service", "dependency"},
    )
)

func init() {
    prometheus.MustRegister(requestsTotal)
    prometheus.MustRegister(requestDuration)
    prometheus.MustRegister(ordersCreated)
    prometheus.MustRegister(orderAmount)
    prometheus.MustRegister(dependencyRequestsTotal)
    prometheus.MustRegister(dependencyRequestDuration)
}

// gRPCæ‹¦æˆªå™¨ - è‡ªåŠ¨è®°å½•æŒ‡æ ‡
func UnaryServerInterceptor(serviceName string) grpc.UnaryServerInterceptor {
    return func(ctx context.Context, req interface{}, info *grpc.UnaryServerInfo, handler grpc.UnaryHandler) (interface{}, error) {
        start := time.Now()
        
        resp, err := handler(ctx, req)
        
        duration := time.Since(start).Seconds()
        status := "success"
        if err != nil {
            status = "error"
        }
        
        requestsTotal.WithLabelValues(serviceName, info.FullMethod, status).Inc()
        requestDuration.WithLabelValues(serviceName, info.FullMethod).Observe(duration)
        
        return resp, err
    }
}

func main() {
    // æš´éœ²æŒ‡æ ‡
    http.Handle("/metrics", promhttp.Handler())
    go http.ListenAndServe(":9090", nil)
    
    // å¯åŠ¨gRPCæœåŠ¡å™¨
    // ...
}
```

### 12.2.3 åˆ†å¸ƒå¼è¿½è¸ªé›†æˆ

**OpenTelemetryé…ç½®**:

```yaml
# opentelemetry-collector-config.yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    timeout: 10s
    send_batch_size: 1024

exporters:
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: "otel"
  
  jaeger:
    endpoint: "jaeger-collector:14250"
    tls:
      insecure: true

service:
  pipelines:
    traces:
      receivers: [otlp]
      processors: [batch]
      exporters: [jaeger]
    
    metrics:
      receivers: [otlp]
      processors: [batch]
      exporters: [prometheus]
```

### 12.2.4 æ ¸å¿ƒç›‘æ§æŒ‡æ ‡

**REDæ–¹æ³•**(Request, Error, Duration):

```promql
# Rate (è¯·æ±‚é€Ÿç‡)
sum(rate(service_requests_total[5m])) by (service)

# Errors (é”™è¯¯ç‡)
sum(rate(service_requests_total{status="error"}[5m])) by (service)
/
sum(rate(service_requests_total[5m])) by (service)

# Duration (å“åº”æ—¶é—´)
histogram_quantile(0.95, 
  sum(rate(service_request_duration_seconds_bucket[5m])) by (le, service)
)
```

**USEæ–¹æ³•**(Utilization, Saturation, Errors):

```promql
# Utilization (èµ„æºä½¿ç”¨ç‡)
- CPU: 1 - avg(rate(node_cpu_seconds_total{mode="idle"}[5m]))
- Memory: 1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes

# Saturation (é¥±å’Œåº¦)
- Load: node_load5 / count(node_cpu_seconds_total{mode="idle"}) by (instance)
- Disk IO: rate(node_disk_io_time_seconds_total[5m])

# Errors (é”™è¯¯)
- Network: rate(node_network_receive_errs_total[5m])
- Disk: rate(node_disk_read_errors_total[5m])
```

---

## 12.3 é¡¹ç›®ä¸‰ï¼šå¯è§‚æµ‹æ€§å¹³å°

### 12.3.1 å®Œæ•´æ¶æ„

**ä¸‰å¤§æ”¯æŸ±**:

```
æŒ‡æ ‡ (Metrics)   â† Prometheus + Grafana
æ—¥å¿— (Logs)      â† Loki + Promtail
è¿½è¸ª (Traces)    â† Jaeger/Tempo
```

### 12.3.2 éƒ¨ç½²Lokiæ—¥å¿—ç³»ç»Ÿ

**å®‰è£…Loki Stack**:

```bash
helm install loki grafana/loki-stack \
  --namespace logging --create-namespace \
  --set loki.persistence.enabled=true \
  --set loki.persistence.size=100Gi \
  --set promtail.enabled=true \
  --set grafana.enabled=false  # ä½¿ç”¨å·²æœ‰Grafana
```

**Promtailé…ç½®**:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: promtail-config
  namespace: logging
data:
  promtail.yaml: |
    server:
      http_listen_port: 9080
      grpc_listen_port: 0

    positions:
      filename: /tmp/positions.yaml

    clients:
      - url: http://loki:3100/loki/api/v1/push

    scrape_configs:
      # Kubernetes Podæ—¥å¿—
      - job_name: kubernetes-pods
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_label_app]
            target_label: app
          - source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - source_labels: [__meta_kubernetes_pod_name]
            target_label: pod
        pipeline_stages:
          - docker: {}
```

### 12.3.3 éƒ¨ç½²Jaegerè¿½è¸ªç³»ç»Ÿ

**å®‰è£…Jaeger Operator**:

```bash
kubectl create namespace observability
kubectl create -f https://github.com/jaegertracing/jaeger-operator/releases/download/v1.49.0/jaeger-operator.yaml -n observability
```

**éƒ¨ç½²Jaegerå®ä¾‹**:

```yaml
apiVersion: jaegertracing.io/v1
kind: Jaeger
metadata:
  name: jaeger
  namespace: observability
spec:
  strategy: production
  storage:
    type: elasticsearch
    options:
      es:
        server-urls: http://elasticsearch:9200
  ingress:
    enabled: true
  query:
    resources:
      limits:
        memory: 512Mi
      requests:
        memory: 256Mi
  collector:
    resources:
      limits:
        memory: 1Gi
      requests:
        memory: 512Mi
```

### 12.3.4 Grafanaç»Ÿä¸€å¯è§†åŒ–

**æ·»åŠ æ•°æ®æº**:

```yaml
# grafana-datasources.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-datasources
  namespace: monitoring
data:
  datasources.yaml: |
    apiVersion: 1
    datasources:
      # Prometheus
      - name: Prometheus
        type: prometheus
        access: proxy
        url: http://prometheus-kube-prometheus-prometheus:9090
        isDefault: true
      
      # Loki
      - name: Loki
        type: loki
        access: proxy
        url: http://loki:3100
      
      # Jaeger
      - name: Jaeger
        type: jaeger
        access: proxy
        url: http://jaeger-query:16686
```

**å…³è”æŸ¥è¯¢ç¤ºä¾‹**:

```
1. åœ¨Grafanaä¸­æŸ¥çœ‹æŒ‡æ ‡å¼‚å¸¸
2. ç‚¹å‡»"Explore"â†’ åˆ‡æ¢åˆ°LokiæŸ¥çœ‹æ—¥å¿—
3. ä»æ—¥å¿—ä¸­æå–trace_id
4. åˆ‡æ¢åˆ°JaegeræŸ¥çœ‹å®Œæ•´è°ƒç”¨é“¾
```

---

## 12.4 ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ¸…å•

### 12.4.1 éƒ¨ç½²å‰æ£€æŸ¥

**åŸºç¡€è®¾æ–½**:
- [ ] Kubernetesé›†ç¾¤ç‰ˆæœ¬â‰¥1.20
- [ ] èŠ‚ç‚¹èµ„æºå……è¶³(CPU/å†…å­˜/ç£ç›˜)
- [ ] æŒä¹…åŒ–å­˜å‚¨å¯ç”¨(StorageClassé…ç½®)
- [ ] ç½‘ç»œç­–ç•¥é…ç½®
- [ ] RBACæƒé™é…ç½®

**ç›‘æ§ç»„ä»¶**:
- [ ] Prometheusèµ„æºé™åˆ¶åˆç†
- [ ] Alertmanager HAéƒ¨ç½²
- [ ] GrafanaæŒä¹…åŒ–é…ç½®
- [ ] Exportersæ­£å¸¸è¿è¡Œ

**å®‰å…¨é…ç½®**:
- [ ] TLSè¯ä¹¦é…ç½®
- [ ] è®¿é—®è®¤è¯(OAuth/LDAP)
- [ ] ç½‘ç»œéš”ç¦»
- [ ] æ•æ„Ÿä¿¡æ¯åŠ å¯†(Secret)

### 12.4.2 å®¹é‡è§„åˆ’

**Prometheusèµ„æºéœ€æ±‚**:

```yaml
# å°è§„æ¨¡ (< 1000 targets, < 100ä¸‡æ—¶é—´åºåˆ—)
resources:
  requests:
    memory: 4Gi
    cpu: 2
  limits:
    memory: 8Gi
    cpu: 4

# ä¸­ç­‰è§„æ¨¡ (1000-5000 targets, 100-500ä¸‡æ—¶é—´åºåˆ—)
resources:
  requests:
    memory: 16Gi
    cpu: 4
  limits:
    memory: 32Gi
    cpu: 8

# å¤§è§„æ¨¡ (> 5000 targets, > 500ä¸‡æ—¶é—´åºåˆ—)
# å»ºè®®ä½¿ç”¨è”é‚¦é›†ç¾¤æˆ–Thanos
```

**å­˜å‚¨è§„åˆ’**:

```
æ¯ç§’æ ·æœ¬æ•° Ã— æ ·æœ¬å¤§å° Ã— ä¿ç•™å¤©æ•° / å‹ç¼©ç‡

ç¤ºä¾‹:
- æ¯ç§’æ ·æœ¬æ•°: 100,000
- æ ·æœ¬å¤§å°: 2å­—èŠ‚
- ä¿ç•™å¤©æ•°: 30å¤©
- å‹ç¼©ç‡: 3å€

å­˜å‚¨éœ€æ±‚ = 100000 Ã— 2 Ã— 86400 Ã— 30 / 3 / (1024^3) â‰ˆ 160GB
```

### 12.4.3 é«˜å¯ç”¨é…ç½®

**Prometheus HA**:

```yaml
apiVersion: monitoring.coreos.com/v1
kind: Prometheus
metadata:
  name: prometheus
  namespace: monitoring
spec:
  replicas: 2  # åŒå‰¯æœ¬
  retention: 30d
  externalLabels:
    cluster: production
    replica: '$(POD_NAME)'
  resources:
    requests:
      memory: 16Gi
      cpu: 4
  storage:
    volumeClaimTemplate:
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 200Gi
  affinity:
    podAntiAffinity:  # Podåäº²å’Œ,ç¡®ä¿åˆ†æ•£éƒ¨ç½²
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app: prometheus
          topologyKey: kubernetes.io/hostname
```

**Alertmanager HA**:

```yaml
apiVersion: monitoring.coreos.com/v1
kind: Alertmanager
metadata:
  name: alertmanager
  namespace: monitoring
spec:
  replicas: 3  # 3å‰¯æœ¬
  cluster:
    enabled: true
  resources:
    requests:
      memory: 512Mi
      cpu: 200m
```

---

## 12.5 æ•…éšœå¤„ç†æ¡ˆä¾‹

### 12.5.1 æ¡ˆä¾‹1: Prometheuså†…å­˜OOM

**ç°è±¡**:
```
Prometheus Podé¢‘ç¹é‡å¯
Error: OOMKilled
```

**æ’æŸ¥**:
```promql
# æŸ¥çœ‹å†…å­˜ä½¿ç”¨
process_resident_memory_bytes{job="prometheus"}

# æŸ¥çœ‹æ—¶é—´åºåˆ—æ•°é‡
prometheus_tsdb_symbol_table_size_bytes

# æŸ¥çœ‹é«˜åŸºæ•°æŒ‡æ ‡
topk(10, count by (__name__) ({__name__=~".+"}))
```

**è§£å†³æ–¹æ¡ˆ**:
1. å¢åŠ å†…å­˜é™åˆ¶
2. å‡å°‘æŠ“å–ç›®æ ‡æˆ–é™ä½é¢‘ç‡
3. åˆ é™¤é«˜åŸºæ•°æŒ‡æ ‡
4. ä½¿ç”¨Remote Writeå¸è½½æ•°æ®
5. åˆ†ç‰‡éƒ¨ç½²

### 12.5.2 æ¡ˆä¾‹2: å‘Šè­¦é£æš´

**ç°è±¡**:
```
çŸ­æ—¶é—´å†…æ”¶åˆ°æ•°ç™¾æ¡å‘Šè­¦
Alertmanagerè¿‡è½½
```

**è§£å†³æ–¹æ¡ˆ**:

1. **é…ç½®å‘Šè­¦åˆ†ç»„**:
```yaml
route:
  group_by: ['alertname', 'cluster']
  group_wait: 30s
  group_interval: 5m
```

2. **é…ç½®å‘Šè­¦æŠ‘åˆ¶**:
```yaml
inhibit_rules:
  - source_match:
      alertname: 'NodeDown'
    target_match_re:
      alertname: '.*'
    equal: ['instance']
```

3. **è°ƒæ•´å‘Šè­¦é˜ˆå€¼**:
```yaml
# å¢åŠ foræ—¶é•¿,é¿å…æŠ–åŠ¨
- alert: HighCPU
  expr: cpu > 80
  for: 10m  # ä»5må¢åŠ åˆ°10m
```

### 12.5.3 æ¡ˆä¾‹3: æŸ¥è¯¢è¶…æ—¶

**ç°è±¡**:
```
Grafana DashboardåŠ è½½è¶…æ—¶
Error: query timeout
```

**è§£å†³æ–¹æ¡ˆ**:

1. **ä¼˜åŒ–æŸ¥è¯¢**:
```promql
# âŒ æ…¢æŸ¥è¯¢
sum(rate(http_requests_total[5m])) by (path, method, status)

# âœ… ä½¿ç”¨Recording Rule
sum(rate(path_method_status:http_requests:rate5m[5m]))
```

2. **å¢åŠ æŸ¥è¯¢è¶…æ—¶**:
```yaml
--query.timeout=2m
--query.max-concurrency=20
```

3. **é™åˆ¶DashboardæŸ¥è¯¢èŒƒå›´**:
```
ä½¿ç”¨æ—¶é—´é€‰æ‹©å™¨é™åˆ¶æŸ¥è¯¢èŒƒå›´(å¦‚æœ€è¿‘24å°æ—¶)
ä½¿ç”¨å˜é‡è¿‡æ»¤å‡å°‘æ•°æ®é‡
```

---

## 12.6 æœ¬ç« å°ç»“

### å®æˆ˜é¡¹ç›®æ€»ç»“

âœ… **Kubernetesç›‘æ§**: Prometheus Operatorã€ServiceMonitorã€PrometheusRule

âœ… **å¾®æœåŠ¡ç›‘æ§**: RED/USEæ–¹æ³•ã€åˆ†å¸ƒå¼è¿½è¸ªã€ä¾èµ–ç›‘æ§

âœ… **å¯è§‚æµ‹æ€§å¹³å°**: Prometheus + Loki + Jaegerä¸‰å¤§æ”¯æŸ±

âœ… **ç”Ÿäº§å®è·µ**: HAéƒ¨ç½²ã€å®¹é‡è§„åˆ’ã€æ•…éšœå¤„ç†

### å®Œæ•´æŠ€æœ¯æ ˆ

```
é‡‡é›†å±‚:
â”œâ”€â”€ Prometheus (æŒ‡æ ‡)
â”œâ”€â”€ Promtail (æ—¥å¿—)
â””â”€â”€ OpenTelemetry (è¿½è¸ª)

å­˜å‚¨å±‚:
â”œâ”€â”€ Prometheus TSDB (çŸ­æœŸæŒ‡æ ‡)
â”œâ”€â”€ Thanos/VictoriaMetrics (é•¿æœŸæŒ‡æ ‡)
â”œâ”€â”€ Loki (æ—¥å¿—)
â””â”€â”€ Jaeger/Tempo (è¿½è¸ª)

å¯è§†åŒ–å±‚:
â”œâ”€â”€ Grafana (ç»Ÿä¸€è§†å›¾)
â”œâ”€â”€ Prometheus UI (æŸ¥è¯¢è°ƒè¯•)
â””â”€â”€ Jaeger UI (è¿½è¸ªåˆ†æ)

å‘Šè­¦å±‚:
â””â”€â”€ Alertmanager (å‘Šè­¦è·¯ç”±å’Œé€šçŸ¥)
```

---

## ğŸ“ è¯¾ç¨‹æ€»ç»“

æ­å–œä½ å®Œæˆäº†ã€ŠPrometheusä»0åˆ°ä¸“å®¶ã€‹å…¨éƒ¨12ç« çš„å­¦ä¹ !

### å­¦ä¹ è·¯å¾„å›é¡¾

```
ç¬¬1-2ç« : åŸºç¡€å…¥é—¨
  â†“
ç¬¬3-4ç« : æ ¸å¿ƒæŠ€èƒ½(PromQL + Exporters)
  â†“
ç¬¬5-6ç« : æœåŠ¡å‘ç° + å‘Šè­¦
  â†“
ç¬¬7-8ç« : ä¼˜åŒ–æŠ€å·§(Recording Rules + Pushgateway)
  â†“
ç¬¬9-10ç« : é«˜çº§æ¶æ„(HA + æ€§èƒ½ä¼˜åŒ–)
  â†“
ç¬¬11-12ç« : å®æˆ˜åº”ç”¨
```

### æ ¸å¿ƒèƒ½åŠ›

ä½ ç°åœ¨å·²ç»æŒæ¡:

âœ… Prometheuså®Œæ•´æ¶æ„å’ŒåŸç†
âœ… PromQLæŸ¥è¯¢è¯­è¨€ç²¾é€š
âœ… å‘Šè­¦è§„åˆ™è®¾è®¡å’ŒAlertmanageré…ç½®
âœ… é«˜å¯ç”¨å’Œè”é‚¦é›†ç¾¤éƒ¨ç½²
âœ… æ€§èƒ½ä¼˜åŒ–å’Œæ•…éšœæ’æŸ¥
âœ… ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ

### ç»§ç»­å­¦ä¹ 

**æ¨èèµ„æº**:
- ğŸ“– Prometheuså®˜æ–¹æ–‡æ¡£: https://prometheus.io/docs/
- ğŸ“ CNCFè®¤è¯è¯¾ç¨‹
- ğŸ’» GitHubç¤ºä¾‹é¡¹ç›®
- ğŸ‘¥ Prometheusç¤¾åŒº

**å®è·µå»ºè®®**:
1. æ­å»ºä¸ªäººå®éªŒç¯å¢ƒ
2. è´¡çŒ®å¼€æºé¡¹ç›®
3. åˆ†äº«ç»éªŒå’Œæ€»ç»“
4. æŒç»­å…³æ³¨æ–°ç‰¹æ€§

---

**ğŸ‰ æ­å–œä½ æˆä¸ºPrometheusä¸“å®¶!**

ç¥ä½ åœ¨ç›‘æ§å’Œå¯è§‚æµ‹æ€§é¢†åŸŸä¸æ–­ç²¾è¿›! ğŸš€
