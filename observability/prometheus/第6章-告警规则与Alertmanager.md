# ç¬¬6ç« ï¼šå‘Šè­¦è§„åˆ™ä¸Alertmanager

> **å­¦ä¹ æ—¶é•¿**: 8-10å°æ—¶  
> **éš¾åº¦**: â­â­â­â­  
> **é‡è¦æ€§**: â­â­â­â­â­ (ç”Ÿäº§ç¯å¢ƒå¿…å¤‡)

## æœ¬ç« ç›®æ ‡

å­¦å®Œæœ¬ç« å,ä½ å°†èƒ½å¤Ÿ:

- âœ… ç¼–å†™Prometheuså‘Šè­¦è§„åˆ™
- âœ… é…ç½®å’Œéƒ¨ç½²Alertmanager
- âœ… è®¾ç½®å¤šç§é€šçŸ¥æ¸ é“(Emailã€Slackã€é’‰é’‰ã€ä¼ä¸šå¾®ä¿¡)
- âœ… æŒæ¡å‘Šè­¦è·¯ç”±å’Œåˆ†ç»„ç­–ç•¥
- âœ… ä½¿ç”¨å‘Šè­¦æŠ‘åˆ¶å’Œé™é»˜åŠŸèƒ½
- âœ… è®¾è®¡å®Œæ•´çš„å‘Šè­¦ä½“ç³»
- âœ… å®æ–½å‘Šè­¦æœ€ä½³å®è·µ

---

## 6.1 å‘Šè­¦æ¦‚è¿°

### 6.1.1 å‘Šè­¦å·¥ä½œæµç¨‹

```
Prometheus â†’ è¯„ä¼°å‘Šè­¦è§„åˆ™ â†’ è§¦å‘å‘Šè­¦ â†’ Alertmanager â†’ è·¯ç”±/åˆ†ç»„/æŠ‘åˆ¶ â†’ é€šçŸ¥æ¸ é“
    â†“              â†“               â†“            â†“                â†“
  æŸ¥è¯¢æ•°æ®      æ¯15ç§’è¯„ä¼°      å‘é€åˆ°AM      å»é‡/èšåˆ        Email/Slackç­‰
```

### 6.1.2 å‘Šè­¦çŠ¶æ€

| çŠ¶æ€ | è¯´æ˜ |
|------|------|
| **Inactive** | æœªæ¿€æ´»(æœªè§¦å‘) |
| **Pending** | å·²è§¦å‘ä½†æœªè¾¾åˆ°æŒç»­æ—¶é—´(`for`å­å¥) |
| **Firing** | å·²è§¦å‘å¹¶å‘é€åˆ°Alertmanager |

---

## 6.2 ç¼–å†™å‘Šè­¦è§„åˆ™

### 6.2.1 å‘Šè­¦è§„åˆ™è¯­æ³•

**åŸºæœ¬ç»“æ„**:

```yaml
groups:
  - name: <group_name>
    interval: <evaluation_interval>
    rules:
      - alert: <alert_name>
        expr: <promql_expression>
        for: <duration>
        labels:
          <label_name>: <label_value>
        annotations:
          <annotation_name>: <annotation_value>
```

**å­—æ®µè¯´æ˜**:
- `alert`: å‘Šè­¦åç§°
- `expr`: PromQLè¡¨è¾¾å¼
- `for`: æŒç»­æ—¶é—´(å¯é€‰)
- `labels`: å‘Šè­¦æ ‡ç­¾
- `annotations`: å‘Šè­¦æè¿°(æ”¯æŒæ¨¡æ¿)

### 6.2.2 åŸºç¡€å‘Šè­¦è§„åˆ™ç¤ºä¾‹

**åˆ›å»ºè§„åˆ™æ–‡ä»¶**: `/etc/prometheus/rules/alerts.yml`

```yaml
groups:
  - name: node_alerts
    interval: 15s
    rules:
      # èŠ‚ç‚¹å®•æœº
      - alert: NodeDown
        expr: up{job="node-exporter"} == 0
        for: 1m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "èŠ‚ç‚¹{{ $labels.instance }}å®•æœº"
          description: "èŠ‚ç‚¹{{ $labels.instance }}å·²å®•æœºè¶…è¿‡1åˆ†é’Ÿ"

      # CPUä½¿ç”¨ç‡è¿‡é«˜
      - alert: HighCpuUsage
        expr: 100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "èŠ‚ç‚¹{{ $labels.instance }}CPUä½¿ç”¨ç‡è¿‡é«˜"
          description: "CPUä½¿ç”¨ç‡ä¸º{{ $value | humanize }}%,å·²æŒç»­5åˆ†é’Ÿ"

      # å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜
      - alert: HighMemoryUsage
        expr: (1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100 > 90
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "èŠ‚ç‚¹{{ $labels.instance }}å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "å†…å­˜ä½¿ç”¨ç‡ä¸º{{ $value | humanize }}%"

      # ç£ç›˜ç©ºé—´ä¸è¶³
      - alert: DiskSpaceLow
        expr: (node_filesystem_avail_bytes{fstype!~"tmpfs|devtmpfs"} / node_filesystem_size_bytes{fstype!~"tmpfs|devtmpfs"}) * 100 < 10
        for: 5m
        labels:
          severity: critical
          team: infrastructure
        annotations:
          summary: "èŠ‚ç‚¹{{ $labels.instance }}ç£ç›˜ç©ºé—´ä¸è¶³"
          description: "æŒ‚è½½ç‚¹{{ $labels.mountpoint }}å‰©ä½™ç©ºé—´{{ $value | humanize }}%"

      # ç£ç›˜å°†åœ¨4å°æ—¶å†…ç”¨å®Œ
      - alert: DiskWillFillIn4Hours
        expr: predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs|devtmpfs"}[1h], 4*3600) < 0
        for: 5m
        labels:
          severity: warning
          team: infrastructure
        annotations:
          summary: "èŠ‚ç‚¹{{ $labels.instance }}ç£ç›˜å³å°†ç”¨å®Œ"
          description: "é¢„è®¡4å°æ—¶åç£ç›˜{{ $labels.mountpoint }}å°†ç”¨å®Œ"
```

### 6.2.3 åº”ç”¨ç¨‹åºå‘Šè­¦è§„åˆ™

```yaml
groups:
  - name: application_alerts
    rules:
      # æœåŠ¡ä¸å¯ç”¨
      - alert: ServiceDown
        expr: up{job="my-service"} == 0
        for: 2m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "æœåŠ¡{{ $labels.job }}ä¸å¯ç”¨"
          description: "å®ä¾‹{{ $labels.instance }}å·²å®•æœºè¶…è¿‡2åˆ†é’Ÿ"

      # é”™è¯¯ç‡è¿‡é«˜
      - alert: HighErrorRate
        expr: |
          sum(rate(http_requests_total{status=~"5.."}[5m])) by (instance)
          /
          sum(rate(http_requests_total[5m])) by (instance) * 100 > 5
        for: 5m
        labels:
          severity: critical
          team: backend
        annotations:
          summary: "æœåŠ¡{{ $labels.instance }}é”™è¯¯ç‡è¿‡é«˜"
          description: "é”™è¯¯ç‡ä¸º{{ $value | humanize }}%,å·²æŒç»­5åˆ†é’Ÿ"

      # å“åº”æ—¶é—´è¿‡é•¿
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
        for: 5m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "æœåŠ¡{{ $labels.instance }}å“åº”å»¶è¿Ÿè¿‡é«˜"
          description: "p95å»¶è¿Ÿä¸º{{ $value | humanize }}ç§’"

      # QPSå¼‚å¸¸ä¸‹é™
      - alert: LowQPS
        expr: |
          sum(rate(http_requests_total[5m])) by (instance) < 10
          and
          sum(rate(http_requests_total[5m] offset 1h)) by (instance) > 100
        for: 10m
        labels:
          severity: warning
          team: backend
        annotations:
          summary: "æœåŠ¡{{ $labels.instance }}QPSå¼‚å¸¸ä¸‹é™"
          description: "å½“å‰QPSä¸º{{ $value | humanize }},1å°æ—¶å‰ä¸º100+"
```

### 6.2.4 æ•°æ®åº“å‘Šè­¦è§„åˆ™

```yaml
groups:
  - name: database_alerts
    rules:
      # MySQLå®•æœº
      - alert: MysqlDown
        expr: mysql_up == 0
        for: 1m
        labels:
          severity: critical
          team: dba
        annotations:
          summary: "MySQLå®ä¾‹{{ $labels.instance }}å®•æœº"

      # æ…¢æŸ¥è¯¢è¿‡å¤š
      - alert: MysqlSlowQueries
        expr: rate(mysql_global_status_slow_queries[5m]) > 10
        for: 5m
        labels:
          severity: warning
          team: dba
        annotations:
          summary: "MySQLå®ä¾‹{{ $labels.instance }}æ…¢æŸ¥è¯¢è¿‡å¤š"
          description: "æ…¢æŸ¥è¯¢é€Ÿç‡ä¸º{{ $value | humanize }}/s"

      # è¿æ¥æ•°ä½¿ç”¨ç‡è¿‡é«˜
      - alert: MysqlConnectionsHigh
        expr: mysql_global_status_threads_connected / mysql_global_variables_max_connections * 100 > 80
        for: 5m
        labels:
          severity: warning
          team: dba
        annotations:
          summary: "MySQLå®ä¾‹{{ $labels.instance }}è¿æ¥æ•°è¿‡é«˜"
          description: "è¿æ¥æ•°ä½¿ç”¨ç‡ä¸º{{ $value | humanize }}%"

      # Rediså†…å­˜ä½¿ç”¨ç‡è¿‡é«˜
      - alert: RedisMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
        for: 5m
        labels:
          severity: warning
          team: dba
        annotations:
          summary: "Rediså®ä¾‹{{ $labels.instance }}å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
          description: "å†…å­˜ä½¿ç”¨ç‡ä¸º{{ $value | humanize }}%"
```

### 6.2.5 é…ç½®PrometheusåŠ è½½è§„åˆ™

åœ¨`prometheus.yml`ä¸­é…ç½®:

```yaml
rule_files:
  - "/etc/prometheus/rules/*.yml"
  - "/etc/prometheus/rules/alerts/*.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
            - 'alertmanager:9093'
```

**é‡è½½é…ç½®**:

```bash
# æ–¹å¼1: å‘é€SIGHUPä¿¡å·
kill -HUP <prometheus_pid>

# æ–¹å¼2: HTTP API
curl -X POST http://localhost:9090/-/reload

# æ–¹å¼3: systemd
sudo systemctl reload prometheus
```

**éªŒè¯è§„åˆ™**:

```bash
# æ£€æŸ¥è¯­æ³•
promtool check rules /etc/prometheus/rules/alerts.yml

# æµ‹è¯•è§„åˆ™
promtool test rules test.yml
```

---

## 6.3 Alertmanageréƒ¨ç½²ä¸é…ç½®

### 6.3.1 å®‰è£…Alertmanager

**Dockeræ–¹å¼**:

```bash
docker run -d \
  --name=alertmanager \
  -p 9093:9093 \
  -v /etc/alertmanager:/etc/alertmanager \
  prom/alertmanager:latest \
  --config.file=/etc/alertmanager/alertmanager.yml
```

**äºŒè¿›åˆ¶å®‰è£…**:

```bash
VERSION=0.26.0
wget https://github.com/prometheus/alertmanager/releases/download/v${VERSION}/alertmanager-${VERSION}.linux-amd64.tar.gz
tar xvfz alertmanager-${VERSION}.linux-amd64.tar.gz
cd alertmanager-${VERSION}.linux-amd64
./alertmanager --config.file=alertmanager.yml
```

### 6.3.2 Alertmanageré…ç½®æ–‡ä»¶

**åŸºç¡€é…ç½®** (`/etc/alertmanager/alertmanager.yml`):

```yaml
global:
  # SMTPé…ç½®(Emailé€šçŸ¥)
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@example.com'
  smtp_auth_username: 'alerts@example.com'
  smtp_auth_password: 'password'
  smtp_require_tls: true
  
  # é»˜è®¤è§£æè¶…æ—¶
  resolve_timeout: 5m

# æ¨¡æ¿æ–‡ä»¶
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# è·¯ç”±é…ç½®
route:
  # é»˜è®¤æ¥æ”¶è€…
  receiver: 'default'
  
  # åˆ†ç»„è§„åˆ™
  group_by: ['alertname', 'cluster', 'service']
  
  # åˆ†ç»„ç­‰å¾…æ—¶é—´(é¦–æ¬¡å‘Šè­¦)
  group_wait: 10s
  
  # åˆ†ç»„é—´éš”æ—¶é—´(åç»­å‘Šè­¦)
  group_interval: 10s
  
  # é‡å¤å‘Šè­¦é—´éš”
  repeat_interval: 12h
  
  # å­è·¯ç”±
  routes:
    # criticalçº§åˆ«å‘Šè­¦ -> ç”µè¯é€šçŸ¥
    - match:
        severity: critical
      receiver: 'pagerduty'
      continue: true  # ç»§ç»­åŒ¹é…åç»­è·¯ç”±
    
    # æ•°æ®åº“å‘Šè­¦ -> DBAå›¢é˜Ÿ
    - match:
        team: dba
      receiver: 'dba-team'
      group_by: ['alertname', 'instance']
    
    # åŸºç¡€è®¾æ–½å‘Šè­¦ -> è¿ç»´å›¢é˜Ÿ
    - match:
        team: infrastructure
      receiver: 'ops-team'
    
    # åç«¯æœåŠ¡å‘Šè­¦ -> åç«¯å›¢é˜Ÿ
    - match:
        team: backend
      receiver: 'backend-team'

# æŠ‘åˆ¶è§„åˆ™
inhibit_rules:
  # å¦‚æœèŠ‚ç‚¹å®•æœº,æŠ‘åˆ¶è¯¥èŠ‚ç‚¹ä¸Šçš„æ‰€æœ‰å…¶ä»–å‘Šè­¦
  - source_match:
      alertname: 'NodeDown'
    target_match_re:
      alertname: '.*'
    equal: ['instance']
  
  # å¦‚æœæœåŠ¡å®Œå…¨å®•æœº,æŠ‘åˆ¶é«˜é”™è¯¯ç‡å‘Šè­¦
  - source_match:
      alertname: 'ServiceDown'
    target_match:
      alertname: 'HighErrorRate'
    equal: ['instance']

# æ¥æ”¶è€…é…ç½®
receivers:
  # é»˜è®¤æ¥æ”¶è€…
  - name: 'default'
    email_configs:
      - to: 'team@example.com'
  
  # DBAå›¢é˜Ÿ
  - name: 'dba-team'
    email_configs:
      - to: 'dba@example.com'
        headers:
          Subject: '[DBA] {{ .GroupLabels.alertname }}'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/XXX'
        channel: '#dba-alerts'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
  
  # è¿ç»´å›¢é˜Ÿ
  - name: 'ops-team'
    email_configs:
      - to: 'ops@example.com'
    webhook_configs:
      - url: 'http://dingtalk-webhook/api/alert'
  
  # åç«¯å›¢é˜Ÿ
  - name: 'backend-team'
    email_configs:
      - to: 'backend@example.com'
    wechat_configs:
      - corp_id: 'ww1234567890'
        api_secret: 'secret'
        to_user: '@all'
        agent_id: '1000001'
  
  # PagerDuty (å…³é”®å‘Šè­¦)
  - name: 'pagerduty'
    pagerduty_configs:
      - service_key: 'your-pagerduty-key'
```

### 6.3.3 å‘Šè­¦æ¨¡æ¿

**åˆ›å»ºæ¨¡æ¿æ–‡ä»¶** (`/etc/alertmanager/templates/email.tmpl`):

```
{{ define "email.default.subject" }}
[{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .GroupLabels.SortedPairs.Values | join " " }}
{{ end }}

{{ define "email.default.html" }}
<!DOCTYPE html>
<html>
<head>
<style>
  table { border-collapse: collapse; width: 100%; }
  th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
  th { background-color: #f2f2f2; }
  .firing { background-color: #ffcccc; }
  .resolved { background-color: #ccffcc; }
</style>
</head>
<body>
<h2>å‘Šè­¦é€šçŸ¥</h2>

<h3>å‘Šè­¦çŠ¶æ€: {{ .Status }}</h3>
<p>åˆ†ç»„: {{ .GroupLabels.SortedPairs }}</p>

{{ if gt (len .Alerts.Firing) 0 }}
<h3>ğŸ”¥ è§¦å‘ä¸­çš„å‘Šè­¦ ({{ .Alerts.Firing | len }})</h3>
<table>
  <tr>
    <th>å‘Šè­¦åç§°</th>
    <th>å®ä¾‹</th>
    <th>ä¸¥é‡ç¨‹åº¦</th>
    <th>æ‘˜è¦</th>
    <th>è§¦å‘æ—¶é—´</th>
  </tr>
  {{ range .Alerts.Firing }}
  <tr class="firing">
    <td>{{ .Labels.alertname }}</td>
    <td>{{ .Labels.instance }}</td>
    <td>{{ .Labels.severity }}</td>
    <td>{{ .Annotations.summary }}</td>
    <td>{{ .StartsAt.Format "2006-01-02 15:04:05" }}</td>
  </tr>
  {{ end }}
</table>
{{ end }}

{{ if gt (len .Alerts.Resolved) 0 }}
<h3>âœ… å·²æ¢å¤çš„å‘Šè­¦ ({{ .Alerts.Resolved | len }})</h3>
<table>
  <tr>
    <th>å‘Šè­¦åç§°</th>
    <th>å®ä¾‹</th>
    <th>æ¢å¤æ—¶é—´</th>
  </tr>
  {{ range .Alerts.Resolved }}
  <tr class="resolved">
    <td>{{ .Labels.alertname }}</td>
    <td>{{ .Labels.instance }}</td>
    <td>{{ .EndsAt.Format "2006-01-02 15:04:05" }}</td>
  </tr>
  {{ end }}
</table>
{{ end }}

<hr>
<p>Prometheus Alertmanager</p>
</body>
</html>
{{ end }}
```

---

## 6.4 é€šçŸ¥æ¸ é“é…ç½®

### 6.4.1 Emailé€šçŸ¥

```yaml
receivers:
  - name: 'email-team'
    email_configs:
      - to: 'team@example.com'
        from: 'alerts@example.com'
        smarthost: 'smtp.gmail.com:587'
        auth_username: 'alerts@example.com'
        auth_password: 'password'
        require_tls: true
        headers:
          Subject: '{{ template "email.default.subject" . }}'
        html: '{{ template "email.default.html" . }}'
```

### 6.4.2 Slacké€šçŸ¥

```yaml
receivers:
  - name: 'slack-team'
    slack_configs:
      - api_url: 'https://hooks.slack.com/services/T00000000/B00000000/XXXXXXXXXXXXXXXXXXXXXXXX'
        channel: '#alerts'
        username: 'Prometheus'
        icon_emoji: ':prometheus:'
        title: '{{ .GroupLabels.alertname }}'
        title_link: 'http://prometheus.example.com'
        text: |
          {{ range .Alerts }}
          *ä¸¥é‡ç¨‹åº¦:* `{{ .Labels.severity }}`
          *æ‘˜è¦:* {{ .Annotations.summary }}
          *æè¿°:* {{ .Annotations.description }}
          {{ end }}
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
        send_resolved: true
```

### 6.4.3 é’‰é’‰é€šçŸ¥

é’‰é’‰éœ€è¦ä½¿ç”¨Webhook,éœ€è¦ä¸­é—´è½¬æ¢å™¨ã€‚

**é’‰é’‰Webhookè½¬æ¢å™¨** (Python):

```python
#!/usr/bin/env python3
"""
Alertmanageré’‰é’‰Webhookè½¬æ¢å™¨
"""

from flask import Flask, request
import requests
import json

app = Flask(__name__)

DINGTALK_WEBHOOK = "https://oapi.dingtalk.com/robot/send?access_token=YOUR_TOKEN"

@app.route('/api/alert', methods=['POST'])
def dingtalk_alert():
    data = request.json
    
    # æ„é€ é’‰é’‰æ¶ˆæ¯
    alerts = data.get('alerts', [])
    status = data.get('status', 'unknown')
    
    if status == 'firing':
        title = f"ğŸ”¥ å‘Šè­¦è§¦å‘ ({len(alerts)}æ¡)"
        color = "#FF0000"
    else:
        title = f"âœ… å‘Šè­¦æ¢å¤ ({len(alerts)}æ¡)"
        color = "#00FF00"
    
    text = f"### {title}\n\n"
    
    for alert in alerts:
        labels = alert.get('labels', {})
        annotations = alert.get('annotations', {})
        
        text += f"**å‘Šè­¦åç§°:** {labels.get('alertname', 'N/A')}\n\n"
        text += f"**å®ä¾‹:** {labels.get('instance', 'N/A')}\n\n"
        text += f"**ä¸¥é‡ç¨‹åº¦:** {labels.get('severity', 'N/A')}\n\n"
        text += f"**æ‘˜è¦:** {annotations.get('summary', 'N/A')}\n\n"
        text += f"**æè¿°:** {annotations.get('description', 'N/A')}\n\n"
        text += "---\n\n"
    
    # å‘é€åˆ°é’‰é’‰
    payload = {
        "msgtype": "markdown",
        "markdown": {
            "title": title,
            "text": text
        }
    }
    
    requests.post(DINGTALK_WEBHOOK, json=payload)
    
    return "OK", 200

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

**Alertmanageré…ç½®**:

```yaml
receivers:
  - name: 'dingtalk'
    webhook_configs:
      - url: 'http://localhost:5000/api/alert'
        send_resolved: true
```

### 6.4.4 ä¼ä¸šå¾®ä¿¡é€šçŸ¥

```yaml
receivers:
  - name: 'wechat-team'
    wechat_configs:
      - corp_id: 'ww1234567890abcdef'
        api_secret: 'your-api-secret'
        to_user: '@all'  # æˆ–æŒ‡å®šç”¨æˆ·ID
        agent_id: '1000001'
        api_url: 'https://qyapi.weixin.qq.com/cgi-bin/'
        message: |
          {{ range .Alerts }}
          å‘Šè­¦: {{ .Labels.alertname }}
          å®ä¾‹: {{ .Labels.instance }}
          çº§åˆ«: {{ .Labels.severity }}
          æ‘˜è¦: {{ .Annotations.summary }}
          {{ end }}
        send_resolved: true
```

---

## 6.5 å‘Šè­¦è·¯ç”±ç­–ç•¥

### 6.5.1 åŸºäºæ ‡ç­¾çš„è·¯ç”±

```yaml
route:
  receiver: 'default'
  group_by: ['alertname']
  
  routes:
    # criticalçº§åˆ« -> 24x7å€¼ç­
    - match:
        severity: critical
      receiver: 'oncall'
      group_wait: 0s
      group_interval: 1m
      repeat_interval: 1h
    
    # warningçº§åˆ« -> å·¥ä½œæ—¶é—´é€šçŸ¥
    - match:
        severity: warning
      receiver: 'work-hours'
      group_wait: 5m
      group_interval: 10m
      repeat_interval: 4h
    
    # infoçº§åˆ« -> ä»…è®°å½•
    - match:
        severity: info
      receiver: 'logger'
      group_interval: 1h
      repeat_interval: 24h
```

### 6.5.2 åŸºäºæ—¶é—´çš„è·¯ç”±

```yaml
route:
  receiver: 'default'
  
  routes:
    # å·¥ä½œæ—¥ç™½å¤© -> Slack
    - match:
        severity: warning
      receiver: 'slack'
      active_time_intervals:
        - weekdays_daytime
    
    # éå·¥ä½œæ—¶é—´ -> Email
    - match:
        severity: warning
      receiver: 'email'
      active_time_intervals:
        - weekends
        - weekdays_night

# æ—¶é—´åŒºé—´å®šä¹‰
time_intervals:
  - name: weekdays_daytime
    time_intervals:
      - times:
          - start_time: '09:00'
            end_time: '18:00'
        weekdays: ['monday:friday']
  
  - name: weekdays_night
    time_intervals:
      - times:
          - start_time: '18:00'
            end_time: '09:00'
        weekdays: ['monday:friday']
  
  - name: weekends
    time_intervals:
      - weekdays: ['saturday', 'sunday']
```

### 6.5.3 å¤šçº§è·¯ç”±

```yaml
route:
  receiver: 'default'
  group_by: ['cluster', 'alertname']
  
  routes:
    # ç”Ÿäº§ç¯å¢ƒ
    - match:
        env: production
      receiver: 'prod-team'
      group_wait: 10s
      
      routes:
        # ç”Ÿäº§ç¯å¢ƒcritical -> ç«‹å³é€šçŸ¥
        - match:
            severity: critical
          receiver: 'prod-oncall'
          group_wait: 0s
        
        # ç”Ÿäº§ç¯å¢ƒwarning -> å»¶è¿Ÿé€šçŸ¥
        - match:
            severity: warning
          receiver: 'prod-team'
          group_wait: 5m
    
    # æµ‹è¯•ç¯å¢ƒ -> ä½ä¼˜å…ˆçº§
    - match:
        env: testing
      receiver: 'test-team'
      group_wait: 10m
      repeat_interval: 24h
```

---

## 6.6 å‘Šè­¦æŠ‘åˆ¶ä¸é™é»˜

### 6.6.1 å‘Šè­¦æŠ‘åˆ¶ (Inhibition)

æŠ‘åˆ¶è§„åˆ™ç”¨äºåœ¨æŸä¸ªå‘Šè­¦è§¦å‘æ—¶,è‡ªåŠ¨æŠ‘åˆ¶å…¶ä»–ç›¸å…³å‘Šè­¦ã€‚

```yaml
inhibit_rules:
  # èŠ‚ç‚¹å®•æœºæ—¶,æŠ‘åˆ¶è¯¥èŠ‚ç‚¹çš„æ‰€æœ‰å‘Šè­¦
  - source_match:
      alertname: 'NodeDown'
    target_match_re:
      alertname: '.*'
    equal: ['instance']
  
  # æœåŠ¡å®Œå…¨å®•æœºæ—¶,æŠ‘åˆ¶æ€§èƒ½å‘Šè­¦
  - source_match:
      alertname: 'ServiceDown'
    target_match_re:
      alertname: '(HighLatency|HighErrorRate|HighCpuUsage)'
    equal: ['instance', 'job']
  
  # ç£ç›˜ç©ºé—´ä¸¥é‡ä¸è¶³æ—¶,æŠ‘åˆ¶é¢„æµ‹å‘Šè­¦
  - source_match:
      alertname: 'DiskSpaceCritical'
      severity: critical
    target_match:
      alertname: 'DiskWillFillIn4Hours'
    equal: ['instance', 'mountpoint']
```

### 6.6.2 å‘Šè­¦é™é»˜ (Silence)

é™é»˜ç”¨äºä¸´æ—¶å±è”½å‘Šè­¦,å¸¸ç”¨äºç»´æŠ¤çª—å£ã€‚

**é€šè¿‡Web UIåˆ›å»ºé™é»˜**:
1. è®¿é—® http://alertmanager:9093
2. ç‚¹å‡»"Silences"
3. ç‚¹å‡»"New Silence"
4. é…ç½®åŒ¹é…å™¨å’ŒæŒç»­æ—¶é—´

**é€šè¿‡amtool CLIåˆ›å»ºé™é»˜**:

```bash
# å®‰è£…amtool
go install github.com/prometheus/alertmanager/cmd/amtool@latest

# é™é»˜ç‰¹å®šå‘Šè­¦
amtool silence add \
  alertname=HighCpuUsage \
  instance=web-01:9100 \
  --duration=2h \
  --author="ops@example.com" \
  --comment="è®¡åˆ’ç»´æŠ¤"

# é™é»˜æ•´ä¸ªèŠ‚ç‚¹
amtool silence add \
  instance=web-01:9100 \
  --duration=4h \
  --comment="æœåŠ¡å™¨ç»´æŠ¤"

# æŸ¥çœ‹æ‰€æœ‰é™é»˜
amtool silence query

# åˆ é™¤é™é»˜
amtool silence expire <silence_id>
```

**é€šè¿‡APIåˆ›å»ºé™é»˜**:

```bash
curl -X POST http://alertmanager:9093/api/v2/silences \
  -H 'Content-Type: application/json' \
  -d '{
    "matchers": [
      {
        "name": "alertname",
        "value": "HighCpuUsage",
        "isRegex": false
      },
      {
        "name": "instance",
        "value": "web-01:9100",
        "isRegex": false
      }
    ],
    "startsAt": "2024-01-01T00:00:00Z",
    "endsAt": "2024-01-01T04:00:00Z",
    "createdBy": "ops@example.com",
    "comment": "è®¡åˆ’ç»´æŠ¤"
  }'
```

---

## 6.7 å‘Šè­¦æœ€ä½³å®è·µ

### 6.7.1 å‘Šè­¦å‘½åè§„èŒƒ

```
âœ… å¥½çš„å‘½å:
- NodeDown
- HighCpuUsage
- DiskSpaceLow
- ServiceLatencyHigh

âŒ å·®çš„å‘½å:
- alert1
- node_problem
- check_cpu
```

### 6.7.2 å‘Šè­¦çº§åˆ«å®šä¹‰

| çº§åˆ« | å«ä¹‰ | å“åº”æ—¶é—´ | ç¤ºä¾‹ |
|------|------|---------|------|
| **critical** | ä¸¥é‡å½±å“ä¸šåŠ¡,éœ€è¦ç«‹å³å¤„ç† | ç«‹å³ | æœåŠ¡å®•æœºã€æ•°æ®ä¸¢å¤± |
| **warning** | å¯èƒ½å½±å“ä¸šåŠ¡,éœ€è¦å…³æ³¨ | å·¥ä½œæ—¶é—´å†… | CPUé«˜ã€å†…å­˜é«˜ |
| **info** | ä¿¡æ¯æ€§å‘Šè­¦,æ— éœ€ç«‹å³å¤„ç† | å¯å¿½ç•¥ | è¯ä¹¦å³å°†è¿‡æœŸ(30å¤©) |

### 6.7.3 å‘Šè­¦æè¿°æœ€ä½³å®è·µ

```yaml
annotations:
  # âœ… å¥½çš„æè¿°
  summary: "èŠ‚ç‚¹{{ $labels.instance }}CPUä½¿ç”¨ç‡ä¸º{{ $value | humanize }}%"
  description: |
    èŠ‚ç‚¹{{ $labels.instance }}çš„CPUä½¿ç”¨ç‡å·²è¶…è¿‡80%é˜ˆå€¼,å½“å‰å€¼ä¸º{{ $value | humanize }}%ã€‚
    
    å¯èƒ½åŸå› :
    1. åº”ç”¨è´Ÿè½½å¢åŠ 
    2. åå°ä»»åŠ¡å ç”¨
    3. ç—…æ¯’æˆ–æ¶æ„è¿›ç¨‹
    
    æ’æŸ¥æ­¥éª¤:
    1. ç™»å½•æœåŠ¡å™¨æŸ¥çœ‹topå‘½ä»¤
    2. æ£€æŸ¥åº”ç”¨æ—¥å¿—
    3. æŸ¥çœ‹å®šæ—¶ä»»åŠ¡
    
    Runbook: https://wiki.example.com/runbook/high-cpu

  # âŒ å·®çš„æè¿°
  summary: "CPUé«˜"
  description: "CPUä½¿ç”¨ç‡è¿‡é«˜"
```

### 6.7.4 é¿å…å‘Šè­¦ç–²åŠ³

**é—®é¢˜**: å‘Šè­¦å¤ªå¤šå¯¼è‡´éº»æœ¨

**è§£å†³æ–¹æ¡ˆ**:

1. **åˆç†è®¾ç½®é˜ˆå€¼**:
```yaml
# âŒ è¿‡äºæ•æ„Ÿ
expr: node_cpu_usage > 50
for: 1m

# âœ… åˆç†è®¾ç½®
expr: node_cpu_usage > 80
for: 5m
```

2. **ä½¿ç”¨`for`å­å¥é¿å…æŠ–åŠ¨**:
```yaml
# âœ… æŒç»­5åˆ†é’Ÿæ‰å‘Šè­¦
expr: http_requests_total{status="500"} > 100
for: 5m
```

3. **åˆç†åˆ†ç»„**:
```yaml
group_by: ['alertname', 'cluster']
group_wait: 30s
group_interval: 5m
```

4. **è®¾ç½®åˆç†çš„é‡å¤é—´éš”**:
```yaml
repeat_interval: 4h  # ä¸è¦å¤ªé¢‘ç¹
```

### 6.7.5 å‘Šè­¦è¦†ç›–ç‡

ä½¿ç”¨"å››ä¸ªé»„é‡‘ä¿¡å·"(Google SRE):

1. **å»¶è¿Ÿ** (Latency):
```yaml
- alert: HighLatency
  expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
```

2. **æµé‡** (Traffic):
```yaml
- alert: LowTraffic
  expr: sum(rate(http_requests_total[5m])) < 10
```

3. **é”™è¯¯** (Errors):
```yaml
- alert: HighErrorRate
  expr: sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) > 0.05
```

4. **é¥±å’Œåº¦** (Saturation):
```yaml
- alert: HighCpuSaturation
  expr: instance:node_cpu:ratio > 0.8
```

---

## 6.8 å®éªŒç»ƒä¹ 

å®éªŒç¯å¢ƒä½äº`code/chapter06/`ç›®å½•ã€‚

### å®éªŒ1: ç¼–å†™åŸºç¡€å‘Šè­¦è§„åˆ™
1. åˆ›å»ºèŠ‚ç‚¹ç›‘æ§å‘Šè­¦
2. æµ‹è¯•å‘Šè­¦è§¦å‘
3. éªŒè¯å‘Šè­¦æ¢å¤

### å®éªŒ2: é…ç½®Alertmanager
1. éƒ¨ç½²Alertmanager
2. é…ç½®Emailé€šçŸ¥
3. æµ‹è¯•å‘Šè­¦å‘é€

### å®éªŒ3: å‘Šè­¦è·¯ç”±å®æˆ˜
1. é…ç½®å¤šçº§è·¯ç”±
2. æµ‹è¯•ä¸åŒä¸¥é‡çº§åˆ«çš„å‘Šè­¦
3. éªŒè¯è·¯ç”±åˆ†å‘

---

## 6.9 æœ¬ç« å°ç»“

### æ ¸å¿ƒçŸ¥è¯†ç‚¹

âœ… **å‘Šè­¦è§„åˆ™**: exprã€forã€labelsã€annotations

âœ… **Alertmanager**: è·¯ç”±ã€åˆ†ç»„ã€æŠ‘åˆ¶ã€é™é»˜

âœ… **é€šçŸ¥æ¸ é“**: Emailã€Slackã€é’‰é’‰ã€ä¼ä¸šå¾®ä¿¡

âœ… **è·¯ç”±ç­–ç•¥**: åŸºäºæ ‡ç­¾ã€åŸºäºæ—¶é—´ã€å¤šçº§è·¯ç”±

âœ… **æœ€ä½³å®è·µ**: åˆç†é˜ˆå€¼ã€é¿å…å‘Šè­¦ç–²åŠ³ã€å®Œå–„æè¿°

### ä¸‹ä¸€ç« é¢„å‘Š

**ç¬¬7ç«  - Recording Rulesè®°å½•è§„åˆ™**,å°†å­¦ä¹ :
- ğŸ“Š Recording RulesåŸç†
- âš¡ é¢„èšåˆæŸ¥è¯¢ä¼˜åŒ–
- ğŸ¯ æœ€ä½³å®è·µå’Œè®¾è®¡æ¨¡å¼

---

**ğŸ‰ æ­å–œ!** ä½ å·²ç»æŒæ¡äº†Prometheuså‘Šè­¦ç³»ç»Ÿçš„æ ¸å¿ƒèƒ½åŠ›!
