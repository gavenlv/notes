# 2.3 Loki数据模型详解

## 🎯 学习目标

在本章中，我们将学习：

- 理解Loki的数据模型核心概念
- 掌握日志流和标签的机制
- 了解Loki的存储和索引结构
- 学习不同的数据模式及其应用场景
- 理解数据生命周期和保留策略

## 🏗️ 数据模型概述

### 核心概念

Loki的数据模型基于以下几个核心概念：

1. **日志流(Log Stream)**: 具有相同标签集的日志条目序列
2. **标签(Labels)**: 描述日志元数据的键值对
3. **日志条目(Log Entry)**: 包含时间戳和日志内容的记录
4. **块(Chunk)**: 压缩存储的日志数据单元
5. **索引(Index)**: 加速标签查询的数据结构

### 数据层级结构

```
租户(Tenant)
  └── 日志流(Log Stream)
      ├── 标签集(Label Set)
      └── 日志块(Chunk)
          └── 日志条目(Log Entry)
              ├── 时间戳(Timestamp)
              └── 日志内容(Line)
```

## 📊 日志流详解

### 什么是日志流？

日志流是具有相同标签集的日志条目序列。在Loki中，每个日志流由唯一的标签集标识。

### 日志流示例

```
流1: {job="nginx", instance="host1", filename="/var/log/nginx/access.log"}
流2: {job="nginx", instance="host2", filename="/var/log/nginx/access.log"}
流3: {job="mysql", instance="db1", filename="/var/log/mysql/error.log"}
```

### 日志流标识

每个日志流由一个唯一的哈希值标识，基于标签集计算：

```
标签集 → SHA256哈希 → 流标识符
```

### 日志流数量影响

日志流数量对系统性能有重要影响：

| 流数量 | 影响程度 | 优化建议 |
|--------|----------|----------|
| < 10,000 | 低 | 正常操作 |
| 10,000-100,000 | 中 | 需要优化标签基数 |
| > 100,000 | 高 | 需要大幅减少标签基数 |

## 🏷️ 标签系统详解

### 标签类型

#### 静态标签

由Promtail在日志收集时添加，通常不变：

```yaml
static_configs:
  - targets:
      - localhost
    labels:
      job: nginx
      instance: host1
      environment: production
```

#### 动态标签

从日志内容中提取，可能随时间变化：

```yaml
pipeline_stages:
  - regex:
      expression: '(?P<level>\w+): (?P<message>.*)'
  - labels:
      level:
```

### 标签命名规范

#### 推荐规范

- 使用小写字母和连字符
- 避免特殊字符和空格
- 使用有意义的名称
- 保持一致的命名约定

```yaml
# 推荐
job: "nginx"
instance: "host1"
environment: "production"

# 不推荐
Job: "Nginx"
instance_name: "host-1"
env: "prod"
```

### 标签限制

#### Loki限制

- **最大标签数**: 默认30个（可配置）
- **标签名长度**: 最大255字节
- **标签值长度**: 最大2048字节
- **特殊字符**: 不能包含`{}`, `[ ]`, `,`等

#### 配置调整

```yaml
limits_config:
  max_label_names_per_series: 50
  max_label_value_length: 4096
```

### 标签优化策略

#### 减少标签基数

高基数标签会显著增加资源消耗：

```yaml
# 高基数（避免）
{request_id="a1b2c3d4-e5f6-7890-1234-567890abcdef"}
{user_id="12345"}
{session_id="abcdef-123456-7890"}

# 低基数（推荐）
{request_id_hash="a1b2c"}
{user_authenticated="true"}
{session_active="true"}
```

#### 标签聚合

将相关信息组合到单个标签：

```yaml
# 多个小标签
{level="info"}
{component="auth"}
{service="api"}

# 聚合标签
{log_source="api:auth:info"}
```

## 📦 日志块详解

### 块结构

日志块是Loki的基本存储单元：

```
块结构:
├── 元数据
│   ├── 标签集
│   ├── 时间范围
│   └── 压缩格式
└── 日志条目
    ├── 条目1 (时间戳 + 内容)
    ├── 条目2 (时间戳 + 内容)
    └── ...
```

### 块生命周期

1. **创建**: 新日志流到达时创建
2. **追加**: 新日志条目追加到块
3. **刷新**: 满足条件时写入存储
4. **压缩**: 定期合并和优化
5. **清理**: 超过保留期时删除

### 块刷新条件

```yaml
ingester:
  chunk_idle_period: 1h       # 空闲时间
  max_chunk_age: 2h           # 最大年龄
  chunk_target_size: 1048576   # 目标大小(1MB)
  chunk_retain_period: 30s    # 内存保留时间
```

### 块压缩

#### 压缩算法

- **Gzip**: 平衡压缩率和速度
- **Snappy**: 高速度，中等压缩率
- **LZ4**: 极高速度，低压缩率

```yaml
chunk_store_config:
  chunk_cache_config:
    memcached:
      expiration: 1h
      max_idle_timeout: 10s
      max_item_size: 1m
```

## 🗂️ 索引结构详解

### 索引类型

#### 主索引

基于标签和时间的主索引结构：

```
租户 → 时间范围 → 标签名 → 标签值 → 块引用
```

#### 倒排索引

支持多标签查询的倒排索引：

```
标签值 → 流ID列表
```

### 索引存储

#### 表结构

```
index/
├── <period>/
│   ├── <table_name>/
│   │   ├── <hash>/
│   │   │   ├── index.gz
│   │   │   └── index.gz.crc
```

#### 表类型

- **bloom-index**: 布隆过滤器索引
- **series-index**: 日志流索引
- **deletion-mapper**: 删除标记映射

### 索引优化

#### 分片策略

```yaml
schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: s3
      schema: v11
      index:
        prefix: index_
        period: 24h           # 索引分片周期
```

#### 压缩策略

```yaml
compactor:
  retention_enabled: true
  retention_delete_delay: 2h
  delete_request_cancel_period: 24h
  retention_delete_worker_count: 150
```

## 📈 数据模式详解

### V11模式

当前推荐的数据模式，支持：

- 高效的标签查询
- 增量压缩
- 多租户隔离

```yaml
schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: s3
      schema: v11
      index:
        prefix: index_
        period: 24h
```

### 存储后端配置

#### 本地存储

```yaml
storage_config:
  boltdb_shipper:
    active_index_directory: /loki/boltdb-shipper-active
    cache_location: /loki/boltdb-shipper-cache
    shared_store: filesystem
  filesystem:
    directory: /loki/chunks
```

#### 云存储

```yaml
storage_config:
  boltdb_shipper:
    active_index_directory: /loki/boltdb-shipper-active
    cache_location: /loki/boltdb-shipper-cache
    shared_store: s3
  s3:
    s3: null
    endpoint: s3.amazonaws.com
    bucket_name: loki-chunks
    access_key_id: your_access_key
    secret_access_key: your_secret_key
```

## 🔄 数据生命周期

### 数据流向

```
应用程序 → Promtail → Distributor → Ingester → 存储后端
                                        ↓
                                   索引创建
                                        ↓
                                   查询优化
```

### 数据保留策略

#### 时间保留

```yaml
limits_config:
  retention_period: 30d         # 全局保留期
  per_tenant_override_config:
    "tenant1": "15d"            # 租户特定保留期
    "tenant2": "60d"
```

#### 大小限制

```yaml
limits_config:
  max_global_bytes_per_user: 50GB  # 每租户最大存储
  ingestion_rate_mb: 100             # 每租户最大摄入率
```

### 数据压缩

#### 自动压缩

```yaml
compactor:
  compaction_interval: 1h        # 压缩间隔
  max_compaction_parallelism: 2   # 并行压缩数
  sandbag_memory_limit: 4GB      # 内存限制
```

#### 手动压缩

```bash
# 触发压缩
curl -X POST http://localhost:3100/loki/api/v1/compaction/plan
```

## 🧪 实验：数据模型分析

让我们通过实验分析Loki的数据模型：

1. 创建不同类型的日志流
2. 分析标签基数对性能的影响
3. 观察块的生命周期
4. 测试索引效率

**实验代码和配置：**

见[code/experiments/data-model-analysis.sh](../code/chapter2/data-model-analysis.sh)

### 实验步骤

1. **创建高基数日志**:

```bash
# 生成高基数日志
for i in {1..10000}; do
  echo "2023-10-01T10:00:00.000Z [INFO] Request ID: $(uuidgen)" >> high-cardinality.log
done
```

2. **创建低基数日志**:

```bash
# 生成低基数日志
for i in {1..10000}; do
  echo "2023-10-01T10:00:00.000Z [INFO] Request processed" >> low-cardinality.log
done
```

3. **性能对比**:

```bash
# 测试高基数查询
time curl -G -s "http://localhost:3100/loki/api/v1/query_range" \
  --data-urlencode 'query={job="high-cardinality"}' \
  --data-urlencode 'start=2023-10-01T09:00:00.000Z' \
  --data-urlencode 'end=2023-10-01T11:00:00.000Z' \
  --data-urlencode 'step=30s'

# 测试低基数查询
time curl -G -s "http://localhost:3100/loki/api/v1/query_range" \
  --data-urlencode 'query={job="low-cardinality"}' \
  --data-urlencode 'start=2023-10-01T09:00:00.000Z' \
  --data-urlencode 'end=2023-10-01T11:00:00.000Z' \
  --data-urlencode 'step=30s'
```

## 📝 本章小结

在本章中，我们深入学习了：

- Loki数据模型的核心概念和结构
- 日志流和标签系统的详细机制
- 日志块和索引的组织方式
- 不同数据模式的特点和应用
- 数据生命周期和保留策略

理解Loki的数据模型有助于优化日志收集和查询性能，减少资源消耗。在下一章[3.1 日志收集](../chapter3/3.1-log-collection.md)中，我们将学习如何使用Promtail和Fluent Bit收集日志。

## 🤔 思考题

1. 为什么高基数标签会影响Loki的性能？
2. 在什么情况下应该调整块的刷新条件？
3. 索引分片周期对系统性能有什么影响？

## 📚 延伸阅读

- [Loki数据模型文档](https://grafana.com/docs/loki/latest/fundamentals/data_model/)
- [Loki存储文档](https://grafana.com/docs/loki/latest/configure/storage/)
- [日志数据最佳实践](https://grafana.com/docs/loki/latest/best-practices/)