# 第13章：微服务架构中的消息模式

## 概述

微服务架构通过消息驱动的方式实现服务间的解耦、异步通信和事件驱动的业务逻辑。本章深入探讨RabbitMQ在微服务架构中的核心消息模式，包括请求-响应、发布-订阅、事件溯源、CQRS、 Saga事务等高级模式，以及如何构建可扩展、高可靠的消息驱动微服务系统。

## 目录

1. [微服务架构基础](#1-微服务架构基础)
2. [核心消息模式](#2-核心消息模式)
3. [异步通信模式](#3-异步通信模式)
4. [事件驱动架构](#4-事件驱动架构)
5. [Saga事务模式](#5-saga事务模式)
6. [消息路由与分发](#6-消息路由与分发)
7. [服务发现与配置](#7-服务发现与配置)
8. [故障处理与重试机制](#8-故障处理与重试机制)
9. [性能优化与扩展](#9-性能优化与扩展)
10. [实战案例：电商系统](#10-实战案例电商系统)

## 1. 微服务架构基础

### 1.1 微服务特征

微服务架构是一种将单体应用分解为一组小型服务的架构风格，每个服务：

- **独立部署**：每个服务可以独立部署、升级和回滚
- **独立扩展**：根据负载需求独立扩展特定服务
- **故障隔离**：单个服务故障不会影响整个系统
- **技术栈多样性**：不同服务可以使用不同技术栈
- **数据自治**：每个服务管理自己的数据

### 1.2 消息驱动的优势

**解耦**：
- 服务间通过消息进行通信，降低直接依赖
- 服务可以独立演进，不影响其他服务

**异步处理**：
- 提高系统响应性
- 提升资源利用率
- 支持长时间运行的任务

**可靠性**：
- 消息持久化确保数据不丢失
- 消息确认机制保证可靠传输
- 支持死信队列处理失败消息

**扩展性**：
- 负载均衡和自动扩展
- 支持流处理和实时分析
- 独立扩展消息处理能力

### 1.3 消息模式分类

**点对点模式**：
- 一个生产者对应一个消费者
- 消息只能被消费一次
- 适用于请求-响应场景

**发布-订阅模式**：
- 一个生产者对应多个消费者
- 消息可以被多个消费者接收
- 适用于事件广播场景

**路由模式**：
- 根据消息内容路由到不同队列
- 支持动态路由决策
- 适用于复杂的消息分发需求

## 2. 核心消息模式

### 2.1 请求-响应模式

**模式特点**：
- 同步通信方式
- 生产者等待消费者响应
- 适用于实时性要求较高的场景

**实现方式**：

```python
import asyncio
import pika
import uuid
import json
from typing import Callable, Optional
from datetime import datetime

class RequestResponseClient:
    """请求-响应客户端"""
    
    def __init__(self, connection_params, service_name: str):
        self.connection_params = connection_params
        self.service_name = service_name
        self.reply_to_queue = f"rpc_reply_{service_name}_{uuid.uuid4().hex[:8]}"
        self.correlation_id_to_response = {}
        self.connection = None
        self.channel = None
        self.callback_queue = None
        
    async def connect(self):
        """建立连接"""
        self.connection = pika.BlockingConnection(self.connection_params)
        self.channel = self.connection.channel()
        
        # 声明回调队列
        result = self.channel.queue_declare(queue=self.reply_to_queue, exclusive=True)
        self.callback_queue = result.method.queue
        
        # 设置消费者回调
        self.channel.basic_consume(
            queue=self.callback_queue,
            on_message_callback=self.on_response,
            auto_ack=True
        )
        
        # 启动消费者线程
        self.channel.start_consuming()
    
    def on_response(self, ch, method, props, body):
        """响应回调处理"""
        if props.correlation_id in self.correlation_id_to_response:
            self.correlation_id_to_response[props.correlation_id] = body
            ch.stop_consuming()
    
    async def call(self, method: str, params: dict, timeout: int = 30) -> dict:
        """发起RPC调用"""
        correlation_id = str(uuid.uuid4())
        self.correlation_id_to_response[correlation_id] = None
        
        properties = pika.BasicProperties(
            reply_to=self.reply_to_queue,
            correlation_id=correlation_id,
            content_type='application/json',
            delivery_mode=2  # 持久化
        )
        
        message = {
            "method": method,
            "params": params,
            "timestamp": datetime.utcnow().isoformat()
        }
        
        # 发送RPC请求
        self.channel.basic_publish(
            exchange='',
            routing_key=f"rpc_{self.service_name}",
            properties=properties,
            body=json.dumps(message)
        )
        
        # 等待响应
        timeout_count = 0
        while self.correlation_id_to_response[correlation_id] is None:
            self.connection.process_data_events(time_limit=1)
            timeout_count += 1
            if timeout_count > timeout:
                raise TimeoutError(f"RPC调用超时: {method}")
        
        response = self.correlation_id_to_response[correlation_id]
        del self.correlation_id_to_response[correlation_id]
        
        return json.loads(response)
```

**使用示例**：

```python
# 客户端使用
async def main():
    connection_params = pika.ConnectionParameters('localhost')
    client = RequestResponseClient(connection_params, "user_service")
    
    try:
        # 发起RPC调用
        response = await client.call("get_user_info", {"user_id": 12345})
        print(f"用户信息: {response}")
        
    except TimeoutError as e:
        print(f"调用失败: {e}")
    finally:
        client.close()

# 服务端处理
class RPCServer:
    def __init__(self, connection_params, service_name: str):
        self.connection_params = connection_params
        self.service_name = service_name
        self.service_methods = {}
        
    def register_method(self, method_name: str, method_func: Callable):
        """注册服务方法"""
        self.service_methods[method_name] = method_func
        
    async def start_server(self):
        """启动RPC服务器"""
        connection = pika.BlockingConnection(self.connection_params)
        channel = connection.channel()
        
        # 声明RPC队列
        channel.queue_declare(queue=f"rpc_{self.service_name}")
        
        # 设置消费者
        channel.basic_qos(prefetch_count=1)
        channel.basic_consume(
            queue=f"rpc_{self.service_name}",
            on_message_callback=self.on_request
        )
        
        print(f"RPC服务 {self.service_name} 已启动")
        channel.start_consuming()
    
    def on_request(self, ch, method, props, body):
        """处理RPC请求"""
        try:
            # 解析请求
            request = json.loads(body)
            method_name = request["method"]
            params = request["params"]
            
            # 调用服务方法
            if method_name in self.service_methods:
                result = self.service_methods[method_name](**params)
                response = {"status": "success", "data": result}
            else:
                response = {"status": "error", "message": f"方法不存在: {method_name}"}
                
        except Exception as e:
            response = {"status": "error", "message": str(e)}
        
        # 发送响应
        ch.basic_publish(
            exchange='',
            routing_key=props.reply_to,
            properties=pika.BasicProperties(
                correlation_id=props.correlation_id,
                content_type='application/json'
            ),
            body=json.dumps(response)
        )
        
        ch.basic_ack(delivery_tag=method.delivery_tag)
```

### 2.2 发布-订阅模式

**模式特点**：
- 多个订阅者接收相同消息
- 发布者和订阅者之间时间解耦
- 适用于事件广播和通知场景

**实现方式**：

```python
import asyncio
from enum import Enum
from dataclasses import dataclass
from typing import List, Dict, Callable, Any
import pika
import json

class EventType(Enum):
    """事件类型枚举"""
    USER_REGISTERED = "user.registered"
    USER_UPDATED = "user.updated"
    USER_DELETED = "user.deleted"
    ORDER_CREATED = "order.created"
    ORDER_PAID = "order.paid"
    ORDER_SHIPPED = "order.shipped"
    ORDER_DELIVERED = "order.delivered"

@dataclass
class Event:
    """事件数据类"""
    event_id: str
    event_type: EventType
    aggregate_id: str
    data: dict
    timestamp: datetime
    version: int
    metadata: dict = None

    def to_dict(self) -> dict:
        """转换为字典"""
        return {
            "event_id": self.event_id,
            "event_type": self.event_type.value,
            "aggregate_id": self.aggregate_id,
            "data": self.data,
            "timestamp": self.timestamp.isoformat(),
            "version": self.version,
            "metadata": self.metadata or {}
        }
    
    @classmethod
    def from_dict(cls, data: dict) -> 'Event':
        """从字典创建事件"""
        return cls(
            event_id=data["event_id"],
            event_type=EventType(data["event_type"]),
            aggregate_id=data["aggregate_id"],
            data=data["data"],
            timestamp=datetime.fromisoformat(data["timestamp"]),
            version=data["version"],
            metadata=data.get("metadata")
        )

class EventBus:
    """事件总线 - 发布-订阅模式实现"""
    
    def __init__(self, connection_params):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        self.subscribers: Dict[EventType, List[Callable]] = {}
        self.exchange_name = "event_bus"
        
    async def connect(self):
        """建立连接"""
        self.connection = pika.BlockingConnection(self.connection_params)
        self.channel = self.connection.channel()
        
        # 声明主题交换机
        self.channel.exchange_declare(
            exchange=self.exchange_name,
            exchange_type='topic',
            durable=True
        )
    
    def subscribe(self, event_type: EventType, callback: Callable):
        """订阅事件"""
        if event_type not in self.subscribers:
            self.subscribers[event_type] = []
        
        self.subscribers[event_type].append(callback)
        
        # 动态创建队列
        queue_name = f"event_queue_{callback.__name__}_{event_type.value}"
        self.channel.queue_declare(queue=queue_name, durable=True)
        
        # 绑定队列到交换机
        routing_key = event_type.value
        self.channel.queue_bind(
            exchange=self.exchange_name,
            queue=queue_name,
            routing_key=routing_key
        )
        
        # 设置消费者
        self.channel.basic_consume(
            queue=queue_name,
            on_message_callback=lambda ch, method, props, body: 
                self.on_event_received(ch, method, props, body, callback)
        )
    
    def on_event_received(self, ch, method, props, body, callback):
        """事件接收处理"""
        try:
            event_data = json.loads(body)
            event = Event.from_dict(event_data)
            
            # 调用订阅者回调
            callback(event)
            
            ch.basic_ack(delivery_tag=method.delivery_tag)
            
        except Exception as e:
            print(f"处理事件失败: {e}")
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
    
    def publish(self, event: Event):
        """发布事件"""
        routing_key = event.event_type.value
        
        self.channel.basic_publish(
            exchange=self.exchange_name,
            routing_key=routing_key,
            properties=pika.BasicProperties(
                delivery_mode=2,  # 持久化
                content_type='application/json'
            ),
            body=json.dumps(event.to_dict())
        )
    
    def start_consuming(self):
        """开始消费事件"""
        print("事件总线启动，等待事件...")
        self.channel.start_consuming()

class EventHandler:
    """事件处理器基类"""
    
    def __init__(self, event_bus: EventBus):
        self.event_bus = event_bus
        
    def handle_user_registered(self, event: Event):
        """处理用户注册事件"""
        user_data = event.data
        print(f"发送欢迎邮件给用户: {user_data['email']}")
        
    def handle_order_created(self, event: Event):
        """处理订单创建事件"""
        order_data = event.data
        print(f"通知库存服务准备商品: {order_data['items']}")
        
    def handle_order_paid(self, event: Event):
        """处理订单支付事件"""
        order_data = event.data
        print(f"通知仓库发货: 订单{order_data['order_id']}")
        
    def handle_order_shipped(self, event: Event):
        """处理订单发货事件"""
        order_data = event.data
        print(f"发送物流跟踪给客户: {order_data['tracking_number']}")

# 使用示例
async def main():
    connection_params = pika.ConnectionParameters('localhost')
    event_bus = EventBus(connection_params)
    await event_bus.connect()
    
    # 创建事件处理器
    handler = EventHandler(event_bus)
    
    # 订阅事件
    event_bus.subscribe(EventType.USER_REGISTERED, handler.handle_user_registered)
    event_bus.subscribe(EventType.ORDER_CREATED, handler.handle_order_created)
    event_bus.subscribe(EventType.ORDER_PAID, handler.handle_order_paid)
    event_bus.subscribe(EventType.ORDER_SHIPPED, handler.handle_order_shipped)
    
    # 发布测试事件
    events = [
        Event(
            event_id=str(uuid.uuid4()),
            event_type=EventType.USER_REGISTERED,
            aggregate_id="user_123",
            data={"email": "user@example.com", "name": "张三"},
            timestamp=datetime.utcnow(),
            version=1
        ),
        Event(
            event_id=str(uuid.uuid4()),
            event_type=EventType.ORDER_CREATED,
            aggregate_id="order_456",
            data={"order_id": "order_456", "items": ["item1", "item2"]},
            timestamp=datetime.utcnow(),
            version=1
        )
    ]
    
    for event in events:
        event_bus.publish(event)
    
    # 开始消费事件
    event_bus.start_consuming()
```

### 2.3 工作队列模式

**模式特点**：
- 多个消费者竞争消息
- 消息只能被消费一次
- 适用于任务处理场景

**实现方式**：

```python
class TaskQueue:
    """任务队列处理器"""
    
    def __init__(self, connection_params, queue_name: str, worker_count: int = 4):
        self.connection_params = connection_params
        self.queue_name = queue_name
        self.worker_count = worker_count
        self.connection = None
        self.channel = None
        self.task_handlers = {}
        
    async def connect(self):
        """建立连接"""
        self.connection = pika.BlockingConnection(self.connection_params)
        self.channel = self.connection.channel()
        
        # 声明持久化队列
        self.channel.queue_declare(
            queue=self.queue_name,
            durable=True,
            arguments={
                'x-message-ttl': 86400000,  # 24小时过期
                'x-dead-letter-exchange': 'dead_letter_exchange',
                'x-dead-letter-routing-key': f"dead_letter_{self.queue_name}"
            }
        )
    
    def register_task_handler(self, task_type: str, handler: Callable):
        """注册任务处理器"""
        self.task_handlers[task_type] = handler
    
    def start_workers(self):
        """启动工作进程"""
        print(f"启动 {self.worker_count} 个工作进程...")
        
        for worker_id in range(self.worker_count):
            thread = threading.Thread(
                target=self.worker_process,
                args=(f"worker_{worker_id}",)
            )
            thread.daemon = True
            thread.start()
    
    def worker_process(self, worker_id: str):
        """工作进程"""
        print(f"工作进程 {worker_id} 已启动")
        
        def callback(ch, method, properties, body):
            try:
                # 解析任务
                task_data = json.loads(body)
                task_type = task_data.get("type")
                task_params = task_data.get("params", {})
                
                # 查找处理器
                if task_type in self.task_handlers:
                    print(f"工作进程 {worker_id} 处理任务: {task_type}")
                    self.task_handlers[task_type](**task_params)
                    print(f"工作进程 {worker_id} 完成任务: {task_type}")
                    ch.basic_ack(delivery_tag=method.delivery_tag)
                else:
                    print(f"未知任务类型: {task_type}")
                    ch.basic_nack(
                        delivery_tag=method.delivery_tag,
                        requeue=False  # 丢弃消息
                    )
                    
            except Exception as e:
                print(f"工作进程 {worker_id} 处理任务失败: {e}")
                ch.basic_nack(
                    delivery_tag=method.delivery_tag,
                    requeue=True  # 重新入队
                )
        
        # 设置消费者
        self.channel.basic_qos(prefetch_count=1)
        self.channel.basic_consume(
            queue=self.queue_name,
            on_message_callback=callback
        )
        
        try:
            self.channel.start_consuming()
        except KeyboardInterrupt:
            self.channel.stop_consuming()
    
    def submit_task(self, task_type: str, params: dict, priority: int = 0):
        """提交任务"""
        task_data = {
            "type": task_type,
            "params": params,
            "timestamp": datetime.utcnow().isoformat(),
            "priority": priority
        }
        
        # 设置消息优先级
        properties = pika.BasicProperties(
            priority=priority,
            delivery_mode=2
        )
        
        self.channel.basic_publish(
            exchange='',
            routing_key=self.queue_name,
            properties=properties,
            body=json.dumps(task_data)
        )
        
        print(f"任务已提交: {task_type}")

# 使用示例
def send_email(email: str, subject: str, content: str):
    """发送邮件任务"""
    print(f"发送邮件: {email} - {subject}")
    time.sleep(2)  # 模拟邮件发送
    print("邮件发送完成")

def generate_report(report_type: str, params: dict):
    """生成报告任务"""
    print(f"生成报告: {report_type}")
    time.sleep(5)  # 模拟报告生成
    print("报告生成完成")

# 创建任务队列
async def main():
    connection_params = pika.ConnectionParameters('localhost')
    task_queue = TaskQueue(connection_params, "task_queue", 4)
    
    await task_queue.connect()
    
    # 注册任务处理器
    task_queue.register_task_handler("send_email", send_email)
    task_queue.register_task_handler("generate_report", generate_report)
    
    # 提交任务
    tasks = [
        {"type": "send_email", "params": {
            "email": "user1@example.com",
            "subject": "欢迎注册",
            "content": "欢迎加入我们的平台"
        }},
        {"type": "generate_report", "params": {
            "report_type": "daily_sales",
            "params": {"date": "2023-11-28"}
        }},
        {"type": "send_email", "params": {
            "email": "user2@example.com", 
            "subject": "订单确认",
            "content": "您的订单已确认"
        }}
    ]
    
    for task in tasks:
        task_queue.submit_task(
            task["type"], 
            task["params"],
            priority=task.get("priority", 0)
        )
    
    # 启动工作进程
    task_queue.start_workers()
```

## 3. 异步通信模式

### 3.1 异步调用模式

**特点**：
- 发起调用后立即返回future对象
- 通过回调或轮询获取结果
- 提高系统响应性

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
from typing import Optional, Callable, Any

class AsyncMessageClient:
    """异步消息客户端"""
    
    def __init__(self, connection_params, service_name: str):
        self.connection_params = connection_params
        self.service_name = service_name
        self.connection = None
        self.channel = None
        self.reply_queue = f"async_reply_{service_name}_{uuid.uuid4().hex[:8]}"
        self.pending_requests = {}
        self.executor = ThreadPoolExecutor(max_workers=10)
        
    async def connect(self):
        """异步连接"""
        self.connection = pika.BlockingConnection(self.connection_params)
        self.channel = self.connection.channel()
        
        # 声明回复队列
        self.channel.queue_declare(queue=self.reply_queue, exclusive=True)
        self.channel.basic_consume(
            queue=self.reply_queue,
            on_message_callback=self.on_response
        )
    
    def on_response(self, ch, method, props, body):
        """异步响应处理"""
        correlation_id = props.correlation_id
        if correlation_id in self.pending_requests:
            future = self.pending_requests[correlation_id]
            
            try:
                result = json.loads(body)
                future.set_result(result)
            except Exception as e:
                future.set_exception(e)
            
            del self.pending_requests[correlation_id]
    
    async def call_async(self, method: str, params: dict, 
                        timeout: int = 30) -> dict:
        """异步调用"""
        loop = asyncio.get_event_loop()
        correlation_id = str(uuid.uuid4())
        
        # 创建future
        future = loop.create_future()
        self.pending_requests[correlation_id] = future
        
        # 发送消息
        message = {
            "method": method,
            "params": params,
            "timestamp": datetime.utcnow().isoformat()
        }
        
        properties = pika.BasicProperties(
            reply_to=self.reply_queue,
            correlation_id=correlation_id,
            content_type='application/json'
        )
        
        self.channel.basic_publish(
            exchange='',
            routing_key=f"async_{self.service_name}",
            properties=properties,
            body=json.dumps(message)
        )
        
        try:
            # 等待结果
            result = await asyncio.wait_for(future, timeout=timeout)
            return result
        except asyncio.TimeoutError:
            del self.pending_requests[correlation_id]
            raise TimeoutError(f"异步调用超时: {method}")
        finally:
            if correlation_id in self.pending_requests:
                del self.pending_requests[correlation_id]
    
    async def call_batch(self, calls: list) -> list:
        """批量异步调用"""
        tasks = []
        for call in calls:
            task = self.call_async(
                call["method"],
                call["params"],
                call.get("timeout", 30)
            )
            tasks.append(task)
        
        return await asyncio.gather(*tasks, return_exceptions=True)

# 使用示例
async def main():
    client = AsyncMessageClient(pika.ConnectionParameters('localhost'), "user_service")
    await client.connect()
    
    # 单个异步调用
    try:
        result = await client.call_async("get_user_profile", {"user_id": 123})
        print(f"用户信息: {result}")
    except TimeoutError as e:
        print(f"调用超时: {e}")
    
    # 批量异步调用
    batch_calls = [
        {"method": "get_user_profile", "params": {"user_id": 123}},
        {"method": "get_user_orders", "params": {"user_id": 123}},
        {"method": "get_user_preferences", "params": {"user_id": 123}}
    ]
    
    results = await client.call_batch(batch_calls)
    for i, result in enumerate(results):
        if isinstance(result, Exception):
            print(f"调用 {i} 失败: {result}")
        else:
            print(f"调用 {i} 成功: {result}")
```

### 3.2 流式通信模式

**特点**：
- 支持大消息分块传输
- 实时数据流处理
- 适用于文件和音视频传输

```python
class StreamMessageHandler:
    """流式消息处理器"""
    
    def __init__(self, connection_params, chunk_size: int = 1024 * 1024):  # 1MB
        self.connection_params = connection_params
        self.chunk_size = chunk_size
        self.streams = {}  # stream_id -> StreamState
        
    async def start_stream(self, stream_id: str, metadata: dict):
        """开始流传输"""
        connection = pika.BlockingConnection(self.connection_params)
        channel = connection.channel()
        
        # 声明临时队列接收流数据
        queue_result = channel.queue_declare(queue='', exclusive=True)
        queue_name = queue_result.method.queue
        
        # 保存流状态
        self.streams[stream_id] = StreamState(
            stream_id=stream_id,
            channel=channel,
            queue_name=queue_name,
            received_chunks=[],
            expected_chunks=None,
            metadata=metadata
        )
        
        # 设置消费者
        channel.basic_consume(
            queue=queue_name,
            on_message_callback=lambda ch, method, props, body:
                self.on_chunk_received(ch, method, props, body, stream_id)
        )
        
        return queue_name
    
    def on_chunk_received(self, ch, method, props, body, stream_id):
        """处理接收到的数据块"""
        if stream_id not in self.streams:
            ch.basic_nack(delivery_tag=method.delivery_tag)
            return
        
        stream_state = self.streams[stream_id]
        
        try:
            chunk_data = json.loads(body)
            chunk_id = chunk_data["chunk_id"]
            data = chunk_data["data"]
            is_final = chunk_data["is_final"]
            
            if stream_state.expected_chunks is None:
                stream_state.expected_chunks = chunk_data["total_chunks"]
            
            # 检查数据块顺序
            if chunk_id == len(stream_state.received_chunks):
                stream_state.received_chunks.append(data)
                
                # 检查是否收到所有数据块
                if is_final or len(stream_state.received_chunks) >= stream_state.expected_chunks:
                    # 流传输完成
                    complete_data = b''.join(stream_state.received_chunks)
                    del self.streams[stream_id]
                    ch.basic_ack(delivery_tag=method.delivery_tag)
                    
                    # 触发完成回调
                    if stream_state.on_complete:
                        stream_state.on_complete(complete_data)
                else:
                    ch.basic_ack(delivery_tag=method.delivery_tag)
            else:
                # 数据块顺序错误，重新请求
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
                
        except Exception as e:
            print(f"处理流数据失败: {e}")
            ch.basic_nack(delivery_tag=method.delivery_tag)
    
    def send_file_stream(self, file_path: str, stream_id: str, 
                        target_queue: str, on_complete: Optional[Callable] = None):
        """发送文件流"""
        if stream_id not in self.streams:
            raise ValueError(f"流 {stream_id} 不存在")
        
        stream_state = self.streams[stream_id]
        stream_state.on_complete = on_complete
        
        with open(file_path, 'rb') as f:
            total_size = f.seek(0, 2)
            f.seek(0)
            
            chunk_id = 0
            while True:
                chunk_data = f.read(self.chunk_size)
                if not chunk_data:
                    break
                
                is_final = (f.tell() >= total_size)
                
                # 构建消息
                message = {
                    "stream_id": stream_id,
                    "chunk_id": chunk_id,
                    "data": chunk_data.hex(),  # 十六进制编码
                    "is_final": is_final,
                    "total_chunks": (total_size + self.chunk_size - 1) // self.chunk_size,
                    "metadata": stream_state.metadata
                }
                
                # 发送数据块
                stream_state.channel.basic_publish(
                    exchange='',
                    routing_key=target_queue,
                    properties=pika.BasicProperties(
                        delivery_mode=2
                    ),
                    body=json.dumps(message)
                )
                
                chunk_id += 1
        
        print(f"文件流传输完成: {stream_id}")

@dataclass
class StreamState:
    """流状态"""
    stream_id: str
    channel: Any
    queue_name: str
    received_chunks: List[bytes]
    expected_chunks: Optional[int] = None
    metadata: dict = None
    on_complete: Optional[Callable] = None

# 使用示例
async def main():
    handler = StreamMessageHandler(pika.ConnectionParameters('localhost'))
    
    # 启动流传输
    stream_id = "file_transfer_123"
    queue_name = await handler.start_stream(
        stream_id, 
        {"filename": "document.pdf", "size": 1048576}
    )
    
    # 发送文件流
    def on_transfer_complete(data):
        print(f"文件传输完成，大小: {len(data)} 字节")
        # 保存接收到的数据
        with open("received_file.pdf", "wb") as f:
            f.write(data)
    
    handler.send_file_stream(
        "document.pdf", 
        stream_id, 
        queue_name,
        on_transfer_complete
    )
    
    # 开始接收
    handler.streams[stream_id].channel.start_consuming()
```

## 4. 事件驱动架构

### 4.1 事件溯源模式

**核心概念**：
- 将状态变化记录为事件序列
- 通过重放事件重建当前状态
- 提供完整的历史追溯能力

```python
from abc import ABC, abstractmethod
from typing import List, Type
import uuid

class Event(ABC):
    """事件基类"""
    
    def __init__(self, aggregate_id: str, version: int, event_data: dict):
        self.event_id = str(uuid.uuid4())
        self.aggregate_id = aggregate_id
        self.version = version
        self.event_data = event_data
        self.timestamp = datetime.utcnow()
    
    @abstractmethod
    def get_event_type(self) -> str:
        pass
    
    def to_dict(self) -> dict:
        return {
            "event_id": self.event_id,
            "aggregate_id": self.aggregate_id,
            "version": self.version,
            "event_type": self.get_event_type(),
            "event_data": self.event_data,
            "timestamp": self.timestamp.isoformat()
        }

class UserRegisteredEvent(Event):
    """用户注册事件"""
    
    def get_event_type(self) -> str:
        return "UserRegistered"
    
    def __init__(self, aggregate_id: str, email: str, name: str):
        super().__init__(
            aggregate_id, 
            version=1,
            event_data={
                "email": email,
                "name": name
            }
        )

class UserUpdatedEvent(Event):
    """用户更新事件"""
    
    def __init__(self, aggregate_id: str, version: int, changes: dict):
        super().__init__(
            aggregate_id, 
            version=version,
            event_data=changes
        )
    
    def get_event_type(self) -> str:
        return "UserUpdated"

class OrderCreatedEvent(Event):
    """订单创建事件"""
    
    def __init__(self, aggregate_id: str, items: List[dict], total: float):
        super().__init__(
            aggregate_id,
            version=1,
            event_data={
                "items": items,
                "total": total,
                "status": "created"
            }
        )
    
    def get_event_type(self) -> str:
        return "OrderCreated"

class AggregateRoot:
    """聚合根基类"""
    
    def __init__(self, aggregate_id: str):
        self.aggregate_id = aggregate_id
        self.version = 0
        self._uncommitted_events = []
    
    def _apply_event(self, event: Event):
        """应用事件"""
        self.version += 1
        self._handle_event(event)
    
    def _handle_event(self, event: Event):
        """处理事件 - 子类实现"""
        pass
    
    def mark_events_as_committed(self):
        """标记事件为已提交"""
        self._uncommitted_events.clear()
    
    def get_uncommitted_events(self) -> List[Event]:
        """获取未提交事件"""
        return self._uncommitted_events.copy()
    
    def load_from_history(self, events: List[Event]):
        """从历史事件加载"""
        for event in sorted(events, key=lambda e: e.version):
            self._handle_event(event)

class User(AggregateRoot):
    """用户聚合"""
    
    def __init__(self, aggregate_id: str):
        super().__init__(aggregate_id)
        self.email = None
        self.name = None
        self.status = None
    
    @staticmethod
    def register(aggregate_id: str, email: str, name: str) -> 'User':
        """注册新用户"""
        user = User(aggregate_id)
        event = UserRegisteredEvent(aggregate_id, email, name)
        user._uncommitted_events.append(event)
        user._apply_event(event)
        return user
    
    def update_profile(self, changes: dict):
        """更新用户信息"""
        if not changes:
            return
        
        event = UserUpdatedEvent(
            self.aggregate_id,
            self.version + 1,
            changes
        )
        self._uncommitted_events.append(event)
        self._apply_event(event)
    
    def _handle_event(self, event: Event):
        """处理事件"""
        if isinstance(event, UserRegisteredEvent):
            self.email = event.event_data["email"]
            self.name = event.event_data["name"]
            self.status = "active"
        elif isinstance(event, UserUpdatedEvent):
            for key, value in event.event_data.items():
                if hasattr(self, key):
                    setattr(self, key, value)

class EventStore:
    """事件存储"""
    
    def __init__(self, connection_params):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        
    async def connect(self):
        """连接RabbitMQ"""
        self.connection = pika.BlockingConnection(self.connection_params)
        self.channel = self.connection.channel()
        
        # 声明事件存储交换机
        self.channel.exchange_declare(
            exchange="event_store",
            exchange_type='topic',
            durable=True
        )
        
        # 声明持久化队列
        self.channel.queue_declare(
            queue="events",
            durable=True
        )
        
        self.channel.queue_bind(
            exchange="event_store",
            queue="events",
            routing_key="events.*"
        )
    
    def save_events(self, aggregate_id: str, events: List[Event], 
                   expected_version: int):
        """保存事件"""
        # 检查版本冲突
        if events and events[-1].version != expected_version + 1:
            raise ConcurrencyError(f"版本冲突: 期望版本 {expected_version + 1}, 实际版本 {events[-1].version}")
        
        for event in events:
            # 保存事件到数据库（这里使用消息队列模拟）
            routing_key = f"events.{event.get_event_type()}"
            
            self.channel.basic_publish(
                exchange="event_store",
                routing_key=routing_key,
                properties=pika.BasicProperties(
                    delivery_mode=2,
                    content_type='application/json',
                    headers={
                        'aggregate_id': event.aggregate_id,
                        'version': event.version,
                        'event_type': event.get_event_type()
                    }
                ),
                body=json.dumps(event.to_dict())
            )
    
    def get_events_for_aggregate(self, aggregate_id: str) -> List[Event]:
        """获取聚合的所有事件"""
        # 这里应该查询数据库
        # 简化实现，模拟从队列获取
        events = []
        
        # 模拟事件数据
        event_data_list = [
            {
                "event_id": str(uuid.uuid4()),
                "aggregate_id": aggregate_id,
                "version": 1,
                "event_type": "UserRegistered",
                "event_data": {"email": "user@example.com", "name": "张三"},
                "timestamp": datetime.utcnow().isoformat()
            }
        ]
        
        for event_data in event_data_list:
            if event_data["event_type"] == "UserRegistered":
                event = UserRegisteredEvent(
                    event_data["aggregate_id"],
                    event_data["event_data"]["email"],
                    event_data["event_data"]["name"]
                )
                event.version = event_data["version"]
                event.event_id = event_data["event_id"]
                event.timestamp = datetime.fromisoformat(event_data["timestamp"])
            events.append(event)
        
        return events

class ConcurrencyError(Exception):
    """并发异常"""
    pass

# 使用示例
async def main():
    event_store = EventStore(pika.ConnectionParameters('localhost'))
    await event_store.connect()
    
    # 创建用户
    user = User.register(
        aggregate_id="user_123",
        email="user@example.com",
        name="张三"
    )
    
    # 保存事件
    event_store.save_events(
        user.aggregate_id,
        user.get_uncommitted_events(),
        expected_version=0
    )
    
    # 标记事件为已提交
    user.mark_events_as_committed()
    
    # 模拟从事件存储恢复用户状态
    user_events = event_store.get_events_for_aggregate("user_123")
    restored_user = User("user_123")
    restored_user.load_from_history(user_events)
    
    print(f"用户信息: {restored_user.name} ({restored_user.email})")
    print(f"用户状态: {restored_user.status}")
```

### 4.2 CQRS模式

**核心概念**：
- Command Query Responsibility Segregation
- 读写分离，优化不同操作性能
- 写端处理业务逻辑，读端优化查询性能

```python
from enum import Enum
from dataclasses import dataclass
from typing import List, Optional, Dict, Any

class CommandType(Enum):
    """命令类型"""
    CREATE_USER = "create_user"
    UPDATE_USER = "update_user"
    DELETE_USER = "delete_user"
    CREATE_ORDER = "create_order"
    UPDATE_ORDER = "update_order"

class QueryType(Enum):
    """查询类型"""
    GET_USER = "get_user"
    LIST_USERS = "list_users"
    GET_ORDER = "get_order"
    LIST_ORDERS = "list_orders"
    GET_USER_ORDERS = "get_user_orders"

@dataclass
class Command:
    """命令"""
    command_id: str
    command_type: CommandType
    aggregate_id: str
    data: dict
    timestamp: datetime
    metadata: Dict[str, Any] = None

@dataclass
class Query:
    """查询"""
    query_id: str
    query_type: QueryType
    parameters: dict
    timestamp: datetime

@dataclass
class Result:
    """结果"""
    success: bool
    data: Any = None
    error: str = None
    timestamp: datetime = None

class CommandBus:
    """命令总线"""
    
    def __init__(self, connection_params):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        self.command_handlers = {}
        self.result_callbacks = {}
        
    async def connect(self):
        """连接RabbitMQ"""
        self.connection = pika.BlockingConnection(self.connection_params)
        self.channel = self.connection.channel()
        
        # 声明交换机
        self.channel.exchange_declare(
            exchange="command_bus",
            exchange_type='topic',
            durable=True
        )
        
        # 声明命令队列
        self.channel.queue_declare(
            queue="commands",
            durable=True
        )
        
        # 声明结果队列
        self.channel.queue_declare(
            queue="command_results",
            durable=True
        )
        
        self.channel.queue_bind(
            exchange="command_bus",
            queue="commands",
            routing_key="commands.*"
        )
        
        self.channel.queue_bind(
            exchange="command_bus",
            queue="command_results",
            routing_key="results.*"
        )
        
        # 启动消费者
        self.channel.basic_consume(
            queue="commands",
            on_message_callback=self.on_command_received
        )
        
        self.channel.basic_consume(
            queue="command_results",
            on_message_callback=self.on_result_received
        )
    
    def register_command_handler(self, command_type: CommandType, handler: Callable):
        """注册命令处理器"""
        self.command_handlers[command_type] = handler
    
    def on_command_received(self, ch, method, props, body):
        """接收命令"""
        try:
            command_data = json.loads(body)
            command = Command(
                command_id=command_data["command_id"],
                command_type=CommandType(command_data["command_type"]),
                aggregate_id=command_data["aggregate_id"],
                data=command_data["data"],
                timestamp=datetime.fromisoformat(command_data["timestamp"]),
                metadata=command_data.get("metadata")
            )
            
            # 查找处理器
            if command.command_type in self.command_handlers:
                result = self.command_handlers[command.command_type](command)
                self.send_result(result, props.correlation_id)
            else:
                result = Result(
                    success=False,
                    error=f"未找到命令处理器: {command.command_type}"
                )
                self.send_result(result, props.correlation_id)
            
            ch.basic_ack(delivery_tag=method.delivery_tag)
            
        except Exception as e:
            print(f"处理命令失败: {e}")
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
    
    def send_result(self, result: Result, correlation_id: str):
        """发送结果"""
        routing_key = f"results.{result.success}"
        
        self.channel.basic_publish(
            exchange="command_bus",
            routing_key=routing_key,
            properties=pika.BasicProperties(
                delivery_mode=2,
                correlation_id=correlation_id,
                content_type='application/json'
            ),
            body=json.dumps({
                "success": result.success,
                "data": result.data,
                "error": result.error,
                "timestamp": result.timestamp.isoformat()
            })
        )

class QueryBus:
    """查询总线"""
    
    def __init__(self, connection_params):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        self.query_handlers = {}
        self.read_replicas = {}  # 读副本缓存
        
    async def connect(self):
        """连接RabbitMQ"""
        self.connection = pika.BlockingConnection(self.connection_params)
        self.channel = self.connection.channel()
        
        # 声明交换机
        self.channel.exchange_declare(
            exchange="query_bus",
            exchange_type='topic',
            durable=True
        )
        
        # 声明查询队列
        self.channel.queue_declare(
            queue="queries",
            durable=True
        )
        
        self.channel.queue_bind(
            exchange="query_bus",
            queue="queries",
            routing_key="queries.*"
        )
        
        # 启动消费者
        self.channel.basic_consume(
            queue="queries",
            on_message_callback=self.on_query_received
        )
    
    def register_query_handler(self, query_type: QueryType, handler: Callable):
        """注册查询处理器"""
        self.query_handlers[query_type] = handler
    
    def on_query_received(self, ch, method, props, body):
        """接收查询"""
        try:
            query_data = json.loads(body)
            query = Query(
                query_id=query_data["query_id"],
                query_type=QueryType(query_data["query_type"]),
                parameters=query_data["parameters"],
                timestamp=datetime.fromisoformat(query_data["timestamp"])
            )
            
            # 检查缓存
            cache_key = f"{query.query_type.value}:{hash(str(sorted(query.parameters.items())))}"
            
            if query.query_type in self.read_replicas and cache_key in self.read_replicas[query.query_type]:
                cached_result = self.read_replicas[query.query_type][cache_key]
                
                # 检查缓存是否过期（简单实现）
                if datetime.utcnow() - cached_result["timestamp"] < timedelta(minutes=5):
                    # 返回缓存结果
                    ch.basic_publish(
                        exchange='',
                        routing_key=props.reply_to,
                        properties=pika.BasicProperties(
                            correlation_id=props.correlation_id,
                            content_type='application/json'
                        ),
                        body=json.dumps({
                            "success": True,
                            "data": cached_result["data"],
                            "cached": True
                        })
                    )
                    ch.basic_ack(delivery_tag=method.delivery_tag)
                    return
            
            # 查找处理器
            if query.query_type in self.query_handlers:
                result = self.query_handlers[query.query_type](query)
                
                # 更新缓存
                if query.query_type not in self.read_replicas:
                    self.read_replicas[query.query_type] = {}
                self.read_replicas[query.query_type][cache_key] = {
                    "data": result["data"],
                    "timestamp": datetime.utcnow()
                }
                
                # 发送结果
                ch.basic_publish(
                    exchange='',
                    routing_key=props.reply_to,
                    properties=pika.BasicProperties(
                        correlation_id=props.correlation_id,
                        content_type='application/json'
                    ),
                    body=json.dumps(result)
                )
            else:
                # 返回错误
                ch.basic_publish(
                    exchange='',
                    routing_key=props.reply_to,
                    properties=pika.BasicProperties(
                        correlation_id=props.correlation_id,
                        content_type='application/json'
                    ),
                    body=json.dumps({
                        "success": False,
                        "error": f"未找到查询处理器: {query.query_type}"
                    })
                )
            
            ch.basic_ack(delivery_tag=method.delivery_tag)
            
        except Exception as e:
            print(f"处理查询失败: {e}")
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)

# 用户命令处理器
def handle_create_user(command: Command) -> Result:
    """处理创建用户命令"""
    user_data = command.data
    
    # 模拟用户创建逻辑
    try:
        # 检查用户是否已存在
        # 创建用户记录
        # 发送事件
        return Result(
            success=True,
            data={"user_id": command.aggregate_id, "status": "created"},
            timestamp=datetime.utcnow()
        )
    except Exception as e:
        return Result(
            success=False,
            error=str(e),
            timestamp=datetime.utcnow()
        )

# 用户查询处理器
def handle_get_user(query: Query) -> dict:
    """处理获取用户查询"""
    user_id = query.parameters["user_id"]
    
    # 从数据库读取用户数据
    # 这里是模拟数据
    user_data = {
        "user_id": user_id,
        "email": "user@example.com",
        "name": "张三",
        "status": "active",
        "created_at": "2023-11-28T10:00:00Z"
    }
    
    return {
        "success": True,
        "data": user_data
    }

def handle_list_users(query: Query) -> dict:
    """处理用户列表查询"""
    page = query.parameters.get("page", 1)
    page_size = query.parameters.get("page_size", 10)
    
    # 模拟分页数据
    users = [
        {
            "user_id": f"user_{i}",
            "email": f"user{i}@example.com",
            "name": f"用户{i}",
            "status": "active"
        }
        for i in range((page - 1) * page_size + 1, page * page_size + 1)
    ]
    
    return {
        "success": True,
        "data": {
            "users": users,
            "page": page,
            "page_size": page_size,
            "total": 100
        }
    }

# 使用示例
async def main():
    # 启动命令总线
    command_bus = CommandBus(pika.ConnectionParameters('localhost'))
    await command_bus.connect()
    command_bus.register_command_handler(CommandType.CREATE_USER, handle_create_user)
    
    # 启动查询总线
    query_bus = QueryBus(pika.ConnectionParameters('localhost'))
    await query_bus.connect()
    query_bus.register_query_handler(QueryType.GET_USER, handle_get_user)
    query_bus.register_query_handler(QueryType.LIST_USERS, handle_list_users)
    
    # 发送命令
    create_command = Command(
        command_id=str(uuid.uuid4()),
        command_type=CommandType.CREATE_USER,
        aggregate_id="user_123",
        data={
            "email": "user@example.com",
            "name": "张三"
        },
        timestamp=datetime.utcnow()
    )
    
    # 发送查询
    get_user_query = Query(
        query_id=str(uuid.uuid4()),
        query_type=QueryType.GET_USER,
        parameters={"user_id": "user_123"},
        timestamp=datetime.utcnow()
    )
    
    list_users_query = Query(
        query_id=str(uuid.uuid4()),
        query_type=QueryType.LIST_USERS,
        parameters={"page": 1, "page_size": 5},
        timestamp=datetime.utcnow()
    )
    
    print("CQRS示例启动完成")
```

## 5. Saga事务模式

### 5.1 分布式事务处理

```python
from enum import Enum
from dataclasses import dataclass
from typing import List, Dict, Callable, Optional
import time

class SagaStatus(Enum):
    """Saga状态"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    COMPENSATING = "compensating"
    COMPENSATED = "compensated"

class StepStatus(Enum):
    """步骤状态"""
    NOT_STARTED = "not_started"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    COMPENSATING = "compensating"
    COMPENSATED = "compensated"

@dataclass
class SagaStep:
    """Saga步骤"""
    step_id: str
    action_name: str
    compensate_name: str
    action_data: dict
    compensate_data: dict
    status: StepStatus = StepStatus.NOT_STARTED
    retry_count: int = 0
    max_retries: int = 3
    timeout: int = 300  # 5分钟超时

@dataclass
class SagaTransaction:
    """Saga事务"""
    saga_id: str
    steps: List[SagaStep]
    status: SagaStatus = SagaStatus.PENDING
    current_step_index: int = 0
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    error_message: Optional[str] = None

class SagaManager:
    """Saga事务管理器"""
    
    def __init__(self, connection_params):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        self.saga_storage = {}  # 简化实现，实际应使用数据库
        self.step_handlers = {}
        self.compensate_handlers = {}
        
    async def connect(self):
        """连接RabbitMQ"""
        self.connection = pika.BlockingConnection(self.connection_params)
        self.channel = self.connection.channel()
        
        # 声明交换机和队列
        self.channel.exchange_declare(
            exchange="saga_bus",
            exchange_type='topic',
            durable=True
        )
        
        # Saga事务队列
        self.channel.queue_declare(queue="saga_transactions", durable=True)
        self.channel.queue_bind(
            exchange="saga_bus",
            queue="saga_transactions",
            routing_key="saga.*"
        )
        
        # Saga状态更新队列
        self.channel.queue_declare(queue="saga_status", durable=True)
        
        # 启动消费者
        self.channel.basic_consume(
            queue="saga_transactions",
            on_message_callback=self.on_saga_message_received
        )
    
    def register_action_handler(self, action_name: str, handler: Callable):
        """注册动作处理器"""
        self.step_handlers[action_name] = handler
    
    def register_compensate_handler(self, compensate_name: str, handler: Callable):
        """注册补偿处理器"""
        self.compensate_handlers[compensate_name] = handler
    
    def on_saga_message_received(self, ch, method, props, body):
        """处理Saga消息"""
        try:
            saga_data = json.loads(body)
            message_type = saga_data.get("type")
            
            if message_type == "execute_saga":
                self.execute_saga(saga_data["saga"])
            elif message_type == "execute_step":
                self.execute_step(saga_data["saga_id"], saga_data["step"])
            elif message_type == "compensate_step":
                self.compensate_step(saga_data["saga_id"], saga_data["step"])
            
            ch.basic_ack(delivery_tag=method.delivery_tag)
            
        except Exception as e:
            print(f"处理Saga消息失败: {e}")
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
    
    def create_saga(self, saga_id: str, steps: List[dict]) -> SagaTransaction:
        """创建Saga事务"""
        saga_steps = []
        for step_data in steps:
            saga_steps.append(SagaStep(
                step_id=step_data["step_id"],
                action_name=step_data["action_name"],
                compensate_name=step_data["compensate_name"],
                action_data=step_data.get("action_data", {}),
                compensate_data=step_data.get("compensate_data", {}),
                max_retries=step_data.get("max_retries", 3),
                timeout=step_data.get("timeout", 300)
            ))
        
        saga = SagaTransaction(
            saga_id=saga_id,
            steps=saga_steps,
            start_time=datetime.utcnow()
        )
        
        self.saga_storage[saga_id] = saga
        return saga
    
    def execute_saga(self, saga_data: dict):
        """执行Saga事务"""
        saga_id = saga_data["saga_id"]
        saga = self.saga_storage.get(saga_id)
        
        if not saga:
            print(f"Saga {saga_id} 不存在")
            return
        
        saga.status = SagaStatus.RUNNING
        print(f"开始执行Saga: {saga_id}")
        
        # 开始执行第一步
        if saga.steps:
            self.send_step_message("execute_step", saga_id, saga.steps[0])
    
    def execute_step(self, saga_id: str, step_data: dict):
        """执行Saga步骤"""
        saga = self.saga_storage.get(saga_id)
        if not saga:
            return
        
        step = next(s for s in saga.steps if s.step_id == step_data["step_id"])
        step.status = StepStatus.RUNNING
        
        print(f"执行Saga步骤: {saga_id} - {step.action_name}")
        
        if step.action_name in self.step_handlers:
            try:
                # 调用动作处理器
                result = self.step_handlers[step.action_name](step.action_data)
                
                if result.get("success", True):
                    step.status = StepStatus.COMPLETED
                    self.advance_saga(saga_id)
                else:
                    step.status = StepStatus.FAILED
                    self.handle_step_failure(saga_id, step, result.get("error", "动作执行失败"))
                    
            except Exception as e:
                step.status = StepStatus.FAILED
                self.handle_step_failure(saga_id, step, str(e))
        else:
            step.status = StepStatus.FAILED
            self.handle_step_failure(saga_id, step, f"未找到处理器: {step.action_name}")
    
    def advance_saga(self, saga_id: str):
        """推进Saga执行"""
        saga = self.saga_storage.get(saga_id)
        if not saga:
            return
        
        completed_steps = sum(1 for step in saga.steps if step.status == StepStatus.COMPLETED)
        
        if completed_steps == len(saga.steps):
            # 所有步骤完成
            saga.status = SagaStatus.COMPLETED
            saga.end_time = datetime.utcnow()
            print(f"Saga {saga_id} 执行完成")
        else:
            # 执行下一步
            next_step = saga.steps[completed_steps]
            self.send_step_message("execute_step", saga_id, next_step)
    
    def handle_step_failure(self, saga_id: str, step: SagaStep, error: str):
        """处理步骤失败"""
        saga = self.saga_storage.get(saga_id)
        if not saga:
            return
        
        step.retry_count += 1
        
        if step.retry_count <= step.max_retries:
            # 重试
            print(f"Saga步骤重试: {saga_id} - {step.action_name} (第{step.retry_count}次)")
            time.sleep(2 ** step.retry_count)  # 指数退避
            self.send_step_message("execute_step", saga_id, step)
        else:
            # 开始补偿事务
            print(f"Saga步骤失败，开始补偿: {saga_id} - {step.action_name}")
            saga.status = SagaStatus.COMPENSATING
            self.start_compensation(saga_id)
    
    def start_compensation(self, saga_id: str):
        """开始补偿事务"""
        saga = self.saga_storage.get(saga_id)
        if not saga:
            return
        
        # 找到最后一个成功执行的步骤
        completed_steps = [
            step for step in saga.steps 
            if step.status == StepStatus.COMPLETED
        ]
        
        if completed_steps:
            # 从后往前补偿
            last_successful_step = completed_steps[-1]
            self.send_step_message("compensate_step", saga_id, last_successful_step)
        else:
            # 没有成功步骤，标记为补偿完成
            saga.status = SagaStatus.COMPENSATED
            saga.end_time = datetime.utcnow()
            saga.error_message = "所有步骤都补偿完成"
    
    def compensate_step(self, saga_id: str, step_data: dict):
        """补偿Saga步骤"""
        saga = self.saga_storage.get(saga_id)
        if not saga:
            return
        
        step = next(s for s in saga.steps if s.step_id == step_data["step_id"])
        step.status = StepStatus.COMPENSATING
        
        print(f"执行补偿步骤: {saga_id} - {step.compensate_name}")
        
        if step.compensate_name in self.compensate_handlers:
            try:
                # 调用补偿处理器
                result = self.compensate_handlers[step.compensate_name](step.compensate_data)
                
                if result.get("success", True):
                    step.status = StepStatus.COMPENSATED
                    self.advance_compensation(saga_id)
                else:
                    step.status = StepStatus.FAILED
                    print(f"补偿步骤失败: {saga_id} - {step.compensate_name}")
                    
            except Exception as e:
                step.status = StepStatus.FAILED
                print(f"补偿步骤异常: {saga_id} - {step.compensate_name} - {e}")
        else:
            step.status = StepStatus.COMPENSATED
            print(f"未找到补偿处理器，标记为已补偿: {step.compensate_name}")
    
    def advance_compensation(self, saga_id: str):
        """推进补偿事务"""
        saga = self.saga_storage.get(saga_id)
        if not saga:
            return
        
        # 找到下一个需要补偿的步骤
        steps_to_compensate = [
            step for step in saga.steps 
            if step.status == StepStatus.COMPLETED
        ]
        
        if steps_to_compensate:
            # 继续补偿
            next_step = steps_to_compensate[-1]
            self.send_step_message("compensate_step", saga_id, next_step)
        else:
            # 补偿完成
            saga.status = SagaStatus.COMPENSATED
            saga.end_time = datetime.utcnow()
            print(f"Saga {saga_id} 补偿完成")
    
    def send_step_message(self, message_type: str, saga_id: str, step: SagaStep):
        """发送步骤消息"""
        message = {
            "type": message_type,
            "saga_id": saga_id,
            "step": {
                "step_id": step.step_id,
                "action_name": step.action_name,
                "compensate_name": step.compensate_name,
                "action_data": step.action_data,
                "compensate_data": step.compensate_data
            }
        }
        
        self.channel.basic_publish(
            exchange="saga_bus",
            routing_key="saga.steps",
            properties=pika.BasicProperties(
                delivery_mode=2,
                content_type='application/json'
            ),
            body=json.dumps(message)
        )

# Saga步骤处理器示例
def create_order_action(action_data: dict) -> dict:
    """创建订单动作"""
    print(f"创建订单: {action_data.get('order_id')}")
    
    # 模拟订单创建
    order_id = action_data.get("order_id")
    if order_id == "existing_order":
        return {"success": False, "error": "订单已存在"}
    
    return {"success": True, "data": {"order_id": order_id}}

def reserve_inventory_action(action_data: dict) -> dict:
    """库存预留动作"""
    print(f"预留库存: {action_data.get('items')}")
    
    # 模拟库存检查
    items = action_data.get("items", [])
    for item in items:
        if item.get("quantity", 0) > 100:
            return {"success": False, "error": f"商品{item['id']}库存不足"}
    
    return {"success": True}

def charge_payment_action(action_data: dict) -> dict:
    """支付扣款动作"""
    print(f"扣款: {action_data.get('amount')}")
    
    # 模拟支付处理
    if action_data.get("amount", 0) > 10000:
        return {"success": False, "error": "支付金额超限"}
    
    return {"success": True}

# 补偿处理器示例
def cancel_order_compensate(compensate_data: dict) -> dict:
    """取消订单补偿"""
    print(f"取消订单: {compensate_data.get('order_id')}")
    return {"success": True}

def release_inventory_compensate(compensate_data: dict) -> dict:
    """释放库存补偿"""
    print(f"释放库存: {compensate_data.get('items')}")
    return {"success": True}

def refund_payment_compensate(compensate_data: dict) -> dict:
    """退款补偿"""
    print(f"退款: {compensate_data.get('amount')}")
    return {"success": True}

# 使用示例
async def main():
    saga_manager = SagaManager(pika.ConnectionParameters('localhost'))
    await saga_manager.connect()
    
    # 注册处理器
    saga_manager.register_action_handler("create_order", create_order_action)
    saga_manager.register_action_handler("reserve_inventory", reserve_inventory_action)
    saga_manager.register_action_handler("charge_payment", charge_payment_action)
    
    saga_manager.register_compensate_handler("cancel_order", cancel_order_compensate)
    saga_manager.register_compensate_handler("release_inventory", release_inventory_compensate)
    saga_manager.register_compensate_handler("refund_payment", refund_payment_compensate)
    
    # 创建订单Saga
    order_saga_steps = [
        {
            "step_id": "create_order",
            "action_name": "create_order",
            "compensate_name": "cancel_order",
            "action_data": {"order_id": "order_123"},
            "compensate_data": {"order_id": "order_123"}
        },
        {
            "step_id": "reserve_inventory",
            "action_name": "reserve_inventory",
            "compensate_name": "release_inventory",
            "action_data": {"items": [{"id": "item1", "quantity": 5}]},
            "compensate_data": {"items": [{"id": "item1", "quantity": 5}]}
        },
        {
            "step_id": "charge_payment",
            "action_name": "charge_payment",
            "compensate_name": "refund_payment",
            "action_data": {"amount": 299.99},
            "compensate_data": {"amount": 299.99}
        }
    ]
    
    saga = saga_manager.create_saga("order_saga_123", order_saga_steps)
    
    # 启动Saga
    saga_message = {
        "type": "execute_saga",
        "saga": {
            "saga_id": saga.saga_id,
            "steps": order_saga_steps
        }
    }
    
    saga_manager.channel.basic_publish(
        exchange="saga_bus",
        routing_key="saga.transactions",
        properties=pika.BasicProperties(
            delivery_mode=2,
            content_type='application/json'
        ),
        body=json.dumps(saga_message)
    )
    
    print(f"订单Saga已启动: {saga.saga_id}")
    
    # 保持程序运行以处理Saga消息
    try:
        saga_manager.channel.start_consuming()
    except KeyboardInterrupt:
        saga_manager.channel.stop_consuming()
```

这个第13章的文档涵盖了微服务架构中消息模式的核心内容，包括：

1. **微服务架构基础** - 介绍微服务特征和消息驱动优势
2. **核心消息模式** - 请求-响应、发布-订阅、工作队列模式
3. **异步通信模式** - 异步调用和流式通信
4. **事件驱动架构** - 事件溯源和CQRS模式
5. **Saga事务模式** - 分布式事务处理

每个模式都提供了完整的代码实现和实际使用示例，帮助理解如何在微服务架构中应用这些消息模式。这些模式可以单独使用，也可以组合使用来构建复杂的分布式系统。
