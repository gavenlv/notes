# ç¬¬3ç« ï¼šRabbitMQé«˜çº§ç‰¹æ€§è¯¦è§£

## ğŸ“š ç« èŠ‚æ¦‚è¿°

RabbitMQä½œä¸ºä¼ä¸šçº§æ¶ˆæ¯é˜Ÿåˆ—è§£å†³æ–¹æ¡ˆï¼Œä¸ä»…æä¾›äº†åŸºç¡€çš„æ¶ˆæ¯ä¼ é€’åŠŸèƒ½ï¼Œè¿˜å…·å¤‡è®¸å¤šå¼ºå¤§çš„é«˜çº§ç‰¹æ€§ã€‚è¿™äº›ç‰¹æ€§ä½¿å¾—RabbitMQèƒ½å¤Ÿåº”å¯¹å¤æ‚çš„ä¸šåŠ¡åœºæ™¯ï¼Œæä¾›å¯é ã€é«˜æ•ˆã€å¯æ‰©å±•çš„æ¶ˆæ¯å¤„ç†èƒ½åŠ›ã€‚

æœ¬ç« èŠ‚å°†æ·±å…¥æ¢è®¨RabbitMQçš„æ ¸å¿ƒé«˜çº§ç‰¹æ€§ï¼ŒåŒ…æ‹¬æ¶ˆæ¯ç¡®è®¤æœºåˆ¶ã€æŒä¹…åŒ–ç­–ç•¥ã€æ­»ä¿¡é˜Ÿåˆ—ã€æ¶ˆæ¯TTLã€ä¼˜å…ˆçº§é˜Ÿåˆ—ã€é›†ç¾¤é…ç½®ç­‰ï¼Œå¸®åŠ©æ‚¨æ„å»ºå¥å£®çš„ä¼ä¸šçº§æ¶ˆæ¯ç³»ç»Ÿã€‚

## ğŸ”„ æ¶ˆæ¯ç¡®è®¤æœºåˆ¶

### 1. ç¡®è®¤æœºåˆ¶æ¦‚è¿°

æ¶ˆæ¯ç¡®è®¤æ˜¯ç¡®ä¿æ¶ˆæ¯å¯é ä¼ é€’çš„å…³é”®æœºåˆ¶ã€‚RabbitMQæä¾›äº†å¤šç§ç¡®è®¤æ–¹å¼ï¼š

#### 1.1 ç”Ÿäº§è€…ç¡®è®¤ï¼ˆPublisher Confirmsï¼‰

ç”Ÿäº§è€…ç¡®è®¤ç¡®ä¿æ¶ˆæ¯æˆåŠŸåˆ°è¾¾RabbitMQæœåŠ¡å™¨ï¼š

```python
import pika

# å¯ç”¨å‘å¸ƒè€…ç¡®è®¤
channel.confirm_delivery()

# å‘é€æ¶ˆæ¯ - å¦‚æœç¡®è®¤å¤±è´¥ä¼šæŠ›å‡ºå¼‚å¸¸
channel.basic_publish(
    exchange='amq.direct',
    routing_key='test.queue',
    body='Hello World!'
)
```

#### 1.2 æ¶ˆè´¹è€…ç¡®è®¤ï¼ˆConsumer Acknowledgmentsï¼‰

æ¶ˆè´¹è€…ç¡®è®¤ç¡®ä¿æ¶ˆæ¯è¢«æ­£ç¡®å¤„ç†ï¼š

```python
def callback(ch, method, properties, body):
    try:
        # å¤„ç†æ¶ˆæ¯
        process_message(body)
        # æ‰‹åŠ¨ç¡®è®¤æ¶ˆæ¯
        ch.basic_ack(delivery_tag=method.delivery_tag)
    except Exception as e:
        # ç¡®è®¤æ‹’ç»æ¶ˆæ¯ï¼Œå¯èƒ½é‡æ–°å…¥é˜Ÿ
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
```

#### 1.3 äº‹åŠ¡æœºåˆ¶

æä¾›ç±»ä¼¼æ•°æ®åº“äº‹åŠ¡çš„ä¿è¯ï¼š

```python
# å¼€å§‹äº‹åŠ¡
channel.tx_select()

try:
    # å‘é€æ¶ˆæ¯
    channel.basic_publish(...)
    # æäº¤äº‹åŠ¡
    channel.tx_commit()
except:
    # å›æ»šäº‹åŠ¡
    channel.tx_rollback()
```

### 2. ç¡®è®¤æ¨¡å¼è¯¦è§£

#### 2.1 è‡ªåŠ¨ç¡®è®¤æ¨¡å¼
```python
# è‡ªåŠ¨ç¡®è®¤ - æ¶ˆæ¯ä¸€æ—¦å‘é€ç»™æ¶ˆè´¹è€…å°±ç¡®è®¤
channel.basic_consume(queue='test_queue', on_message_callback=callback)
```

**ç‰¹ç‚¹**ï¼š
- ååé‡é«˜
- ä¸ä¿è¯æ¶ˆæ¯å¤„ç†
- å¯èƒ½å¯¼è‡´æ¶ˆæ¯ä¸¢å¤±

#### 2.2 æ‰‹åŠ¨ç¡®è®¤æ¨¡å¼
```python
# æ‰‹åŠ¨ç¡®è®¤
channel.basic_consume(
    queue='test_queue',
    on_message_callback=callback,
    auto_ack=False
)

def callback(ch, method, properties, body):
    # å¤„ç†æ¶ˆæ¯
    process_message(body)
    # æ‰‹åŠ¨ç¡®è®¤
    ch.basic_ack(delivery_tag=method.delivery_tag)
```

**ä¼˜ç‚¹**ï¼š
- å¯é çš„æ¶ˆæ¯ä¼ é€’
- æ”¯æŒå¤±è´¥é‡è¯•
- ç²¾ç¡®çš„æµæ§åˆ¶

#### 2.3 é¢„å–æ•°é‡æ§åˆ¶

```python
# è®¾ç½®é¢„å–æ•°é‡ä¸º1ï¼Œç¡®ä¿ä¸€æ¬¡åªå¤„ç†ä¸€æ¡æ¶ˆæ¯
channel.basic_qos(prefetch_count=1)

# é¢„å–å¤šæ¡æ¶ˆæ¯ï¼Œæé«˜ååé‡
channel.basic_qos(prefetch_count=10)
```

## ğŸ’¾ æ¶ˆæ¯æŒä¹…åŒ–

### 1. æŒä¹…åŒ–ç­–ç•¥

#### 1.1 äº¤æ¢æœºæŒä¹…åŒ–
```python
channel.exchange_declare(
    exchange='durable_exchange',
    exchange_type='direct',
    durable=True  # äº¤æ¢æœºæŒä¹…åŒ–
)
```

#### 1.2 é˜Ÿåˆ—æŒä¹…åŒ–
```python
channel.queue_declare(
    queue='durable_queue',
    durable=True  # é˜Ÿåˆ—æŒä¹…åŒ–
)
```

#### 1.3 æ¶ˆæ¯æŒä¹…åŒ–
```python
channel.basic_publish(
    exchange='amq.direct',
    routing_key='test.queue',
    body='Persistent message',
    properties=pika.BasicProperties(
        delivery_mode=2,  # æ¶ˆæ¯æŒä¹…åŒ– (1=éæŒä¹…, 2=æŒä¹…)
        priority=1,       # æ¶ˆæ¯ä¼˜å…ˆçº§
        message_id='msg_001',
        correlation_id='cor_001',
        reply_to='reply_queue',
        expiration='60000',  # æ¶ˆæ¯TTL (æ¯«ç§’)
        timestamp=datetime.now(),
        type='event',
        user_id='user',
        app_id='app_001'
    )
)
```

### 2. æŒä¹…åŒ–åŸç†

#### 2.1 å†™å…¥ç­–ç•¥
- **é˜Ÿåˆ—é•œåƒ**ï¼šæ¶ˆæ¯å¤åˆ¶åˆ°é›†ç¾¤å¤šä¸ªèŠ‚ç‚¹
- **é˜Ÿåˆ—è½ç›˜**ï¼šæ¶ˆæ¯æŒä¹…åŒ–åˆ°ç£ç›˜
- **ç¡®è®¤æœºåˆ¶**ï¼šç¡®ä¿æ¶ˆæ¯æˆåŠŸè½ç›˜

#### 2.2 æ€§èƒ½å½±å“
- **å†…å­˜å­˜å‚¨**ï¼šå¿«é€Ÿä½†å¯èƒ½ä¸¢å¤±
- **ç£ç›˜å­˜å‚¨**ï¼šå¯é ä½†é€Ÿåº¦è¾ƒæ…¢
- **æ··åˆç­–ç•¥**ï¼šæ ¹æ®æ¶ˆæ¯é‡è¦æ€§é€‰æ‹©

## âš°ï¸ æ­»ä¿¡é˜Ÿåˆ—ï¼ˆDead Letter Queueï¼‰

### 1. æ­»ä¿¡é˜Ÿåˆ—æ¦‚è¿°

æ­»ä¿¡é˜Ÿåˆ—ç”¨äºå¤„ç†æ— æ³•æ­£å¸¸å¤„ç†çš„æ¶ˆæ¯ï¼Œé¿å…æ¶ˆæ¯ä¸¢å¤±ã€‚

### 2. æ­»ä¿¡é˜Ÿåˆ—é…ç½®

#### 2.1 å£°æ˜æ­»ä¿¡äº¤æ¢æœº
```python
# å£°æ˜æ­»ä¿¡äº¤æ¢æœº
channel.exchange_declare(
    exchange='dlx_exchange',
    exchange_type='direct',
    durable=True
)

# å£°æ˜æ­»ä¿¡é˜Ÿåˆ—
channel.queue_declare(
    queue='dead_letter_queue',
    durable=True
)

# ç»‘å®šæ­»ä¿¡äº¤æ¢æœºåˆ°æ­»ä¿¡é˜Ÿåˆ—
channel.queue_bind(
    exchange='dlx_exchange',
    queue='dead_letter_queue',
    routing_key='dead_letter'
)
```

#### 2.2 é…ç½®ä¸»é˜Ÿåˆ—çš„æ­»ä¿¡å±æ€§
```python
channel.queue_declare(
    queue='main_queue',
    durable=True,
    arguments={
        'x-dead-letter-exchange': 'dlx_exchange',  # æ­»ä¿¡äº¤æ¢æœº
        'x-dead-letter-routing-key': 'dead_letter',  # æ­»ä¿¡è·¯ç”±é”®
        'x-message-ttl': 30000,  # æ¶ˆæ¯TTL (30ç§’)
        'x-max-priority': 10  # æœ€å¤§ä¼˜å…ˆçº§
    }
)
```

### 3. æ­»ä¿¡è§¦å‘æ¡ä»¶

#### 3.1 æ¶ˆæ¯è¢«æ‹’ç»ä¸”ä¸é‡æ–°å…¥é˜Ÿ
```python
def callback(ch, method, properties, body):
    try:
        # å¤„ç†æ¶ˆæ¯å¤±è´¥
        if not process_message(body):
            # æ‹’ç»æ¶ˆæ¯ä½†ä¸é‡æ–°å…¥é˜Ÿ
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
    except Exception as e:
        # æ‹’ç»æ¶ˆæ¯å¹¶é‡æ–°å…¥é˜Ÿ
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
```

#### 3.2 æ¶ˆæ¯è¿‡æœŸ
```python
# è®¾ç½®æ¶ˆæ¯è¿‡æœŸæ—¶é—´
properties = pika.BasicProperties(
    expiration='10000'  # 10ç§’åè¿‡æœŸ
)

channel.basic_publish(
    exchange='amq.direct',
    routing_key='main_queue',
    body='Message with TTL',
    properties=properties
)
```

#### 3.3 é˜Ÿåˆ—è¾¾åˆ°æœ€å¤§é•¿åº¦
```python
# å£°æ˜æœ‰æœ€å¤§é•¿åº¦é™åˆ¶çš„é˜Ÿåˆ—
channel.queue_declare(
    queue='limited_queue',
    durable=True,
    arguments={
        'x-max-length': 100,  # æœ€å¤§é˜Ÿåˆ—é•¿åº¦
        'x-dead-letter-exchange': 'dlx_exchange'
    }
)
```

## â° æ¶ˆæ¯TTLï¼ˆTime To Liveï¼‰

### 1. TTLç±»å‹

#### 1.1 é˜Ÿåˆ—çº§TTL
```python
# ä¸ºé˜Ÿåˆ—ä¸­çš„æ‰€æœ‰æ¶ˆæ¯è®¾ç½®TTL
channel.queue_declare(
    queue='ttl_queue',
    arguments={
        'x-message-ttl': 60000  # 60ç§’
    }
)
```

#### 1.2 æ¶ˆæ¯çº§TTL
```python
# ä¸ºå•ä¸ªæ¶ˆæ¯è®¾ç½®TTL
properties = pika.BasicProperties(
    expiration='30000'  # 30ç§’
)

channel.basic_publish(
    exchange='amq.direct',
    routing_key='ttl_queue',
    body='Message with individual TTL',
    properties=properties
)
```

### 2. TTLå¤„ç†æœºåˆ¶

#### 2.1 TTLæ£€æŸ¥
- **é˜Ÿåˆ—æ£€æŸ¥**ï¼šå®šæœŸæ£€æŸ¥é˜Ÿåˆ—ä¸­çš„è¿‡æœŸæ¶ˆæ¯
- **ä¼˜å…ˆçº§å¤„ç†**ï¼šæŒ‰ç…§ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥
- **ç²¾ç¡®æ—¶é—´**ï¼šä½¿ç”¨Unixæ—¶é—´æˆ³ç²¾ç¡®è®¡ç®—

#### 2.2 TTLè¿‡æœŸå¤„ç†
- **è½¬å…¥æ­»ä¿¡é˜Ÿåˆ—**ï¼šè¿‡æœŸæ¶ˆæ¯è‡ªåŠ¨è½¬å…¥DLQ
- **ç«‹å³åˆ é™¤**ï¼šæ²¡æœ‰æ­»ä¿¡é˜Ÿåˆ—é…ç½®çš„é˜Ÿåˆ—ç›´æ¥åˆ é™¤
- **æ‰¹é‡æ¸…ç†**ï¼šæ‰¹é‡å¤„ç†è¿‡æœŸæ¶ˆæ¯æé«˜æ€§èƒ½

## ğŸ¯ ä¼˜å…ˆçº§é˜Ÿåˆ—

### 1. ä¼˜å…ˆçº§é˜Ÿåˆ—é…ç½®

```python
# å£°æ˜æœ€å¤§ä¼˜å…ˆçº§ä¸º10çš„é˜Ÿåˆ—
channel.queue_declare(
    queue='priority_queue',
    durable=True,
    arguments={
        'x-max-priority': 10  # æœ€å¤§ä¼˜å…ˆçº§
    }
)
```

### 2. å‘é€ä¼˜å…ˆçº§æ¶ˆæ¯

```python
# å‘é€é«˜ä¼˜å…ˆçº§æ¶ˆæ¯
properties = pika.BasicProperties(
    priority=9  # é«˜ä¼˜å…ˆçº§
)

channel.basic_publish(
    exchange='amq.direct',
    routing_key='priority_queue',
    body='High priority message',
    properties=properties
)

# å‘é€æ™®é€šä¼˜å…ˆçº§æ¶ˆæ¯
properties = pika.BasicProperties(
    priority=1  # æ™®é€šä¼˜å…ˆçº§
)

channel.basic_publish(
    exchange='amq.direct',
    routing_key='priority_queue',
    body='Normal priority message',
    properties=properties
)
```

### 3. ä¼˜å…ˆçº§å¤„ç†æœºåˆ¶

#### 3.1 é˜Ÿåˆ—å†…éƒ¨ç»“æ„
- **ä¼˜å…ˆçº§å †**ï¼šä½¿ç”¨å †æ•°æ®ç»“æ„ç»´æŠ¤ä¼˜å…ˆçº§
- **å¤šé˜Ÿåˆ—**ï¼šä¸åŒä¼˜å…ˆçº§çš„æ¶ˆæ¯å­˜å‚¨åœ¨ä¸åŒçš„è™šæ‹Ÿé˜Ÿåˆ—ä¸­
- **æ™ºèƒ½è°ƒåº¦**ï¼šä¼˜å…ˆå¤„ç†é«˜ä¼˜å…ˆçº§æ¶ˆæ¯

#### 3.2 æ¶ˆè´¹é¡ºåº
1. é«˜ä¼˜å…ˆçº§æ¶ˆæ¯ä¼˜å…ˆæ¶ˆè´¹
2. åŒä¼˜å…ˆçº§æ¶ˆæ¯æŒ‰FIFOé¡ºåºæ¶ˆè´¹
3. ç¡®ä¿æ¶ˆæ¯å¤„ç†é¡ºåºçš„ç›¸å¯¹ç¨³å®šæ€§

## ğŸ”’ æ¶ˆæ¯å±æ€§è¯¦è§£

### 1. åŸºæœ¬å±æ€§

```python
properties = pika.BasicProperties(
    delivery_mode=2,        # æ¶ˆæ¯æŒä¹…åŒ– (1=éæŒä¹…, 2=æŒä¹…)
    priority=5,             # æ¶ˆæ¯ä¼˜å…ˆçº§ (0-255)
    message_id='unique_id', # æ¶ˆæ¯å”¯ä¸€æ ‡è¯†
    correlation_id='corr_123', # å…³è”IDï¼Œç”¨äºè¯·æ±‚/å“åº”
    reply_to='reply_queue', # å›å¤é˜Ÿåˆ—åç§°
    timestamp=datetime.now(), # æ¶ˆæ¯æ—¶é—´æˆ³
    type='event_type',      # æ¶ˆæ¯ç±»å‹
    user_id='user123',      # ç”¨æˆ·ID
    app_id='app_456'        # åº”ç”¨ID
)
```

### 2. æ¶ˆæ¯å±æ€§åº”ç”¨åœºæ™¯

#### 2.1 è¯·æ±‚/å“åº”æ¨¡å¼
```python
# å‘é€è¯·æ±‚
def send_request(message, correlation_id):
    properties = pika.BasicProperties(
        reply_to='response_queue',
        correlation_id=correlation_id
    )
    channel.basic_publish(
        exchange='request_exchange',
        routing_key='request_routing_key',
        body=message,
        properties=properties
    )

# å¤„ç†å“åº”
def handle_response(ch, method, properties, body):
    correlation_id = properties.correlation_id
    response_queue = properties.reply_to
    # å¤„ç†å“åº”æ•°æ®...
```

#### 2.2 æ¶ˆæ¯è¿½è¸ª
```python
properties = pika.BasicProperties(
    message_id=f"msg_{uuid.uuid4()}",
    timestamp=datetime.now(),
    user_id='user_service',
    app_id='order_service',
    type='order_created'
)
```

## ğŸŒ RabbitMQé›†ç¾¤é…ç½®

### 1. é›†ç¾¤åŸºç¡€æ¶æ„

#### 1.1 èŠ‚ç‚¹ç±»å‹
- **ç£ç›˜èŠ‚ç‚¹**ï¼šæŒä¹…åŒ–å­˜å‚¨ï¼Œæ€§èƒ½è¾ƒæ…¢
- **å†…å­˜èŠ‚ç‚¹**ï¼šä»…å†…å­˜å­˜å‚¨ï¼Œæ€§èƒ½è¾ƒå¿«ï¼Œé‡å¯åæ•°æ®ä¸¢å¤±

#### 1.2 é›†ç¾¤é…ç½®
```bash
# åœæ­¢RabbitMQæœåŠ¡
sudo systemctl stop rabbitmq-server

# å¤åˆ¶Erlang Cookie
sudo cp /var/lib/rabbitmq/.erlang.cookie /home/user/.erlang.cookie
sudo chmod 400 /home/user/.erlang.cookie
sudo chown user:user /home/user/.erlang.cookie

# é‡å¯RabbitMQæœåŠ¡
sudo systemctl start rabbitmq-server

# åŠ å…¥é›†ç¾¤
sudo rabbitmqctl stop_app
sudo rabbitmqctl join_cluster rabbit@node2
sudo rabbitmqctl start_app
```

### 2. é«˜å¯ç”¨é…ç½®

#### 2.1 é˜Ÿåˆ—é•œåƒ
```python
# å£°æ˜é•œåƒé˜Ÿåˆ—
channel.queue_declare(
    queue='mirrored_queue',
    durable=True,
    arguments={
        'x-ha-policy': 'all'  # æ‰€æœ‰èŠ‚ç‚¹é•œåƒ
    }
)

# æˆ–è€…æŒ‡å®šç‰¹å®šèŠ‚ç‚¹é•œåƒ
channel.queue_declare(
    queue='mirrored_queue',
    durable=True,
    arguments={
        'x-ha-policy': 'nodes',
        'x-ha-nodes': ['rabbit@node1', 'rabbit@node2']
    }
)
```

#### 2.2 è´Ÿè½½å‡è¡¡
```bash
# å®‰è£…è´Ÿè½½å‡è¡¡å™¨
sudo apt install haproxy

# é…ç½®HAProxy
# /etc/haproxy/haproxy.cfg
frontend rabbitmq_front
    bind *:5672
    default_backend rabbitmq_backend

backend rabbitmq_backend
    balance roundrobin
    server rabbit1 rabbit@node1:5672 check
    server rabbit2 rabbit@node2:5672 check
    server rabbit3 rabbit@node3:5672 check
```

### 3. é›†ç¾¤ç®¡ç†

#### 3.1 é›†ç¾¤çŠ¶æ€ç›‘æ§
```python
# ä½¿ç”¨management APIç›‘æ§é›†ç¾¤
import requests

def get_cluster_status():
    url = 'http://localhost:15672/api/cluster-name'
    auth = ('guest', 'guest')
    
    response = requests.get(url, auth=auth)
    if response.status_code == 200:
        return response.json()
    return None
```

#### 3.2 èŠ‚ç‚¹ç®¡ç†
```bash
# æŸ¥çœ‹é›†ç¾¤çŠ¶æ€
sudo rabbitmqctl cluster_status

# ç§»é™¤èŠ‚ç‚¹
sudo rabbitmqctl forget_cluster_node rabbit@node_to_remove

# è®¾ç½®èŠ‚ç‚¹ç±»å‹
sudo rabbitmqctl set_policy ha-mirror "^ha\." '{"ha-mode":"all"}'
```

## ğŸ”„ æ¶ˆæ¯å¹‚ç­‰æ€§

### 1. å¹‚ç­‰æ€§è®¾è®¡

#### 1.1 æ¶ˆæ¯å»é‡
```python
import hashlib

class IdempotentMessageHandler:
    def __init__(self):
        self.processed_messages = set()
        self.ttl = 3600  # 1å°æ—¶
    
    def process_message(self, message_id, message_body):
        # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦å·²ç»å¤„ç†è¿‡
        if message_id in self.processed_messages:
            print(f"æ¶ˆæ¯ {message_id} å·²ç»å¤„ç†è¿‡ï¼Œè·³è¿‡")
            return
        
        # è®°å½•æ¶ˆæ¯ID
        self.processed_messages.add(message_id)
        
        # å¤„ç†æ¶ˆæ¯
        self._execute_logic(message_body)
        
        # æ¸…ç†è¿‡æœŸæ¶ˆæ¯IDï¼ˆç®€åŒ–å®ç°ï¼‰
        if len(self.processed_messages) > 10000:
            self.processed_messages.clear()
```

#### 1.2 çŠ¶æ€æ£€æŸ¥
```python
class OrderProcessor:
    def process_order_created(self, order_data):
        order_id = order_data['order_id']
        
        # æ£€æŸ¥è®¢å•æ˜¯å¦å·²ç»å¤„ç†è¿‡
        if self.is_order_processed(order_id):
            print(f"è®¢å• {order_id} å·²ç»å¤„ç†è¿‡")
            return
        
        # æ£€æŸ¥è®¢å•çŠ¶æ€
        current_status = self.get_order_status(order_id)
        if current_status != 'created':
            print(f"è®¢å•çŠ¶æ€ä¸åŒ¹é…: {current_status}")
            return
        
        # å¤„ç†è®¢å•
        self.update_order_status(order_id, 'processing')
        self._create_inventory_reservation(order_id)
        self._send_confirmation_email(order_id)
        self.update_order_status(order_id, 'processed')
    
    def is_order_processed(self, order_id):
        # æŸ¥è¯¢æ•°æ®åº“æˆ–ç¼“å­˜
        return self.db.order_status.get(order_id) == 'processed'
    
    def get_order_status(self, order_id):
        return self.db.order_status.get(order_id, 'unknown')
```

### 2. åˆ†å¸ƒå¼é”æœºåˆ¶

#### 2.1 åŸºäºRedisçš„åˆ†å¸ƒå¼é”
```python
import redis
import uuid

class DistributedLock:
    def __init__(self, redis_client, key, expire_time=30):
        self.redis_client = redis_client
        self.key = key
        self.expire_time = expire_time
        self.token = None
    
    def acquire(self, timeout=10):
        """å°è¯•è·å–é”"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            self.token = str(uuid.uuid4())
            
            result = self.redis_client.set(
                self.key, 
                self.token, 
                nx=True, 
                ex=self.expire_time
            )
            
            if result:
                return True
            
            time.sleep(0.1)
        
        return False
    
    def release(self):
        """é‡Šæ”¾é”"""
        if self.token:
            script = '''
            if redis.call("get", KEYS[1]) == ARGV[1] then
                return redis.call("del", KEYS[1])
            else
                return 0
            end
            '''
            self.redis_client.eval(script, 1, self.key, self.token)

# ä½¿ç”¨ç¤ºä¾‹
def process_message_with_lock(message_data):
    lock = DistributedLock(
        redis_client=redis.Redis(),
        key=f"message_lock:{message_data['id']}"
    )
    
    if lock.acquire(timeout=5):
        try:
            # å¤„ç†æ¶ˆæ¯
            process_message(message_data)
        finally:
            lock.release()
    else:
        print("æ— æ³•è·å–é”ï¼Œæ¶ˆæ¯å·²è¢«å…¶ä»–èŠ‚ç‚¹å¤„ç†")
```

## ğŸ” å®‰å…¨é…ç½®

### 1. ç”¨æˆ·è®¤è¯

#### 1.1 åˆ›å»ºç”¨æˆ·å’Œæƒé™
```bash
# åˆ›å»ºç”¨æˆ·
sudo rabbitmqctl add_user admin admin123

# è®¾ç½®ç”¨æˆ·æ ‡ç­¾
sudo rabbitmqctl set_user_tags admin administrator

# è®¾ç½®æƒé™
sudo rabbitmqctl set_permissions -p / admin ".*" ".*" ".*"

# åˆ é™¤ç”¨æˆ·
sudo rabbitmqctl delete_user username
```

#### 1.2 SSL/TLSé…ç½®
```bash
# ç”ŸæˆSSLè¯ä¹¦
sudo mkdir /etc/rabbitmq/ssl
cd /etc/rabbitmq/ssl

# ç”ŸæˆCAè¯ä¹¦
openssl genrsa -out ca-key.pem 2048
openssl req -new -x509 -days 1000 -key ca-key.pem -out ca-cert.pem -subj "/C=US/ST=CA/L=San Francisco/O=MyOrg/OU=MyUnit/CN=my-ca"

# ç”ŸæˆæœåŠ¡å™¨è¯ä¹¦
openssl genrsa -out server-key.pem 2048
openssl req -new -key server-key.pem -out server-req.pem -subj "/C=US/ST=CA/L=San Francisco/O=MyOrg/OU=MyUnit/CN=localhost"
openssl x509 -req -in server-req.pem -CA ca-cert.pem -CAkey ca-key.pem -CAcreateserial -out server-cert.pem -days 1000
```

### 2. ç½‘ç»œå®‰å…¨

#### 2.1 é˜²ç«å¢™é…ç½®
```bash
# å…è®¸ç‰¹å®šIPè®¿é—®
sudo ufw allow from 192.168.1.0/24 to any port 5672
sudo ufw allow from 192.168.1.0/24 to any port 15672

# é˜»æ­¢å¤–éƒ¨è®¿é—®ç®¡ç†ç•Œé¢
sudo ufw deny 15672
```

#### 2.2 ç½‘ç»œéš”ç¦»
```bash
# RabbitMQé…ç½®æ–‡ä»¶
# /etc/rabbitmq/rabbitmq.conf
listeners.tcp.default = 5672
loopback_users.guest = false
default_permissions.configure = (.*)
default_permissions.read = (.*)
default_permissions.write = (.*)
```

## ğŸ“Š ç›‘æ§ä¸è¿ç»´

### 1. æ€§èƒ½ç›‘æ§

#### 1.1 å…³é”®æŒ‡æ ‡
- **é˜Ÿåˆ—æ·±åº¦**ï¼šé˜Ÿåˆ—ä¸­æœªç¡®è®¤çš„æ¶ˆæ¯æ•°é‡
- **æ¶ˆæ¯é€Ÿç‡**ï¼šæ¯ç§’å¤„ç†çš„æ¶ˆæ¯æ•°
- **å†…å­˜ä½¿ç”¨**ï¼šRabbitMQè¿›ç¨‹å†…å­˜å ç”¨
- **ç£ç›˜ä½¿ç”¨**ï¼šæŒä¹…åŒ–å­˜å‚¨å ç”¨
- **è¿æ¥æ•°é‡**ï¼šæ´»è·ƒçš„å®¢æˆ·ç«¯è¿æ¥æ•°
- **é€šé“æ•°é‡**ï¼šæ´»è·ƒçš„AMQPé€šé“æ•°

#### 1.2 Prometheusç›‘æ§
```python
from prometheus_client import Gauge, Counter, Histogram

# å®šä¹‰ç›‘æ§æŒ‡æ ‡
QUEUE_LENGTH = Gauge('rabbitmq_queue_length', 'Queue length', ['queue_name'])
MESSAGE_RATE = Counter('rabbitmq_message_rate', 'Messages processed per second', ['queue_name'])
PROCESSING_TIME = Histogram('rabbitmq_processing_time', 'Message processing time', ['queue_name'])

def monitor_queue():
    """ç›‘æ§é˜Ÿåˆ—çŠ¶æ€"""
    while True:
        try:
            # è·å–é˜Ÿåˆ—çŠ¶æ€
            channel = get_rabbitmq_channel()
            queues = get_all_queues(channel)
            
            for queue in queues:
                QUEUE_LENGTH.labels(queue_name=queue['name']).set(queue['messages'])
                # å…¶ä»–ç›‘æ§é€»è¾‘...
                
        except Exception as e:
            print(f"ç›‘æ§é”™è¯¯: {e}")
        
        time.sleep(30)  # æ¯30ç§’ç›‘æ§ä¸€æ¬¡
```

### 2. æ—¥å¿—ç®¡ç†

#### 2.1 æ—¥å¿—çº§åˆ«é…ç½®
```python
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('rabbitmq_app.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def process_message(ch, method, properties, body):
    try:
        logger.info(f"å¼€å§‹å¤„ç†æ¶ˆæ¯: {properties.message_id}")
        
        # å¤„ç†é€»è¾‘
        result = process_order(body)
        
        logger.info(f"æ¶ˆæ¯å¤„ç†å®Œæˆ: {properties.message_id}, ç»“æœ: {result}")
        ch.basic_ack(delivery_tag=method.delivery_tag)
        
    except Exception as e:
        logger.error(f"æ¶ˆæ¯å¤„ç†å¤±è´¥: {properties.message_id}, é”™è¯¯: {e}")
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
```

#### 2.2 ç»“æ„åŒ–æ—¥å¿—
```python
import json
import structlog

# é…ç½®ç»“æ„åŒ–æ—¥å¿—
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

def log_message_processing(message_id, operation, status):
    logger.info(
        "message_processing",
        message_id=message_id,
        operation=operation,
        status=status,
        timestamp=datetime.now().isoformat()
    )
```

## ğŸ”§ æ•…éšœå¤„ç†ä¸æ¢å¤

### 1. å¸¸è§æ•…éšœåœºæ™¯

#### 1.1 æ¶ˆæ¯ç§¯å‹
```python
def handle_queue_backlog(channel, queue_name):
    """å¤„ç†é˜Ÿåˆ—ç§¯å‹"""
    # ç›‘æ§é˜Ÿåˆ—é•¿åº¦
    result = channel.queue_declare(queue=queue_name, passive=True)
    queue_length = result.method.message_count
    
    if queue_length > 1000:
        logger.warning(f"é˜Ÿåˆ— {queue_name} ç§¯å‹ä¸¥é‡: {queue_length} æ¡æ¶ˆæ¯")
        
        # å¯åŠ¨å¤šä¸ªæ¶ˆè´¹è€…å¤„ç†
        for i in range(5):  # å¯åŠ¨5ä¸ªæ¶ˆè´¹è€…
            start_consumer_thread(queue_name, f"worker_{i}")
    
    return queue_length
```

#### 1.2 ç½‘ç»œåˆ†åŒº
```python
class NetworkPartitionHandler:
    def __init__(self):
        self.partition_detection_time = None
        self.partition_threshold = 30  # 30ç§’
    
    def detect_partition(self):
        """æ£€æµ‹ç½‘ç»œåˆ†åŒº"""
        cluster_status = get_cluster_status()
        nodes = cluster_status['running_nodes']
        
        if len(nodes) < expected_nodes:
            if not self.partition_detection_time:
                self.partition_detection_time = time.time()
            elif time.time() - self.partition_detection_time > self.partition_threshold:
                logger.critical("æ£€æµ‹åˆ°ç½‘ç»œåˆ†åŒºï¼Œæ‰§è¡Œæ¢å¤ç­–ç•¥")
                self.execute_recovery_strategy()
        else:
            self.partition_detection_time = None
    
    def execute_recovery_strategy(self):
        """æ‰§è¡Œæ¢å¤ç­–ç•¥"""
        # é‡æ–°è¿æ¥èŠ‚ç‚¹
        restart_cluster_nodes()
        # é‡æ–°å»ºç«‹é•œåƒé˜Ÿåˆ—
        recreate_mirrored_queues()
        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        verify_data_consistency()
```

### 2. æ•°æ®æ¢å¤

#### 2.1 æ¶ˆæ¯æ¢å¤
```python
def recover_lost_messages(channel, recovery_queue='dead_letter_queue'):
    """ä»æ­»ä¿¡é˜Ÿåˆ—æ¢å¤ä¸¢å¤±çš„æ¶ˆæ¯"""
    try:
        # è·å–æ­»ä¿¡é˜Ÿåˆ—ä¸­çš„æ¶ˆæ¯
        result = channel.queue_declare(queue=recovery_queue, passive=True)
        message_count = result.method.message_count
        
        logger.info(f"å‘ç° {message_count} æ¡æ­»ä¿¡æ¶ˆæ¯ï¼Œå‡†å¤‡æ¢å¤")
        
        recovered_count = 0
        while message_count > 0:
            # è·å–ä¸€æ¡æ¶ˆæ¯
            method_frame, header_frame, body = channel.basic_get(
                queue=recovery_queue,
                auto_ack=False
            )
            
            if method_frame:
                try:
                    # è§£ææ¶ˆæ¯
                    message_data = json.loads(body.decode('utf-8'))
                    
                    # åˆ†ææ­»ä¿¡åŸå› 
                    if self.is_recoverable(message_data):
                        # æ¢å¤æ¶ˆæ¯åˆ°åŸå§‹é˜Ÿåˆ—
                        self.recover_message_to_original_queue(message_data)
                        recovered_count += 1
                    
                    # ç¡®è®¤å¤„ç†
                    channel.basic_ack(delivery_tag=method_frame.delivery_tag)
                    
                except Exception as e:
                    logger.error(f"æ¢å¤æ¶ˆæ¯å¤±è´¥: {e}")
                    channel.basic_nack(delivery_tag=method_frame.delivery_tag, requeue=True)
            
            message_count -= 1
        
        logger.info(f"æˆåŠŸæ¢å¤ {recovered_count} æ¡æ¶ˆæ¯")
        
    except Exception as e:
        logger.error(f"æ¶ˆæ¯æ¢å¤å¤±è´¥: {e}")
```

## ğŸš€ æœ€ä½³å®è·µ

### 1. æ€§èƒ½ä¼˜åŒ–

#### 1.1 è¿æ¥æ± ç®¡ç†
```python
import threading
from queue import Queue
import pika

class ConnectionPool:
    def __init__(self, connection_params, pool_size=10):
        self.connection_params = connection_params
        self.pool_size = pool_size
        self.connections = Queue()
        self.lock = threading.Lock()
    
    def get_connection(self):
        """è·å–è¿æ¥"""
        try:
            # å°è¯•ä»æ± ä¸­è·å–ç°æœ‰è¿æ¥
            connection = self.connections.get_nowait()
            
            # æ£€æŸ¥è¿æ¥æ˜¯å¦ä»ç„¶æœ‰æ•ˆ
            if connection.is_open:
                return connection
            
            connection.close()
            
        except:
            pass
        
        # åˆ›å»ºæ–°è¿æ¥
        return pika.BlockingConnection(self.connection_params)
    
    def return_connection(self, connection):
        """å½’è¿˜è¿æ¥"""
        try:
            if connection.is_open:
                self.connections.put_nowait(connection)
        except:
            connection.close()
    
    def close_all(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        while not self.connections.empty():
            try:
                connection = self.connections.get_nowait()
                connection.close()
            except:
                break
```

#### 1.2 æ‰¹å¤„ç†ä¼˜åŒ–
```python
class BatchMessageHandler:
    def __init__(self, batch_size=100, batch_timeout=5):
        self.batch_size = batch_size
        self.batch_timeout = batch_timeout
        self.pending_messages = []
        self.last_batch_time = time.time()
    
    def add_message(self, message_data):
        """æ·»åŠ æ¶ˆæ¯åˆ°æ‰¹å¤„ç†"""
        self.pending_messages.append(message_data)
        
        # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æ‰¹å¤„ç†å¤§å°æˆ–è¶…æ—¶
        if (len(self.pending_messages) >= self.batch_size or 
            time.time() - self.last_batch_time > self.batch_timeout):
            return self.process_batch()
        
        return False
    
    def process_batch(self):
        """å¤„ç†æ‰¹æ¬¡"""
        if not self.pending_messages:
            return False
        
        batch = self.pending_messages.copy()
        self.pending_messages.clear()
        self.last_batch_time = time.time()
        
        try:
            # æ‰¹é‡å¤„ç†æ¶ˆæ¯
            self.batch_process(batch)
            logger.info(f"æ‰¹å¤„ç†å®Œæˆï¼Œå¤„ç†äº† {len(batch)} æ¡æ¶ˆæ¯")
            return True
            
        except Exception as e:
            logger.error(f"æ‰¹å¤„ç†å¤±è´¥: {e}")
            # å°†æ¶ˆæ¯é‡æ–°åŠ å…¥å¾…å¤„ç†é˜Ÿåˆ—
            self.pending_messages.extend(batch)
            return False
    
    def batch_process(self, messages):
        """å®é™…æ‰¹é‡å¤„ç†é€»è¾‘"""
        # ä½¿ç”¨æ•°æ®åº“äº‹åŠ¡æ‰¹é‡æ’å…¥
        with self.db.transaction():
            for message in messages:
                self.process_single_message(message)
```

### 2. æ¶æ„è®¾è®¡æ¨¡å¼

#### 2.1 äº‹ä»¶é©±åŠ¨æ¶æ„
```python
class EventBus:
    def __init__(self):
        self.subscribers = {}
    
    def subscribe(self, event_type, handler):
        """è®¢é˜…äº‹ä»¶"""
        if event_type not in self.subscribers:
            self.subscribers[event_type] = []
        self.subscribers[event_type].append(handler)
    
    def publish(self, event_type, data):
        """å‘å¸ƒäº‹ä»¶"""
        if event_type in self.subscribers:
            for handler in self.subscribers[event_type]:
                try:
                    handler(data)
                except Exception as e:
                    logger.error(f"äº‹ä»¶å¤„ç†å™¨æ‰§è¡Œå¤±è´¥: {e}")
    
    def handle_rabbitmq_message(self, ch, method, properties, body):
        """å¤„ç†RabbitMQæ¶ˆæ¯å¹¶å‘å¸ƒäº‹ä»¶"""
        try:
            event_data = json.loads(body.decode('utf-8'))
            event_type = event_data.get('type')
            
            if event_type:
                self.publish(event_type, event_data)
            
            ch.basic_ack(delivery_tag=method.delivery_tag)
            
        except Exception as e:
            logger.error(f"äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
```

#### 2.2 CQRSæ¨¡å¼
```python
class CommandHandler:
    """å‘½ä»¤å¤„ç†å™¨ - å†™æ“ä½œ"""
    def __init__(self, rabbitmq_channel):
        self.channel = rabbitmq_channel
    
    def handle_order_created(self, order_data):
        """å¤„ç†è®¢å•åˆ›å»ºå‘½ä»¤"""
        try:
            # éªŒè¯å‘½ä»¤
            self.validate_order(order_data)
            
            # æ›´æ–°å†™æ¨¡å‹ï¼ˆæ•°æ®åº“ï¼‰
            order_id = self.create_order(order_data)
            
            # å‘å¸ƒé¢†åŸŸäº‹ä»¶
            event = {
                'type': 'order_created',
                'order_id': order_id,
                'data': order_data,
                'timestamp': datetime.now().isoformat()
            }
            
            self.publish_event(event)
            
        except Exception as e:
            logger.error(f"è®¢å•åˆ›å»ºå¤±è´¥: {e}")
            raise

class EventHandler:
    """äº‹ä»¶å¤„ç†å™¨ - è¯»æ“ä½œ"""
    def __init__(self, rabbitmq_channel, read_model_db):
        self.channel = rabbitmq_channel
        self.read_model_db = read_model_db
    
    def handle_order_created_event(self, ch, method, properties, body):
        """å¤„ç†è®¢å•åˆ›å»ºäº‹ä»¶"""
        try:
            event_data = json.loads(body.decode('utf-8'))
            
            # æ›´æ–°è¯»æ¨¡å‹ï¼ˆç¼“å­˜ã€æœç´¢ç´¢å¼•ç­‰ï¼‰
            self.update_order_summary(event_data)
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.update_statistics(event_data)
            
            ch.basic_ack(delivery_tag=method.delivery_tag)
            
        except Exception as e:
            logger.error(f"äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
```

## ğŸ“ˆ æ‰©å±•é˜…è¯»

### 1. æ€§èƒ½è°ƒä¼˜
- RabbitMQæ€§èƒ½è°ƒä¼˜æŒ‡å—
- é›†ç¾¤å®¹é‡è§„åˆ’
- é«˜å¹¶å‘åœºæ™¯ä¼˜åŒ–

### 2. ç›‘æ§è¿ç»´
- Prometheus + Grafanaç›‘æ§æ–¹æ¡ˆ
- ELKæ—¥å¿—åˆ†æç³»ç»Ÿ
- å‘Šè­¦è§„åˆ™è®¾è®¡

### 3. æ¶æ„æ¨¡å¼
- äº‹ä»¶æº¯æºï¼ˆEvent Sourcingï¼‰
- Sagaåˆ†å¸ƒå¼äº‹åŠ¡
- æ¶ˆæ¯é©±åŠ¨å¾®æœåŠ¡

### 4. æ•…éšœå¤„ç†
- ç¾éš¾æ¢å¤è®¡åˆ’
- æ•°æ®ä¸€è‡´æ€§ä¿éšœ
- ä¸šåŠ¡è¿ç»­æ€§è®¾è®¡

## ğŸ¯ æ€»ç»“

RabbitMQçš„é«˜çº§ç‰¹æ€§ä¸ºä¼ä¸šçº§æ¶ˆæ¯ç³»ç»Ÿæä¾›äº†å¼ºå¤§çš„åŸºç¡€èƒ½åŠ›ï¼š

1. **å¯é ä¼ é€’**ï¼šé€šè¿‡æ¶ˆæ¯ç¡®è®¤å’ŒæŒä¹…åŒ–ç¡®ä¿æ¶ˆæ¯ä¸ä¸¢å¤±
2. **çµæ´»è·¯ç”±**ï¼šå¤šç§äº¤æ¢æœºç±»å‹æ”¯æŒå¤æ‚çš„è·¯ç”±éœ€æ±‚
3. **é«˜å¯ç”¨**ï¼šé›†ç¾¤å’Œé•œåƒé˜Ÿåˆ—æä¾›é«˜å¯ç”¨æ€§ä¿éšœ
4. **å¯æ‰©å±•**ï¼šæ”¯æŒæ°´å¹³æ‰©å±•å’Œè´Ÿè½½å‡è¡¡
5. **å®‰å…¨æ€§**ï¼šå®Œæ•´çš„è®¤è¯æˆæƒå’Œå®‰å…¨æœºåˆ¶
6. **å¯ç›‘æ§**ï¼šä¸°å¯Œçš„ç›‘æ§æŒ‡æ ‡å’Œè¿ç»´å·¥å…·

æŒæ¡è¿™äº›é«˜çº§ç‰¹æ€§ï¼Œèƒ½å¤Ÿå¸®åŠ©æ‚¨æ„å»ºå¥å£®ã€é«˜æ•ˆã€å¯æ‰©å±•çš„ä¼ä¸šçº§æ¶ˆæ¯ç³»ç»Ÿã€‚åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œéœ€è¦æ ¹æ®ä¸šåŠ¡éœ€æ±‚é€‰æ‹©åˆé€‚çš„ç‰¹æ€§ç»„åˆï¼Œå¹¶è¿›è¡Œå……åˆ†çš„æµ‹è¯•å’Œè°ƒä¼˜ã€‚

**ä¸‹ä¸€æ­¥å­¦ä¹ **ï¼šå»ºè®®ç»“åˆå®é™…é¡¹ç›®åœºæ™¯ï¼Œæ·±å…¥å­¦ä¹ RabbitMQä¸å…·ä½“ä¸šåŠ¡ç³»ç»Ÿçš„é›†æˆæ–¹æ¡ˆï¼Œä»¥åŠåœ¨äº‘åŸç”Ÿç¯å¢ƒä¸‹çš„éƒ¨ç½²å’Œè¿ç»´å®è·µã€‚