# ç¬¬4ç« ï¼šRabbitMQæ¶ˆæ¯ç¡®è®¤ä¸æŒä¹…åŒ–

## ğŸ“– æ¦‚è¿°

æ¶ˆæ¯ç¡®è®¤ä¸æŒä¹…åŒ–æ˜¯RabbitMQä¿è¯æ¶ˆæ¯å¯é ä¼ é€’çš„æ ¸å¿ƒæœºåˆ¶ã€‚åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œæ¶ˆæ¯çš„å¯é ä¼ é€’è‡³å…³é‡è¦ï¼Œç‰¹åˆ«æ˜¯åœ¨é‡‘èã€ç”µå•†ã€ä¼ä¸šæœåŠ¡ç­‰å¯¹æ•°æ®ä¸€è‡´æ€§è¦æ±‚ä¸¥æ ¼çš„åœºæ™¯ã€‚æœ¬ç« å°†æ·±å…¥æ¢è®¨RabbitMQçš„æ¶ˆæ¯ç¡®è®¤æœºåˆ¶ã€æŒä¹…åŒ–ç­–ç•¥ï¼Œä»¥åŠå¦‚ä½•æ„å»ºé«˜å¯é çš„æ¶ˆæ¯ä¼ é€’ç³»ç»Ÿã€‚

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæ‚¨å°†æŒæ¡ï¼š

- ç†è§£RabbitMQæ¶ˆæ¯ç¡®è®¤çš„ä¸‰ç§æœºåˆ¶
- æŒæ¡è‡ªåŠ¨ç¡®è®¤vsæ‰‹åŠ¨ç¡®è®¤çš„é€‚ç”¨åœºæ™¯
- æ·±å…¥ç†è§£é˜Ÿåˆ—å’Œæ¶ˆæ¯çš„æŒä¹…åŒ–ç­–ç•¥
- å®ç°å‘å¸ƒè€…ç¡®è®¤æœºåˆ¶
- è®¾è®¡å’Œé…ç½®æ­»ä¿¡é˜Ÿåˆ—å¤„ç†æœºåˆ¶
- æ„å»ºé«˜å¯ç”¨çš„æ¶ˆæ¯ä¼ é€’æ¶æ„
- ä¼˜åŒ–æ¶ˆæ¯ä¼ é€’çš„æ€§èƒ½å’Œå¯é æ€§

## ğŸ“‹ ç›®å½•

- [4.1 æ¶ˆæ¯ç¡®è®¤æœºåˆ¶æ¦‚è¿°](#41-æ¶ˆæ¯ç¡®è®¤æœºåˆ¶æ¦‚è¿°)
- [4.2 è‡ªåŠ¨ç¡®è®¤æ¨¡å¼](#42-è‡ªåŠ¨ç¡®è®¤æ¨¡å¼)
- [4.3 æ‰‹åŠ¨ç¡®è®¤æ¨¡å¼](#43-æ‰‹åŠ¨ç¡®è®¤æ¨¡å¼)
- [4.4 æ¶ˆæ¯æŒä¹…åŒ–ç­–ç•¥](#44-æ¶ˆæ¯æŒä¹…åŒ–ç­–ç•¥)
- [4.5 å‘å¸ƒè€…ç¡®è®¤æœºåˆ¶](#45-å‘å¸ƒè€…ç¡®è®¤æœºåˆ¶)
- [4.6 æ­»ä¿¡é˜Ÿåˆ—è®¾è®¡](#46-æ­»ä¿¡é˜Ÿåˆ—è®¾è®¡)
- [4.7 é«˜å¯ç”¨æ¶æ„è®¾è®¡](#47-é«˜å¯ç”¨æ¶æ„è®¾è®¡)
- [4.8 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](#48-æ€§èƒ½ä¼˜åŒ–ç­–ç•¥)
- [4.9 ç›‘æ§ä¸è¿ç»´](#49-ç›‘æ§ä¸è¿ç»´)
- [4.10 æœ€ä½³å®è·µ](#410-æœ€ä½³å®è·µ)

---

## 4.1 æ¶ˆæ¯ç¡®è®¤æœºåˆ¶æ¦‚è¿°

### 4.1.1 ç¡®è®¤æœºåˆ¶çš„é‡è¦æ€§

åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œæ¶ˆæ¯ç¡®è®¤æœºåˆ¶ç¡®ä¿ï¼š

- **æ¶ˆæ¯ä¸ä¸¢å¤±**ï¼šé˜²æ­¢æ¶ˆæ¯åœ¨ä¼ è¾“è¿‡ç¨‹ä¸­ä¸¢å¤±
- **å¤„ç†å®Œæ•´æ€§**ï¼šç¡®ä¿æ¶ˆæ¯è¢«å®Œæ•´å¤„ç†
- **ç³»ç»Ÿå¯é æ€§**ï¼šæé«˜æ•´ä¸ªæ¶ˆæ¯ç³»ç»Ÿçš„å¯é æ€§
- **æ•°æ®ä¸€è‡´æ€§**ï¼šç»´æŠ¤åˆ†å¸ƒå¼ç³»ç»Ÿçš„æ•°æ®ä¸€è‡´æ€§

### 4.1.2 ç¡®è®¤æœºåˆ¶ç±»å‹

```python
import pika
import time
from typing import Any, Callable, Optional
from dataclasses import dataclass
from enum import Enum
import logging

class AcknowledgeType(Enum):
    """ç¡®è®¤ç±»å‹æšä¸¾"""
    AUTO = "auto"           # è‡ªåŠ¨ç¡®è®¤
    MANUAL = "manual"       # æ‰‹åŠ¨ç¡®è®¤
    MULTIPLE = "multiple"   # æ‰¹é‡ç¡®è®¤

@dataclass
class MessageContext:
    """æ¶ˆæ¯ä¸Šä¸‹æ–‡"""
    delivery_tag: str
    exchange: str
    routing_key: str
    redelivered: bool
    message_id: Optional[str] = None
    timestamp: Optional[float] = None

class AcknowledgeManager:
    """æ¶ˆæ¯ç¡®è®¤ç®¡ç†å™¨"""
    
    def __init__(self, channel: pika.channel.Channel):
        self.channel = channel
        self.pending_messages = {}
        self.logger = logging.getLogger(__name__)
        
    def handle_message(self, 
                      ch: pika.channel.Channel,
                      method: pika.spec.Basic.Deliver,
                      properties: pika.spec.Basic.Properties,
                      body: bytes,
                      ack_type: AcknowledgeType = AcknowledgeType.AUTO) -> MessageContext:
        """å¤„ç†æ¶ˆæ¯çš„ä¸»å…¥å£"""
        
        # åˆ›å»ºæ¶ˆæ¯ä¸Šä¸‹æ–‡
        context = MessageContext(
            delivery_tag=method.delivery_tag,
            exchange=method.exchange,
            routing_key=method.routing_key,
            redelivered=method.redelivered,
            message_id=properties.message_id,
            timestamp=time.time()
        )
        
        # æ ¹æ®ç¡®è®¤ç±»å‹å¤„ç†æ¶ˆæ¯
        if ack_type == AcknowledgeType.AUTO:
            self._handle_auto_ack(context, body)
        elif ack_type == AcknowledgeType.MANUAL:
            self._handle_manual_ack(context, body)
        elif ack_type == AcknowledgeType.MULTIPLE:
            self._handle_multiple_ack(context, body)
            
        return context
        
    def _handle_auto_ack(self, context: MessageContext, body: bytes):
        """å¤„ç†è‡ªåŠ¨ç¡®è®¤"""
        self.logger.info(f"å¤„ç†è‡ªåŠ¨ç¡®è®¤æ¶ˆæ¯: {context.message_id}")
        try:
            # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†
            self._process_message(body)
            self.logger.info(f"è‡ªåŠ¨ç¡®è®¤æ¶ˆæ¯å¤„ç†å®Œæˆ: {context.message_id}")
        except Exception as e:
            self.logger.error(f"è‡ªåŠ¨ç¡®è®¤æ¶ˆæ¯å¤„ç†å¤±è´¥: {e}")
            # è‡ªåŠ¨ç¡®è®¤æ¨¡å¼ä¸‹ï¼Œå¼‚å¸¸ä¹Ÿä¼šå¯¼è‡´æ¶ˆæ¯è¢«æ ‡è®°ä¸ºå·²å¤„ç†
            
    def _handle_manual_ack(self, context: MessageContext, body: bytes):
        """å¤„ç†æ‰‹åŠ¨ç¡®è®¤"""
        self.logger.info(f"å¤„ç†æ‰‹åŠ¨ç¡®è®¤æ¶ˆæ¯: {context.message_id}")
        try:
            # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†
            result = self._process_message(body)
            # åªæœ‰å¤„ç†æˆåŠŸåæ‰ç¡®è®¤æ¶ˆæ¯
            if result:
                self.manual_ack(context)
            else:
                self.manual_nack(context, requeue=True)
        except Exception as e:
            self.logger.error(f"æ‰‹åŠ¨ç¡®è®¤æ¶ˆæ¯å¤„ç†å¤±è´¥: {e}")
            # å¤„ç†å¤±è´¥ï¼Œå¦è®¤æ¶ˆæ¯å¹¶é‡æ–°å…¥é˜Ÿ
            self.manual_nack(context, requeue=True)
            
    def _handle_multiple_ack(self, context: MessageContext, body: bytes):
        """å¤„ç†æ‰¹é‡ç¡®è®¤"""
        self.logger.info(f"å¤„ç†æ‰¹é‡ç¡®è®¤æ¶ˆæ¯: {context.message_id}")
        # å­˜å‚¨å¾…ç¡®è®¤æ¶ˆæ¯
        self.pending_messages[context.delivery_tag] = {
            'context': context,
            'body': body,
            'processed': False
        }
        
    def manual_ack(self, context: MessageContext):
        """æ‰‹åŠ¨ç¡®è®¤æ¶ˆæ¯"""
        try:
            self.channel.basic_ack(delivery_tag=context.delivery_tag)
            self.logger.info(f"æ¶ˆæ¯æ‰‹åŠ¨ç¡®è®¤æˆåŠŸ: {context.message_id}")
        except Exception as e:
            self.logger.error(f"æ¶ˆæ¯æ‰‹åŠ¨ç¡®è®¤å¤±è´¥: {e}")
            
    def manual_nack(self, context: MessageContext, requeue: bool = True):
        """æ‰‹åŠ¨å¦è®¤æ¶ˆæ¯"""
        try:
            self.channel.basic_nack(
                delivery_tag=context.delivery_tag,
                requeue=requeue
            )
            self.logger.info(f"æ¶ˆæ¯æ‰‹åŠ¨å¦è®¤ {'é‡æ–°å…¥é˜Ÿ' if requeue else 'ä¸¢å¼ƒ'}: {context.message_id}")
        except Exception as e:
            self.logger.error(f"æ¶ˆæ¯æ‰‹åŠ¨å¦è®¤å¤±è´¥: {e}")
            
    def batch_ack(self, delivery_tag: str):
        """æ‰¹é‡ç¡®è®¤æ¶ˆæ¯"""
        try:
            if delivery_tag in self.pending_messages:
                self.channel.basic_ack(delivery_tag=delivery_tag, multiple=True)
                self.pending_messages[delivery_tag]['processed'] = True
                self.logger.info(f"æ‰¹é‡ç¡®è®¤æ¶ˆæ¯: {delivery_tag}")
        except Exception as e:
            self.logger.error(f"æ‰¹é‡ç¡®è®¤å¤±è´¥: {e}")
            
    def _process_message(self, body: bytes) -> bool:
        """æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†é€»è¾‘"""
        # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†æ—¶é—´
        time.sleep(0.1)
        # æ¨¡æ‹Ÿå¤„ç†ç»“æœï¼Œ90%æˆåŠŸç‡
        import random
        return random.random() > 0.1
```

---

## 4.2 è‡ªåŠ¨ç¡®è®¤æ¨¡å¼

### 4.2.1 å·¥ä½œåŸç†

```python
import pika

class AutoAckConsumer:
    """è‡ªåŠ¨ç¡®è®¤æ¨¡å¼æ¶ˆè´¹è€…"""
    
    def __init__(self, connection_params: dict):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        self.is_consuming = False
        
    def setup_connection(self):
        """å»ºç«‹è¿æ¥"""
        credentials = pika.PlainCredentials(
            self.connection_params['username'],
            self.connection_params['password']
        )
        
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(
                host=self.connection_params['host'],
                port=self.connection_params['port'],
                credentials=credentials
            )
        )
        
        self.channel = self.connection.channel()
        
    def consume_messages_auto_ack(self, queue_name: str):
        """æ¶ˆè´¹æ¶ˆæ¯å¹¶è‡ªåŠ¨ç¡®è®¤"""
        self.setup_connection()
        
        # å£°æ˜é˜Ÿåˆ—
        self.channel.queue_declare(queue=queue_name, durable=True)
        
        # è®¾ç½®æ¶ˆè´¹è€…ï¼Œä½¿ç”¨auto_ack=Trueè¿›è¡Œè‡ªåŠ¨ç¡®è®¤
        self.channel.basic_consume(
            queue=queue_name,
            auto_ack=True,  # å…³é”®ï¼šè®¾ç½®ä¸ºè‡ªåŠ¨ç¡®è®¤
            on_message_callback=self.auto_ack_callback
        )
        
        self.is_consuming = True
        print("å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯ï¼ˆè‡ªåŠ¨ç¡®è®¤æ¨¡å¼ï¼‰...")
        
        # å¼€å§‹æ¶ˆè´¹
        try:
            self.channel.start_consuming()
        except KeyboardInterrupt:
            self.channel.stop_consuming()
            
    def auto_ack_callback(self, ch: pika.channel.Channel,
                         method: pika.spec.Basic.Deliver,
                         properties: pika.spec.Basic.Properties,
                         body: bytes):
        """è‡ªåŠ¨ç¡®è®¤å›è°ƒå‡½æ•°"""
        try:
            message_id = properties.message_id
            print(f"[è‡ªåŠ¨ç¡®è®¤] æ”¶åˆ°æ¶ˆæ¯: {message_id}")
            print(f"[è‡ªåŠ¨ç¡®è®¤] æ¶ˆæ¯å†…å®¹: {body.decode()}")
            
            # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†
            self._process_message(body)
            
            print(f"[è‡ªåŠ¨ç¡®è®¤] æ¶ˆæ¯å¤„ç†å®Œæˆï¼ˆå·²è‡ªåŠ¨ç¡®è®¤ï¼‰: {message_id}")
            
        except Exception as e:
            print(f"[è‡ªåŠ¨ç¡®è®¤] æ¶ˆæ¯å¤„ç†å¤±è´¥: {e}")
            # æ³¨æ„ï¼šåœ¨è‡ªåŠ¨ç¡®è®¤æ¨¡å¼ä¸‹ï¼Œå³ä½¿å¤„ç†å¤±è´¥ï¼Œæ¶ˆæ¯ä¹Ÿä¼šè¢«æ ‡è®°ä¸ºå·²ç¡®è®¤
            
    def _process_message(self, body: bytes):
        """æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†"""
        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        import time
        time.sleep(0.5)
        
        # æ¨¡æ‹Ÿå¤„ç†é€»è¾‘
        message_content = body.decode()
        print(f"[è‡ªåŠ¨ç¡®è®¤] æ­£åœ¨å¤„ç†æ¶ˆæ¯: {message_content}")
        
        # æ¨¡æ‹Ÿå¯èƒ½çš„å¤„ç†å¤±è´¥
        import random
        if random.random() < 0.1:  # 10%å¤±è´¥ç‡
            raise Exception("æ¨¡æ‹Ÿå¤„ç†å¤±è´¥")
            
        print(f"[è‡ªåŠ¨ç¡®è®¤] å¤„ç†æˆåŠŸ")
        
    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if self.connection and self.connection.is_open:
            self.connection.close()
```

### 4.2.2 è‡ªåŠ¨ç¡®è®¤çš„ä½¿ç”¨åœºæ™¯

```python
class AutoAckUseCase:
    """è‡ªåŠ¨ç¡®è®¤ä½¿ç”¨åœºæ™¯ç¤ºä¾‹"""
    
    @staticmethod
    def scenario_1_high_throughput_logging():
        """åœºæ™¯1ï¼šé«˜ååé‡æ—¥å¿—æ”¶é›†"""
        print("=== åœºæ™¯1: é«˜ååé‡æ—¥å¿—æ”¶é›† ===")
        print("é€‚ç”¨æƒ…å†µï¼š")
        print("- å¯¹æ¶ˆæ¯ä¸¢å¤±ä¸æ•æ„Ÿ")
        print("- è¿½æ±‚æœ€é«˜ååé‡")
        print("- æ—¥å¿—ã€ç›‘æ§ç­‰éå…³é”®æ•°æ®")
        print("- å¯ä»¥å®¹å¿ä¸€å®šç¨‹åº¦çš„ä¸¢å¤±")
        
    @staticmethod
    def scenario_2_realtime_notification():
        """åœºæ™¯2ï¼šå®æ—¶é€šçŸ¥"""
        print("\n=== åœºæ™¯2: å®æ—¶é€šçŸ¥ç³»ç»Ÿ ===")
        print("é€‚ç”¨æƒ…å†µï¼š")
        print("- å®æ—¶æ€§è¦æ±‚é«˜")
        print("- å°‘é‡æ¶ˆæ¯ä¸¢å¤±å¯ä»¥æ¥å—")
        print("- ç”¨æˆ·ä½“éªŒä¼˜å…ˆäºå¯é æ€§")
        print("- ç¤¾äº¤åª’ä½“ç‚¹èµã€é€šçŸ¥ç­‰")
        
    @staticmethod
    def scenario_3_metric_collection():
        """åœºæ™¯3ï¼šæŒ‡æ ‡æ”¶é›†"""
        print("\n=== åœºæ™¯3: æ€§èƒ½æŒ‡æ ‡æ”¶é›† ===")
        print("é€‚ç”¨æƒ…å†µï¼š")
        print("- ç»Ÿè®¡æ•°æ®æ”¶é›†")
        print("- ä¸´æ—¶æ€§æ•°æ®")
        print("- å¯ä»¥é€šè¿‡å…¶ä»–æ–¹å¼è¡¥å……ä¸¢å¤±æ•°æ®")
        print("- APMã€ç³»ç»Ÿç›‘æ§ç­‰")
        
    @staticmethod
    def anti_pattern_scenarios():
        """åæ¨¡å¼åœºæ™¯ï¼šä¸é€‚åˆè‡ªåŠ¨ç¡®è®¤çš„æƒ…å†µ"""
        print("\n=== ä¸é€‚åˆè‡ªåŠ¨ç¡®è®¤çš„åœºæ™¯ ===")
        print("- è´¢åŠ¡äº¤æ˜“æ•°æ®")
        print("- è®¢å•å¤„ç†ç³»ç»Ÿ")
        print("- ç”¨æˆ·æ³¨å†Œæµç¨‹")
        print("- æ•°æ®åŒæ­¥ä»»åŠ¡")
        print("- ä»»ä½•ä¸èƒ½ä¸¢å¤±çš„å…³é”®ä¸šåŠ¡æ•°æ®")
```

### 4.2.3 è‡ªåŠ¨ç¡®è®¤çš„æ€§èƒ½ä¼˜åŒ–

```python
import threading
from queue import Queue
from concurrent.futures import ThreadPoolExecutor
import time

class OptimizedAutoAckConsumer:
    """ä¼˜åŒ–çš„è‡ªåŠ¨ç¡®è®¤æ¶ˆè´¹è€…"""
    
    def __init__(self, connection_params: dict, worker_count: int = 5):
        self.connection_params = connection_params
        self.worker_count = worker_count
        self.connection = None
        self.channel = None
        self.message_queue = Queue(maxsize=1000)
        self.workers = []
        self.is_running = False
        
    def start_consuming(self, queue_name: str):
        """å¯åŠ¨ä¼˜åŒ–çš„æ¶ˆè´¹"""
        self.setup_connection()
        self.setup_queue(queue_name)
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹æ± 
        self.start_worker_pool()
        
        # å¼€å§‹æ¥æ”¶æ¶ˆæ¯
        self.start_consuming_messages(queue_name)
        
    def setup_connection(self):
        """è®¾ç½®è¿æ¥"""
        credentials = pika.PlainCredentials(
            self.connection_params['username'],
            self.connection_params['password']
        )
        
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(
                host=self.connection_params['host'],
                port=self.connection_params['port'],
                credentials=credentials,
                connection_attempts=3,
                retry_delay=5
            )
        )
        
        self.channel = self.connection.channel()
        
    def setup_queue(self, queue_name: str):
        """è®¾ç½®é˜Ÿåˆ—"""
        self.channel.queue_declare(queue=queue_name, durable=True)
        
        # ä¼˜åŒ–ï¼šè®¾ç½®é¢„å–æ•°é‡ä»¥æé«˜æ€§èƒ½
        self.channel.basic_qos(prefetch_count=100)
        
    def start_worker_pool(self):
        """å¯åŠ¨å·¥ä½œçº¿ç¨‹æ± """
        self.is_running = True
        for i in range(self.worker_count):
            worker = threading.Thread(
                target=self.message_worker,
                args=(f"worker-{i}",)
            )
            worker.daemon = True
            worker.start()
            self.workers.append(worker)
            
    def start_consuming_messages(self, queue_name: str):
        """å¼€å§‹æ¥æ”¶æ¶ˆæ¯"""
        def simple_callback(ch, method, properties, body):
            # å°†æ¶ˆæ¯æ”¾å…¥é˜Ÿåˆ—ï¼Œä¸è¿›è¡Œä¸šåŠ¡å¤„ç†
            self.message_queue.put({
                'body': body,
                'message_id': properties.message_id,
                'delivery_tag': method.delivery_tag
            })
            
        self.channel.basic_consume(
            queue=queue_name,
            auto_ack=True,
            on_message_callback=simple_callback
        )
        
        print(f"å¯åŠ¨{self.worker_count}ä¸ªå·¥ä½œçº¿ç¨‹...")
        try:
            self.channel.start_consuming()
        except Exception as e:
            print(f"æ¶ˆè´¹é”™è¯¯: {e}")
        finally:
            self.is_running = False
            
    def message_worker(self, worker_name: str):
        """æ¶ˆæ¯å·¥ä½œçº¿ç¨‹"""
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—è·å–æ¶ˆæ¯
                message = self.message_queue.get(timeout=1)
                self.process_message(worker_name, message)
                self.message_queue.task_done()
            except:
                continue  # è¶…æ—¶ç»§ç»­å¾ªç¯
                
    def process_message(self, worker_name: str, message: dict):
        """å¤„ç†æ¶ˆæ¯"""
        try:
            body = message['body']
            message_id = message['message_id']
            
            # ä¸šåŠ¡å¤„ç†é€»è¾‘
            start_time = time.time()
            result = self.business_logic(body)
            process_time = time.time() - start_time
            
            print(f"[{worker_name}] å¤„ç†æ¶ˆæ¯ {message_id} ç”¨æ—¶: {process_time:.3f}s")
            
        except Exception as e:
            print(f"[{worker_name}] å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
            
    def business_logic(self, body: bytes) -> bool:
        """ä¸šåŠ¡å¤„ç†é€»è¾‘"""
        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        time.sleep(0.1)
        return True
        
    def stop(self):
        """åœæ­¢æ¶ˆè´¹"""
        self.is_running = False
        if self.connection and self.connection.is_open:
            self.connection.close()
```

---

## 4.3 æ‰‹åŠ¨ç¡®è®¤æ¨¡å¼

### 4.3.1 åŸºç¡€æ‰‹åŠ¨ç¡®è®¤

```python
class ManualAckConsumer:
    """æ‰‹åŠ¨ç¡®è®¤æ¨¡å¼æ¶ˆè´¹è€…"""
    
    def __init__(self, connection_params: dict):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        self.acknowledge_manager = None
        self.processed_messages = 0
        self.failed_messages = 0
        
    def consume_with_manual_ack(self, queue_name: str):
        """ä½¿ç”¨æ‰‹åŠ¨ç¡®è®¤æ¶ˆè´¹æ¶ˆæ¯"""
        self.setup_connection()
        
        # å£°æ˜é˜Ÿåˆ—
        self.channel.queue_declare(queue=queue_name, durable=True)
        
        # è®¾ç½®é¢„å–æ•°é‡ï¼Œç¡®ä¿è´Ÿè½½å‡è¡¡
        self.channel.basic_qos(prefetch_count=1)
        
        # åˆ›å»ºç¡®è®¤ç®¡ç†å™¨
        self.acknowledge_manager = AcknowledgeManager(self.channel)
        
        # è®¾ç½®æ¶ˆè´¹è€…ï¼ˆauto_ack=Falseè¡¨ç¤ºæ‰‹åŠ¨ç¡®è®¤ï¼‰
        self.channel.basic_consume(
            queue=queue_name,
            auto_ack=False,  # å…³é”®ï¼šè®¾ç½®ä¸ºæ‰‹åŠ¨ç¡®è®¤
            on_message_callback=self.manual_ack_callback
        )
        
        print("å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯ï¼ˆæ‰‹åŠ¨ç¡®è®¤æ¨¡å¼ï¼‰...")
        
        try:
            self.channel.start_consuming()
        except KeyboardInterrupt:
            self.channel.stop_consuming()
            
    def manual_ack_callback(self, ch: pika.channel.Channel,
                          method: pika.spec.Basic.Deliver,
                          properties: pika.spec.Basic.Properties,
                          body: bytes):
        """æ‰‹åŠ¨ç¡®è®¤å›è°ƒå‡½æ•°"""
        try:
            message_id = properties.message_id
            print(f"[æ‰‹åŠ¨ç¡®è®¤] æ”¶åˆ°æ¶ˆæ¯: {message_id}")
            
            # åˆ›å»ºæ¶ˆæ¯ä¸Šä¸‹æ–‡
            context = MessageContext(
                delivery_tag=method.delivery_tag,
                exchange=method.exchange,
                routing_key=method.routing_key,
                redelivered=method.redelivered,
                message_id=message_id,
                timestamp=time.time()
            )
            
            # å¤„ç†æ¶ˆæ¯
            success = self.process_message_with_retry(body)
            
            if success:
                # å¤„ç†æˆåŠŸï¼Œç¡®è®¤æ¶ˆæ¯
                self.manual_ack(context)
                self.processed_messages += 1
                print(f"[æ‰‹åŠ¨ç¡®è®¤] æ¶ˆæ¯å¤„ç†æˆåŠŸå¹¶ç¡®è®¤: {message_id}")
            else:
                # å¤„ç†å¤±è´¥ï¼Œå¦è®¤æ¶ˆæ¯
                self.manual_nack(context, requeue=True)
                self.failed_messages += 1
                print(f"[æ‰‹åŠ¨ç¡®è®¤] æ¶ˆæ¯å¤„ç†å¤±è´¥å¹¶å¦è®¤: {message_id}")
                
        except Exception as e:
            print(f"[æ‰‹åŠ¨ç¡®è®¤] æ¶ˆæ¯å¤„ç†å¼‚å¸¸: {e}")
            # å¼‚å¸¸æƒ…å†µä¸‹ä¹Ÿå¦è®¤æ¶ˆæ¯
            context = MessageContext(
                delivery_tag=method.delivery_tag,
                exchange=method.exchange,
                routing_key=method.routing_key,
                redelivered=method.redelivered,
                message_id=properties.message_id,
                timestamp=time.time()
            )
            self.manual_nack(context, requeue=True)
            self.failed_messages += 1
            
    def process_message_with_retry(self, body: bytes) -> bool:
        """å¸¦é‡è¯•çš„æ¶ˆæ¯å¤„ç†"""
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                # å¤„ç†æ¶ˆæ¯
                self._process_message(body)
                return True
            except Exception as e:
                retry_count += 1
                if retry_count < max_retries:
                    wait_time = 2 ** retry_count  # æŒ‡æ•°é€€é¿
                    print(f"å¤„ç†å¤±è´¥ï¼Œ{wait_time}ç§’åé‡è¯• ({retry_count}/{max_retries})")
                    time.sleep(wait_time)
                else:
                    print(f"å¤„ç†æœ€ç»ˆå¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡")
                    return False
                    
    def manual_ack(self, context: MessageContext):
        """æ‰‹åŠ¨ç¡®è®¤æ¶ˆæ¯"""
        self.channel.basic_ack(delivery_tag=context.delivery_tag)
        
    def manual_nack(self, context: MessageContext, requeue: bool = True):
        """æ‰‹åŠ¨å¦è®¤æ¶ˆæ¯"""
        self.channel.basic_nack(
            delivery_tag=context.delivery_tag,
            requeue=requeue
        )
        
    def _process_message(self, body: bytes):
        """æ¶ˆæ¯å¤„ç†é€»è¾‘"""
        import random
        # æ¨¡æ‹Ÿå¤„ç†ï¼Œå¯èƒ½å¤±è´¥
        if random.random() < 0.1:  # 10%å¤±è´¥ç‡
            raise Exception("æ¨¡æ‹Ÿå¤„ç†å¤±è´¥")
            
        time.sleep(0.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
    def setup_connection(self):
        """å»ºç«‹è¿æ¥"""
        credentials = pika.PlainCredentials(
            self.connection_params['username'],
            self.connection_params['password']
        )
        
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(
                host=self.connection_params['host'],
                port=self.connection_params['port'],
                credentials=credentials
            )
        )
        
        self.channel = self.connection.channel()
        
    def get_statistics(self):
        """è·å–å¤„ç†ç»Ÿè®¡"""
        total = self.processed_messages + self.failed_messages
        success_rate = (self.processed_messages / total * 100) if total > 0 else 0
        
        return {
            'processed': self.processed_messages,
            'failed': self.failed_messages,
            'total': total,
            'success_rate': f"{success_rate:.1f}%"
        }
```

### 4.3.2 é«˜çº§æ‰‹åŠ¨ç¡®è®¤æ¨¡å¼

```python
import json
from datetime import datetime, timedelta
from typing import Dict, Any, List

class AdvancedManualAckConsumer:
    """é«˜çº§æ‰‹åŠ¨ç¡®è®¤æ¶ˆè´¹è€…"""
    
    def __init__(self, connection_params: dict):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        
        # ç¡®è®¤çŠ¶æ€è·Ÿè¸ª
        self.pending_acks = {}
        self.processed_messages = set()
        self.failed_messages = {}
        
        # é‡è¯•æœºåˆ¶
        self.max_retries = 3
        self.retry_intervals = [1, 5, 30]  # é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
        
        # æ€§èƒ½ç›‘æ§
        self.processing_times = []
        self.start_time = None
        
    def consume_advanced_manual_ack(self, queue_name: str):
        """é«˜çº§æ‰‹åŠ¨ç¡®è®¤æ¶ˆè´¹"""
        self.setup_connection()
        
        # è®¾ç½®é˜Ÿåˆ—å‚æ•°
        self.setup_advanced_queue(queue_name)
        
        # å¯åŠ¨å®šæ—¶æ£€æŸ¥å™¨
        self.start_periodic_checker()
        
        # å¼€å§‹æ¶ˆè´¹
        self.channel.basic_consume(
            queue=queue_name,
            auto_ack=False,
            on_message_callback=self.advanced_manual_ack_callback
        )
        
        self.start_time = datetime.now()
        print("å¼€å§‹é«˜çº§æ‰‹åŠ¨ç¡®è®¤æ¶ˆè´¹...")
        
        try:
            self.channel.start_consuming()
        except KeyboardInterrupt:
            self.channel.stop_consuming()
            
    def setup_advanced_queue(self, queue_name: str):
        """è®¾ç½®é«˜çº§é˜Ÿåˆ—å‚æ•°"""
        # å£°æ˜é˜Ÿåˆ—ï¼Œå¯ç”¨æ­»ä¿¡é˜Ÿåˆ—
        arguments = {
            'x-dead-letter-exchange': 'dlx_exchange',
            'x-dead-letter-routing-key': 'dead_letter_queue',
            'x-message-ttl': 300000,  # 5åˆ†é’ŸTTL
            'x-max-length': 10000,    # æœ€å¤§é•¿åº¦
            'x-max-length-bytes': 50000000  # 50MB
        }
        
        self.channel.queue_declare(
            queue=queue_name,
            durable=True,
            arguments=arguments
        )
        
        # è®¾ç½®é¢„å–æ•°é‡
        self.channel.basic_qos(prefetch_count=10)
        
    def advanced_manual_ack_callback(self, ch: pika.channel.Channel,
                                   method: pika.spec.Basic.Deliver,
                                   properties: pika.spec.Basic.Properties,
                                   body: bytes):
        """é«˜çº§æ‰‹åŠ¨ç¡®è®¤å›è°ƒ"""
        start_time = time.time()
        message_id = properties.message_id
        
        try:
            # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦é‡å¤
            if message_id in self.processed_messages:
                print(f"æ£€æµ‹åˆ°é‡å¤æ¶ˆæ¯ï¼Œè·³è¿‡å¤„ç†: {message_id}")
                self.manual_ack(method.delivery_tag)
                return
                
            print(f"[é«˜çº§æ‰‹åŠ¨ç¡®è®¤] æ”¶åˆ°æ¶ˆæ¯: {message_id}")
            
            # è§£ææ¶ˆæ¯
            message_data = json.loads(body.decode())
            
            # æ£€æŸ¥é‡è¯•æ¬¡æ•°
            retry_count = self.get_retry_count(message_id)
            if retry_count >= self.max_retries:
                print(f"æ¶ˆæ¯å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç§»åŠ¨åˆ°æ­»ä¿¡é˜Ÿåˆ—: {message_id}")
                self.manual_nack(method.delivery_tag, requeue=False)
                return
                
            # å¤„ç†æ¶ˆæ¯
            success = self.advanced_process_message(message_data, message_id)
            
            if success:
                # å¤„ç†æˆåŠŸ
                self.manual_ack(method.delivery_tag)
                self.processed_messages.add(message_id)
                
                # è®°å½•å¤„ç†æ—¶é—´
                processing_time = time.time() - start_time
                self.processing_times.append(processing_time)
                
                print(f"[é«˜çº§æ‰‹åŠ¨ç¡®è®¤] å¤„ç†æˆåŠŸå¹¶ç¡®è®¤: {message_id}, ç”¨æ—¶: {processing_time:.2f}s")
                
            else:
                # å¤„ç†å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•
                self.handle_processing_failure(message_id, method.delivery_tag, retry_count)
                
        except Exception as e:
            print(f"[é«˜çº§æ‰‹åŠ¨ç¡®è®¤] æ¶ˆæ¯å¤„ç†å¼‚å¸¸: {e}")
            self.handle_processing_failure(
                message_id, 
                method.delivery_tag, 
                self.get_retry_count(message_id),
                exception=e
            )
            
    def advanced_process_message(self, message_data: Dict[str, Any], message_id: str) -> bool:
        """é«˜çº§æ¶ˆæ¯å¤„ç†"""
        try:
            # éªŒè¯æ¶ˆæ¯æ ¼å¼
            if not self.validate_message(message_data):
                raise ValueError("æ¶ˆæ¯æ ¼å¼éªŒè¯å¤±è´¥")
                
            # æ‰§è¡Œä¸šåŠ¡é€»è¾‘
            self.execute_business_logic(message_data)
            
            # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
            time.sleep(random.uniform(0.1, 0.5))
            
            return True
            
        except Exception as e:
            print(f"ä¸šåŠ¡å¤„ç†å¤±è´¥: {e}")
            return False
            
    def handle_processing_failure(self, message_id: str, delivery_tag: str, 
                                retry_count: int, exception: Exception = None):
        """å¤„ç†å¤„ç†å¤±è´¥"""
        if retry_count < self.max_retries:
            # å¢åŠ é‡è¯•æ¬¡æ•°å¹¶å‡†å¤‡é‡è¯•
            next_retry_count = retry_count + 1
            self.failed_messages[message_id] = {
                'delivery_tag': delivery_tag,
                'retry_count': next_retry_count,
                'last_attempt': datetime.now(),
                'next_retry': datetime.now() + timedelta(seconds=self.retry_intervals[min(next_retry_count - 1, len(self.retry_intervals) - 1)]),
                'error': str(exception) if exception else "æœªçŸ¥é”™è¯¯"
            }
            
            # å¦è®¤æ¶ˆæ¯ï¼Œé‡æ–°å…¥é˜Ÿ
            self.manual_nack(delivery_tag, requeue=True)
            
            print(f"å¤„ç†å¤±è´¥ï¼Œå‡†å¤‡é‡è¯• {next_retry_count}/{self.max_retries}: {message_id}")
            
        else:
            # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç§»åŠ¨åˆ°æ­»ä¿¡é˜Ÿåˆ—
            self.manual_nack(delivery_tag, requeue=False)
            print(f"å¤„ç†æœ€ç»ˆå¤±è´¥ï¼Œç§»åŠ¨åˆ°æ­»ä¿¡é˜Ÿåˆ—: {message_id}")
            
    def start_periodic_checker(self):
        """å¯åŠ¨å®šæ—¶æ£€æŸ¥å™¨"""
        def check_pending_messages():
            while True:
                try:
                    current_time = datetime.now()
                    messages_to_retry = []
                    
                    for message_id, info in self.failed_messages.items():
                        if current_time >= info['next_retry']:
                            messages_to_retry.append((message_id, info))
                            
                    # é‡è¯•æ¶ˆæ¯
                    for message_id, info in messages_to_retry:
                        if info['retry_count'] < self.max_retries:
                            # é‡æ–°å‘å¸ƒæ¶ˆæ¯åˆ°é˜Ÿåˆ—
                            self.republish_message(message_id, info)
                            # ä»å¤±è´¥åˆ—è¡¨ä¸­ç§»é™¤
                            del self.failed_messages[message_id]
                            
                    time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                    
                except Exception as e:
                    print(f"å®šæ—¶æ£€æŸ¥å™¨é”™è¯¯: {e}")
                    time.sleep(60)  # å‡ºé”™åç­‰å¾…æ›´é•¿æ—¶é—´
                    
        # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œæ£€æŸ¥å™¨
        checker_thread = threading.Thread(target=check_pending_messages, daemon=True)
        checker_thread.start()
        
    def republish_message(self, message_id: str, retry_info: Dict[str, Any]):
        """é‡æ–°å‘å¸ƒæ¶ˆæ¯"""
        # è¿™é‡Œéœ€è¦ä»åŸå§‹æ•°æ®æºé‡æ–°è·å–æ¶ˆæ¯
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå¯èƒ½éœ€è¦ä»æ•°æ®åº“æˆ–ç¼“å­˜ä¸­è·å–
        print(f"é‡æ–°å‘å¸ƒæ¶ˆæ¯åˆ°é˜Ÿåˆ—: {message_id}")
        
    def get_retry_count(self, message_id: str) -> int:
        """è·å–æ¶ˆæ¯é‡è¯•æ¬¡æ•°"""
        if message_id in self.failed_messages:
            return self.failed_messages[message_id]['retry_count']
        return 0
        
    def validate_message(self, message_data: Dict[str, Any]) -> bool:
        """éªŒè¯æ¶ˆæ¯æ ¼å¼"""
        required_fields = ['id', 'type', 'data']
        return all(field in message_data for field in required_fields)
        
    def execute_business_logic(self, message_data: Dict[str, Any]):
        """æ‰§è¡Œä¸šåŠ¡é€»è¾‘"""
        message_type = message_data.get('type')
        
        if message_type == 'order':
            self.process_order(message_data['data'])
        elif message_type == 'user':
            self.process_user(message_data['data'])
        elif message_type == 'notification':
            self.process_notification(message_data['data'])
        else:
            raise ValueError(f"æœªçŸ¥æ¶ˆæ¯ç±»å‹: {message_type}")
            
    def process_order(self, order_data: Dict[str, Any]):
        """å¤„ç†è®¢å•æ¶ˆæ¯"""
        # æ¨¡æ‹Ÿè®¢å•å¤„ç†
        time.sleep(0.2)
        print(f"å¤„ç†è®¢å•: {order_data.get('order_id')}")
        
    def process_user(self, user_data: Dict[str, Any]):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
        # æ¨¡æ‹Ÿç”¨æˆ·å¤„ç†
        time.sleep(0.1)
        print(f"å¤„ç†ç”¨æˆ·: {user_data.get('user_id')}")
        
    def process_notification(self, notification_data: Dict[str, Any]):
        """å¤„ç†é€šçŸ¥æ¶ˆæ¯"""
        # æ¨¡æ‹Ÿé€šçŸ¥å¤„ç†
        time.sleep(0.05)
        print(f"å‘é€é€šçŸ¥: {notification_data.get('user_id')}")
        
    def manual_ack(self, delivery_tag: str):
        """æ‰‹åŠ¨ç¡®è®¤"""
        self.channel.basic_ack(delivery_tag=delivery_tag)
        
    def manual_nack(self, delivery_tag: str, requeue: bool = True):
        """æ‰‹åŠ¨å¦è®¤"""
        self.channel.basic_nack(delivery_tag=delivery_tag, requeue=requeue)
        
    def get_performance_stats(self):
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        if not self.start_time:
            return {}
            
        runtime = datetime.now() - self.start_time
        total_messages = len(self.processed_messages)
        avg_processing_time = sum(self.processing_times) / len(self.processing_times) if self.processing_times else 0
        
        return {
            'runtime_seconds': runtime.total_seconds(),
            'total_processed': total_messages,
            'pending_failed': len(self.failed_messages),
            'avg_processing_time': avg_processing_time,
            'messages_per_second': total_messages / runtime.total_seconds() if runtime.total_seconds() > 0 else 0
        }
```

### 4.3.3 äº‹åŠ¡æ€§ç¡®è®¤

```python
class TransactionalAckConsumer:
    """äº‹åŠ¡æ€§ç¡®è®¤æ¶ˆè´¹è€…"""
    
    def __init__(self, connection_params: dict):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        
    def consume_with_transaction(self, queue_name: str):
        """ä½¿ç”¨äº‹åŠ¡æ¶ˆè´¹æ¶ˆæ¯"""
        self.setup_connection()
        
        # å£°æ˜é˜Ÿåˆ—
        self.channel.queue_declare(queue=queue_name, durable=True)
        
        # å¼€å§‹æ¶ˆè´¹
        self.channel.basic_consume(
            queue=queue_name,
            auto_ack=False,
            on_message_callback=self.transactional_ack_callback
        )
        
        print("å¼€å§‹äº‹åŠ¡æ€§ç¡®è®¤æ¶ˆè´¹...")
        
        try:
            self.channel.start_consuming()
        except KeyboardInterrupt:
            self.channel.stop_consuming()
            
    def transactional_ack_callback(self, ch: pika.channel.Channel,
                                  method: pika.spec.Basic.Deliver,
                                  properties: pika.spec.Basic.Properties,
                                  body: bytes):
        """äº‹åŠ¡æ€§ç¡®è®¤å›è°ƒ"""
        message_id = properties.message_id
        
        try:
            print(f"[äº‹åŠ¡ç¡®è®¤] å¼€å§‹å¤„ç†æ¶ˆæ¯: {message_id}")
            
            # å¼€å§‹äº‹åŠ¡
            ch.tx_select()
            
            # å¤„ç†æ¶ˆæ¯
            self._process_message_in_transaction(body)
            
            # ç¡®è®¤æ¶ˆæ¯
            ch.basic_ack(delivery_tag=method.delivery_tag)
            
            # æäº¤äº‹åŠ¡
            ch.tx_commit()
            
            print(f"[äº‹åŠ¡ç¡®è®¤] æ¶ˆæ¯å¤„ç†æˆåŠŸå¹¶æäº¤: {message_id}")
            
        except Exception as e:
            print(f"[äº‹åŠ¡ç¡®è®¤] æ¶ˆæ¯å¤„ç†å¤±è´¥ï¼Œå¼€å§‹å›æ»š: {e}")
            
            try:
                # å›æ»šäº‹åŠ¡
                ch.tx_rollback()
                print(f"[äº‹åŠ¡ç¡®è®¤] äº‹åŠ¡å›æ»šå®Œæˆ: {message_id}")
            except Exception as rollback_error:
                print(f"[äº‹åŠ¡ç¡®è®¤] å›æ»šå¤±è´¥: {rollback_error}")
                
            # å¦è®¤æ¶ˆæ¯
            ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
            
    def _process_message_in_transaction(self, body: bytes):
        """åœ¨äº‹åŠ¡ä¸­å¤„ç†æ¶ˆæ¯"""
        # æ¨¡æ‹Ÿä¸šåŠ¡å¤„ç†
        import random
        time.sleep(0.3)
        
        # æ¨¡æ‹Ÿå¯èƒ½çš„å¤±è´¥
        if random.random() < 0.1:
            raise Exception("äº‹åŠ¡å¤„ç†å¤±è´¥")
            
    def setup_connection(self):
        """å»ºç«‹è¿æ¥"""
        credentials = pika.PlainCredentials(
            self.connection_params['username'],
            self.connection_params['password']
        )
        
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(
                host=self.connection_params['host'],
                port=self.connection_params['port'],
                credentials=credentials
            )
        )
        
        self.channel = self.connection.channel()
```

---

## 4.4 æ¶ˆæ¯æŒä¹…åŒ–ç­–ç•¥

### 4.4.1 åŸºç¡€æŒä¹…åŒ–é…ç½®

```python
class PersistenceManager:
    """æ¶ˆæ¯æŒä¹…åŒ–ç®¡ç†å™¨"""
    
    def __init__(self, connection_params: dict):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        
    def setup_durable_queue(self, queue_name: str):
        """è®¾ç½®æŒä¹…åŒ–é˜Ÿåˆ—"""
        self.setup_connection()
        
        # å£°æ˜æŒä¹…åŒ–é˜Ÿåˆ—
        self.channel.queue_declare(
            queue=queue_name,
            durable=True,      # å…³é”®ï¼šé˜Ÿåˆ—æŒä¹…åŒ–
            auto_delete=False, # ä¸è‡ªåŠ¨åˆ é™¤
            arguments={
                'x-message-ttl': 300000,    # 5åˆ†é’ŸTTL
                'x-dead-letter-exchange': 'dlx',
                'x-dead-letter-routing-key': 'dead_letter',
                'x-max-length': 10000,      # æœ€å¤§é•¿åº¦
                'x-overflow': 'reject-publish'  # æº¢å‡ºæ—¶æ‹’ç»æ–°æ¶ˆæ¯
            }
        )
        
        print(f"åˆ›å»ºæŒä¹…åŒ–é˜Ÿåˆ—: {queue_name}")
        
    def setup_durable_exchange(self, exchange_name: str, exchange_type: str):
        """è®¾ç½®æŒä¹…åŒ–äº¤æ¢æœº"""
        # å£°æ˜æŒä¹…åŒ–äº¤æ¢æœº
        self.channel.exchange_declare(
            exchange=exchange_name,
            exchange_type=exchange_type,
            durable=True,  # å…³é”®ï¼šäº¤æ¢æœºæŒä¹…åŒ–
            auto_delete=False
        )
        
        print(f"åˆ›å»ºæŒä¹…åŒ–äº¤æ¢æœº: {exchange_name} ({exchange_type})")
        
    def publish_durable_message(self, exchange: str, routing_key: str, message: dict):
        """å‘å¸ƒæŒä¹…åŒ–æ¶ˆæ¯"""
        # åˆ›å»ºæŒä¹…åŒ–å±æ€§
        properties = pika.BasicProperties(
            delivery_mode=2,        # å…³é”®ï¼šæ¶ˆæ¯æŒä¹…åŒ–
            message_id=message.get('id'),
            timestamp=time.time(),
            content_type='application/json',
            expiration=str(message.get('ttl', 300000))  # æ¶ˆæ¯çº§TTL
        )
        
        # å‘å¸ƒæ¶ˆæ¯
        self.channel.basic_publish(
            exchange=exchange,
            routing_key=routing_key,
            body=json.dumps(message),
            properties=properties,
            mandatory=True  # ç¡®ä¿æ¶ˆæ¯è¢«è·¯ç”±
        )
        
        print(f"å‘å¸ƒæŒä¹…åŒ–æ¶ˆæ¯: {message.get('id')} -> {routing_key}")
        
    def publish_with_confirm_delivery(self, exchange: str, routing_key: str, messages: list):
        """å‘å¸ƒæ¶ˆæ¯å¹¶ç¡®è®¤æŠ•é€’"""
        # å¯ç”¨å‘å¸ƒè€…ç¡®è®¤
        self.channel.confirm_delivery()
        
        failed_messages = []
        
        for i, message in enumerate(messages):
            try:
                # å‘å¸ƒæ¯æ¡æ¶ˆæ¯
                self.channel.basic_publish(
                    exchange=exchange,
                    routing_key=routing_key,
                    body=json.dumps(message),
                    properties=pika.BasicProperties(
                        delivery_mode=2,
                        message_id=message.get('id', f'msg_{i}'),
                        timestamp=time.time()
                    )
                )
                
                print(f"æ¶ˆæ¯å‘å¸ƒæˆåŠŸ: {message.get('id', f'msg_{i}')}")
                
            except pika.exceptions.NackError:
                print(f"æ¶ˆæ¯å‘å¸ƒå¤±è´¥ï¼ˆè¢«æ‹’ç»ï¼‰: {message.get('id', f'msg_{i}')}")
                failed_messages.append(message)
            except Exception as e:
                print(f"æ¶ˆæ¯å‘å¸ƒå¼‚å¸¸: {e}")
                failed_messages.append(message)
                
        return failed_messages
        
    def check_queue_persistence(self, queue_name: str) -> dict:
        """æ£€æŸ¥é˜Ÿåˆ—æŒä¹…åŒ–çŠ¶æ€"""
        try:
            # å£°æ˜é˜Ÿåˆ—ï¼ˆè¢«åŠ¨æ¨¡å¼ï¼Œæ£€æŸ¥æ˜¯å¦å­˜åœ¨ï¼‰
            result = self.channel.queue_declare(queue=queue_name, passive=True)
            
            return {
                'queue_exists': True,
                'message_count': result.method.message_count,
                'consumer_count': result.method.consumer_count,
                'queue_name': queue_name
            }
            
        except pika.exceptions.ChannelClosedByBroker:
            return {
                'queue_exists': False,
                'error': 'é˜Ÿåˆ—ä¸å­˜åœ¨'
            }
            
    def get_messages_from_queue(self, queue_name: str, count: int = 10) -> list:
        """ä»é˜Ÿåˆ—è·å–æ¶ˆæ¯ï¼ˆç”¨äºæ£€æŸ¥ï¼‰"""
        messages = []
        
        for _ in range(count):
            try:
                method_frame, header_frame, body = self.channel.basic_get(
                    queue=queue_name,
                    auto_ack=False
                )
                
                if method_frame:
                    messages.append({
                        'delivery_tag': method_frame.delivery_tag,
                        'message_id': header_frame.message_id,
                        'body': json.loads(body) if body else None,
                        'redelivered': method_frame.redelivered
                    })
                    
                    # ç¡®è®¤æ¶ˆæ¯ä»¥ä»é˜Ÿåˆ—ä¸­ç§»é™¤
                    self.channel.basic_ack(delivery_tag=method_frame.delivery_tag)
                else:
                    break  # é˜Ÿåˆ—ä¸ºç©º
                    
            except Exception as e:
                print(f"è·å–æ¶ˆæ¯å¤±è´¥: {e}")
                break
                
        return messages
        
    def setup_connection(self):
        """å»ºç«‹è¿æ¥"""
        credentials = pika.PlainCredentials(
            self.connection_params['username'],
            self.connection_params['password']
        )
        
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(
                host=self.connection_params['host'],
                port=self.connection_params['port'],
                credentials=credentials,
                heartbeat=30,  # å¿ƒè·³
                blocked_connection_timeout=300  # é˜»å¡è¿æ¥è¶…æ—¶
            )
        )
        
        self.channel = self.connection.channel()
```

### 4.4.2 é«˜å¯ç”¨æŒä¹…åŒ–

```python
class HighAvailabilityPersistenceManager:
    """é«˜å¯ç”¨æŒä¹…åŒ–ç®¡ç†å™¨"""
    
    def __init__(self, connection_params: dict, cluster_nodes: list):
        self.connection_params = connection_params
        self.cluster_nodes = cluster_nodes  # é›†ç¾¤èŠ‚ç‚¹åˆ—è¡¨
        self.primary_connection = None
        self.backup_connection = None
        self.primary_channel = None
        self.backup_channel = None
        
    def setup_ha_queue(self, queue_name: str):
        """è®¾ç½®é«˜å¯ç”¨é˜Ÿåˆ—"""
        self.setup_dual_connections()
        
        # åœ¨ä¸»èŠ‚ç‚¹åˆ›å»ºé•œåƒé˜Ÿåˆ—
        ha_arguments = {
            'x-ha-policy': 'all',              # é•œåƒç­–ç•¥ï¼šå¤åˆ¶åˆ°æ‰€æœ‰èŠ‚ç‚¹
            'x-ha-sync-mode': 'automatic',     # è‡ªåŠ¨åŒæ­¥
            'x-message-ttl': 300000,           # 5åˆ†é’ŸTTL
            'x-dead-letter-exchange': 'dlx',
            'x-dead-letter-routing-key': 'dead_letter',
            'x-max-length': 50000,             # æœ€å¤§æ¶ˆæ¯æ•°
            'x-max-length-bytes': '100MB'      # æœ€å¤§å†…å­˜
        }
        
        # åœ¨ä¸»èŠ‚ç‚¹åˆ›å»ºé˜Ÿåˆ—
        self.primary_channel.queue_declare(
            queue=queue_name,
            durable=True,
            arguments=ha_arguments
        )
        
        print(f"åœ¨ä¸»èŠ‚ç‚¹åˆ›å»ºé«˜å¯ç”¨é˜Ÿåˆ—: {queue_name}")
        
    def setup_dual_connections(self):
        """è®¾ç½®ä¸»å¤‡è¿æ¥"""
        try:
            # ä¸»è¿æ¥
            self.primary_connection = pika.BlockingConnection(
                pika.ConnectionParameters(host=self.cluster_nodes[0])
            )
            self.primary_channel = self.primary_connection.channel()
            
            # å¤‡ä»½è¿æ¥
            self.backup_connection = pika.BlockingConnection(
                pika.ConnectionParameters(host=self.cluster_nodes[1])
            )
            self.backup_channel = self.backup_connection.channel()
            
        except Exception as e:
            print(f"è¿æ¥è®¾ç½®å¤±è´¥: {e}")
            
    def publish_ha_message(self, queue_name: str, message: dict, exchange: str = ''):
        """å‘å¸ƒé«˜å¯ç”¨æ¶ˆæ¯"""
        properties = pika.BasicProperties(
            delivery_mode=2,  # æŒä¹…åŒ–
            message_id=message.get('id'),
            timestamp=time.time(),
            content_type='application/json',
            correlation_id=message.get('correlation_id'),
            reply_to=message.get('reply_to'),
            expiration=str(message.get('ttl', 300000)),
            priority=message.get('priority', 0),
            headers=message.get('headers', {})
        )
        
        try:
            # å°è¯•ä¸»è¿æ¥å‘å¸ƒ
            self.primary_channel.basic_publish(
                exchange=exchange,
                routing_key=queue_name,
                body=json.dumps(message),
                properties=properties,
                mandatory=True
            )
            
            print(f"é€šè¿‡ä¸»èŠ‚ç‚¹å‘å¸ƒæ¶ˆæ¯: {message.get('id')}")
            
        except Exception as e:
            print(f"ä¸»èŠ‚ç‚¹å‘å¸ƒå¤±è´¥ï¼Œå°è¯•å¤‡ä»½èŠ‚ç‚¹: {e}")
            
            try:
                # ä¸»èŠ‚ç‚¹å¤±è´¥ï¼Œä½¿ç”¨å¤‡ä»½èŠ‚ç‚¹
                self.backup_channel.basic_publish(
                    exchange=exchange,
                    routing_key=queue_name,
                    body=json.dumps(message),
                    properties=properties,
                    mandatory=True
                )
                
                print(f"é€šè¿‡å¤‡ä»½èŠ‚ç‚¹å‘å¸ƒæ¶ˆæ¯: {message.get('id')}")
                
            except Exception as backup_error:
                print(f"å¤‡ä»½èŠ‚ç‚¹ä¹Ÿå‘å¸ƒå¤±è´¥: {backup_error}")
                raise Exception("æ‰€æœ‰èŠ‚ç‚¹éƒ½æ— æ³•å‘å¸ƒæ¶ˆæ¯")
                
    def monitor_ha_status(self, queue_name: str) -> dict:
        """ç›‘æ§é«˜å¯ç”¨çŠ¶æ€"""
        status = {
            'queue_name': queue_name,
            'primary_node': self.cluster_nodes[0],
            'backup_node': self.cluster_nodes[1],
            'primary_connection_ok': False,
            'backup_connection_ok': False,
            'message_count': 0,
            'consumer_count': 0
        }
        
        # æ£€æŸ¥ä¸»è¿æ¥
        try:
            if self.primary_connection and self.primary_connection.is_open:
                result = self.primary_channel.queue_declare(queue=queue_name, passive=True)
                status['primary_connection_ok'] = True
                status['message_count'] = result.method.message_count
                status['consumer_count'] = result.method.consumer_count
        except Exception as e:
            print(f"ä¸»èŠ‚ç‚¹çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
            
        # æ£€æŸ¥å¤‡ä»½è¿æ¥
        try:
            if self.backup_connection and self.backup_connection.is_open:
                result = self.backup_channel.queue_declare(queue=queue_name, passive=True)
                status['backup_connection_ok'] = True
                if status['message_count'] == 0:
                    status['message_count'] = result.method.message_count
                    status['consumer_count'] = result.method.consumer_count
        except Exception as e:
            print(f"å¤‡ä»½èŠ‚ç‚¹çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
            
        return status
        
    def failover_to_backup(self):
        """æ•…éšœè½¬ç§»åˆ°å¤‡ä»½èŠ‚ç‚¹"""
        try:
            print("å¼€å§‹æ•…éšœè½¬ç§»...")
            
            # å…³é—­ä¸»è¿æ¥
            if self.primary_connection and self.primary_connection.is_open:
                self.primary_connection.close()
                
            # å°†å¤‡ä»½è¿æ¥æå‡ä¸ºä¸»è¿æ¥
            self.primary_connection = self.backup_connection
            self.primary_channel = self.backup_channel
            
            # åˆ›å»ºæ–°çš„å¤‡ä»½è¿æ¥
            if len(self.cluster_nodes) > 2:
                self.backup_connection = pika.BlockingConnection(
                    pika.ConnectionParameters(host=self.cluster_nodes[2])
                )
                self.backup_channel = self.backup_connection.channel()
                
            print("æ•…éšœè½¬ç§»å®Œæˆ")
            
        except Exception as e:
            print(f"æ•…éšœè½¬ç§»å¤±è´¥: {e}")
            
    def setup_mirrored_exchange(self, exchange_name: str, exchange_type: str):
        """è®¾ç½®é•œåƒäº¤æ¢æœº"""
        # åœ¨é›†ç¾¤ä¸­ï¼Œäº¤æ¢æœºé»˜è®¤å°±æ˜¯é•œåƒçš„
        self.primary_channel.exchange_declare(
            exchange=exchange_name,
            exchange_type=exchange_type,
            durable=True,
            auto_delete=False
        )
        
        print(f"åˆ›å»ºé•œåƒäº¤æ¢æœº: {exchange_name}")
```

### 4.4.3 æ€§èƒ½ä¼˜åŒ–çš„æŒä¹…åŒ–

```python
class PerformanceOptimizedPersistence:
    """æ€§èƒ½ä¼˜åŒ–çš„æŒä¹…åŒ–ç®¡ç†å™¨"""
    
    def __init__(self, connection_params: dict):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        
        # æ‰¹å¤„ç†ç›¸å…³
        self.pending_messages = []
        self.batch_size = 100
        self.batch_timeout = 5  # ç§’
        
        # å‹ç¼©ç›¸å…³
        self.enable_compression = True
        self.compression_level = 6
        
        # æ€§èƒ½ç›‘æ§
        self.publish_stats = {
            'total_messages': 0,
            'successful_messages': 0,
            'failed_messages': 0,
            'total_bytes': 0,
            'start_time': time.time()
        }
        
    def setup_performance_optimized_queue(self, queue_name: str):
        """è®¾ç½®æ€§èƒ½ä¼˜åŒ–çš„é˜Ÿåˆ—"""
        self.setup_connection()
        
        # ä¼˜åŒ–çš„é˜Ÿåˆ—å‚æ•°
        arguments = {
            'x-message-ttl': 600000,            # 10åˆ†é’ŸTTL
            'x-dead-letter-exchange': 'dlx',
            'x-dead-letter-routing-key': 'dead_letter',
            'x-max-length': 100000,             # å¤§é˜Ÿåˆ—
            'x-max-length-bytes': '1GB',        # å¤§å®¹é‡
            'x-overflow': 'reject-publish',
            'x-max-priority': 10,               # ä¼˜å…ˆçº§é˜Ÿåˆ—
            'x-queue-mode': 'lazy'              # æ‡’åŠ è½½ï¼ˆæé«˜æ€§èƒ½ï¼‰
        }
        
        self.channel.queue_declare(
            queue=queue_name,
            durable=True,
            arguments=arguments
        )
        
        # è®¾ç½®é¢„å–æ•°é‡ï¼ˆæ ¹æ®å¤„ç†èƒ½åŠ›è°ƒæ•´ï¼‰
        self.channel.basic_qos(prefetch_count=50)
        
        print(f"åˆ›å»ºæ€§èƒ½ä¼˜åŒ–é˜Ÿåˆ—: {queue_name}")
        
    def publish_optimized_message(self, queue_name: str, message: dict, priority: int = 0):
        """å‘å¸ƒä¼˜åŒ–çš„æ¶ˆæ¯"""
        # å‹ç¼©æ¶ˆæ¯ä½“
        compressed_body = self.compress_message(json.dumps(message))
        
        # åˆ›å»ºä¼˜åŒ–çš„å±æ€§
        properties = pika.BasicProperties(
            delivery_mode=2,  # æŒä¹…åŒ–
            message_id=message.get('id'),
            timestamp=time.time(),
            content_type='application/json',
            content_encoding='gzip' if self.enable_compression else None,
            priority=priority,
            expiration=str(message.get('ttl', 600000)),
            correlation_id=message.get('correlation_id'),
            reply_to=message.get('reply_to'),
            headers={
                'compressed': self.enable_compression,
                'original_size': len(json.dumps(message)),
                'priority': priority
            }
        )
        
        # æ·»åŠ åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—
        self.pending_messages.append({
            'queue_name': queue_name,
            'body': compressed_body,
            'properties': properties,
            'message_id': message.get('id')
        })
        
        # æ›´æ–°ç»Ÿè®¡
        self.publish_stats['total_messages'] += 1
        self.publish_stats['total_bytes'] += len(compressed_body)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘é€æ‰¹æ¬¡
        if len(self.pending_messages) >= self.batch_size:
            self.flush_batch()
            
    def flush_batch(self):
        """å‘é€æ‰¹æ¬¡æ¶ˆæ¯"""
        if not self.pending_messages:
            return
            
        successful_messages = 0
        failed_messages = 0
        
        # å¯ç”¨å‘å¸ƒè€…ç¡®è®¤
        self.channel.confirm_delivery()
        
        for msg_data in self.pending_messages:
            try:
                self.channel.basic_publish(
                    exchange='',
                    routing_key=msg_data['queue_name'],
                    body=msg_data['body'],
                    properties=msg_data['properties'],
                    mandatory=True
                )
                
                successful_messages += 1
                
            except Exception as e:
                failed_messages += 1
                print(f"æ‰¹æ¬¡æ¶ˆæ¯å‘å¸ƒå¤±è´¥: {e}")
                
        # æ›´æ–°ç»Ÿè®¡
        self.publish_stats['successful_messages'] += successful_messages
        self.publish_stats['failed_messages'] += failed_messages
        
        print(f"æ‰¹æ¬¡å‘é€å®Œæˆ: æˆåŠŸ {successful_messages}, å¤±è´¥ {failed_messages}")
        
        # æ¸…ç©ºæ‰¹æ¬¡é˜Ÿåˆ—
        self.pending_messages = []
        
    def start_batch_timer(self):
        """å¯åŠ¨æ‰¹æ¬¡å®šæ—¶å™¨"""
        def batch_timer():
            while True:
                time.sleep(self.batch_timeout)
                if self.pending_messages:
                    self.flush_batch()
                    
        timer_thread = threading.Thread(target=batch_timer, daemon=True)
        timer_thread.start()
        
    def compress_message(self, message_body: str) -> bytes:
        """å‹ç¼©æ¶ˆæ¯ä½“"""
        if not self.enable_compression:
            return message_body.encode()
            
        import gzip
        compressed_data = gzip.compress(
            message_body.encode(), 
            compresslevel=self.compression_level
        )
        
        compression_ratio = len(compressed_data) / len(message_body)
        print(f"æ¶ˆæ¯å‹ç¼©: {len(message_body)} -> {len(compressed_data)} å­—èŠ‚ "
              f"(å‹ç¼©æ¯”: {compression_ratio:.2f})")
        
        return compressed_data
        
    def decompress_message(self, compressed_body: bytes) -> str:
        """è§£å‹ç¼©æ¶ˆæ¯ä½“"""
        if not self.enable_compression:
            return compressed_body.decode()
            
        import gzip
        return gzip.decompress(compressed_body).decode()
        
    def consume_optimized_messages(self, queue_name: str):
        """æ¶ˆè´¹ä¼˜åŒ–çš„æ¶ˆæ¯"""
        def optimized_callback(ch, method, properties, body):
            try:
                # å¤„ç†å‹ç¼©æ¶ˆæ¯
                if properties.content_encoding == 'gzip':
                    message_body = self.decompress_message(body)
                else:
                    message_body = body.decode()
                    
                message_data = json.loads(message_body)
                
                # å¤„ç†æ¶ˆæ¯
                self.process_message_optimized(message_data, properties)
                
                # æ‰‹åŠ¨ç¡®è®¤
                ch.basic_ack(delivery_tag=method.delivery_tag)
                
                print(f"æ¶ˆæ¯å¤„ç†æˆåŠŸ: {properties.message_id}")
                
            except Exception as e:
                print(f"æ¶ˆæ¯å¤„ç†å¤±è´¥: {e}")
                # å¦è®¤æ¶ˆæ¯å¹¶é‡æ–°å…¥é˜Ÿ
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
                
        self.channel.basic_consume(
            queue=queue_name,
            auto_ack=False,
            on_message_callback=optimized_callback
        )
        
        print("å¼€å§‹æ¶ˆè´¹ä¼˜åŒ–æ¶ˆæ¯...")
        self.channel.start_consuming()
        
    def process_message_optimized(self, message_data: dict, properties: pika.BasicProperties):
        """ä¼˜åŒ–çš„æ¶ˆæ¯å¤„ç†"""
        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        time.sleep(0.01)  # éå¸¸çŸ­çš„å¤„ç†æ—¶é—´
        
        # æ¨¡æ‹Ÿå¯èƒ½çš„å¤±è´¥
        if random.random() < 0.001:  # 0.1%å¤±è´¥ç‡
            raise Exception("æ¨¡æ‹Ÿå¤„ç†å¤±è´¥")
            
    def get_performance_statistics(self):
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        runtime = time.time() - self.publish_stats['start_time']
        throughput = self.publish_stats['total_messages'] / runtime if runtime > 0 else 0
        success_rate = (self.publish_stats['successful_messages'] / 
                       max(1, self.publish_stats['total_messages']) * 100)
        
        return {
            'runtime_seconds': runtime,
            'total_messages': self.publish_stats['total_messages'],
            'successful_messages': self.publish_stats['successful_messages'],
            'failed_messages': self.publish_stats['failed_messages'],
            'throughput_msg_per_sec': throughput,
            'success_rate_percent': success_rate,
            'total_bytes': self.publish_stats['total_bytes'],
            'avg_message_size_bytes': (self.publish_stats['total_bytes'] / 
                                     max(1, self.publish_stats['total_messages'])),
            'pending_in_batch': len(self.pending_messages)
        }
        
    def setup_connection(self):
        """å»ºç«‹ä¼˜åŒ–è¿æ¥"""
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(
                host=self.connection_params['host'],
                port=self.connection_params['port'],
                credentials=pika.PlainCredentials(
                    self.connection_params['username'],
                    self.connection_params['password']
                ),
                heartbeat=60,                    # é•¿å¿ƒè·³
                blocked_connection_timeout=600,  # é•¿è¶…æ—¶
                connection_attempts=3,
                retry_delay=5
            )
        )
        
        self.channel = self.connection.channel()
```

---

## 4.5 å‘å¸ƒè€…ç¡®è®¤æœºåˆ¶

### 4.5.1 åŸºç¡€å‘å¸ƒè€…ç¡®è®¤

```python
class PublisherConfirmationManager:
    """å‘å¸ƒè€…ç¡®è®¤ç®¡ç†å™¨"""
    
    def __init__(self, connection_params: dict):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        
        # ç¡®è®¤ç›¸å…³
        self.pending_confirmations = {}
        self.confirmation_timeout = 30  # ç§’
        self.confirmed_messages = set()
        self.failed_messages = set()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.confirmation_stats = {
            'published': 0,
            'confirmed': 0,
            'failed': 0,
            'timeout': 0
        }
        
    def setup_confirm_delivery(self):
        """è®¾ç½®ç¡®è®¤æŠ•é€’"""
        self.setup_connection()
        
        # å¯ç”¨å‘å¸ƒè€…ç¡®è®¤
        self.channel.confirm_delivery()
        print("å‘å¸ƒè€…ç¡®è®¤æœºåˆ¶å·²å¯ç”¨")
        
    def publish_with_confirmation(self, exchange: str, routing_key: str, 
                                message: dict, timeout: int = 30) -> bool:
        """ä½¿ç”¨ç¡®è®¤æœºåˆ¶å‘å¸ƒæ¶ˆæ¯"""
        message_id = message.get('id', f'msg_{time.time()}')
        
        try:
            # åˆ›å»ºæ¶ˆæ¯å±æ€§
            properties = pika.BasicProperties(
                delivery_mode=2,  # æŒä¹…åŒ–
                message_id=message_id,
                timestamp=time.time(),
                content_type='application/json',
                expiration=str(message.get('ttl', 300000))
            )
            
            # æ³¨å†Œå¾…ç¡®è®¤æ¶ˆæ¯
            self.pending_confirmations[message_id] = {
                'exchange': exchange,
                'routing_key': routing_key,
                'message': message,
                'timestamp': time.time(),
                'retries': 0
            }
            
            # å‘å¸ƒæ¶ˆæ¯
            self.channel.basic_publish(
                exchange=exchange,
                routing_key=routing_key,
                body=json.dumps(message),
                properties=properties,
                mandatory=True
            )
            
            # æ›´æ–°ç»Ÿè®¡
            self.confirmation_stats['published'] += 1
            
            print(f"æ¶ˆæ¯å·²å‘å¸ƒï¼Œç­‰å¾…ç¡®è®¤: {message_id}")
            
            # ç­‰å¾…ç¡®è®¤
            confirmed = self.wait_for_confirmation(message_id, timeout)
            
            if confirmed:
                self.confirmation_stats['confirmed'] += 1
                self.confirmed_messages.add(message_id)
                print(f"æ¶ˆæ¯ç¡®è®¤æˆåŠŸ: {message_id}")
                return True
            else:
                self.confirmation_stats['timeout'] += 1
                self.failed_messages.add(message_id)
                print(f"æ¶ˆæ¯ç¡®è®¤è¶…æ—¶: {message_id}")
                return False
                
        except pika.exceptions.NackError:
            # å‘å¸ƒè¢«æ‹’ç»
            self.confirmation_stats['failed'] += 1
            self.failed_messages.add(message_id)
            print(f"æ¶ˆæ¯å‘å¸ƒè¢«æ‹’ç»: {message_id}")
            return False
            
        except Exception as e:
            self.confirmation_stats['failed'] += 1
            print(f"æ¶ˆæ¯å‘å¸ƒå¼‚å¸¸: {e}")
            return False
            
        finally:
            # ä»å¾…ç¡®è®¤åˆ—è¡¨ä¸­ç§»é™¤
            self.pending_confirmations.pop(message_id, None)
            
    def wait_for_confirmation(self, message_id: str, timeout: int) -> bool:
        """ç­‰å¾…æ¶ˆæ¯ç¡®è®¤"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            # æ£€æŸ¥æ˜¯å¦æœ‰ç¡®è®¤äº‹ä»¶
            if message_id in self.confirmed_messages:
                return True
                
            if message_id in self.failed_messages:
                return False
                
            # å¤„ç†I/Oäº‹ä»¶
            self.connection.process_data_events(time_limit=0.1)
            
            time.sleep(0.1)  # çŸ­æš‚ä¼‘çœ 
            
        # è¶…æ—¶
        return False
        
    def setup_callbacks(self):
        """è®¾ç½®ç¡®è®¤å›è°ƒ"""
        # è¿™é‡Œéœ€è¦è®¾ç½®on_returnå›è°ƒæ¥æ•è·æ— æ³•è·¯ç”±çš„æ¶ˆæ¯
        def return_callback(ch, method, properties, body):
            message_id = properties.message_id if properties else 'unknown'
            print(f"æ¶ˆæ¯æ— æ³•è·¯ç”±ï¼Œè¿”å›ç»™å‘é€è€…: {message_id}")
            self.failed_messages.add(message_id)
            
        self.channel.add_on_return_callback(return_callback)
        
    def handle_unroutable_messages(self):
        """å¤„ç†æ— æ³•è·¯ç”±çš„æ¶ˆæ¯"""
        def return_callback(ch, method, properties, body):
            message_id = properties.message_id if properties else 'unknown'
            reason = method.reply_text
            
            print(f"æ¶ˆæ¯æ— æ³•è·¯ç”±: {message_id}, åŸå› : {reason}")
            
            # å¯ä»¥åœ¨è¿™é‡Œå®ç°é‡è¯•é€»è¾‘
            self.retry_unroutable_message(message_id, body, properties)
            
        self.channel.add_on_return_callback(return_callback)
        
    def retry_unroutable_message(self, message_id: str, body: bytes, 
                               properties: pika.BasicProperties):
        """é‡è¯•æ— æ³•è·¯ç”±çš„æ¶ˆæ¯"""
        try:
            # è§£æåŸå§‹æ¶ˆæ¯
            message_data = json.loads(body.decode())
            
            # å°è¯•å…¶ä»–è·¯ç”±é”®
            alternative_routing_keys = [
                message_data.get('alternative_key'),
                f"backup_{message_data.get('id')}",
                "default_queue"
            ]
            
            for routing_key in alternative_routing_keys:
                if routing_key:
                    try:
                        self.channel.basic_publish(
                            exchange='',
                            routing_key=routing_key,
                            body=body,
                            properties=properties,
                            mandatory=True
                        )
                        print(f"æ¶ˆæ¯é‡è·¯ç”±æˆåŠŸ: {message_id} -> {routing_key}")
                        return
                    except:
                        continue
                        
            print(f"æ‰€æœ‰é‡è·¯ç”±å°è¯•éƒ½å¤±è´¥: {message_id}")
            
        except Exception as e:
            print(f"é‡è¯•å¤„ç†å¼‚å¸¸: {e}")
            
    def batch_publish_with_confirmation(self, exchange: str, routing_key: str, 
                                      messages: list, batch_timeout: int = 30) -> dict:
        """æ‰¹é‡å‘å¸ƒæ¶ˆæ¯å¹¶ç­‰å¾…ç¡®è®¤"""
        results = {
            'successful': [],
            'failed': [],
            'timeout': []
        }
        
        # å¯ç”¨ç¡®è®¤æŠ•é€’
        self.channel.confirm_delivery()
        
        start_time = time.time()
        
        for i, message in enumerate(messages):
            message_id = message.get('id', f'batch_msg_{i}_{time.time()}')
            
            try:
                # å‘å¸ƒæ¶ˆæ¯
                self.channel.basic_publish(
                    exchange=exchange,
                    routing_key=routing_key,
                    body=json.dumps(message),
                    properties=pika.BasicProperties(
                        delivery_mode=2,
                        message_id=message_id,
                        timestamp=time.time()
                    ),
                    mandatory=True
                )
                
                self.pending_confirmations[message_id] = {
                    'timestamp': time.time(),
                    'batch_index': i
                }
                
                self.confirmation_stats['published'] += 1
                
            except Exception as e:
                results['failed'].append({
                    'message_id': message_id,
                    'error': str(e),
                    'index': i
                })
                
            # æ£€æŸ¥æ‰¹é‡è¶…æ—¶
            if time.time() - start_time > batch_timeout:
                break
                
        # ç­‰å¾…æ‰€æœ‰ç¡®è®¤
        self.wait_for_all_confirmations(batch_timeout - (time.time() - start_time))
        
        # åˆ†ç±»ç»“æœ
        for message_id in self.confirmed_messages:
            if message_id in self.pending_confirmations:
                results['successful'].append(message_id)
                
        for message_id in self.failed_messages:
            if message_id in self.pending_confirmations:
                results['failed'].append({
                    'message_id': message_id,
                    'error': 'ç¡®è®¤å¤±è´¥'
                })
                
        for message_id, info in self.pending_confirmations.items():
            if message_id not in self.confirmed_messages and message_id not in self.failed_messages:
                results['timeout'].append({
                    'message_id': message_id,
                    'index': info.get('batch_index')
                })
                
        return results
        
    def wait_for_all_confirmations(self, timeout: int):
        """ç­‰å¾…æ‰€æœ‰ç¡®è®¤"""
        start_time = time.time()
        
        while self.pending_confirmations and time.time() - start_time < timeout:
            # å¤„ç†I/Oäº‹ä»¶
            self.connection.process_data_events(time_limit=0.1)
            
            # æ£€æŸ¥è¶…æ—¶
            current_time = time.time()
            timed_out = [
                msg_id for msg_id, info in self.pending_confirmations.items()
                if current_time - info['timestamp'] > self.confirmation_timeout
            ]
            
            for msg_id in timed_out:
                self.failed_messages.add(msg_id)
                del self.pending_confirmations[msg_id]
                
            time.sleep(0.1)
            
    def get_confirmation_statistics(self) -> dict:
        """è·å–ç¡®è®¤ç»Ÿè®¡ä¿¡æ¯"""
        total_published = self.confirmation_stats['published']
        total_confirmed = self.confirmation_stats['confirmed']
        total_failed = self.confirmation_stats['failed']
        total_timeout = self.confirmation_stats['timeout']
        
        return {
            'total_published': total_published,
            'total_confirmed': total_confirmed,
            'total_failed': total_failed,
            'total_timeout': total_timeout,
            'confirmation_rate': (total_confirmed / max(1, total_published)) * 100,
            'failure_rate': ((total_failed + total_timeout) / max(1, total_published)) * 100,
            'pending_confirmations': len(self.pending_confirmations)
        }
        
    def setup_connection(self):
        """å»ºç«‹è¿æ¥"""
        credentials = pika.PlainCredentials(
            self.connection_params['username'],
            self.connection_params['password']
        )
        
        self.connection = pika.BlockingConnection(
            pika.ConnectionParameters(
                host=self.connection_params['host'],
                port=self.connection_params['port'],
                credentials=credentials,
                heartbeat=30,
                blocked_connection_timeout=300
            )
        )
        
        self.channel = self.connection.channel()
        
        # è®¾ç½®å›è°ƒ
        self.setup_callbacks()
```

### 4.5.2 é«˜çº§å‘å¸ƒè€…ç¡®è®¤

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor
import time

class AdvancedPublisherConfirmation:
    """é«˜çº§å‘å¸ƒè€…ç¡®è®¤ç®¡ç†å™¨"""
    
    def __init__(self, connection_params: dict):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        self.executor = ThreadPoolExecutor(max_workers=10)
        
        # å¼‚æ­¥ç¡®è®¤ç›¸å…³
        self.confirmation_queue = asyncio.Queue()
        self.pending_async_confirmations = {}
        self.async_confirmation_timeout = 30
        
        # äº‹åŠ¡æ€§ç¡®è®¤
        self.transactional_mode = False
        self.current_transaction = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.advanced_stats = {
            'sync_published': 0,
            'async_published': 0,
            'transactional_published': 0,
            'confirmed': 0,
            'failed': 0,
            'avg_confirmation_time': 0,
            'total_confirmation_time': 0
        }
        
    async def setup_async_connection(self):
        """è®¾ç½®å¼‚æ­¥è¿æ¥"""
        import aio_pika
        self.connection = await aio_pika.connect_robust(
            host=self.connection_params['host'],
            port=self.connection_params['port'],
            login=self.connection_params['username'],
            password=self.connection_params['password'],
            loop=asyncio.get_event_loop()
        )
        
        self.channel = await self.connection.channel()
        print("å¼‚æ­¥è¿æ¥å»ºç«‹æˆåŠŸ")
        
    async def async_publish_with_confirmation(self, exchange: str, routing_key: str,
                                            message: dict) -> bool:
        """å¼‚æ­¥å‘å¸ƒæ¶ˆæ¯å¹¶ç­‰å¾…ç¡®è®¤"""
        message_id = message.get('id', f'async_msg_{time.time()}')
        
        try:
            # åˆ›å»ºå¼‚æ­¥æ¶ˆæ¯å±æ€§
            properties = aio_pika.MessageProperties(
                delivery_mode=2,  # æŒä¹…åŒ–
                message_id=message_id,
                timestamp=time.time(),
                content_type='application/json',
                expiration=str(message.get('ttl', 300000))
            )
            
            # åˆ›å»ºå¼‚æ­¥æ¶ˆæ¯
            async_message = aio_pika.Message(
                json.dumps(message).encode(),
                properties=properties
            )
            
            # å¼‚æ­¥å‘å¸ƒ
            start_time = time.time()
            await self.channel.default_exchange.publish(
                async_message,
                routing_key=routing_key
            )
            
            # ç­‰å¾…å¼‚æ­¥ç¡®è®¤
            confirmed = await self.wait_for_async_confirmation(message_id, start_time)
            
            if confirmed:
                self.advanced_stats['async_published'] += 1
                print(f"å¼‚æ­¥æ¶ˆæ¯ç¡®è®¤æˆåŠŸ: {message_id}")
                return True
            else:
                print(f"å¼‚æ­¥æ¶ˆæ¯ç¡®è®¤å¤±è´¥: {message_id}")
                return False
                
        except Exception as e:
            print(f"å¼‚æ­¥å‘å¸ƒå¼‚å¸¸: {e}")
            return False
            
    async def wait_for_async_confirmation(self, message_id: str, start_time: float) -> bool:
        """ç­‰å¾…å¼‚æ­¥ç¡®è®¤"""
        try:
            # è®¾ç½®è¶…æ—¶
            confirmation = await asyncio.wait_for(
                self.confirmation_queue.get(),
                timeout=self.async_confirmation_timeout
            )
            
            if confirmation['message_id'] == message_id:
                confirmation_time = time.time() - start_time
                self.update_confirmation_stats(confirmation_time)
                return confirmation['confirmed']
            else:
                # æ¶ˆæ¯ä¸åŒ¹é…ï¼Œæ”¾å›é˜Ÿåˆ—
                await self.confirmation_queue.put(confirmation)
                return False
                
        except asyncio.TimeoutError:
            print(f"å¼‚æ­¥ç¡®è®¤è¶…æ—¶: {message_id}")
            return False
            
    def update_confirmation_stats(self, confirmation_time: float):
        """æ›´æ–°ç¡®è®¤ç»Ÿè®¡"""
        self.advanced_stats['confirmed'] += 1
        self.advanced_stats['total_confirmation_time'] += confirmation_time
        self.advanced_stats['avg_confirmation_time'] = (
            self.advanced_stats['total_confirmation_time'] / self.advanced_stats['confirmed']
        )
        
    def transactional_publish(self, exchange: str, routing_key: str, message: dict) -> bool:
        """äº‹åŠ¡æ€§å‘å¸ƒ"""
        try:
            if not self.transactional_mode:
                # å¼€å¯äº‹åŠ¡æ¨¡å¼
                self.channel.tx_select()
                self.transactional_mode = True
                
            message_id = message.get('id', f'tx_msg_{time.time()}')
            
            # å‘å¸ƒæ¶ˆæ¯åˆ°äº‹åŠ¡
            self.channel.basic_publish(
                exchange=exchange,
                routing_key=routing_key,
                body=json.dumps(message),
                properties=pika.BasicProperties(
                    delivery_mode=2,
                    message_id=message_id
                )
            )
            
            self.advanced_stats['transactional_published'] += 1
            print(f"æ¶ˆæ¯å·²æ·»åŠ åˆ°äº‹åŠ¡: {message_id}")
            
            return True
            
        except Exception as e:
            print(f"äº‹åŠ¡æ€§å‘å¸ƒå¤±è´¥: {e}")
            return False
            
    def commit_transaction(self) -> bool:
        """æäº¤äº‹åŠ¡"""
        try:
            if self.transactional_mode:
                self.channel.tx_commit()
                print("äº‹åŠ¡æäº¤æˆåŠŸ")
                self.transactional_mode = False
                return True
            return False
        except Exception as e:
            print(f"äº‹åŠ¡æäº¤å¤±è´¥: {e}")
            return False
            
    def rollback_transaction(self) -> bool:
        """å›æ»šäº‹åŠ¡"""
        try:
            if self.transactional_mode:
                self.channel.tx_rollback()
                print("äº‹åŠ¡å›æ»šæˆåŠŸ")
                self.transactional_mode = False
                return True
            return False
        except Exception as e:
            print(f"äº‹åŠ¡å›æ»šå¤±è´¥: {e}")
            return False
            
    def batch_transactional_publish(self, exchange: str, routing_key: str,
                                  messages: list) -> tuple:
        """æ‰¹é‡äº‹åŠ¡æ€§å‘å¸ƒ"""
        success_count = 0
        failure_count = 0
        
        try:
            # å¼€å¯äº‹åŠ¡
            self.channel.tx_select()
            self.transactional_mode = True
            
            for message in messages:
                if self.transactional_publish(exchange, routing_key, message):
                    success_count += 1
                else:
                    failure_count += 1
                    
            if failure_count == 0:
                # æ‰€æœ‰æ¶ˆæ¯éƒ½æˆåŠŸï¼Œæäº¤äº‹åŠ¡
                self.commit_transaction()
                return success_count, 0
            else:
                # æœ‰å¤±è´¥ï¼Œå›æ»šäº‹åŠ¡
                self.rollback_transaction()
                return 0, len(messages)  # å›æ»šæ„å‘³ç€æ‰€æœ‰æ¶ˆæ¯éƒ½å¤±è´¥
                
        except Exception as e:
            print(f"æ‰¹é‡äº‹åŠ¡å‘å¸ƒå¼‚å¸¸: {e}")
            self.rollback_transaction()
            return 0, len(messages)
            
    async def parallel_async_publish(self, exchange: str, routing_key: str,
                                   messages: list, max_concurrent: int = 10) -> dict:
        """å¹¶è¡Œå¼‚æ­¥å‘å¸ƒ"""
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def publish_single_message(message):
            async with semaphore:
                success = await self.async_publish_with_confirmation(exchange, routing_key, message)
                return {
                    'message_id': message.get('id'),
                    'success': success,
                    'message': message
                }
                
        # åˆ›å»ºæ‰€æœ‰å‘å¸ƒä»»åŠ¡
        tasks = [publish_single_message(message) for message in messages]
        
        # å¹¶è¡Œæ‰§è¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # åˆ†ç±»ç»“æœ
        successful = [r for r in results if not isinstance(r, Exception) and r['success']]
        failed = [r for r in results if isinstance(r, Exception) or not r['success']]
        
        return {
            'total': len(messages),
            'successful': len(successful),
            'failed': len(failed),
            'success_rate': len(successful) / len(messages) * 100 if messages else 0
        }
        
    def get_advanced_statistics(self) -> dict:
        """è·å–é«˜çº§ç»Ÿè®¡ä¿¡æ¯"""
        total_published = (
            self.advanced_stats['sync_published'] +
            self.advanced_stats['async_published'] +
            self.advanced_stats['transactional_published']
        )
        
        return {
            'total_published': total_published,
            'sync_published': self.advanced_stats['sync_published'],
            'async_published': self.advanced_stats['async_published'],
            'transactional_published': self.advanced_stats['transactional_published'],
            'confirmed': self.advanced_stats['confirmed'],
            'failed': self.advanced_stats['failed'],
            'confirmation_rate': (self.advanced_stats['confirmed'] / max(1, total_published)) * 100,
            'avg_confirmation_time_ms': self.advanced_stats['avg_confirmation_time'] * 1000,
            'transactional_mode_active': self.transactional_mode
        }
        
    async def close_async_connection(self):
        """å…³é—­å¼‚æ­¥è¿æ¥"""
        if self.connection:
            await self.connection.close()
            
    def close_sync_connection(self):
        """å…³é—­åŒæ­¥è¿æ¥"""
        if self.connection and self.connection.is_open:
            self.connection.close()
```

---

## 4.6 æ­»ä¿¡é˜Ÿåˆ—è®¾è®¡

### 4.6.1 åŸºç¡€æ­»ä¿¡é˜Ÿåˆ—

```python
class DeadLetterQueueManager:
    """æ­»ä¿¡é˜Ÿåˆ—ç®¡ç†å™¨"""
    
    def __init__(self, connection_params: dict):
        self.connection_params = connection_params
        self.connection = None
        self.channel = None
        
        # æ­»ä¿¡ç›¸å…³
        self.main_queue_prefix = 'main_queue'
        self.dlx_exchange_prefix = 'dlx'
        self.dlq_queue_prefix = 'dlq'
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.dlq_stats = {
            'total_messages': 0,
            'expired_messages': 0,
            'rejected_messages': 0,
            'max_length_messages': 0,
            'processed_messages': 0
        }
        
    def setup_dead_letter_queue(self, queue_name: str, ttl: int = None,
                              max_length: int = None, priority_queue: bool = False):
        """è®¾ç½®æ­»ä¿¡é˜Ÿåˆ—"""
        self.setup_connection()
        
        # ç”Ÿæˆç›¸å…³åç§°
        dlx_exchange = f"{self.dlx_exchange_prefix}_{queue_name}"
        dlq_queue = f"{self.dlq_queue_prefix}_{queue_name}"
        
        # å£°æ˜æ­»ä¿¡äº¤æ¢æœº
        self.channel.exchange_declare(
            exchange=dlx_exchange,
            exchange_type='direct',
            durable=True,
            auto_delete=False
        )
        
        # å£°æ˜æ­»ä¿¡é˜Ÿåˆ—
        self.channel.queue_declare(
            queue=dlq_queue,
            durable=True,
            arguments={
                'x-message-ttl': 604800,  # 7å¤©TTL
                'x-max-length': 10000,    # æœ€å¤§é•¿åº¦
                'x-overflow': 'reject-publish'
            }
        )
        
        # ç»‘å®šæ­»ä¿¡é˜Ÿåˆ—åˆ°æ­»ä¿¡äº¤æ¢æœº
        self.channel.queue_bind(
            exchange=dlx_exchange,
            queue=dlq_queue,
            routing_key=dlq_queue  # ä½¿ç”¨é˜Ÿåˆ—åä½œä¸ºè·¯ç”±é”®
        )
        
        # å£°æ˜ä¸»é˜Ÿåˆ—ï¼Œé…ç½®æ­»ä¿¡
        main_queue_arguments = {
            'x-dead-letter-exchange': dlx_exchange,
            'x-dead-letter-routing-key': dlq_queue