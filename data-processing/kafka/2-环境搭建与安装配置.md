# 第2章：环境搭建与安装配置

## 目录
1. [环境准备](#环境准备)
2. [单机Kafka安装](#单机kafka安装)
3. [集群环境搭建](#集群环境搭建)
4. [基础配置详解](#基础配置详解)
5. [管理工具使用](#管理工具使用)
6. [第一个Hello World](#第一个hello-world)
7. [常见问题解决](#常见问题解决)

## 环境准备

### 系统要求
```
操作系统：
✅ Linux (Ubuntu 18.04+ / CentOS 7+)
✅ macOS 10.14+
✅ Windows 10+ (WSL推荐)

硬件配置：
- CPU: 2核心以上
- 内存: 4GB以上 (推荐8GB)
- 磁盘: 20GB以上可用空间
- 网络: 稳定的互联网连接

软件依赖：
- Java 8 或 Java 11 (必需)
- SSH (集群环境)
- wget/curl (下载工具)
```

### Java环境验证
```bash
# 检查Java版本
java -version
javac -version

# 如果没有安装Java，Ubuntu/Debian:
sudo apt update
sudo apt install openjdk-11-jdk

# CentOS/RHEL:
sudo yum install java-11-openjdk-devel

# 设置JAVA_HOME
echo 'export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64' >> ~/.bashrc
source ~/.bashrc
echo $JAVA_HOME
```

### 下载Kafka
```bash
# 创建工作目录
mkdir -p ~/kafka-install
cd ~/kafka-install

# 下载Kafka (选择稳定版本)
wget https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz

# 解压
tar -xzf kafka_2.13-3.6.1.tgz
cd kafka_2.13-3.6.1

# 查看目录结构
ls -la
```

## 单机Kafka安装

### 目录结构说明
```
kafka_2.13-3.6.1/
├── bin/           # 可执行脚本
│   ├── kafka-server-start.sh     # 启动broker
│   ├── kafka-server-stop.sh      # 停止broker
│   ├── kafka-topics.sh           # 主题管理
│   ├── kafka-console-producer.sh # 命令行生产者
│   ├── kafka-console-consumer.sh # 命令行消费者
│   └── ...
├── config/        # 配置文件
│   ├── server.properties         # broker配置
│   ├── producer.properties       # 生产者配置
│   ├── consumer.properties       # 消费者配置
│   └── ...
├── libs/          # 依赖库
├── logs/          # 日志目录
└── ...
```

### 基础配置修改
```bash
# 编辑broker配置文件
nano config/server.properties

# 重要配置项：
# 1. broker.id - 集群中唯一标识
broker.id=0

# 2. listeners - 监听地址
listeners=PLAINTEXT://localhost:9092

# 3. advertised.listeners - 对外公布的地址
advertised.listeners=PLAINTEXT://localhost:9092

# 4. log.dirs - 日志存储目录
log.dirs=/tmp/kafka-logs

# 5. zookeeper.connect - Zookeeper地址
zookeeper.connect=localhost:2181

# 6. delete.topic.enable - 允许删除主题
delete.topic.enable=true

# 7. auto.create.topics.enable - 自动创建主题
auto.create.topics.enable=true
```

### 启动Kafka服务
```bash
# 启动Zookeeper (Kafka依赖)
bin/zookeeper-server-start.sh config/zookeeper.properties &

# 等待Zookeeper启动 (约10秒)
sleep 10

# 验证Zookeeper启动
echo "ruok" | nc localhost 2181

# 启动Kafka broker
bin/kafka-server-start.sh config/server.properties &
```

### 服务状态检查
```bash
# 检查Java进程
jps -l

# 预期输出应包含：
# - QuorumPeerMain (Zookeeper)
# - Kafka (Kafka broker)

# 检查端口监听
netstat -tlnp | grep 9092
netstat -tlnp | grep 2181

# 查看Kafka日志
tail -f logs/server.log
```

## 集群环境搭建

### 集群规划
```bash
# 假设3节点集群
# 节点1: 192.168.1.10
# 节点2: 192.168.1.11
# 节点3: 192.168.1.12

# 每台机器配置：
# broker.id: 0, 1, 2
# 端口: 9092, 9093, 9094
```

### 集群安装步骤

#### 1. 准备统一环境
```bash
# 所有节点执行
mkdir -p ~/kafka-cluster
cd ~/kafka-cluster

# 下载并解压Kafka (所有节点)
wget https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz
tar -xzf kafka_2.13-3.6.1.tgz

# 创建日志目录
mkdir -p kafka-logs-1 kafka-logs-2 kafka-logs-3
```

#### 2. 配置节点1
```bash
# 编辑config/server-1.properties
cat > config/server-1.properties << EOF
# 基础配置
broker.id=1
listeners=PLAINTEXT://192.168.1.10:9092
advertised.listeners=PLAINTEXT://192.168.1.10:9092

# 日志配置
log.dirs=/home/user/kafka-cluster/kafka-logs-1

# Zookeeper配置
zookeeper.connect=192.168.1.10:2181,192.168.1.11:2181,192.168.1.12:2181

# 优化配置
num.network.threads=8
num.io.threads=16
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600

# 主题配置
default.replication.factor=3
min.insync.replicas=2
auto.create.topics.enable=true
delete.topic.enable=true

# 日志配置
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000

# 网络配置
num.partitions=3
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=2
EOF
```

#### 3. 配置节点2和3
```bash
# 节点2: broker.id=2, 端口9093
cat > config/server-2.properties << EOF
# 基础配置
broker.id=2
listeners=PLAINTEXT://192.168.1.11:9093
advertised.listeners=PLAINTEXT://192.168.1.11:9093

# 日志配置
log.dirs=/home/user/kafka-cluster/kafka-logs-2

# Zookeeper配置
zookeeper.connect=192.168.1.10:2181,192.168.1.11:2181,192.168.1.12:2181

# 优化配置
num.network.threads=8
num.io.threads=16
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600

# 主题配置
default.replication.factor=3
min.insync.replicas=2
auto.create.topics.enable=true
delete.topic.enable=true

# 日志配置
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000

# 网络配置
num.partitions=3
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=2
EOF

# 节点3: broker.id=3, 端口9094
cat > config/server-3.properties << EOF
# 基础配置
broker.id=3
listeners=PLAINTEXT://192.168.1.12:9094
advertised.listeners=PLAINTEXT://192.168.1.12:9094

# 日志配置
log.dirs=/home/user/kafka-cluster/kafka-logs-3

# Zookeeper配置
zookeeper.connect=192.168.1.10:2181,192.168.1.11:2181,192.168.1.12:2181

# 优化配置
num.network.threads=8
num.io.threads=16
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600

# 主题配置
default.replication.factor=3
min.insync.replicas=2
auto.create.topics.enable=true
delete.topic.enable=true

# 日志配置
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000

# 网络配置
num.partitions=3
offsets.topic.replication.factor=3
transaction.state.log.replication.factor=3
transaction.state.log.min.isr=2
EOF
```

#### 4. 集群启动脚本
```bash
# 创建启动脚本 start-cluster.sh
cat > start-cluster.sh << 'EOF'
#!/bin/bash

echo "Starting Zookeeper cluster..."
# 启动Zookeeper (建议单独部署Zookeeper集群)
bin/zookeeper-server-start.sh config/zookeeper.properties &

sleep 10

echo "Starting Kafka cluster..."
# 启动所有Kafka节点
bin/kafka-server-start.sh config/server-1.properties &
sleep 5
bin/kafka-server-start.sh config/server-2.properties &
sleep 5
bin/kafka-server-start.sh config/server-3.properties &

echo "Cluster started!"
echo "Waiting for cluster initialization..."
sleep 30

echo "Cluster status:"
jps -l
EOF

chmod +x start-cluster.sh

# 创建停止脚本 stop-cluster.sh
cat > stop-cluster.sh << 'EOF'
#!/bin/bash

echo "Stopping Kafka cluster..."

# 停止Kafka进程
ps aux | grep kafka | grep -v grep | awk '{print $2}' | xargs kill -TERM

# 停止Zookeeper
ps aux | grep zookeeper | grep -v grep | awk '{print $2}' | xargs kill -TERM

echo "Cluster stopped!"
jps -l
EOF

chmod +x stop-cluster.sh
```

## 基础配置详解

### 核心配置参数
```properties
# ==== 基础配置 ====
# broker唯一标识 (集群中必须唯一)
broker.id=0

# 监听地址和端口
listeners=PLAINTEXT://0.0.0.0:9092

# 对外公布的地址 (客户端连接时使用)
advertised.listeners=PLAINTEXT://your-public-ip:9092

# ==== 存储配置 ====
# 日志存储目录
log.dirs=/tmp/kafka-logs

# 数据保留时间 (小时)
log.retention.hours=168

# 分段文件大小
log.segment.bytes=1073741824

# 保留检查间隔
log.retention.check.interval.ms=300000

# ==== 性能配置 ====
# 网络处理线程数
num.network.threads=8

# IO处理线程数
num.io.threads=16

# 发送缓冲区大小
socket.send.buffer.bytes=102400

# 接收缓冲区大小
socket.receive.buffer.bytes=102400

# 最大请求大小
socket.request.max.bytes=104857600

# ==== 主题配置 ====
# 默认分区数
num.partitions=3

# 默认副本因子
default.replication.factor=1

# ISR最小副本数
min.insync.replicas=1

# ==== Zookeeper配置 ====
# Zookeeper连接地址
zookeeper.connect=localhost:2181

# Session超时时间
zookeeper.session.timeout.ms=6000

# ==== 功能开关 ====
# 自动创建主题
auto.create.topics.enable=true

# 删除主题功能
delete.topic.enable=true

# ==== 高级配置 ====
# 压缩类型 (none, gzip, snappy, lz4, zstd)
compression.type=none

# 刷盘策略 (0: 异步刷盘, 1: 同步刷盘)
flush.ms=1000

# 批量大小控制
batch.size=16384
linger.ms=0
```

### 生产环境推荐配置
```properties
# ==== 集群环境配置示例 ====

# 基础配置
broker.id=1
listeners=PLAINTEXT://internal-ip:9092
advertised.listeners=PLAINTEXT://external-ip:9092

# 存储优化
log.dirs=/data/kafka-logs
log.retention.hours=168
log.segment.bytes=536870912  # 512MB

# 性能调优
num.network.threads=16
num.io.threads=32
socket.send.buffer.bytes=512000
socket.receive.buffer.bytes=512000

# 可靠性设置
default.replication.factor=3
min.insync.replicas=2
unclean.leader.election.enable=false

# 压缩优化
compression.type=snappy

# 内存优化
log.flush.interval.messages=10000
log.flush.interval.ms=1000
```

## 管理工具使用

### 主题管理
```bash
# 创建主题
bin/kafka-topics.sh --create \
    --topic my-topic \
    --bootstrap-server localhost:9092 \
    --partitions 3 \
    --replication-factor 1

# 列出所有主题
bin/kafka-topics.sh --list --bootstrap-server localhost:9092

# 查看主题详情
bin/kafka-topics.sh --describe \
    --topic my-topic \
    --bootstrap-server localhost:9092

# 修改主题分区数
bin/kafka-topics.sh --alter \
    --topic my-topic \
    --partitions 5 \
    --bootstrap-server localhost:9092

# 删除主题
bin/kafka-topics.sh --delete \
    --topic my-topic \
    --bootstrap-server localhost:9092
```

### 集群管理
```bash
# 查看集群信息
bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092

# 查看消费者组
bin/kafka-consumer-groups.sh --list --bootstrap-server localhost:9092

# 查看消费者组详情
bin/kafka-consumer-groups.sh --describe \
    --group my-group \
    --bootstrap-server localhost:9092

# 重置消费者组偏移量
bin/kafka-consumer-groups.sh --reset-offsets \
    --group my-group \
    --topic my-topic \
    --execute \
    --bootstrap-server localhost:9092
```

### 性能测试
```bash
# 生产者性能测试
bin/kafka-producer-perf-test.sh \
    --topic my-topic \
    --num-records 10000 \
    --record-size 100 \
    --throughput 1000 \
    --producer-props bootstrap.servers=localhost:9092

# 消费者性能测试
bin/kafka-consumer-perf-test.sh \
    --topic my-topic \
    --bootstrap-server localhost:9092 \
    --messages 10000 \
    --timeout 10000
```

## 第一个Hello World

### 使用命令行工具
```bash
# 1. 创建测试主题
bin/kafka-topics.sh --create \
    --topic hello-world \
    --bootstrap-server localhost:9092 \
    --partitions 1 \
    --replication-factor 1

# 2. 启动生产者 (发送消息)
bin/kafka-console-producer.sh \
    --topic hello-world \
    --bootstrap-server localhost:9092

# 输入消息：
Hello Kafka!
This is my first message.
Kafka is awesome!
# 按 Ctrl+C 退出

# 3. 启动消费者 (接收消息)
bin/kafka-console-consumer.sh \
    --topic hello-world \
    --bootstrap-server localhost:9092 \
    --from-beginning

# 预期输出：
Hello Kafka!
This is my first message.
Kafka is awesome!
```

### 使用Kafka客户端API
```java
// 创建Maven项目，添加依赖
// pom.xml
<dependencies>
    <dependency>
        <groupId>org.apache.kafka</groupId>
        <artifactId>kafka-clients</artifactId>
        <version>3.6.1</version>
    </dependency>
</dependencies>
```

```java
// SimpleProducer.java
import org.apache.kafka.clients.producer.*;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;

public class SimpleProducer {
    public static void main(String[] args) {
        // 配置属性
        Properties props = new Properties();
        props.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        props.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
        
        // 创建生产者
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        
        try {
            // 发送消息
            for (int i = 0; i < 10; i++) {
                String key = "key-" + i;
                String value = "Hello Kafka! Message " + i;
                
                ProducerRecord<String, String> record = 
                    new ProducerRecord<>("hello-world", key, value);
                
                // 异步发送
                producer.send(record, new Callback() {
                    @Override
                    public void onCompletion(RecordMetadata metadata, Exception exception) {
                        if (exception == null) {
                            System.out.println("消息发送成功: " +
                                "主题=" + metadata.topic() + 
                                ", 分区=" + metadata.partition() + 
                                ", 偏移量=" + metadata.offset());
                        } else {
                            System.out.println("消息发送失败: " + exception.getMessage());
                        }
                    }
                });
            }
        } finally {
            // 关闭生产者
            producer.close();
        }
    }
}
```

```java
// SimpleConsumer.java
import org.apache.kafka.clients.consumer.*;
import org.apache.kafka.common.serialization.StringDeserializer;

import java.time.Duration;
import java.util.Arrays;
import java.util.Properties;

public class SimpleConsumer {
    public static void main(String[] args) {
        // 配置属性
        Properties props = new Properties();
        props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(ConsumerConfig.GROUP_ID_CONFIG, "hello-world-group");
        props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");
        
        // 创建消费者
        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);
        
        try {
            // 订阅主题
            consumer.subscribe(Arrays.asList("hello-world"));
            
            // 消费消息
            while (true) {
                ConsumerRecords<String, String> records = 
                    consumer.poll(Duration.ofMillis(100));
                
                for (ConsumerRecord<String, String> record : records) {
                    System.out.printf("收到消息: key=%s, value=%s, 主题=%s, 分区=%d, 偏移量=%d%n",
                        record.key(), record.value(), 
                        record.topic(), record.partition(), record.offset());
                }
            }
        } finally {
            // 关闭消费者
            consumer.close();
        }
    }
}
```

### 编译和运行
```bash
# 编译Java代码
javac -cp /path/to/kafka/libs/* SimpleProducer.java SimpleConsumer.java

# 运行生产者
java -cp .:/path/to/kafka/libs/* SimpleProducer

# 运行消费者 (新终端窗口)
java -cp .:/path/to/kafka/libs/* SimpleConsumer

# 预期输出:
# 生产者:
消息发送成功: 主题=hello-world, 分区=0, 偏移量=0
消息发送成功: 主题=hello-world, 分区=0, 偏移量=1
...

# 消费者:
收到消息: key=key-0, value=Hello Kafka! Message 0, 主题=hello-world, 分区=0, 偏移量=0
收到消息: key=key-1, value=Hello Kafka! Message 1, 主题=hello-world, 分区=0, 偏移量=1
...
```

## 常见问题解决

### 安装问题
```bash
# 问题1: Java版本不兼容
java -version  # 确保是8或11版本

# 问题2: 端口被占用
netstat -tlnp | grep 9092
# 解决方法：修改config/server.properties中的listeners端口

# 问题3: Zookeeper连接失败
echo "ruok" | nc localhost 2181
# 返回"imok"表示正常，否则检查Zookeeper是否启动
```

### 运行时问题
```bash
# 问题1: 消息发送失败
# 检查：网络连接、broker状态、主题是否存在
bin/kafka-topics.sh --list:9092

 --bootstrap-server localhost# 问题2: 消费者无法接收消息
# 检查：消费者组状态、偏移量、重平衡
bin/kafka-consumer-groups.sh --describe \
    --group my-group \
    --bootstrap-server localhost:9092

# 问题3: 集群节点无法通信
# 检查：防火墙设置、网络连通性、监听地址配置
ping other-broker-ip
telnet other-broker-ip 9092
```

### 性能问题
```bash
# 问题1: 吞吐量低
# 调整配置：
# - 增加batch.size
# - 增加linger.ms
# - 启用压缩

# 问题2: 延迟高
# 检查：
# - 磁盘I/O
# - 网络带宽
# - JVM内存设置

# 问题3: 内存使用过高
# 调整：
# - 减少JVM堆内存
# - 优化GC参数
# - 调整缓冲设置
```

### 日志查看
```bash
# 查看broker日志
tail -f logs/server.log

# 查看Zookeeper日志
tail -f logs/zookeeper.log

# 查看消费者日志
tail -f logs/kafka-authorizer.log

# 查看控制器日志
tail -f logs/controller.log
```

## 本章小结

### 学习要点
```
1. 环境准备：Java环境、系统要求、软件依赖
2. 单机安装：下载、解压、配置、启动
3. 集群搭建：多节点配置、集群管理脚本
4. 核心配置：broker.id、listeners、log.dirs等
5. 管理工具：主题管理、集群管理、性能测试
6. 实战演练：命令行工具、Java客户端API
7. 故障排除：常见问题诊断和解决方法
```

### 实践建议
```
1. 先在单机环境练习，熟悉基础操作
2. 再搭建集群环境，学习分布式部署
3. 编写管理脚本，自动化常用操作
4. 建立监控机制，及时发现问题
5. 制定备份恢复策略，确保数据安全
```

### 下一章预告
第3章《核心架构与组件详解》将深入介绍：
- Kafka整体架构设计
- Broker内部组件原理
- 分区副本机制详解
- Leader选举算法
- 数据一致性保证

### 验证清单
```
□ Java环境配置正确
□ Kafka单机安装成功
□ 能创建主题并发送/接收消息
□ 集群环境搭建完成
□ 基础配置参数理解
□ 管理工具使用熟练
□ 常见问题能够定位和解决
```

---

**重要提醒**：
- 生产环境部署前务必进行充分测试
- 配置修改后需要重启broker生效
- 定期监控集群状态和性能指标
- 建立完善的日志收集和分析机制