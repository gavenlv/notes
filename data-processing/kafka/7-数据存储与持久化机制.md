# 第7章：数据存储与持久化机制

## 目录
1. [Kafka存储架构概述](#Kafka存储架构概述)
2. [日志段存储原理](#日志段存储原理)
3. [索引机制详解](#索引机制详解)
4. [数据写入流程](#数据写入流程)
5. [数据读取机制](#数据读取机制)
6. [压缩与清理策略](#压缩与清理策略)
7. [磁盘I/O优化](#磁盘I/O优化)
8. [存储配置调优](#存储配置调优)
9. [数据恢复与备份](#数据恢复与备份)
10. [实战：存储性能监控](#实战存储性能监控)

---

## Kafka存储架构概述

### Kafka存储设计理念

Kafka的存储设计基于以下核心原则，实现了高吞吐量和数据持久化的完美平衡：

#### 设计原则：
1. **顺序写入**：消息追加到日志末尾，避免随机I/O
2. **分段存储**：将日志分为多个段文件，便于管理
3. **稀疏索引**：使用稀疏索引减少内存占用
4. **多副本机制**：数据复制确保可靠性
5. **批量处理**：大量写入减少系统调用次数
6. **压缩存储**：启用压缩减少磁盘空间

### 存储架构组件

```java
package com.kafka.tutorial.storage;

import org.apache.kafka.common.record.*;
import org.apache.kafka.common.utils.Time;
import org.apache.kafka.common.utils.Utils;

import java.io.*;
import java.nio.ByteBuffer;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.file.*;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.*;
import java.util.concurrent.locks.ReentrantReadWriteLock;
import java.time.Duration;

/**
 * Kafka存储架构模拟实现
 * 展示Kafka核心存储组件的工作原理
 */
public class KafkaStorageArchitecture {
    
    /**
     * LogSegment: 日志段实现
     */
    public static class LogSegment {
        private final File file;
        private final long baseOffset;
        private final int maxSizeBytes;
        private final long maxRecordBatchSize;
        private final CompressionType compressionType;
        private final Time time;
        private final AtomicBoolean isRollNeeded = new AtomicBoolean(false);
        private final AtomicBoolean isClosed = new AtomicBoolean(false);
        private final AtomicLong size = new AtomicLong(0);
        private final AtomicLong lastModified = new AtomicLong(0);
        private final MappedByteBuffer memoryMappedBuffer;
        private final FileChannel fileChannel;
        
        // 索引相关
        private final OffsetIndex offsetIndex;
        private final TimeIndex timeIndex;
        private final Long writeLock = 0L; // 写入锁标记
        
        public LogSegment(File file, long baseOffset, int maxSizeBytes, int maxRecordBatchSize,
                         CompressionType compressionType, Time time) throws IOException {
            this.file = file;
            this.baseOffset = baseOffset;
            this.maxSizeBytes = maxSizeBytes;
            this.maxRecordBatchSize = maxRecordBatchSize;
            this.compressionType = compressionType;
            this.time = time;
            
            this.fileChannel = FileChannel.open(file.toPath(), 
                StandardOpenOption.CREATE, StandardOpenOption.READ, StandardOpenOption.WRITE);
            
            // 创建内存映射文件用于高效随机访问
            this.memoryMappedBuffer = fileChannel.map(FileChannel.MapMode.READ_WRITE, 0, maxSizeBytes);
            
            // 初始化索引
            this.offsetIndex = new OffsetIndex(file, baseOffset, maxSizeBytes);
            this.timeIndex = new TimeIndex(file, baseOffset, maxSizeBytes);
            
            // 如果是现有文件，加载索引
            if (file.exists() && file.length() > 0) {
                loadExistingSegment();
            }
        }
        
        /**
         * 写入消息到日志段
         */
        public AppendResult append(long offset, ByteBuffer key, ByteBuffer value, 
                                  long timestamp, Long checksum) {
            synchronized (writeLock) {
                try {
                    // 创建压缩记录批次
                    CompressionType compression = chooseCompression(value);
                    RecordBatch batch = createCompressedBatch(offset, key, value, timestamp, compression);
                    
                    // 检查是否需要滚动段
                    if (size.get() + batch.sizeInBytes() > maxSizeBytes) {
                        isRollNeeded.set(true);
                        return AppendResult.FAILURE_ROLL_NEEDED;
                    }
                    
                    // 写入数据到内存映射缓冲区
                    batch.writeTo(memoryMappedBuffer);
                    
                    // 更新索引
                    updateIndices(offset, timestamp, batch.sizeInBytes());
                    
                    // 更新段大小
                    size.addAndGet(batch.sizeInBytes());
                    lastModified.set(time.milliseconds());
                    
                    // 强制写入磁盘
                    memoryMappedBuffer.force();
                    
                    return AppendResult.success(batch.sizeInBytes());
                    
                } catch (Exception e) {
                    return AppendResult.failure(e);
                }
            }
        }
        
        /**
         * 从日志段读取消息
         */
        public List<RecordBatch> read(long startOffset, long maxOffset, int maxBytes) {
            List<RecordBatch> batches = new ArrayList<>();
            
            try {
                // 找到起始位置
                int startPosition = findPosition(startOffset);
                if (startPosition < 0) return batches;
                
                memoryMappedBuffer.position(startPosition);
                
                while (memoryMappedBuffer.remaining() > 0 && batches.size() < maxBytes) {
                    // 读取记录批次头部
                    if (memoryMappedBuffer.remaining() < Records.HEADER_SIZE_UP_TO_MAGIC) {
                        break; // 数据不完整
                    }
                    
                    RecordBatch batch = RecordBatch.readFrom(memoryMappedBuffer);
                    if (batch == null) break;
                    
                    // 检查偏移量范围
                    if (batch.lastOffset() > maxOffset) {
                        break;
                    }
                    
                    batches.add(batch);
                    
                    // 检查字节数限制
                    int totalSize = batches.stream().mapToInt(b -> b.sizeInBytes()).sum();
                    if (totalSize > maxBytes) {
                        break;
                    }
                }
                
            } catch (Exception e) {
                System.err.println("读取日志段时发生错误: " + e.getMessage());
            }
            
            return batches;
        }
        
        /**
         * 更新索引
         */
        private void updateIndices(long offset, long timestamp, int sizeInBytes) {
            // 更新偏移量索引
            int relativeOffset = (int) (offset - baseOffset);
            offsetIndex.maybeAppend(relativeOffset, size.get());
            
            // 更新时间索引
            timeIndex.maybeAppend(timestamp, size.get());
        }
        
        /**
         * 查找偏移量对应的文件位置
         */
        private int findPosition(long targetOffset) {
            int relativeOffset = (int) (targetOffset - baseOffset);
            
            // 二分查找索引
            int position = offsetIndex.lookup(relativeOffset);
            if (position < 0) {
                return -1;
            }
            
            return position;
        }
        
        /**
         * 压缩策略选择
         */
        private CompressionType chooseCompression(ByteBuffer value) {
            if (value != null && value.remaining() > 1024) {
                return compressionType; // 大消息使用压缩
            }
            return CompressionType.NONE; // 小消息不压缩
        }
        
        /**
         * 创建压缩记录批次
         */
        private RecordBatch createCompressedBatch(long offset, ByteBuffer key, ByteBuffer value,
                                                 long timestamp, CompressionType compression) {
            Record record = new DefaultRecord(offset, timestamp, key, value);
            return new DefaultRecordBatch(offset, Collections.singletonList(record), compression);
        }
        
        /**
         * 加载现有段文件
         */
        private void loadExistingSegment() throws IOException {
            memoryMappedBuffer.position(0);
            
            while (memoryMappedBuffer.remaining() > Records.HEADER_SIZE_UP_TO_MAGIC) {
                RecordBatch batch = RecordBatch.readFrom(memoryMappedBuffer);
                if (batch == null) break;
                
                // 重建索引
                updateIndices(batch.baseOffset(), batch.timestamp(), batch.sizeInBytes());
                size.addAndGet(batch.sizeInBytes());
            }
        }
        
        /**
         * 滚动到新段
         */
        public LogSegment roll() throws IOException {
            if (isRollNeeded.compareAndSet(true, false)) {
                close();
                return new LogSegment(generateNextFile(), baseOffset + size.get(), 
                                    maxSizeBytes, maxRecordBatchSize, compressionType, time);
            }
            return this;
        }
        
        /**
         * 生成下一个段文件名
         */
        private File generateNextFile() {
            String fileName = String.format("%d.log", baseOffset + size.get() + 1);
            return new File(file.getParent(), fileName);
        }
        
        /**
         * 关闭段
         */
        public void close() throws IOException {
            if (isClosed.compareAndSet(false, true)) {
                // 刷新索引到磁盘
                offsetIndex.flush();
                timeIndex.flush();
                
                // 关闭文件通道
                if (memoryMappedBuffer != null) {
                    memoryMappedBuffer.force();
                }
                fileChannel.close();
            }
        }
        
        /**
         * 获取段状态
         */
        public SegmentStatus getStatus() {
            return new SegmentStatus(
                file.getName(),
                baseOffset,
                size.get(),
                lastModified.get(),
                isRollNeeded.get(),
                isClosed.get(),
                offsetIndex.size(),
                timeIndex.size()
            );
        }
        
        // Getters
        public long getBaseOffset() { return baseOffset; }
        public long getSize() { return size.get(); }
        public boolean isRollNeeded() { return isRollNeeded.get(); }
        public boolean isClosed() { return isClosed.get(); }
        public File getFile() { return file; }
        public OffsetIndex getOffsetIndex() { return offsetIndex; }
        public TimeIndex getTimeIndex() { return timeIndex; }
    }
    
    /**
     * OffsetIndex: 偏移量索引
     */
    public static class OffsetIndex {
        private final File file;
        private final long baseOffset;
        private final int maxSize;
        private final AtomicInteger entries = new AtomicInteger(0);
        private final MappedByteBuffer buffer;
        private final int entrySize = 8; // 相对偏移量(4字节) + 物理位置(4字节)
        
        public OffsetIndex(File file, long baseOffset, int maxSize) throws IOException {
            this.file = file;
            this.baseOffset = baseOffset;
            this.maxSize = maxSize;
            
            File indexFile = new File(file.getAbsolutePath().replace(".log", ".index"));
            this.buffer = FileChannel.open(indexFile.toPath(), 
                StandardOpenOption.CREATE, StandardOpenOption.READ, StandardOpenOption.WRITE)
                .map(FileChannel.MapMode.READ_WRITE, 0, maxSize);
        }
        
        /**
         * 添加索引条目
         */
        public void maybeAppend(int relativeOffset, int position) {
            // 稀疏索引：每隔一定间隔才添加索引条目
            if (shouldAppend(relativeOffset)) {
                append(relativeOffset, position);
            }
        }
        
        /**
         * 插入索引条目
         */
        public void append(int relativeOffset, int position) {
            int slot = entries.getAndIncrement();
            if (slot >= maxSize / entrySize - 1) {
                throw new IndexOutOfBoundsException("索引空间不足");
            }
            
            buffer.putInt(slot * entrySize, relativeOffset);
            buffer.putInt(slot * entrySize + 4, position);
        }
        
        /**
         * 查找偏移量对应的物理位置
         */
        public int lookup(int targetOffset) {
            int entries = this.entries.get();
            if (entries == 0) return 0;
            
            int left = 0;
            int right = entries - 1;
            
            while (left <= right) {
                int mid = (left + right) / 2;
                buffer.position(mid * entrySize);
                int offset = buffer.getInt();
                
                if (offset == targetOffset) {
                    return buffer.getInt(mid * entrySize + 4);
                } else if (offset < targetOffset) {
                    left = mid + 1;
                } else {
                    right = mid - 1;
                }
            }
            
            // 如果找不到精确匹配，返回小于目标偏移量的最大位置
            if (right >= 0) {
                return buffer.getInt(right * entrySize + 4);
            }
            
            return 0;
        }
        
        /**
         * 判断是否应该添加索引条目
         */
        private boolean shouldAppend(int relativeOffset) {
            int currentEntries = entries.get();
            return currentEntries == 0 || relativeOffset >= currentEntries * 4; // 每4个偏移量添加一个索引
        }
        
        public void flush() {
            buffer.force();
        }
        
        public int size() {
            return entries.get();
        }
    }
    
    /**
     * TimeIndex: 时间戳索引
     */
    public static class TimeIndex {
        private final File file;
        private final long baseOffset;
        private final int maxSize;
        private final AtomicInteger entries = new AtomicInteger(0);
        private final MappedByteBuffer buffer;
        private final int entrySize = 12; // 时间戳(8字节) + 物理位置(4字节)
        
        public TimeIndex(File file, long baseOffset, int maxSize) throws IOException {
            this.file = file;
            this.baseOffset = baseOffset;
            this.maxSize = maxSize;
            
            File indexFile = new File(file.getAbsolutePath().replace(".log", ".timeindex"));
            this.buffer = FileChannel.open(indexFile.toPath(), 
                StandardOpenOption.CREATE, StandardOpenOption.READ, StandardOpenOption.WRITE)
                .map(FileChannel.MapMode.READ_WRITE, 0, maxSize);
        }
        
        /**
         * 添加时间索引
         */
        public void maybeAppend(long timestamp, int position) {
            if (shouldAppend(timestamp)) {
                append(timestamp, position);
            }
        }
        
        /**
         * 插入时间索引条目
         */
        public void append(long timestamp, int position) {
            int slot = entries.getAndIncrement();
            if (slot >= maxSize / entrySize - 1) {
                throw new IndexOutOfBoundsException("时间索引空间不足");
            }
            
            buffer.putLong(slot * entrySize, timestamp);
            buffer.putInt(slot * entrySize + 8, position);
        }
        
        /**
         * 查找时间戳对应的物理位置
         */
        public int lookup(long targetTimestamp) {
            int entries = this.entries.get();
            if (entries == 0) return 0;
            
            int left = 0;
            int right = entries - 1;
            
            while (left <= right) {
                int mid = (left + right) / 2;
                buffer.position(mid * entrySize);
                long timestamp = buffer.getLong();
                
                if (timestamp == targetTimestamp) {
                    return buffer.getInt(mid * entrySize + 8);
                } else if (timestamp < targetTimestamp) {
                    left = mid + 1;
                } else {
                    right = mid - 1;
                }
            }
            
            if (right >= 0) {
                return buffer.getInt(right * entrySize + 8);
            }
            
            return 0;
        }
        
        private boolean shouldAppend(long timestamp) {
            int currentEntries = entries.get();
            if (currentEntries == 0) return true;
            
            // 检查是否与最后一个条目的时间戳足够远
            buffer.position((currentEntries - 1) * entrySize);
            long lastTimestamp = buffer.getLong();
            
            return timestamp - lastTimestamp > 1000; // 每秒最多一个索引条目
        }
        
        public void flush() {
            buffer.force();
        }
        
        public int size() {
            return entries.get();
        }
    }
    
    /**
     * 记录批次
     */
    public static abstract class RecordBatch {
        protected long baseOffset;
        protected long lastOffset;
        protected long timestamp;
        protected int sizeInBytes;
        
        public abstract void writeTo(ByteBuffer buffer);
        public abstract List<Record> getRecords();
        
        // Getters
        public long getBaseOffset() { return baseOffset; }
        public long getLastOffset() { return lastOffset; }
        public long getTimestamp() { return timestamp; }
        public int getSizeInBytes() { return sizeInBytes; }
        public long lastOffset() { return lastOffset; }
        public long timestamp() { return timestamp; }
        public int sizeInBytes() { return sizeInBytes; }
    }
    
    /**
     * 默认记录批次
     */
    public static class DefaultRecordBatch extends RecordBatch {
        private List<Record> records;
        private CompressionType compressionType;
        
        public DefaultRecordBatch(long baseOffset, List<Record> records, CompressionType compressionType) {
            this.baseOffset = baseOffset;
            this.records = records;
            this.compressionType = compressionType;
            this.lastOffset = records.get(records.size() - 1).getOffset();
            this.timestamp = records.get(0).getTimestamp();
            this.sizeInBytes = calculateSize();
        }
        
        @Override
        public void writeTo(ByteBuffer buffer) {
            // 写入批次头部信息
            buffer.putLong(baseOffset);
            buffer.putLong(lastOffset);
            buffer.putLong(timestamp);
            buffer.putInt(sizeInBytes);
            buffer.put((byte) compressionType.ordinal());
            
            // 写入压缩后的记录数据
            ByteBuffer compressedData = compressRecords(records, compressionType);
            buffer.put(compressedData);
        }
        
        @Override
        public List<Record> getRecords() {
            return records;
        }
        
        private ByteBuffer compressRecords(List<Record> records, CompressionType compressionType) {
            // 模拟压缩过程
            ByteBuffer buffer = ByteBuffer.allocate(records.size() * 100); // 假设每条记录100字节
            
            for (Record record : records) {
                record.writeTo(buffer);
            }
            
            buffer.flip();
            return buffer;
        }
        
        private int calculateSize() {
            int headerSize = 8 + 8 + 8 + 4 + 1; // baseOffset + lastOffset + timestamp + size + compressionType
            int recordsSize = records.size() * 100; // 假设每条记录平均100字节
            return headerSize + recordsSize;
        }
        
        /**
         * 从ByteBuffer读取批次
         */
        public static RecordBatch readFrom(ByteBuffer buffer) {
            try {
                long baseOffset = buffer.getLong();
                long lastOffset = buffer.getLong();
                long timestamp = buffer.getLong();
                int size = buffer.getInt();
                byte compressionTypeOrdinal = buffer.get();
                
                RecordBatch batch = new DefaultRecordBatch(baseOffset, 
                    Collections.emptyList(), CompressionType.values()[compressionTypeOrdinal]);
                batch.lastOffset = lastOffset;
                batch.timestamp = timestamp;
                batch.sizeInBytes = size;
                
                return batch;
            } catch (Exception e) {
                return null;
            }
        }
    }
    
    /**
     * 记录
     */
    public static class DefaultRecord {
        private long offset;
        private long timestamp;
        private ByteBuffer key;
        private ByteBuffer value;
        
        public DefaultRecord(long offset, long timestamp, ByteBuffer key, ByteBuffer value) {
            this.offset = offset;
            this.timestamp = timestamp;
            this.key = key;
            this.value = value;
        }
        
        public void writeTo(ByteBuffer buffer) {
            buffer.putLong(offset);
            buffer.putLong(timestamp);
            if (key != null) {
                buffer.putInt(key.remaining());
                buffer.put(key);
            } else {
                buffer.putInt(-1);
            }
            if (value != null) {
                buffer.putInt(value.remaining());
                buffer.put(value);
            } else {
                buffer.putInt(-1);
            }
        }
        
        // Getters
        public long getOffset() { return offset; }
        public long getTimestamp() { return timestamp; }
        public ByteBuffer getKey() { return key; }
        public ByteBuffer getValue() { return value; }
    }
    
    /**
     * 追加结果
     */
    public static class AppendResult {
        public static final AppendResult FAILURE_ROLL_NEEDED = new AppendResult(false, true, null, 0);
        
        private final boolean success;
        private final boolean rollNeeded;
        private final Exception error;
        private final int bytesWritten;
        
        private AppendResult(boolean success, boolean rollNeeded, Exception error, int bytesWritten) {
            this.success = success;
            this.rollNeeded = rollNeeded;
            this.error = error;
            this.bytesWritten = bytesWritten;
        }
        
        public static AppendResult success(int bytesWritten) {
            return new AppendResult(true, false, null, bytesWritten);
        }
        
        public static AppendResult failure(Exception error) {
            return new AppendResult(false, false, error, 0);
        }
        
        public boolean isSuccess() { return success; }
        public boolean isRollNeeded() { return rollNeeded; }
        public Exception getError() { return error; }
        public int getBytesWritten() { return bytesWritten; }
    }
    
    /**
     * 段状态
     */
    public static class SegmentStatus {
        private final String fileName;
        private final long baseOffset;
        private final long size;
        private final long lastModified;
        private final boolean rollNeeded;
        private final boolean isClosed;
        private final int offsetIndexSize;
        private final int timeIndexSize;
        
        public SegmentStatus(String fileName, long baseOffset, long size, long lastModified,
                           boolean rollNeeded, boolean isClosed, int offsetIndexSize, int timeIndexSize) {
            this.fileName = fileName;
            this.baseOffset = baseOffset;
            this.size = size;
            this.lastModified = lastModified;
            this.rollNeeded = rollNeeded;
            this.isClosed = isClosed;
            this.offsetIndexSize = offsetIndexSize;
            this.timeIndexSize = timeIndexSize;
        }
        
        @Override
        public String toString() {
            return String.format("Segment[file=%s, baseOffset=%d, size=%d, modified=%d, rollNeeded=%s, closed=%s, offsets=%d, times=%d]",
                fileName, baseOffset, size, lastModified, rollNeeded, isClosed, offsetIndexSize, timeIndexSize);
        }
    }
    
    /**
     * 压缩类型枚举
     */
    public enum CompressionType {
        NONE(0, "none"),
        GZIP(1, "gzip"),
        SNAPPY(2, "snappy"),
        LZ4(3, "lz4"),
        ZSTD(4, "zstd");
        
        private final int id;
        private final String name;
        
        CompressionType(int id, String name) {
            this.id = id;
            this.name = name;
        }
        
        public int getId() { return id; }
        public String getName() { return name; }
    }
}
```

### LogManager: 日志管理器

```java
package com.kafka.tutorial.storage;

import java.io.*;
import java.nio.ByteBuffer;
import java.nio.file.*;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.*;
import java.util.concurrent.locks.ReentrantReadWriteLock;
import java.time.Duration;

/**
 * Kafka日志管理器
 * 负责管理整个topic的日志存储
 */
public class KafkaLogManager {
    private final String topic;
    private final int partition;
    private final int maxSegmentSizeBytes;
    private final int maxIndexSizeBytes;
    private final CompressionType compressionType;
    private final Path logDir;
    private final ScheduledExecutorService flushScheduler;
    private final Map<Long, LogSegment> segments;
    private final AtomicLong activeSegmentBaseOffset;
    private final ReentrantReadWriteLock lock;
    private final LogStats logStats;
    
    public KafkaLogManager(String topic, int partition, int maxSegmentSizeBytes, 
                          int maxIndexSizeBytes, CompressionType compressionType) throws IOException {
        this.topic = topic;
        this.partition = partition;
        this.maxSegmentSizeBytes = maxSegmentSizeBytes;
        this.maxIndexSizeBytes = maxIndexSizeBytes;
        this.compressionType = compressionType;
        this.logDir = Paths.get("logs", topic, String.valueOf(partition));
        this.flushScheduler = Executors.newSingleThreadScheduledExecutor();
        this.segments = new ConcurrentHashMap<>();
        this.activeSegmentBaseOffset = new AtomicLong(0);
        this.lock = new ReentrantReadWriteLock();
        this.logStats = new LogStats();
        
        // 创建日志目录
        Files.createDirectories(logDir);
        
        // 加载现有段
        loadExistingSegments();
        
        // 启动定期刷新任务
        scheduleFlushTask();
    }
    
    /**
     * 加载现有段文件
     */
    private void loadExistingSegments() throws IOException {
        File[] logFiles = logDir.toFile().listFiles((dir, name) -> name.endsWith(".log"));
        
        if (logFiles == null || logFiles.length == 0) {
            // 创建第一个段
            createNewSegment(0);
            return;
        }
        
        // 按文件名排序
        Arrays.sort(logFiles, (f1, f2) -> {
            String name1 = f1.getName().replace(".log", "");
            String name2 = f2.getName().replace(".log", "");
            return Long.compare(Long.parseLong(name1), Long.parseLong(name2));
        });
        
        // 加载所有段
        for (File logFile : logFiles) {
            String baseOffsetStr = logFile.getName().replace(".log", "");
            long baseOffset = Long.parseLong(baseOffsetStr);
            
            LogSegment segment = new LogSegment(
                logFile, 
                baseOffset, 
                maxSegmentSizeBytes, 
                maxSegmentSizeBytes / 4, 
                compressionType,
                new SystemTime()
            );
            
            segments.put(baseOffset, segment);
            activeSegmentBaseOffset.set(baseOffset);
        }
        
        System.out.println("加载了 " + segments.size() + " 个日志段");
    }
    
    /**
     * 创建新的日志段
     */
    private void createNewSegment(long baseOffset) throws IOException {
        File segmentFile = logDir.resolve(baseOffset + ".log").toFile();
        LogSegment segment = new LogSegment(
            segmentFile,
            baseOffset,
            maxSegmentSizeBytes,
            maxSegmentSizeBytes / 4,
            compressionType,
            new SystemTime()
        );
        
        segments.put(baseOffset, segment);
        activeSegmentBaseOffset.set(baseOffset);
        
        System.out.println("创建新段: " + segmentFile.getName());
    }
    
    /**
     * 追加消息到日志
     */
    public AppendResult append(long offset, ByteBuffer key, ByteBuffer value, long timestamp) {
        lock.writeLock().lock();
        
        try {
            long currentActiveBaseOffset = activeSegmentBaseOffset.get();
            LogSegment activeSegment = segments.get(currentActiveBaseOffset);
            
            // 检查当前段是否需要滚动
            if (activeSegment.isRollNeeded()) {
                LogSegment newSegment = activeSegment.roll();
                if (newSegment != activeSegment) {
                    // 新段被创建
                    createNewSegment(activeSegment.getBaseOffset() + activeSegment.getSize());
                }
                activeSegment = segments.get(activeSegmentBaseOffset.get());
            }
            
            // 追加到当前段
            AppendResult result = activeSegment.append(offset, key, value, timestamp, null);
            
            if (result.isSuccess()) {
                logStats.recordWrite(result.getBytesWritten());
            }
            
            return result;
            
        } catch (Exception e) {
            return AppendResult.failure(e);
        } finally {
            lock.writeLock().unlock();
        }
    }
    
    /**
     * 从日志读取消息
     */
    public List<RecordBatch> read(long startOffset, long maxOffset, int maxBytes) {
        lock.readLock().lock();
        
        try {
            List<RecordBatch> batches = new ArrayList<>();
            
            // 找到包含起始偏移量的段
            LogSegment targetSegment = findSegment(startOffset);
            if (targetSegment == null) {
                return batches;
            }
            
            // 读取目标段及其后续段
            long currentOffset = targetSegment.getBaseOffset();
            
            for (LogSegment segment : getSegmentsFrom(currentOffset)) {
                List<RecordBatch> segmentBatches = segment.read(startOffset, maxOffset, maxBytes);
                batches.addAll(segmentBatches);
                
                // 检查是否已达到字节限制
                int totalBytes = batches.stream().mapToInt(b -> b.sizeInBytes()).sum();
                if (totalBytes >= maxBytes) {
                    break;
                }
            }
            
            return batches;
            
        } finally {
            lock.readLock().unlock();
        }
    }
    
    /**
     * 查找包含指定偏移量的段
     */
    private LogSegment findSegment(long offset) {
        List<LogSegment> segmentList = new ArrayList<>(segments.values());
        
        // 按baseOffset降序排列
        segmentList.sort((s1, s2) -> Long.compare(s2.getBaseOffset(), s1.getBaseOffset()));
        
        for (LogSegment segment : segmentList) {
            if (offset >= segment.getBaseOffset()) {
                return segment;
            }
        }
        
        return null;
    }
    
    /**
     * 从指定偏移量开始的段列表
     */
    private List<LogSegment> getSegmentsFrom(long fromOffset) {
        return segments.values().stream()
            .filter(segment -> segment.getBaseOffset() >= fromOffset)
            .sorted((s1, s2) -> Long.compare(s1.getBaseOffset(), s2.getBaseOffset()))
            .collect(ArrayList::new, ArrayList::add, ArrayList::addAll);
    }
    
    /**
     * 调度刷新任务
     */
    private void scheduleFlushTask() {
        flushScheduler.scheduleAtFixedRate(() -> {
            try {
                flushAllSegments();
            } catch (Exception e) {
                System.err.println("刷新段时发生错误: " + e.getMessage());
            }
        }, 5000, 5000, TimeUnit.MILLISECONDS); // 每5秒刷新一次
    }
    
    /**
     * 刷新所有段的索引到磁盘
     */
    private void flushAllSegments() {
        for (LogSegment segment : segments.values()) {
            segment.getOffsetIndex().flush();
            segment.getTimeIndex().flush();
        }
        logStats.recordFlush();
    }
    
    /**
     * 获取日志状态
     */
    public LogStatus getStatus() {
        lock.readLock().lock();
        
        try {
            List<SegmentStatus> segmentStatuses = new ArrayList<>();
            for (LogSegment segment : segments.values()) {
                segmentStatuses.add(segment.getStatus());
            }
            
            segmentStatuses.sort((s1, s2) -> Long.compare(s1.baseOffset, s2.baseOffset));
            
            return new LogStatus(
                topic,
                partition,
                logDir.toString(),
                segmentStatuses,
                logStats.getSnapshot()
            );
            
        } finally {
            lock.readLock().unlock();
        }
    }
    
    /**
     * 清理旧段文件
     */
    public void cleanupOldSegments(long retentionMs) {
        long cutoffTime = System.currentTimeMillis() - retentionMs;
        
        List<Long> segmentsToDelete = new ArrayList<>();
        
        for (Map.Entry<Long, LogSegment> entry : segments.entrySet()) {
            long baseOffset = entry.getKey();
            LogSegment segment = entry.getValue();
            
            // 检查段的最后修改时间
            if (segment.getStatus().lastModified < cutoffTime) {
                segmentsToDelete.add(baseOffset);
            }
        }
        
        // 删除旧段（保留活跃段）
        for (long baseOffset : segmentsToDelete) {
            LogSegment segment = segments.get(baseOffset);
            if (segment != null && !segment.isClosed()) {
                try {
                    segment.close();
                    Files.deleteIfExists(Paths.get(segment.getFile().getAbsolutePath()));
                    
                    // 删除对应的索引文件
                    Files.deleteIfExists(Paths.get(segment.getFile().getAbsolutePath().replace(".log", ".index")));
                    Files.deleteIfExists(Paths.get(segment.getFile().getAbsolutePath().replace(".log", ".timeindex")));
                    
                    segments.remove(baseOffset);
                    System.out.println("删除了旧段: " + segment.getFile().getName());
                    
                } catch (IOException e) {
                    System.err.println("删除段失败: " + e.getMessage());
                }
            }
        }
    }
    
    /**
     * 关闭日志管理器
     */
    public void close() {
        flushScheduler.shutdown();
        try {
            if (!flushScheduler.awaitTermination(30, TimeUnit.SECONDS)) {
                flushScheduler.shutdownNow();
            }
        } catch (InterruptedException e) {
            flushScheduler.shutdownNow();
            Thread.currentThread().interrupt();
        }
        
        // 关闭所有段
        for (LogSegment segment : segments.values()) {
            try {
                segment.close();
            } catch (IOException e) {
                System.err.println("关闭段时发生错误: " + e.getMessage());
            }
        }
        
        System.out.println("日志管理器已关闭: " + topic + "-" + partition);
    }
    
    /**
     * 系统时间
     */
    public static class SystemTime implements Time {
        @Override
        public long milliseconds() {
            return System.currentTimeMillis();
        }
        
        @Override
        public long nanoseconds() {
            return System.nanoTime();
        }
        
        @Override
        public void sleep(long ms) {
            try {
                Thread.sleep(ms);
            } catch (InterruptedException e) {
                Thread.currentThread().interrupt();
            }
        }
    }
    
    /**
     * 日志统计
     */
    public static class LogStats {
        private final AtomicLong totalBytesWritten = new AtomicLong(0);
        private final AtomicLong totalFlushes = new AtomicLong(0);
        private final AtomicLong totalReads = new AtomicLong(0);
        private final AtomicLong totalReadBytes = new AtomicLong(0);
        private final long startTime = System.currentTimeMillis();
        
        public void recordWrite(int bytes) {
            totalBytesWritten.addAndGet(bytes);
        }
        
        public void recordFlush() {
            totalFlushes.incrementAndGet();
        }
        
        public void recordRead(int bytes) {
            totalReads.incrementAndGet();
            totalReadBytes.addAndGet(bytes);
        }
        
        public LogStatsSnapshot getSnapshot() {
            long uptime = System.currentTimeMillis() - startTime;
            
            return new LogStatsSnapshot(
                totalBytesWritten.get(),
                totalFlushes.get(),
                totalReads.get(),
                totalReadBytes.get(),
                uptime
            );
        }
        
        public static class LogStatsSnapshot {
            private final long totalBytesWritten;
            private final long totalFlushes;
            private final long totalReads;
            private final long totalReadBytes;
            private final long uptime;
            
            public LogStatsSnapshot(long totalBytesWritten, long totalFlushes, 
                                  long totalReads, long totalReadBytes, long uptime) {
                this.totalBytesWritten = totalBytesWritten;
                this.totalFlushes = totalFlushes;
                this.totalReads = totalReads;
                this.totalReadBytes = totalReadBytes;
                this.uptime = uptime;
            }
            
            public double getWriteThroughput() {
                return uptime > 0 ? (double) totalBytesWritten / (uptime / 1000.0) : 0.0;
            }
            
            public double getReadThroughput() {
                return uptime > 0 ? (double) totalReadBytes / (uptime / 1000.0) : 0.0;
            }
            
            // Getters
            public long getTotalBytesWritten() { return totalBytesWritten; }
            public long getTotalFlushes() { return totalFlushes; }
            public long getTotalReads() { return totalReads; }
            public long getTotalReadBytes() { return totalReadBytes; }
            public long getUptime() { return uptime; }
        }
    }
    
    /**
     * 日志状态
     */
    public static class LogStatus {
        private final String topic;
        private final int partition;
        private final String logDir;
        private final List<SegmentStatus> segments;
        private final LogStats.LogStatsSnapshot stats;
        
        public LogStatus(String topic, int partition, String logDir, 
                        List<SegmentStatus> segments, LogStats.LogStatsSnapshot stats) {
            this.topic = topic;
            this.partition = partition;
            this.logDir = logDir;
            this.segments = new ArrayList<>(segments);
            this.stats = stats;
        }
        
        @Override
        public String toString() {
            StringBuilder sb = new StringBuilder();
            sb.append("=== Kafka日志状态 ===\n");
            sb.append("主题: ").append(topic).append("\n");
            sb.append("分区: ").append(partition).append("\n");
            sb.append("日志目录: ").append(logDir).append("\n");
            sb.append("段数量: ").append(segments.size()).append("\n");
            sb.append("总写入字节: ").append(stats.getTotalBytesWritten()).append("\n");
            sb.append("写入吞吐量: ").append(String.format("%.2f", stats.getWriteThroughput())).append(" bytes/s\n");
            sb.append("读取次数: ").append(stats.getTotalReads()).append("\n");
            sb.append("读取吞吐量: ").append(String.format("%.2f", stats.getReadThroughput())).append(" bytes/s\n");
            sb.append("运行时间: ").append(stats.getUptime() / 1000).append(" 秒\n");
            sb.append("段详情:\n");
            
            for (SegmentStatus segment : segments) {
                sb.append("  ").append(segment).append("\n");
            }
            
            return sb.toString();
        }
        
        // Getters
        public String getTopic() { return topic; }
        public int getPartition() { return partition; }
        public String getLogDir() { return logDir; }
        public List<SegmentStatus> getSegments() { return segments; }
        public LogStats.LogStatsSnapshot getStats() { return stats; }
    }
}
```

---

## 日志段存储原理

### 段文件组织结构

Kafka的日志段文件采用以下组织结构：

```java
package com.kafka.tutorial.storage;

import java.io.*;
import java.nio.ByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.file.*;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.*;

/**
 * 日志段存储原理详解
 */
public class LogSegmentStorage {
    
    /**
     * 日志段文件结构
     */
    public static class LogSegmentFile {
        private final String baseOffset;
        private final Path logFile;
        private final Path offsetIndexFile;
        private final Path timeIndexFile;
        private final Path producerSnapshotFile;
        
        public LogSegmentFile(String baseOffset, Path baseDir) {
            this.baseOffset = baseOffset;
            this.logFile = baseDir.resolve(baseOffset + ".log");
            this.offsetIndexFile = baseDir.resolve(baseOffset + ".index");
            this.timeIndexFile = baseDir.resolve(baseOffset + ".timeindex");
            this.producerSnapshotFile = baseDir.resolve(baseOffset + ".snapshot");
        }
        
        /**
         * 创建新段文件
         */
        public void createFiles() throws IOException {
            // 创建所有必要的文件
            Files.createDirectories(logFile.getParent());
            Files.createFile(logFile);
            Files.createFile(offsetIndexFile);
            Files.createFile(timeIndexFile);
            Files.createFile(producerSnapshotFile);
            
            System.out.println("创建段文件: " + logFile.getFileName());
        }
        
        /**
         * 获取文件信息
         */
        public FileInfo getFileInfo() throws IOException {
            return new FileInfo(
                logFile.toFile().length(),
                offsetIndexFile.toFile().length(),
                timeIndexFile.toFile().length(),
                producerSnapshotFile.toFile().length()
            );
        }
        
        // Getters
        public String getBaseOffset() { return baseOffset; }
        public Path getLogFile() { return logFile; }
        public Path getOffsetIndexFile() { return offsetIndexFile; }
        public Path getTimeIndexFile() { return timeIndexFile; }
        public Path getProducerSnapshotFile() { return producerSnapshotFile; }
    }
    
    /**
     * 文件信息
     */
    public static class FileInfo {
        private final long logFileSize;
        private final long offsetIndexSize;
        private final long timeIndexSize;
        private final long snapshotSize;
        
        public FileInfo(long logFileSize, long offsetIndexSize, long timeIndexSize, long snapshotSize) {
            this.logFileSize = logFileSize;
            this.offsetIndexSize = offsetIndexSize;
            this.timeIndexSize = timeIndexSize;
            this.snapshotSize = snapshotSize;
        }
        
        public long getTotalSize() {
            return logFileSize + offsetIndexSize + timeIndexSize + snapshotSize;
        }
        
        // Getters
        public long getLogFileSize() { return logFileSize; }
        public long getOffsetIndexSize() { return offsetIndexSize; }
        public long getTimeIndexSize() { return timeIndexSize; }
        public long getSnapshotSize() { return snapshotSize; }
    }
    
    /**
     * 消息写入模拟器
     */
    public static class MessageWriter {
        private final FileChannel logChannel;
        private final FileChannel indexChannel;
        private final ByteBuffer buffer;
        private final AtomicLong position = new AtomicLong(0);
        private final AtomicLong lastOffset = new AtomicLong(0);
        private final int maxMessageSize;
        
        public MessageWriter(Path logFile, int bufferSize, int maxMessageSize) throws IOException {
            this.logChannel = FileChannel.open(logFile, StandardOpenOption.CREATE, 
                StandardOpenOption.WRITE, StandardOpenOption.APPEND);
            this.buffer = ByteBuffer.allocate(bufferSize);
            this.maxMessageSize = maxMessageSize;
        }
        
        /**
         * 写入消息批次
         */
        public WriteResult writeMessageBatch(long offset, ByteBuffer key, ByteBuffer value, 
                                           long timestamp) throws IOException {
            try {
                // 构建消息批次
                ByteBuffer messageBuffer = buildMessageBatch(offset, key, value, timestamp);
                
                // 检查消息大小
                if (messageBuffer.remaining() > maxMessageSize) {
                    return WriteResult.FAILURE_MESSAGE_TOO_LARGE;
                }
                
                // 如果缓冲区空间不足，先刷新
                if (buffer.remaining() < messageBuffer.remaining()) {
                    flush();
                }
                
                // 写入缓冲区
                buffer.put(messageBuffer);
                
                // 更新统计信息
                position.addAndGet(messageBuffer.remaining());
                lastOffset.set(offset);
                
                return WriteResult.success(messageBuffer.remaining());
                
            } catch (Exception e) {
                return WriteResult.failure(e);
            }
        }
        
        /**
         * 构建消息批次
         */
        private ByteBuffer buildMessageBatch(long offset, ByteBuffer key, ByteBuffer value, long timestamp) {
            int keyLength = key != null ? key.remaining() : -1;
            int valueLength = value != null ? value.remaining() : -1;
            
            // 计算批次大小
            int headerSize = 8 + 8 + 4 + 4; // offset + timestamp + key length + value length
            int messageSize = headerSize + (keyLength > 0 ? keyLength : 0) + (valueLength > 0 ? valueLength : 0);
            
            ByteBuffer batch = ByteBuffer.allocate(messageSize);
            
            // 写入批次头
            batch.putLong(offset);  // baseOffset
            batch.putLong(offset);  // lastOffset
            batch.putLong(timestamp);
            batch.putInt(keyLength);
            batch.putInt(valueLength);
            
            // 写入键和值
            if (keyLength > 0 && key != null) {
                batch.put(key);
            }
            if (valueLength > 0 && value != null) {
                batch.put(value);
            }
            
            batch.flip();
            return batch;
        }
        
        /**
         * 刷新缓冲区到磁盘
         */
        public void flush() throws IOException {
            if (buffer.position() > 0) {
                buffer.flip();
                while (buffer.hasRemaining()) {
                    logChannel.write(buffer);
                }
                logChannel.force(true);
                buffer.clear();
            }
        }
        
        /**
         * 关闭写入器
         */
        public void close() throws IOException {
            flush();
            logChannel.close();
        }
        
        // Getters
        public long getPosition() { return position.get(); }
        public long getLastOffset() { return lastOffset.get(); }
    }
    
    /**
     * 索引写入器
     */
    public static class IndexWriter {
        private final FileChannel indexChannel;
        private final ByteBuffer indexBuffer;
        private final AtomicInteger entries = new AtomicInteger(0);
        private final int maxEntries;
        
        public IndexWriter(Path indexFile, int bufferSize, int maxIndexEntries) throws IOException {
            this.indexChannel = FileChannel.open(indexFile, StandardOpenOption.CREATE, 
                StandardOpenOption.WRITE, StandardOpenOption.APPEND);
            this.indexBuffer = ByteBuffer.allocate(bufferSize);
            this.maxEntries = maxIndexEntries;
        }
        
        /**
         * 添加索引条目
         */
        public IndexResult addIndexEntry(int relativeOffset, int position) {
            if (entries.get() >= maxEntries) {
                return IndexResult.FAILURE_INDEX_FULL;
            }
            
            if (indexBuffer.remaining() < 8) { // 每个索引条目8字节
                try {
                    flush();
                } catch (IOException e) {
                    return IndexResult.failure(e);
                }
            }
            
            // 写入相对偏移量和物理位置
            indexBuffer.putInt(relativeOffset);
            indexBuffer.putInt(position);
            
            entries.incrementAndGet();
            
            return IndexResult.success();
        }
        
        /**
         * 刷新索引缓冲区
         */
        public void flush() throws IOException {
            if (indexBuffer.position() > 0) {
                indexBuffer.flip();
                while (indexBuffer.hasRemaining()) {
                    indexChannel.write(indexBuffer);
                }
                indexChannel.force(true);
                indexBuffer.clear();
            }
        }
        
        /**
         * 关闭索引写入器
         */
        public void close() throws IOException {
            flush();
            indexChannel.close();
        }
        
        // Getters
        public int getEntries() { return entries.get(); }
        public int getMaxEntries() { return maxEntries; }
    }
    
    /**
     * 写入结果
     */
    public static class WriteResult {
        public static final WriteResult FAILURE_MESSAGE_TOO_LARGE = new WriteResult(false, null, "消息过大");
        
        private final boolean success;
        private final Exception error;
        private final String errorMessage;
        private final int bytesWritten;
        
        private WriteResult(boolean success, Exception error, String errorMessage) {
            this(success, error, errorMessage, 0);
        }
        
        private WriteResult(boolean success, Exception error, String errorMessage, int bytesWritten) {
            this.success = success;
            this.error = error;
            this.errorMessage = errorMessage;
            this.bytesWritten = bytesWritten;
        }
        
        public static WriteResult success(int bytesWritten) {
            return new WriteResult(true, null, null, bytesWritten);
        }
        
        public static WriteResult failure(Exception error) {
            return new WriteResult(false, error, error.getMessage(), 0);
        }
        
        // Getters
        public boolean isSuccess() { return success; }
        public Exception getError() { return error; }
        public String getErrorMessage() { return errorMessage; }
        public int getBytesWritten() { return bytesWritten; }
    }
    
    /**
     * 索引结果
     */
    public static class IndexResult {
        public static final IndexResult FAILURE_INDEX_FULL = new IndexResult(false, "索引空间不足");
        
        private final boolean success;
        private final String errorMessage;
        
        private IndexResult(boolean success, String errorMessage) {
            this.success = success;
            this.errorMessage = errorMessage;
        }
        
        public static IndexResult success() {
            return new IndexResult(true, null);
        }
        
        public static IndexResult failure(Exception error) {
            return new IndexResult(false, error.getMessage());
        }
        
        public boolean isSuccess() { return success; }
        public String getErrorMessage() { return errorMessage; }
    }
    
    /**
     * 段滚动策略
     */
    public static class SegmentRollStrategy {
        private final int maxSegmentSize;
        private final int maxSegmentDuration;
        private final long baseOffset;
        private final AtomicLong segmentSize = new AtomicLong(0);
        private final AtomicLong segmentStartTime = new AtomicLong(System.currentTimeMillis());
        
        public SegmentRollStrategy(int maxSegmentSize, int maxSegmentDuration, long baseOffset) {
            this.maxSegmentSize = maxSegmentSize;
            this.maxSegmentDuration = maxSegmentDuration;
            this.baseOffset = baseOffset;
        }
        
        /**
         * 检查是否需要滚动段
         */
        public RollDecision shouldRoll(int messageSize) {
            long currentSize = segmentSize.addAndGet(messageSize);
            long currentTime = System.currentTimeMillis();
            long duration = currentTime - segmentStartTime.get();
            
            boolean shouldRollBySize = currentSize >= maxSegmentSize;
            boolean shouldRollByTime = duration >= maxSegmentDuration;
            boolean shouldRollBySizeOnly = shouldRollBySize && !shouldRollByTime;
            
            return new RollDecision(
                shouldRollBySize || shouldRollByTime,
                shouldRollBySizeOnly,
                shouldRollBySize,
                shouldRollByTime,
                currentSize,
                duration
            );
        }
        
        /**
         * 重置滚动检查器
         */
        public void reset() {
            segmentSize.set(0);
            segmentStartTime.set(System.currentTimeMillis());
        }
        
        public static class RollDecision {
            private final boolean shouldRoll;
            private final boolean shouldRollBySizeOnly;
            private final boolean sizeExceeded;
            private final boolean timeExceeded;
            private final long currentSize;
            private final long currentDuration;
            
            public RollDecision(boolean shouldRoll, boolean shouldRollBySizeOnly, 
                              boolean sizeExceeded, boolean timeExceeded, 
                              long currentSize, long currentDuration) {
                this.shouldRoll = shouldRoll;
                this.shouldRollBySizeOnly = shouldRollBySizeOnly;
                this.sizeExceeded = sizeExceeded;
                this.timeExceeded = timeExceeded;
                this.currentSize = currentSize;
                this.currentDuration = currentDuration;
            }
            
            // Getters
            public boolean shouldRoll() { return shouldRoll; }
            public boolean shouldRollBySizeOnly() { return shouldRollBySizeOnly; }
            public boolean isSizeExceeded() { return sizeExceeded; }
            public boolean isTimeExceeded() { return timeExceeded; }
            public long getCurrentSize() { return currentSize; }
            public long getCurrentDuration() { return currentDuration; }
        }
    }
    
    /**
     * 性能监控器
     */
    public static class PerformanceMonitor {
        private final AtomicLong totalMessages = new AtomicLong(0);
        private final AtomicLong totalBytes = new AtomicLong(0);
        private final AtomicLong totalFlushes = new AtomicLong(0);
        private final AtomicLong totalWriteTime = new AtomicLong(0);
        private final AtomicLong totalFlushTime = new AtomicLong(0);
        private final long startTime = System.currentTimeMillis();
        
        public void recordMessageWrite(int bytes, long writeTime) {
            totalMessages.incrementAndGet();
            totalBytes.addAndGet(bytes);
            totalWriteTime.addAndGet(writeTime);
        }
        
        public void recordFlush(long flushTime) {
            totalFlushes.incrementAndGet();
            totalFlushTime.addAndGet(flushTime);
        }
        
        public PerformanceStats getStats() {
            long uptime = System.currentTimeMillis() - startTime;
            
            return new PerformanceStats(
                totalMessages.get(),
                totalBytes.get(),
                totalFlushes.get(),
                totalWriteTime.get(),
                totalFlushTime.get(),
                uptime
            );
        }
        
        public static class PerformanceStats {
            private final long totalMessages;
            private final long totalBytes;
            private final long totalFlushes;
            private final long totalWriteTime;
            private final long totalFlushTime;
            private final long uptime;
            
            public PerformanceStats(long totalMessages, long totalBytes, long totalFlushes,
                                  long totalWriteTime, long totalFlushTime, long uptime) {
                this.totalMessages = totalMessages;
                this.totalBytes = totalBytes;
                this.totalFlushes = totalFlushes;
                this.totalWriteTime = totalWriteTime;
                this.totalFlushTime = totalFlushTime;
                this.uptime = uptime;
            }
            
            public double getMessagesPerSecond() {
                return uptime > 0 ? (double) totalMessages / (uptime / 1000.0) : 0.0;
            }
            
            public double getBytesPerSecond() {
                return uptime > 0 ? (double) totalBytes / (uptime / 1000.0) : 0.0;
            }
            
            public double getAverageWriteTime() {
                return totalMessages > 0 ? (double) totalWriteTime / totalMessages : 0.0;
            }
            
            public double getAverageFlushTime() {
                return totalFlushes > 0 ? (double) totalFlushTime / totalFlushes : 0.0;
            }
            
            // Getters
            public long getTotalMessages() { return totalMessages; }
            public long getTotalBytes() { return totalBytes; }
            public long getTotalFlushes() { return totalFlushes; }
            public long getTotalWriteTime() { return totalWriteTime; }
            public long getTotalFlushTime() { return totalFlushTime; }
            public long getUptime() { return uptime; }
        }
    }
    
    /**
     * 演示存储原理
     */
    public static void demonstrateStorage() throws IOException {
        System.out.println("=== Kafka日志段存储原理演示 ===\n");
        
        // 创建测试目录
        Path testDir = Paths.get("test_logs", "demo");
        Files.createDirectories(testDir);
        
        // 创建段文件
        LogSegmentFile segmentFile = new LogSegmentFile("0", testDir);
        segmentFile.createFiles();
        
        // 创建消息写入器
        MessageWriter messageWriter = new MessageWriter(segmentFile.getLogFile(), 1024, 1024 * 1024);
        
        // 创建索引写入器
        IndexWriter indexWriter = new IndexWriter(segmentFile.getOffsetIndexFile(), 1024, 1000);
        
        // 创建滚动策略
        SegmentRollStrategy rollStrategy = new SegmentRollStrategy(1024 * 1024, 60000, 0);
        
        // 创建性能监控器
        PerformanceMonitor monitor = new PerformanceMonitor();
        
        // 写入测试消息
        System.out.println("开始写入测试消息...");
        
        for (int i = 0; i < 100; i++) {
            long startTime = System.nanoTime();
            
            // 创建测试消息
            String key = "key-" + i;
            String value = "value-" + i + " " + "x".repeat(100); // 100字节的value
            
            ByteBuffer keyBuffer = ByteBuffer.wrap(key.getBytes());
            ByteBuffer valueBuffer = ByteBuffer.wrap(value.getBytes());
            
            // 写入消息
            WriteResult result = messageWriter.writeMessageBatch(i, keyBuffer, valueBuffer, System.currentTimeMillis());
            
            long writeTime = System.nanoTime() - startTime;
            
            if (result.isSuccess()) {
                monitor.recordMessageWrite(result.getBytesWritten(), writeTime);
                
                // 添加索引条目
                if (i % 10 == 0) { // 每10条消息添加一个索引条目
                    IndexResult indexResult = indexWriter.addIndexEntry(i, (int) messageWriter.getPosition());
                    if (!indexResult.isSuccess()) {
                        System.err.println("添加索引失败: " + indexResult.getErrorMessage());
                    }
                }
                
                // 检查滚动策略
                RollDecision rollDecision = rollStrategy.shouldRoll(result.getBytesWritten());
                if (rollDecision.shouldRoll()) {
                    System.out.println("段需要滚动: " + rollDecision);
                    break;
                }
                
            } else {
                System.err.println("写入消息失败: " + result.getErrorMessage());
            }
        }
        
        // 刷新数据
        long flushStart = System.nanoTime();
        messageWriter.flush();
        indexWriter.flush();
        long flushTime = System.nanoTime() - flushStart;
        monitor.recordFlush(flushTime);
        
        // 获取文件信息
        FileInfo fileInfo = segmentFile.getFileInfo();
        
        // 获取性能统计
        PerformanceMonitor.PerformanceStats stats = monitor.getStats();
        
        // 输出结果
        System.out.println("\n=== 写入完成 ===");
        System.out.println("文件信息:");
        System.out.println("  日志文件大小: " + fileInfo.getLogFileSize() + " 字节");
        System.out.println("  索引文件大小: " + fileInfo.getOffsetIndexSize() + " 字节");
        System.out.println("  总文件大小: " + fileInfo.getTotalSize() + " 字节");
        
        System.out.println("\n性能统计:");
        System.out.println("  总消息数: " + stats.getTotalMessages());
        System.out.println("  总字节数: " + stats.getTotalBytes());
        System.out.println("  消息吞吐量: " + String.format("%.2f", stats.getMessagesPerSecond()) + " msg/s");
        System.out.println("  字节吞吐量: " + String.format("%.2f", stats.getBytesPerSecond()) + " bytes/s");
        System.out.println("  平均写入时间: " + String.format("%.2f", stats.getAverageWriteTime() / 1000000.0) + " ms");
        System.out.println("  平均刷新时间: " + String.format("%.2f", stats.getAverageFlushTime() / 1000000.0) + " ms");
        System.out.println("  运行时间: " + stats.getUptime() / 1000 + " 秒");
        
        // 清理
        messageWriter.close();
        indexWriter.close();
        
        System.out.println("\n=== 演示完成 ===");
    }
}
```

---

## 索引机制详解

### Kafka的双重索引系统

```java
package com.kafka.tutorial.storage;

import java.io.*;
import java.nio.ByteBuffer;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;
import java.nio.file.*;
import java.util.*;
import java.util.concurrent.*;
import java.util.concurrent.atomic.*;

/**
 * Kafka索引机制详解
 * 实现偏移量索引和时间戳索引
 */
public class KafkaIndexing {
    
    /**
     * 高级偏移量索引
     */
    public static class AdvancedOffsetIndex {
        private final MappedByteBuffer buffer;
        private final int entrySize = 8; // 4字节相对偏移量 + 4字节物理位置
        private final AtomicInteger entries = new AtomicInteger(0);
        private final AtomicLong lastRelativeOffset = new AtomicLong(-1);
        private final AtomicLong lastPosition = new AtomicLong(-1);
        private final int maxEntries;
        
        public AdvancedOffsetIndex(ByteBuffer buffer, int maxEntries) {
            this.buffer = buffer;
            this.maxEntries = maxEntries;
        }
        
        /**
         * 稀疏索引插入
         */
        public boolean maybeAppend(int relativeOffset, int position, int indexInterval) {
            // 检查是否满足稀疏条件
            int currentLastOffset = (int) lastRelativeOffset.get();
            
            if (currentLastOffset < 0 || 
                (relativeOffset - currentLastOffset) >= indexInterval ||
                entries.get() == 0) {
                return append(relativeOffset, position);
            }
            
            return false;
        }
        
        /**
         * 插入索引条目
         */
        public boolean append(int relativeOffset, int position) {
            int slot = entries.get();
            if (slot >= maxEntries) {
                return false; // 索引空间不足
            }
            
            try {
                buffer.putInt(slot * entrySize, relativeOffset);
                buffer.putInt(slot * entrySize + 4, position);
                
                entries.incrementAndGet();
                lastRelativeOffset.set(relativeOffset);
                lastPosition.set(position);
                
                return true;
            } catch (Exception e) {
                return false;
            }
        }
        
        /**
         * 二分查找定位
         */
        public int lookup(int targetOffset) {
            int numEntries = entries.get();
            if (numEntries == 0) {
                return 0;
            }
            
            // 二分查找
            int low = 0;
            int high = numEntries - 1;
            int result = -1;
            
            while (low <= high) {
                int mid = (low + high) >>> 1;
                buffer.position(mid * entrySize);
                int offset = buffer.getInt();
                
                if (offset <= targetOffset) {
                    result = mid;
                    low = mid + 1;
                } else {
                    high = mid - 1;
                }
            }
            
            if (result >= 0) {
                buffer.position(result * entrySize + 4);
                return buffer.getInt();
            }
            
            return 0;
        }
        
        /**
         * 获取索引区间
         */
        public IndexInterval getInterval(int offset) {
            int numEntries = entries.get();
            if (numEntries <= 1) {
                return new IndexInterval(0, Integer.MAX_VALUE, 0, Integer.MAX_VALUE);
            }
            
            int currentOffset = offset;
            int prevOffset = 0;
            int prevPosition = 0;
            
            // 找到当前位置
            int position = lookup(currentOffset);
            
            // 找到上一个索引点
            int slot = findSlot(currentOffset);
            if (slot > 0) {
                buffer.position((slot - 1) * entrySize);
                prevOffset = buffer.getInt();
                prevPosition = buffer.getInt();
            }
            
            // 找到下一个索引点
            int nextOffset = Integer.MAX_VALUE;
            int nextPosition = Integer.MAX_VALUE;
            
            if (slot < numEntries - 1) {
                buffer.position((slot + 1) * entrySize);
                nextOffset = buffer.getInt();
                nextPosition = buffer.getInt();
            }
            
            return new IndexInterval(prevOffset, currentOffset, prevPosition, nextPosition);
        }
        
        /**
         * 找到偏移量对应的槽位
         */
        private int findSlot(int offset) {
            int numEntries = entries.get();
            int low = 0;
            int high = numEntries - 1;
            
            while (low <= high) {
                int mid = (low + high) >>> 1;
                buffer.position(mid * entrySize);
                int currentOffset = buffer.getInt();
                
                if (currentOffset == offset) {
                    return mid;
                } else if (currentOffset < offset) {
                    low = mid + 1;
                } else {
                    high = mid - 1;
                }
            }
            
            return high; // 返回小于目标偏移量的最大槽位
        }
        
        /**
         * 重建索引
         */
        public void rebuild(int baseOffset, List<Long> offsets, List<Integer> positions) {
            entries.set(0);
            
            for (int i = 0; i < offsets.size(); i++) {
                int relativeOffset = (int) (offsets.get(i) - baseOffset);
                int position = positions.get(i);
                
                if (!append(relativeOffset, position)) {
                    break; // 索引空间不足
                }
            }
        }
        
        /**
         * 索引压缩
         */
        public void compress(int compressionFactor) {
            int numEntries = entries.get();
            if (numEntries <= compressionFactor) {
                return;
            }
            
            int compressedEntries = numEntries / compressionFactor;
            ByteBuffer tempBuffer = ByteBuffer.allocate(compressedEntries * entrySize);
            
            // 保留压缩后的条目
            for (int i = 0; i < compressedEntries; i++) {
                int originalSlot = i * compressionFactor;
                buffer.position(originalSlot * entrySize);
                int offset = buffer.getInt();
                int position = buffer.getInt();
                
                tempBuffer.putInt(offset);
                tempBuffer.putInt(position);
            }
            
            // 写回索引
            buffer.position(0);
            buffer.put(tempBuffer.flip());
            entries.set(compressedEntries);
        }
        
        public static class IndexInterval {
            public final int previousOffset;
            public final int currentOffset;
            public final int previousPosition;
            public final int nextPosition;
            
            public IndexInterval(int previousOffset, int currentOffset, 
                               int previousPosition, int nextPosition) {
                this.previousOffset = previousOffset;
                this.currentOffset = currentOffset;
                this.previousPosition = previousPosition;
                this.nextPosition = nextPosition;
            }
        }
        
        // Getters
        public int getEntryCount() { return entries.get(); }
        public long getLastRelativeOffset() { return lastRelativeOffset.get(); }
        public long getLastPosition() { return lastPosition.get(); }
    }
    
    /**
     * 时间戳索引
     */
    public static class TimestampIndex {
        private final MappedByteBuffer buffer;
        private final int entrySize = 12; // 8字节时间戳 + 4字节物理位置
        private final AtomicInteger entries = new AtomicInteger(0);
        private final AtomicLong lastTimestamp = new AtomicLong(-1);
        private final AtomicLong lastPosition = new AtomicLong(-1);
        private final int maxEntries;
        
        public TimestampIndex(ByteBuffer buffer, int maxEntries) {
            this.buffer = buffer;
            this.maxEntries = maxEntries;
        }
        
        /**
         * 插入时间戳索引
         */
        public boolean maybeAppend(long timestamp, int position, long indexIntervalMs) {
            long lastTs = lastTimestamp.get();
            
            if (lastTs < 0 || 
                (timestamp - lastTs) >= indexIntervalMs ||
                entries.get() == 0) {
                return append(timestamp, position);
            }
            
            return false;
        }
        
        /**
         * 插入时间戳索引条目
         */
        public boolean append(long timestamp, int position) {
            int slot = entries.get();
            if (slot >= maxEntries) {
                return false;
            }
            
            try {
                buffer.putLong(slot * entrySize, timestamp);
                buffer.putInt(slot * entrySize + 8, position);
                
                entries.incrementAndGet();
                lastTimestamp.set(timestamp);
                lastPosition.set(position);
                
                return true;
            } catch (Exception e) {
                return false;
            }
        }
        
        /**
         * 时间戳查找
         */
        public int lookup(long targetTimestamp) {
            int numEntries = entries.get();
            if (numEntries == 0) {
                return 0;
            }
            
            // 二分查找
            int low = 0;
            int high = numEntries - 1;
            int result = -1;
            
            while (low <= high) {
                int mid = (low + high) >>> 1;
                buffer.position(mid * entrySize);
                long timestamp = buffer.getLong();
                
                if (timestamp <= targetTimestamp) {
                    result = mid;
                    low = mid + 1;
                } else {
                    high = mid - 1;
                }
            }
            
            if (result >= 0) {
                buffer.position(result * entrySize + 8);
                return buffer.getInt();
            }
            
            return 0;
        }
        
        /**
         * 时间范围查询
         */
        public List<TimestampIndexEntry> queryTimeRange(long startTime, long endTime) {
            List<TimestampIndexEntry> results = new ArrayList<>();
            int numEntries = entries.get();
            
            for (int i = 0; i < numEntries; i++) {
                buffer.position(i * entrySize);
                long timestamp = buffer.getLong();
                int position = buffer.getInt();
                
                if (timestamp >= startTime && timestamp <= endTime) {
                    results.add(new TimestampIndexEntry(timestamp, position));
                }
            }
            
            return results;
        }
        
        /**
         * 查找最近的时间戳索引
         */
        public Optional<TimestampIndexEntry> findLatestEntryBefore(long timestamp) {
            int numEntries = entries.get();
            int bestIndex = -1;
            long bestTimestamp = Long.MIN_VALUE;
            
            for (int i = 0; i < numEntries; i++) {
                buffer.position(i * entrySize);
                long entryTimestamp = buffer.getLong();
                
                if (entryTimestamp <= timestamp && entryTimestamp > bestTimestamp) {
                    bestTimestamp = entryTimestamp;
                    bestIndex = i;
                }
            }
            
            if (bestIndex >= 0) {
                buffer.position(bestIndex * entrySize + 8);
                int position = buffer.getInt();
                return Optional.of(new TimestampIndexEntry(bestTimestamp, position));
            }
            
            return Optional.empty();
        }
        
        public static class TimestampIndexEntry {
            public final long timestamp;
            public final int position;
            
            public TimestampIndexEntry(long timestamp, int position) {
                this.timestamp = timestamp;
                this.position = position;
            }
        }
        
        // Getters
        public int getEntryCount() { return entries.get(); }
        public long getLastTimestamp() { return lastTimestamp.get(); }
        public long getLastPosition() { return lastPosition.get(); }
    }
    
    /**
     * 复合索引管理器
     */
    public static class CompoundIndexManager {
        private final AdvancedOffsetIndex offsetIndex;
        private final TimestampIndex timestampIndex;
        private final AtomicLong totalLookups = new AtomicLong(0);
        private final AtomicLong totalIndexHits = new AtomicLong(0);
        private final AtomicLong totalIndexMisses = new AtomicLong(0);
        
        public CompoundIndexManager(ByteBuffer offsetBuffer, ByteBuffer timestampBuffer, int maxEntries) {
            this.offsetIndex = new AdvancedOffsetIndex(offsetBuffer, maxEntries);
            this.timestampIndex = new TimestampIndex(timestampBuffer, maxEntries);
        }
        
        /**
         * 统一索引查询
         */
        public IndexLookupResult lookup(long targetOffset, long targetTimestamp, int lookupType) {
            totalLookups.incrementAndGet();
            
            long startTime = System.nanoTime();
            
            int position = 0;
            boolean found = false;
            
            switch (lookupType) {
                case LookupType.OFFSET_ONLY:
                    position = offsetIndex.lookup((int) targetOffset);
                    found = true;
                    break;
                    
                case LookupType.TIMESTAMP_ONLY:
                    position = timestampIndex.lookup(targetTimestamp);
                    found = true;
                    break;
                    
                case LookupType.HYBRID:
                    // 先尝试时间戳查找
                    Optional<TimestampIndex.TimestampIndexEntry> timeEntry = 
                        timestampIndex.findLatestEntryBefore(targetTimestamp);
                    
                    if (timeEntry.isPresent()) {
                        position = timeEntry.get().position;
                        found = true;
                    } else {
                        // 回退到偏移量查找
                        position = offsetIndex.lookup((int) targetOffset);
                        found = true;
                    }
                    break;
                    
                default:
                    throw new IllegalArgumentException("未知的查找类型: " + lookupType);
            }
            
            long lookupTime = System.nanoTime() - startTime;
            
            if (found && position >= 0) {
                totalIndexHits.incrementAndGet();
            } else {
                totalIndexMisses.incrementAndGet();
            }
            
            return new IndexLookupResult(position, found, lookupTime, lookupType);
        }
        
        /**
         * 批量索引更新
         */
        public void batchUpdate(List<IndexUpdateEntry> updates) {
            for (IndexUpdateEntry update : updates) {
                if (update.type == UpdateType.OFFSET) {
                    offsetIndex.maybeAppend(
                        update.relativeOffset, 
                        update.position, 
                        update.indexInterval
                    );
                } else if (update.type == UpdateType