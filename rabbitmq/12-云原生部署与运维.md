# ç¬¬12ç« ï¼šäº‘åŸç”ŸRabbitMQéƒ¨ç½²ä¸è¿ç»´

éšç€äº‘åŸç”ŸæŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œä¼ä¸šçº§æ¶ˆæ¯ä¸­é—´ä»¶éœ€è¦åœ¨å®¹å™¨åŒ–ã€å¾®æœåŠ¡åŒ–å’Œè‡ªåŠ¨åŒ–çš„ç¯å¢ƒä¸­è¿è¡Œã€‚RabbitMQä½œä¸ºä¼ä¸šçº§æ¶ˆæ¯é˜Ÿåˆ—ï¼Œåœ¨äº‘åŸç”Ÿç¯å¢ƒä¸­çš„éƒ¨ç½²ä¸è¿ç»´é¢ä¸´ç€æ–°çš„æŒ‘æˆ˜ã€‚æœ¬ç« å°†æ·±å…¥æ¢è®¨RabbitMQåœ¨Kubernetesã€Dockerç­‰å®¹å™¨ç¯å¢ƒä¸­çš„æœ€ä½³éƒ¨ç½²å®è·µï¼Œä»¥åŠé…å¥—çš„ç›‘æ§ã€å‘Šè­¦å’Œè¿ç»´ç­–ç•¥ã€‚

## ğŸ“‹ ç›®å½•
1. [äº‘åŸç”ŸåŸºç¡€æ¦‚å¿µ](#1-äº‘åŸç”ŸåŸºç¡€æ¦‚å¿µ)
2. [Kubernetesç¯å¢ƒå‡†å¤‡](#2-kubernetesç¯å¢ƒå‡†å¤‡)
3. [RabbitMQå®¹å™¨åŒ–éƒ¨ç½²](#3-rabbitmqå®¹å™¨åŒ–éƒ¨ç½²)
4. [Helm Charté«˜çº§é…ç½®](#4-helm-charté«˜çº§é…ç½®)
5. [æœåŠ¡ç½‘æ ¼é›†æˆ](#5-æœåŠ¡ç½‘æ ¼é›†æˆ)
6. [ç›‘æ§ä¸å‘Šè­¦ç³»ç»Ÿ](#6-ç›‘æ§ä¸å‘Šè­¦ç³»ç»Ÿ)
7. [è‡ªåŠ¨åŒ–è¿ç»´å·¥å…·](#7-è‡ªåŠ¨åŒ–è¿ç»´å·¥å…·)
8. [å¤šäº‘éƒ¨ç½²ä¸ç¾å¤‡](#8-å¤šäº‘éƒ¨ç½²ä¸ç¾å¤‡)

## 1. äº‘åŸç”ŸåŸºç¡€æ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯äº‘åŸç”Ÿ(Cloud Native)

äº‘åŸç”Ÿæ˜¯ä¸€å¥—æŠ€æœ¯ä½“ç³»å’Œæ–¹æ³•è®ºï¼Œé€šè¿‡å®¹å™¨åŒ–ã€å¾®æœåŠ¡ã€æŒç»­äº¤ä»˜ç­‰æŠ€æœ¯ï¼Œæ„å»ºå¯å¼¹æ€§æ‰©å±•çš„åº”ç”¨æ¶æ„ï¼š

#### æ ¸å¿ƒç†å¿µ
- **å®¹å™¨åŒ–å°è£…**ï¼šåº”ç”¨åŠå…¶ä¾èµ–æ‰“åŒ…ä¸ºå®¹å™¨
- **åŠ¨æ€ç®¡ç†**ï¼šé€šè¿‡ç¼–æ’å¹³å°è‡ªåŠ¨åŒ–éƒ¨ç½²å’Œç®¡ç†
- **å¾®æœåŠ¡å¯¼å‘**ï¼šåº”ç”¨æ‹†åˆ†ä¸ºæ¾è€¦åˆçš„å¾®æœåŠ¡
- **åŸºç¡€è®¾æ–½å³ä»£ç **ï¼šä»£ç åŒ–çš„åŸºç¡€è®¾æ–½ç®¡ç†

#### æŠ€æœ¯æ ˆ
```
äº‘åŸç”ŸæŠ€æœ¯æ ˆï¼š
â”œâ”€â”€ å®¹å™¨åŒ–æŠ€æœ¯
â”‚   â”œâ”€â”€ Docker - å®¹å™¨è¿è¡Œæ—¶
â”‚   â”œâ”€â”€ containerd - å®¹å™¨è¿è¡Œæ—¶å¼•æ“
â”‚   â””â”€â”€ Podman - å®¹å™¨ç®¡ç†å·¥å…·
â”œâ”€â”€ ç¼–æ’ä¸è°ƒåº¦
â”‚   â”œâ”€â”€ Kubernetes - å®¹å™¨ç¼–æ’å¹³å°
â”‚   â”œâ”€â”€ Docker Swarm - DockeråŸç”Ÿç¼–æ’
â”‚   â””â”€â”€ OpenShift - ä¼ä¸šçº§Kubernetes
â”œâ”€â”€ æœåŠ¡ç½‘æ ¼
â”‚   â”œâ”€â”€ Istio - å¼€æºæœåŠ¡ç½‘æ ¼
â”‚   â”œâ”€â”€ Linkerd - è½»é‡çº§æœåŠ¡ç½‘æ ¼
â”‚   â””â”€â”€ Consul Connect - HashiCorpæœåŠ¡ç½‘æ ¼
â”œâ”€â”€ ç›‘æ§ä¸å¯è§‚æµ‹æ€§
â”‚   â”œâ”€â”€ Prometheus - æŒ‡æ ‡æ”¶é›†
â”‚   â”œâ”€â”€ Grafana - å¯è§†åŒ–ä»ªè¡¨æ¿
â”‚   â”œâ”€â”€ Jaeger - åˆ†å¸ƒå¼è¿½è¸ª
â”‚   â””â”€â”€ ELK Stack - æ—¥å¿—åˆ†æ
â””â”€â”€ CI/CD
    â”œâ”€â”€ Jenkins - æŒç»­é›†æˆ
    â”œâ”€â”€ GitLab CI/CD - æŒç»­äº¤ä»˜
    â”œâ”€â”€ Argo CD - GitOpsæŒç»­éƒ¨ç½²
    â””â”€â”€ Flux - å£°æ˜å¼æŒç»­éƒ¨ç½²
```

### 1.2 RabbitMQäº‘åŸç”Ÿé€‚é…

#### ä¼ ç»Ÿéƒ¨ç½² vs äº‘åŸç”Ÿéƒ¨ç½²
| ç»´åº¦ | ä¼ ç»Ÿéƒ¨ç½² | äº‘åŸç”Ÿéƒ¨ç½² |
|------|----------|------------|
| éƒ¨ç½²æ–¹å¼ | ç‰©ç†æœº/è™šæ‹Ÿæœº | å®¹å™¨ + Kubernetes |
| æ‰©ç¼©å®¹ | æ‰‹åŠ¨é…ç½® | è‡ªåŠ¨æ‰©ç¼©å®¹ |
| æœåŠ¡å‘ç° | é™æ€é…ç½® | åŠ¨æ€æœåŠ¡å‘ç° |
| é…ç½®ç®¡ç† | é…ç½®æ–‡ä»¶ | ConfigMap/Secret |
| å¥åº·æ£€æŸ¥ | åº”ç”¨çº§åˆ« | æ¢é’ˆæ£€æŸ¥ |
| ç›‘æ§å‘Šè­¦ | å¤–éƒ¨å·¥å…· | å†…ç½®ç›‘æ§ + Prometheus |
| å‡çº§æ–¹å¼ | åœæœºå‡çº§ | æ»šåŠ¨å‡çº§/è“ç»¿éƒ¨ç½² |

#### RabbitMQäº‘åŸç”Ÿç‰¹æ€§è¦æ±‚
- **çŠ¶æ€ç®¡ç†**ï¼šæ”¯æŒæŒä¹…åŒ–å­˜å‚¨å’ŒçŠ¶æ€åŒæ­¥
- **ç½‘ç»œéš”ç¦»**ï¼šæ”¯æŒç½‘ç»œç­–ç•¥å’Œå®‰å…¨ç»„
- **å¥åº·æ£€æŸ¥**ï¼šé›†æˆKubernetesæ¢é’ˆæœºåˆ¶
- **é…ç½®åŠ¨æ€åŒ–**ï¼šæ”¯æŒé…ç½®çƒ­æ›´æ–°
- **é›†ç¾¤å‘ç°**ï¼šè‡ªåŠ¨åŒ–çš„é›†ç¾¤æˆå‘˜ç®¡ç†
- **èµ„æºç®¡ç†**ï¼šç²¾ç¡®çš„èµ„æºé™åˆ¶å’Œè¯·æ±‚

## 2. Kubernetesç¯å¢ƒå‡†å¤‡

### 2.1 ç¯å¢ƒè¦æ±‚å’Œç»„ä»¶å®‰è£…

#### æœ€å°ç³»ç»Ÿè¦æ±‚
```
ç¡¬ä»¶è¦æ±‚ï¼š
â”œâ”€â”€ æ§åˆ¶èŠ‚ç‚¹(3å°)ï¼š4æ ¸CPUã€8GBå†…å­˜ã€50GBå­˜å‚¨
â”œâ”€â”€ å·¥ä½œèŠ‚ç‚¹(3å°)ï¼š8æ ¸CPUã€16GBå†…å­˜ã€100GBå­˜å‚¨
â”œâ”€â”€ ç½‘ç»œï¼š10Gbpså†…ç½‘å¸¦å®½
â””â”€â”€ å­˜å‚¨ï¼šSSDæ¨èï¼Œæ”¯æŒReadWriteManyè®¿é—®æ¨¡å¼

è½¯ä»¶è¦æ±‚ï¼š
â”œâ”€â”€ æ“ä½œç³»ç»Ÿï¼šUbuntu 20.04+ / CentOS 8+ / RHEL 8+
â”œâ”€â”€ Kubernetesï¼šv1.20+ (æ¨èv1.24+)
â”œâ”€â”€ Dockerï¼šv20.10+ æˆ– containerd 1.4+
â”œâ”€â”€ Helmï¼šv3.6+
â””â”€â”€ kubectlï¼šä¸Kubernetesç‰ˆæœ¬åŒ¹é…
```

#### ç»„ä»¶å®‰è£…è„šæœ¬
```bash
#!/bin/bash
# k8s-setup.sh - Kubernetesç¯å¢ƒåˆå§‹åŒ–è„šæœ¬

set -e

# 1. å…³é—­swap
echo "å…³é—­swapåˆ†åŒº..."
swapoff -a
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

# 2. å®‰è£…Docker
echo "å®‰è£…Docker..."
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh
systemctl enable docker
systemctl start docker

# 3. å®‰è£…containerd
echo "å®‰è£…containerd..."
cat > /etc/modules-load.d/containerd.conf <<EOF
overlay
br_netfilter
EOF

modprobe overlay
modprobe br_netfilter

cat > /etc/sysctl.d/k8s.conf <<EOF
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sysctl --system

# 4. å®‰è£…Kubernetes
echo "å®‰è£…Kubernetes..."
apt-get update && apt-get install -y apt-transport-https ca-certificates curl
curl -fsSLo /usr/share/keyrings/kubernetes-apt-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
echo "deb [signed-by=/usr/share/keyrings/kubernetes-apt-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | tee /etc/apt/sources.list.d/kubernetes.list

apt-get update
apt-get install -y kubelet kubeadm kubectl

# 5. åˆå§‹åŒ–MasterèŠ‚ç‚¹
echo "åˆå§‹åŒ–MasterèŠ‚ç‚¹..."
kubeadm init --pod-network-cidr=192.168.0.0/16

# 6. å®‰è£…ç½‘ç»œæ’ä»¶(Calico)
echo "å®‰è£…Calicoç½‘ç»œæ’ä»¶..."
kubectl apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml

# 7. å®‰è£…Helm
echo "å®‰è£…Helm..."
curl https://get.helm.sh/helm-v3.10.3-linux-amd64.tar.gz | tar -xz
mv linux-amd64/helm /usr/local/bin/helm

echo "Kubernetesç¯å¢ƒåˆå§‹åŒ–å®Œæˆï¼"
echo "è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤é…ç½®kubectlï¼š"
echo "mkdir -p \$HOME/.kube"
echo "cp -i /etc/kubernetes/admin.conf \$HOME/.kube/config"
echo "chown \$(id -u):\$(id -g) \$HOME/.kube/config"
```

### 2.2 é›†ç¾¤é…ç½®å’ŒéªŒè¯

#### Kubernetesé›†ç¾¤éªŒè¯è„šæœ¬
```bash
#!/bin/bash
# cluster-verify.sh - é›†ç¾¤å¥åº·æ£€æŸ¥è„šæœ¬

# æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€
echo "æ£€æŸ¥èŠ‚ç‚¹çŠ¶æ€..."
kubectl get nodes -o wide

# æ£€æŸ¥ç³»ç»ŸpodçŠ¶æ€
echo "æ£€æŸ¥ç³»ç»ŸpodçŠ¶æ€..."
kubectl get pods -n kube-system

# æ£€æŸ¥é›†ç¾¤ä¿¡æ¯
echo "æ£€æŸ¥é›†ç¾¤ä¿¡æ¯..."
kubectl cluster-info

# æµ‹è¯•åº”ç”¨éƒ¨ç½²
echo "æµ‹è¯•åº”ç”¨éƒ¨ç½²..."
kubectl create deployment test-nginx --image=nginx --replicas=3
kubectl expose deployment test-nginx --port=80 --type=NodePort

echo "é›†ç¾¤éƒ¨ç½²éªŒè¯å®Œæˆï¼"
```

#### StorageClassé…ç½®
```yaml
# storage-class.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rabbitmq-storage
provisioner: kubernetes.io/aws-ebs  # æ ¹æ®äº‘å¹³å°è°ƒæ•´
parameters:
  type: gp3
  iops: "3000"
  throughput: "125"
  encrypted: "true"
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Retain
```

## 3. RabbitMQå®¹å™¨åŒ–éƒ¨ç½²

### 3.1 å•èŠ‚ç‚¹RabbitMQéƒ¨ç½²

#### åŸºç¡€Deploymenté…ç½®
```yaml
# rabbitmq-single.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: rabbitmq
  namespace: default
  labels:
    app: rabbitmq
spec:
  replicas: 1
  selector:
    matchLabels:
      app: rabbitmq
  template:
    metadata:
      labels:
        app: rabbitmq
    spec:
      containers:
      - name: rabbitmq
        image: rabbitmq:3.10-management
        ports:
        - containerPort: 5672
          name: amqp
        - containerPort: 15672
          name: management
        - containerPort: 25672
          name: clustering
        env:
        - name: RABBITMQ_DEFAULT_USER
          value: "admin"
        - name: RABBITMQ_DEFAULT_PASS
          valueFrom:
            secretKeyRef:
              name: rabbitmq-credentials
              key: password
        - name: RABBITMQ_ERLANG_COOKIE
          valueFrom:
            secretKeyRef:
              name: rabbitmq-credentials
              key: erlang-cookie
        volumeMounts:
        - name: rabbitmq-data
          mountPath: /var/lib/rabbitmq
        - name: rabbitmq-log
          mountPath: /var/log/rabbitmq
        - name: rabbitmq-config
          mountPath: /etc/rabbitmq
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          exec:
            command:
            - rabbitmq-diagnostics
            - ping
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          exec:
            command:
            - rabbitmq-diagnostics
            - check_port_connectivity
          initialDelaySeconds: 30
          periodSeconds: 10
      volumes:
      - name: rabbitmq-data
        persistentVolumeClaim:
          claimName: rabbitmq-data-pvc
      - name: rabbitmq-log
        persistentVolumeClaim:
          claimName: rabbitmq-log-pvc
      - name: rabbitmq-config
        configMap:
          name: rabbitmq-config
---
apiVersion: v1
kind: Service
metadata:
  name: rabbitmq
spec:
  selector:
    app: rabbitmq
  ports:
  - name: amqp
    port: 5672
    targetPort: 5672
  - name: management
    port: 15672
    targetPort: 15672
  type: ClusterIP
```

#### ç¯å¢ƒå˜é‡é…ç½®
```yaml
# rabbitmq-env.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: rabbitmq-env
data:
  RABBITMQ_NODENAME: "rabbit@rabbitmq"
  RABBITMQ_NODE_PORT: "25672"
  RABBITMQ_NODE_IP_ADDRESS: "0.0.0.0"
  RABBITMQ_DEFAULT_VHOST: "/"
  RABBITMQ_DEFAULT_USER: "admin"
  RABBITMQ_DEFAULT_PASS: "admin123"
  RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: "-proto_dist inet_tcp"
```

### 3.2 RabbitMQé›†ç¾¤éƒ¨ç½²

#### é›†ç¾¤é…ç½®æ–‡ä»¶
```yaml
# rabbitmq-cluster.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: rabbitmq-cluster
spec:
  serviceName: rabbitmq-cluster
  replicas: 3
  selector:
    matchLabels:
      app: rabbitmq-cluster
  template:
    metadata:
      labels:
        app: rabbitmq-cluster
    spec:
      containers:
      - name: rabbitmq
        image: rabbitmq:3.10-management
        ports:
        - containerPort: 5672
          name: amqp
        - containerPort: 15672
          name: management
        - containerPort: 25672
          name: clustering
        env:
        - name: RABBITMQ_DEFAULT_USER
          value: "admin"
        - name: RABBITMQ_DEFAULT_PASS
          valueFrom:
            secretKeyRef:
              name: rabbitmq-credentials
              key: password
        - name: RABBITMQ_ERLANG_COOKIE
          valueFrom:
            secretKeyRef:
              name: rabbitmq-credentials
              key: erlang-cookie
        - name: RABBITMQ_NODENAME
          value: "rabbit@$(POD_NAME).rabbitmq-cluster.default.svc.cluster.local"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        volumeMounts:
        - name: rabbitmq-data
          mountPath: /var/lib/rabbitmq
        - name: rabbitmq-config
          mountPath: /etc/rabbitmq
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        livenessProbe:
          exec:
            command:
            - rabbitmq-diagnostics
            - ping
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          exec:
            command:
            - rabbitmq-diagnostics
            - check_port_connectivity
          initialDelaySeconds: 30
          periodSeconds: 10
      initContainers:
      - name: setup-cluster
        image: rabbitmq:3.10-management
        env:
        - name: RABBITMQ_ERLANG_COOKIE
          valueFrom:
            secretKeyRef:
              name: rabbitmq-credentials
              key: erlang-cookie
        command:
        - /bin/bash
        - -c
        - |
          set -e
          echo "Starting cluster setup for pod $POD_NAME"
          
          # ç­‰å¾…å…¶ä»–podå¯åŠ¨
          echo "Waiting for cluster pods to be ready..."
          sleep 30
          
          # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼ŒåŠ å…¥é›†ç¾¤
          if [ "$POD_NAME" != "rabbitmq-cluster-0" ]; then
            echo "Joining cluster as $POD_NAME"
            
            # åœæ­¢å½“å‰èŠ‚ç‚¹
            rabbitmqctl stop_app
            
            # åŠ å…¥é›†ç¾¤
            rabbitmqctl join_cluster rabbit@rabbitmq-cluster-0.rabbitmq-cluster.default.svc.cluster.local
            
            # å¯åŠ¨èŠ‚ç‚¹
            rabbitmqctl start_app
            
            echo "Successfully joined cluster"
          else
            echo "This is the first node, setting up cluster"
          fi
        volumeMounts:
        - name: rabbitmq-data
          mountPath: /var/lib/rabbitmq
      volumes:
      - name: rabbitmq-config
        configMap:
          name: rabbitmq-config
  volumeClaimTemplates:
  - metadata:
      name: rabbitmq-data
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 20Gi
      storageClassName: rabbitmq-storage
---
apiVersion: v1
kind: Service
metadata:
  name: rabbitmq-cluster
spec:
  clusterIP: None
  selector:
    app: rabbitmq-cluster
  ports:
  - name: amqp
    port: 5672
    targetPort: 5672
  - name: management
    port: 15672
    targetPort: 15672
---
apiVersion: v1
kind: Service
metadata:
  name: rabbitmq-lb
spec:
  selector:
    app: rabbitmq-cluster
  ports:
  - name: amqp
    port: 5672
    targetPort: 5672
  type: LoadBalancer
```

### 3.3 é•œåƒä¼˜åŒ–å’Œè‡ªå®šä¹‰

#### Dockerfileæœ€ä½³å®è·µ
```dockerfile
# Dockerfile.rabbitmq
FROM rabbitmq:3.10-management-alpine AS base

# è®¾ç½®éäº¤äº’å¼æ¨¡å¼
ENV DEBIAN_FRONTEND=noninteractive

# å®‰è£…å¿…è¦çš„å·¥å…·å’Œä¾èµ–
RUN apk add --no-cache \
    curl \
    jq \
    bash \
    openssl \
    python3 \
    py3-pip \
    && pip3 install --no-cache-dir \
    prometheus-client \
    psutil

# å¤åˆ¶è‡ªå®šä¹‰é…ç½®æ–‡ä»¶
COPY rabbitmq.conf /etc/rabbitmq/rabbitmq.conf
COPY enabled_plugins /etc/rabbitmq/enabled_plugins
COPY definitions.json /etc/rabbitmq/definitions.json

# åˆ›å»ºåº”ç”¨ç›®å½•
RUN mkdir -p /opt/rabbitmq/plugins
RUN mkdir -p /var/log/rabbitmq

# è®¾ç½®æƒé™
RUN chown -R rabbitmq:rabbitmq /opt/rabbitmq
RUN chown -R rabbitmq:rabbitmq /var/log/rabbitmq

# æ·»åŠ å¥åº·æ£€æŸ¥è„šæœ¬
COPY scripts/health-check.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/health-check.sh

# æ·»åŠ ç›‘æ§è„šæœ¬
COPY scripts/metrics-export.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/metrics-export.sh

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER rabbitmq

# æš´éœ²ç«¯å£
EXPOSE 5672 15672 25672 9419

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD /usr/local/bin/health-check.sh

# å¯åŠ¨å‘½ä»¤
CMD ["rabbitmq-server"]
```

#### è‡ªå®šä¹‰é…ç½®
```erlang
% rabbitmq.conf - RabbitMQé…ç½®æ–‡ä»¶
loopback_users = none
default_user = admin
default_pass = admin123
default_permissions.configure = .*
default_permissions.read = .*
default_permissions.write = .*

% é›†ç¾¤é…ç½®
cluster_formation.peer_discovery_backend = classic_config
cluster_formation.classic_config.nodes.1 = rabbit@rabbitmq-cluster-0.rabbitmq-cluster.default.svc.cluster.local
cluster_formation.classic_config.nodes.2 = rabbit@rabbitmq-cluster-1.rabbitmq-cluster.default.svc.cluster.local
cluster_formation.classic_config.nodes.3 = rabbit@rabbitmq-cluster-2.rabbitmq-cluster.default.svc.cluster.local

% æ€§èƒ½è°ƒä¼˜
å“ˆæœºé…ç½®ï¼š
å“ˆæœº.memory_scale = 1.20
å“ˆæœº.disk_free_limit.absolute = 6GB
å“ˆæœº.max_message_size = 134217728
å“ˆæœº.default_user_tags.administrator = true

% é˜Ÿåˆ—é•œåƒé…ç½®
å“ˆæœº.default_queue_mirror_masters = 1
å“ˆæœº.ha-mode = all
å“ˆæœº.ha-sync-mode = automatic
å“ˆæœº.queue_leader_locator = min-masters
```

## 4. Helm Charté«˜çº§é…ç½®

### 4.1 HelmåŸºç¡€å’ŒChartç»“æ„

#### Helmå®‰è£…å’Œé…ç½®
```bash
# å®‰è£…Helm
curl https://get.helm.sh/helm-v3.10.3-linux-amd64.tar.gz | tar -xz
sudo mv linux-amd64/helm /usr/local/bin/helm

# æ·»åŠ å¸¸ç”¨ä»“åº“
helm repo add stable https://charts.helm.sh/stable
helm repo add bitnami https://charts.bitnami.com/bitnami
helm repo add rabbitmq https://charts.bitnami.com/rabbitmq
helm repo update

# åˆ›å»ºæ–°çš„Chart
helm create rabbitmq-advanced
```

#### Chartç›®å½•ç»“æ„
```
rabbitmq-advanced/
â”œâ”€â”€ Chart.yaml              # Chartå…ƒæ•°æ®
â”œâ”€â”€ values.yaml            # é»˜è®¤é…ç½®
â”œâ”€â”€ templates/             # æ¨¡æ¿æ–‡ä»¶
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â”œâ”€â”€ secret.yaml
â”‚   â”œâ”€â”€ pvc.yaml
â”‚   â”œâ”€â”€ ingress.yaml
â”‚   â””â”€â”€ NOTES.txt
â”œâ”€â”€ templates/NOTES.txt    # å®‰è£…è¯´æ˜
â””â”€â”€ README.md             # æ–‡æ¡£è¯´æ˜
```

### 4.2 è‡ªå®šä¹‰RabbitMQ Helm Chart

#### Chart.yamlé…ç½®
```yaml
# Chart.yaml
apiVersion: v2
name: rabbitmq-advanced
description: é«˜çº§RabbitMQéƒ¨ç½²Chartï¼Œæ”¯æŒé›†ç¾¤ã€ç›‘æ§å’Œè‡ªåŠ¨åŒ–è¿ç»´
type: application
version: 1.0.0
appVersion: "3.10"
keywords:
  - rabbitmq
  - messaging
  - amqp
  - kubernetes
home: https://www.rabbitmq.com
sources:
  - https://github.com/rabbitmq/rabbitmq-server
maintainers:
  - name: DevOps Team
    email: devops@company.com
dependencies:
  - name: common
    version: "1.x.x"
    repository: https://charts.bitnami.com/bitnami
    tags:
      - bitnami-common
```

#### values.yamlé…ç½®
```yaml
# values.yaml
global:
  imageRegistry: ""
  imagePullSecrets: []
  storageClass: ""

image:
  registry: docker.io
  repository: rabbitmq
  tag: "3.10-management-alpine"
  pullPolicy: IfNotPresent

# é›†ç¾¤é…ç½®
replicaCount: 3
cluster:
  enabled: true
  nodes: 3
  partitionHandling: ignore

# é…ç½®
existingConfigMap: ""
existingSecret: ""
configuration: |
  ## RabbitMQé…ç½®æ–‡ä»¶å†…å®¹
  loopback_users = none
  default_user = admin
  default_pass = admin123
  default_permissions.configure = .*
  default_permissions.read = .*
  default_permissions.write = .*
  
  cluster_formation.peer_discovery_backend = classic_config
  cluster_formation.classic_config.nodes.1 = rabbit@{{ include "rabbitmq-advanced.fullname" }}-0.{{ include "rabbitmq-advanced.fullname" }}.{{ .Release.Namespace }}.svc.cluster.local
  cluster_formation.classic_config.nodes.2 = rabbit@{{ include "rabbitmq-advanced.fullname" }}-1.{{ include "rabbitmq-advanced.fullname" }}.{{ .Release.Namespace }}.svc.cluster.local
  cluster_formation.classic_config.nodes.3 = rabbit@{{ include "rabbitmq-advanced.fullname" }}-2.{{ include "rabbitmq-advanced.fullname" }}.{{ .Release.Namespace }}.svc.cluster.local
  
  å“ˆæœº.memory_scale = 1.20
  å“ˆæœº.disk_free_limit.absolute = 6GB
  å“ˆæœº.max_message_size = 134217728

# æŒä¹…åŒ–å­˜å‚¨
persistence:
  enabled: true
  storageClass: ""
  accessMode: ReadWriteOnce
  size: 20Gi

# æœåŠ¡é…ç½®
service:
  type: ClusterIP
  amqpPort: 5672
  managementPort: 15672
  clusterPort: 25672
  annotations: {}
  labels: {}

# è´Ÿè½½å‡è¡¡å™¨
loadBalancer:
  enabled: false
  annotations: {}
  ip: ""
  ports:
    amqp: 5672

# èµ„æºé™åˆ¶
resources:
  limits:
    cpu: 1000m
    memory: 2Gi
  requests:
    cpu: 500m
    memory: 1Gi

# æ¢é’ˆé…ç½®
livenessProbe:
  enabled: true
  initialDelaySeconds: 60
  periodSeconds: 30
  timeoutSeconds: 10
  failureThreshold: 3
  exec:
    command:
    - rabbitmq-diagnostics
    - ping

readinessProbe:
  enabled: true
  initialDelaySeconds: 30
  periodSeconds: 10
  timeoutSeconds: 5
  failureThreshold: 3
  exec:
    command:
    - rabbitmq-diagnostics
    - check_port_connectivity

# ç›‘æ§é…ç½®
metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    interval: 30s
    path: /metrics
  prometheusRule:
    enabled: true
    rules:
      high_queue_depth: "true"
      high_memory_usage: "true"
      connection_errors: "true"

# å¤‡ä»½é…ç½®
backup:
  enabled: true
  schedule: "0 2 * * *"  # æ¯å¤©2ç‚¹å¤‡ä»½
  retention: "7d"         # ä¿ç•™7å¤©
  s3:
    enabled: false
    bucket: ""
    region: ""
    accessKey: ""
    secretKey: ""

# å®‰å…¨é…ç½®
securityContext:
  enabled: true
  runAsNonRoot: true
  runAsUser: 1001
  fsGroup: 1001

podSecurityContext:
  enabled: true
  fsGroup: 1001

# ç½‘ç»œç­–ç•¥
networkPolicy:
  enabled: true
  ingress:
  - from:
    - namespaceSelector: {}
    ports:
    - port: 5672
    - port: 15672
  egress:
  - to: []
    ports:
    - port: 53
    - port: 53

# èŠ‚ç‚¹äº²å’Œæ€§
nodeAffinity:
  enabled: false

# Podé—´äº²å’Œæ€§
podAffinity:
  enabled: false

# å®¹å¿åº¦
tolerations: []

# ä¼˜å…ˆçº§
priorityClassName: ""

# Podç®¡ç†ç­–ç•¥
podManagementPolicy: OrderedReady

# æ›´æ–°ç­–ç•¥
updateStrategy:
  type: RollingUpdate
  rollingUpdate:
    maxSurge: 1
    maxUnavailable: 0
```

### 4.3 æ¨¡æ¿æ–‡ä»¶åˆ›å»º

#### Deploymentæ¨¡æ¿
```yaml
# templates/deployment.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ include "rabbitmq-advanced.fullname" }}
  namespace: {{ .Release.Namespace | quote }}
  labels: {{- include "common.labels.standard" . | nindent 4 }}
    app.kubernetes.io/component: rabbitmq
    {{- if .Values.commonLabels }}
    {{- toYaml .Values.commonLabels | nindent 4 }}
    {{- end }}
  {{- if .Values.commonAnnotations }}
  annotations: {{- toYaml .Values.commonAnnotations | nindent 4 }}
  {{- end }}
spec:
  {{- if .Values.podManagementPolicy }}
  podManagementPolicy: {{ .Values.podManagementPolicy }}
  {{- end }}
  serviceName: {{ include "rabbitmq-advanced.fullname" }}-headless
  replicas: {{ .Values.replicaCount }}
  {{- if .Values.updateStrategy }}
  updateStrategy: {{- toYaml .Values.updateStrategy | nindent 4 }}
  {{- end }}
  selector:
    matchLabels: {{- include "common.labels.matchLabels" . | nindent 6 }}
      app.kubernetes.io/component: rabbitmq
  template:
    metadata:
      labels: {{- include "common.labels.standard" . | nindent 8 }}
        app.kubernetes.io/component: rabbitmq
      {{- if .Values.podLabels }}
      {{- toYaml .Values.podLabels | nindent 8 }}
      {{- end }}
      {{- if .Values.podAnnotations }}
      annotations: {{- toYaml .Values.podAnnotations | nindent 8 }}
      {{- end }}
    spec:
      {{- if .Values.imagePullSecrets }}
      imagePullSecrets: {{- toYaml .Values.imagePullSecrets | nindent 8 }}
      {{- end }}
      {{- if .Values.priorityClassName }}
      priorityClassName: {{ .Values.priorityClassName }}
      {{- end }}
      {{- if .Values.podSecurityContext.enabled }}
      securityContext: {{- omit .Values.podSecurityContext "enabled" | toYaml | nindent 8 }}
      {{- end }}
      {{- if .Values.serviceAccount.enabled }}
      serviceAccountName: {{ template "rabbitmq-advanced.serviceAccountName" . }}
      {{- end }}
      {{- if .Values.affinity }}
      affinity: {{- toYaml .Values.affinity | nindent 8 }}
      {{- end }}
      {{- if .Values.nodeSelector }}
      nodeSelector: {{- toYaml .Values.nodeSelector | nindent 8 }}
      {{- end }}
      {{- if .Values.tolerations }}
      tolerations: {{- toYaml .Values.tolerations | nindent 8 }}
      {{- end }}
      initContainers:
      {{- if .Values.cluster.enabled }}
      - name: setup-cluster
        image: {{ template "rabbitmq.image" . }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        env:
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: RABBITMQ_ERLANG_COOKIE
          valueFrom:
            secretKeyRef:
              name: {{ template "rabbitmq-advanced.secretName" . }}
              key: erlang-cookie
        command:
        - /bin/bash
        - -c
        - |
          set -e
          
          echo "Starting cluster setup for pod $POD_NAME"
          
          # ç­‰å¾…å…¶ä»–podå¯åŠ¨
          sleep 30
          
          # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼ŒåŠ å…¥é›†ç¾¤
          if [ "$POD_NAME" != "{{ include "rabbitmq-advanced.fullname" }}-0" ]; then
            echo "Joining cluster as $POD_NAME"
            
            # åœæ­¢å½“å‰èŠ‚ç‚¹
            rabbitmqctl stop_app
            
            # åŠ å…¥é›†ç¾¤
            rabbitmqctl join_cluster rabbit@{{ include "rabbitmq-advanced.fullname" }}-0.{{ include "rabbitmq-advanced.fullname" }}-headless.${POD_NAMESPACE}.svc.cluster.local
            
            # å¯åŠ¨èŠ‚ç‚¹
            rabbitmqctl start_app
            
            echo "Successfully joined cluster"
          else
            echo "This is the first node, setting up cluster"
          fi
        {{- if .Values.resources }}
        resources: {{- toYaml .Values.resources | nindent 10 }}
        {{- end }}
      {{- end }}
      containers:
      - name: rabbitmq
        image: {{ template "rabbitmq.image" . }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        {{- if .Values.containerSecurityContext.enabled }}
        securityContext: {{- omit .Values.containerSecurityContext "enabled" | toYaml | nindent 10 }}
        {{- end }}
        ports:
        - name: amqp
          containerPort: 5672
          protocol: TCP
        - name: management
          containerPort: 15672
          protocol: TCP
        - name: cluster
          containerPort: 25672
          protocol: TCP
        env:
        - name: RABBITMQ_DEFAULT_USER
          valueFrom:
            secretKeyRef:
              name: {{ template "rabbitmq-advanced.secretName" . }}
              key: rabbitmq-username
        - name: RABBITMQ_DEFAULT_PASS
          valueFrom:
            secretKeyRef:
              name: {{ template "rabbitmq-advanced.secretName" . }}
              key: rabbitmq-password
        - name: RABBITMQ_NODENAME
          value: "rabbit@$(POD_NAME).{{ include "rabbitmq-advanced.fullname" }}-headless.$(POD_NAMESPACE).svc.cluster.local"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        {{- if .Values.extraEnvVars }}
        {{- toYaml .Values.extraEnvVars | nindent 8 }}
        {{- end }}
        {{- if .Values.livenessProbe.enabled }}
        livenessProbe:
          {{- if .Values.livenessProbe.exec }}
          exec:
            {{- toYaml .Values.livenessProbe.exec | nindent 10 }}
          {{- else }}
          httpGet:
            path: /
            port: 15672
            httpHeaders:
            - name: Authorization
              value: Basic {{ printf "%s:%s" .Values.auth.username .Values.auth.password | b64enc }}
          {{- end }}
          initialDelaySeconds: {{ .Values.livenessProbe.initialDelaySeconds }}
          periodSeconds: {{ .Values.livenessProbe.periodSeconds }}
          timeoutSeconds: {{ .Values.livenessProbe.timeoutSeconds }}
          failureThreshold: {{ .Values.livenessProbe.failureThreshold }}
        {{- end }}
        {{- if .Values.readinessProbe.enabled }}
        readinessProbe:
          {{- if .Values.readinessProbe.exec }}
          exec:
            {{- toYaml .Values.readinessProbe.exec | nindent 10 }}
          {{- else }}
          httpGet:
            path: /
            port: 15672
            httpHeaders:
            - name: Authorization
              value: Basic {{ printf "%s:%s" .Values.auth.username .Values.auth.password | b64enc }}
          {{- end }}
          initialDelaySeconds: {{ .Values.readinessProbe.initialDelaySeconds }}
          periodSeconds: {{ .Values.readinessProbe.periodSeconds }}
          timeoutSeconds: {{ .Values.readinessProbe.timeoutSeconds }}
          failureThreshold: {{ .Values.readinessProbe.failureThreshold }}
        {{- end }}
        volumeMounts:
        {{- if .Values.persistence.enabled }}
        - name: rabbitmq-data
          mountPath: /var/lib/rabbitmq/mnesia
        {{- end }}
        {{- if .Values.configurationExistingConfigMap }}
        - name: rabbitmq-config
          mountPath: /etc/rabbitmq/rabbitmq.conf
          subPath: rabbitmq.conf
        {{- end }}
        - name: rabbitmq-logs
          mountPath: /var/log/rabbitmq
        {{- if .Values.extraVolumeMounts }}
        {{- toYaml .Values.extraVolumeMounts | nindent 8 }}
        {{- end }}
        {{- if .Values.metrics.enabled }}
        - name: metrics
          image: {{ include "rabbitmq.metrics.image" . }}
          imagePullPolicy: {{ .Values.metrics.image.pullPolicy }}
          ports:
          - name: metrics
            containerPort: {{ .Values.metrics.containerPort }}
          command:
          - /bin/bash
          - -c
          - |
            {{- if .Values.metrics.command }}
            {{- range .Values.metrics.command }}
            {{ . | nindent 10 }}
            {{- end }}
            {{- else }}
            exec rabbitmq_exporter
            {{- end }}
        {{- end }}
        {{- if .Values.resources }}
        resources: {{- toYaml .Values.resources | nindent 10 }}
        {{- end }}
      volumes:
      {{- if not .Values.persistence.enabled }}
      - name: rabbitmq-data
        emptyDir: {}
      {{- end }}
      {{- if .Values.configurationExistingConfigMap }}
      - name: rabbitmq-config
        configMap:
          name: {{ .Values.configurationExistingConfigMap }}
      {{- end }}
      - name: rabbitmq-logs
        emptyDir: {}
      {{- if .Values.extraVolumes }}
      {{- toYaml .Values.extraVolumes | nindent 6 }}
      {{- end }}
  {{- if .Values.persistence.enabled }}
  volumeClaimTemplates:
  - metadata:
      name: rabbitmq-data
      labels: {{- include "common.labels.standard" . | nindent 8 }}
    spec:
      accessModes:
      {{- range .Values.persistence.accessMode }}
      - {{ . }}
      {{- end }}
      resources:
        requests:
          storage: {{ .Values.persistence.size }}
      {{- if .Values.persistence.storageClass }}
      storageClassName: {{ .Values.persistence.storageClass }}
      {{- end }}
  {{- end }}
```

## 5. æœåŠ¡ç½‘æ ¼é›†æˆ

### 5.1 Istioé›†æˆæ¶æ„

#### Istio Sidecaræ³¨å…¥
```yaml
# istio-rabbitmq.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: rabbitmq-vs
  namespace: default
spec:
  hosts:
  - rabbitmq.default.svc.cluster.local
  http:
  - match:
    - port: 5672
    route:
    - destination:
        host: rabbitmq.default.svc.cluster.local
        port:
          number: 5672
      weight: 100
  - match:
    - port: 15672
    route:
    - destination:
        host: rabbitmq.default.svc.cluster.local
        port:
          number: 15672
      weight: 100
---
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: rabbitmq-dr
  namespace: default
spec:
  host: rabbitmq.default.svc.cluster.local
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 100
      http:
        http1MaxPendingRequests: 10
        http2MaxRequests: 100
    outlierDetection:
      consecutiveErrors: 3
      interval: 10s
      baseEjectionTime: 10s
    loadBalancer:
      simple: LEAST_CONN
  portLevelSettings:
  - port:
      number: 5672
    loadBalancer:
      simple: ROUND_ROBIN
  - port:
      number: 15672
    loadBalancer:
      simple: LEAST_CONN
```

#### ç½‘ç»œç­–ç•¥é…ç½®
```yaml
# network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: rabbitmq-network-policy
  namespace: default
spec:
  podSelector:
    matchLabels:
      app: rabbitmq
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: istio-system
    ports:
    - protocol: TCP
      port: 5672
    - protocol: TCP
      port: 15672
  - from:
    - namespaceSelector:
        matchLabels:
          name: default
    - podSelector:
        matchLabels:
          app: application
    ports:
    - protocol: TCP
      port: 5672
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: istio-system
    ports:
    - protocol: TCP
      port: 15001  # Sidecar outbound
    - protocol: TCP
      port: 15006  # Sidecar inbound
```

### 5.2 æµé‡ç®¡ç†å’Œç†”æ–­

#### ç†”æ–­å™¨é…ç½®
```yaml
# circuit-breaker.yaml
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: rabbitmq-circuit-breaker
spec:
  host: rabbitmq.default.svc.cluster.local
  trafficPolicy:
    connectionPool:
      tcp:
        maxConnections: 50
        connectTimeout: 30s
      http:
        http1MaxPendingRequests: 25
        http2MaxRequests: 100
        maxRequestsPerConnection: 2
    circuitBreakers:
      thresholds:
      - maxConnections: 100
        maxPendingRequests: 20
        maxRequests: 100
        maxRetries: 3
        consecutiveGatewayErrors: 5
        interval: 30s
        baseEjectionTime: 30s
```

#### é‡è¯•ç­–ç•¥
```yaml
# retry-policy.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: rabbitmq-retry
spec:
  hosts:
  - rabbitmq.default.svc.cluster.local
  http:
  - match:
    - headers:
        retry:
          exact: "true"
    route:
    - destination:
        host: rabbitmq.default.svc.cluster.local
    retries:
      attempts: 3
      perTryTimeout: 30s
      retryOn: 5xx,reset,connect-failure,refused-stream
  - route:
    - destination:
        host: rabbitmq.default.svc.cluster.local
    retries:
      attempts: 1
      perTryTimeout: 15s
```

## 6. ç›‘æ§ä¸å‘Šè­¦ç³»ç»Ÿ

### 6.1 Prometheusé›†æˆ

#### Prometheusé…ç½®
```yaml
# prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    scrape_configs:
    - job_name: 'rabbitmq'
      static_configs:
      - targets: ['rabbitmq-cluster-0.rabbitmq-cluster.default.svc.cluster.local:15692']
        labels:
          service: 'rabbitmq'
      relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        replacement: 'rabbitmq-cluster'
      - source_labels: [__meta_kubernetes_pod_label_app]
        target_label: app
        replacement: 'rabbitmq'
      scrape_interval: 10s
      metrics_path: /metrics
```

#### ç›‘æ§æŒ‡æ ‡é…ç½®
```yaml
# service-monitor.yaml
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: rabbitmq-monitor
  namespace: monitoring
  labels:
    app: rabbitmq
    release: prometheus
spec:
  selector:
    matchLabels:
      app: rabbitmq
  endpoints:
  - port: metrics
    path: /metrics
    interval: 15s
    scrapeTimeout: 10s
  namespaceSelector:
    matchNames:
    - default
```

### 6.2 Grafanaä»ªè¡¨æ¿

#### RabbitMQä»ªè¡¨æ¿JSON
```json
{
  "dashboard": {
    "id": null,
    "title": "RabbitMQ Cluster Overview",
    "tags": ["rabbitmq", "messaging"],
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "Cluster Overview",
        "type": "stat",
        "targets": [
          {
            "expr": "rabbitmq_queues",
            "refId": "A",
            "legendFormat": "Total Queues"
          },
          {
            "expr": "rabbitmq_channels",
            "refId": "B",
            "legendFormat": "Total Channels"
          },
          {
            "expr": "rabbitmq_connections",
            "refId": "C",
            "legendFormat": "Total Connections"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "Message Rates",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(rabbitmq_channel_messages_published[5m])",
            "refId": "A",
            "legendFormat": "Publish Rate"
          },
          {
            "expr": "rate(rabbitmq_channel_messages_delivered[5m])",
            "refId": "B",
            "legendFormat": "Deliver Rate"
          },
          {
            "expr": "rate(rabbitmq_channel_messages_confirmed[5m])",
            "refId": "C",
            "legendFormat": "Confirm Rate"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
      },
      {
        "id": 3,
        "title": "Queue Depths",
        "type": "table",
        "targets": [
          {
            "expr": "rabbitmq_queue_messages_ready",
            "refId": "A",
            "legendFormat": "{{ queue }}"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16}
      },
      {
        "id": 4,
        "title": "Memory Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "rabbitmq_process_resident_memory_bytes",
            "refId": "A",
            "legendFormat": "Resident Memory"
          },
          {
            "expr": "rabbitmq_process_binary_heap_size_bytes",
            "refId": "B",
            "legendFormat": "Binary Heap"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 24}
      }
    ]
  }
}
```

### 6.3 AlertManagerå‘Šè­¦è§„åˆ™

#### å‘Šè­¦è§„åˆ™é…ç½®
```yaml
# alert-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: rabbitmq-alerts
  namespace: monitoring
spec:
  groups:
  - name: rabbitmq.rules
    rules:
    - alert: RabbitMQDown
      expr: up{job="rabbitmq"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "RabbitMQ instance is down"
        description: "RabbitMQ instance {{ $labels.instance }} is down for more than 5 minutes."
        
    - alert: RabbitMQHighMemoryUsage
      expr: rabbitmq_process_resident_memory_bytes / 1024 / 1024 > 1024
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "RabbitMQ high memory usage"
        description: "RabbitMQ instance {{ $labels.instance }} memory usage is {{ $value }} MB."
        
    - alert: RabbitMQQueueDepthHigh
      expr: rabbitmq_queue_messages_ready > 1000
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: "RabbitMQ queue depth high"
        description: "Queue {{ $labels.queue }} has {{ $value }} messages waiting."
        
    - alert: RabbitMQHighConnectionErrors
      expr: rate(rabbitmq_connections_failed_total[5m]) > 0.1
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "RabbitMQ high connection errors"
        description: "RabbitMQ connection error rate is {{ $value }} per second."
        
    - alert: RabbitMQDiskSpaceLow
      expr: rabbitmq_disk_free_alarm == 1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "RabbitMQ disk space low"
        description: "RabbitMQ instance {{ $labels.instance }} disk space is low."
```

#### AlertManageré…ç½®
```yaml
# alertmanager-config.yaml
apiVersion: v1
kind: Secret
metadata:
  name: alertmanager-config
  namespace: monitoring
stringData:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'smtp.company.com:587'
      smtp_from: 'alerts@company.com'
      smtp_auth_username: 'alerts@company.com'
      smtp_auth_password: 'password'
    
    route:
      group_by: ['alertname']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
      - match:
          severity: warning
        receiver: 'warning-alerts'
    
    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://webhook-service:8080/alerts'
    
    - name: 'critical-alerts'
      email_configs:
      - to: 'devops@company.com'
        subject: '[CRITICAL] RabbitMQ Alert'
        body: |
          Alert: {{ .GroupLabels.alertname }}
          Severity: {{ .CommonLabels.severity }}
          Summary: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
          {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
    
    - name: 'warning-alerts'
      email_configs:
      - to: 'devops@company.com'
        subject: '[WARNING] RabbitMQ Alert'
        body: |
          Alert: {{ .GroupLabels.alertname }}
          Severity: {{ .CommonLabels.severity }}
          Summary: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}
          {{ range .Alerts }}{{ .Annotations.description }}{{ end }}
```

## 7. è‡ªåŠ¨åŒ–è¿ç»´å·¥å…·

### 7.1 å¤‡ä»½å’Œæ¢å¤è„šæœ¬

#### å¤‡ä»½è„šæœ¬
```bash
#!/bin/bash
# backup-rabbitmq.sh - RabbitMQå¤‡ä»½è„šæœ¬

set -e

# é…ç½®å‚æ•°
BACKUP_DIR="/backup/rabbitmq/$(date +%Y%m%d_%H%M%S)"
K8S_NAMESPACE="default"
RABBITMQ_SERVICE="rabbitmq-cluster"
RETENTION_DAYS=7

# æ—¥å¿—å‡½æ•°
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
}

# æ¸…ç†æ—§å¤‡ä»½
cleanup_old_backups() {
    log "æ¸…ç† ${RETENTION_DAYS} å¤©å‰çš„å¤‡ä»½..."
    find /backup/rabbitmq -type d -mtime +${RETENTION_DAYS} -exec rm -rf {} +
}

# åˆ›å»ºå¤‡ä»½ç›®å½•
create_backup_dir() {
    log "åˆ›å»ºå¤‡ä»½ç›®å½•: ${BACKUP_DIR}"
    mkdir -p "${BACKUP_DIR}"
}

# å¤‡ä»½é…ç½®å’Œæ•°æ®
backup_data() {
    log "å¼€å§‹å¤‡ä»½RabbitMQæ•°æ®..."
    
    # å¤‡ä»½definitions
    log "å¤‡ä»½é˜Ÿåˆ—å’Œäº¤æ¢å™¨å®šä¹‰..."
    kubectl exec -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE}-0 -- rabbitmqctl export_definitions > "${BACKUP_DIR}/definitions.json"
    
    # å¤‡ä»½é›†ç¾¤çŠ¶æ€
    log "å¤‡ä»½é›†ç¾¤çŠ¶æ€..."
    kubectl exec -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE}-0 -- rabbitmqctl cluster_status > "${BACKUP_DIR}/cluster_status.txt"
    
    # å¤‡ä»½ç”¨æˆ·ä¿¡æ¯
    log "å¤‡ä»½ç”¨æˆ·ä¿¡æ¯..."
    kubectl exec -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE}-0 -- rabbitmqctl list_users > "${BACKUP_DIR}/users.txt"
    
    # å¤‡ä»½é˜Ÿåˆ—è¯¦ç»†ä¿¡æ¯
    log "å¤‡ä»½é˜Ÿåˆ—è¯¦ç»†ä¿¡æ¯..."
    kubectl exec -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE}-0 -- rabbitmqctl list_queues name durable auto_delete policy messages > "${BACKUP_DIR}/queues.txt"
    
    # å¤‡ä»½äº¤æ¢å™¨ä¿¡æ¯
    log "å¤‡ä»½äº¤æ¢å™¨ä¿¡æ¯..."
    kubectl exec -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE}-0 -- rabbitmqctl list_exchanges name type durable > "${BACKUP_DIR}/exchanges.txt"
}

# å‹ç¼©å¤‡ä»½æ–‡ä»¶
compress_backup() {
    log "å‹ç¼©å¤‡ä»½æ–‡ä»¶..."
    cd /backup/rabbitmq
    tar -czf "rabbitmq_backup_$(date +%Y%m%d_%H%M%S).tar.gz" "$(basename ${BACKUP_DIR})"
    rm -rf "${BACKUP_DIR}"
}

# ä¸Šä¼ åˆ°äº‘å­˜å‚¨
upload_to_cloud() {
    if [ -n "${S3_BUCKET}" ]; then
        log "ä¸Šä¼ å¤‡ä»½åˆ°S3: ${S3_BUCKET}"
        aws s3 cp /backup/rabbitmq/rabbitmq_backup_*.tar.gz "s3://${S3_BUCKET}/rabbitmq/"
    fi
}

# ä¸»å‡½æ•°
main() {
    log "å¼€å§‹RabbitMQå¤‡ä»½..."
    
    # æ£€æŸ¥kubectlé…ç½®
    if ! kubectl cluster-info &> /dev/null; then
        log "é”™è¯¯: æ— æ³•è¿æ¥åˆ°Kubernetesé›†ç¾¤"
        exit 1
    fi
    
    # æ£€æŸ¥RabbitMQæœåŠ¡çŠ¶æ€
    if ! kubectl get statefulset -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE} &> /dev/null; then
        log "é”™è¯¯: æ‰¾ä¸åˆ°RabbitMQ StatefulSet: ${RABBITMQ_SERVICE}"
        exit 1
    fi
    
    cleanup_old_backups
    create_backup_dir
    backup_data
    compress_backup
    upload_to_cloud
    
    log "RabbitMQå¤‡ä»½å®Œæˆ!"
}

# é”™è¯¯å¤„ç†
trap 'log "å¤‡ä»½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œé€€å‡ºä»£ç : $?"' ERR

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
```

#### æ¢å¤è„šæœ¬
```bash
#!/bin/bash
# restore-rabbitmq.sh - RabbitMQæ¢å¤è„šæœ¬

set -e

# é…ç½®å‚æ•°
BACKUP_FILE="$1"
K8S_NAMESPACE="default"
RABBITMQ_SERVICE="rabbitmq-cluster"

# å‚æ•°éªŒè¯
if [ -z "${BACKUP_FILE}" ]; then
    echo "ç”¨æ³•: $0 <backup_file>"
    echo "ç¤ºä¾‹: $0 /backup/rabbitmq/rabbitmq_backup_20231201_120000.tar.gz"
    exit 1
fi

# æ—¥å¿—å‡½æ•°
log() {
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] $1"
}

# éªŒè¯å¤‡ä»½æ–‡ä»¶
validate_backup() {
    log "éªŒè¯å¤‡ä»½æ–‡ä»¶: ${BACKUP_FILE}"
    
    if [ ! -f "${BACKUP_FILE}" ]; then
        log "é”™è¯¯: å¤‡ä»½æ–‡ä»¶ä¸å­˜åœ¨: ${BACKUP_FILE}"
        exit 1
    fi
    
    # æ£€æŸ¥æ–‡ä»¶æ ¼å¼
    if [[ "${BACKUP_FILE}" == *.tar.gz ]]; then
        log "è§£å‹å¤‡ä»½æ–‡ä»¶..."
        tar -tzf "${BACKUP_FILE}" > /dev/null || {
            log "é”™è¯¯: å¤‡ä»½æ–‡ä»¶æŸå"
            exit 1
        }
    else
        log "é”™è¯¯: ä¸æ”¯æŒçš„å¤‡ä»½æ–‡ä»¶æ ¼å¼"
        exit 1
    fi
}

# åœæ­¢RabbitMQé›†ç¾¤
stop_rabbitmq_cluster() {
    log "åœæ­¢RabbitMQé›†ç¾¤..."
    
    REPLICAS=$(kubectl get statefulset -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE} -o jsonpath='{.spec.replicas}')
    
    for i in $(seq $((REPLICAS - 1)) -1 0); do
        POD="${RABBITMQ_SERVICE}-${i}"
        log "åœæ­¢èŠ‚ç‚¹: ${POD}"
        kubectl exec -n ${K8S_NAMESPACE} ${POD} -- rabbitmqctl stop_app || true
    done
}

# æ¢å¤æ•°æ®
restore_data() {
    log "å¼€å§‹æ¢å¤æ•°æ®..."
    
    # è§£å‹å¤‡ä»½æ–‡ä»¶
    TEMP_DIR=$(mktemp -d)
    tar -xzf "${BACKUP_FILE}" -C "${TEMP_DIR}"
    
    BACKUP_CONTENT_DIR=$(find "${TEMP_DIR}" -type d -name "rabbitmq_*" | head -1)
    
    if [ -z "${BACKUP_CONTENT_DIR}" ]; then
        log "é”™è¯¯: å¤‡ä»½æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„å¤‡ä»½å†…å®¹"
        exit 1
    fi
    
    # æ¢å¤definitions.json
    if [ -f "${BACKUP_CONTENT_DIR}/definitions.json" ]; then
        log "æ¢å¤é˜Ÿåˆ—å’Œäº¤æ¢å™¨å®šä¹‰..."
        kubectl cp "${BACKUP_CONTENT_DIR}/definitions.json" "${K8S_NAMESPACE}/${RABBITMQ_SERVICE}-0:/tmp/definitions.json"
        kubectl exec -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE}-0 -- rabbitmqctl import_definitions /tmp/definitions.json
    fi
    
    # æ¢å¤ç”¨æˆ·ä¿¡æ¯
    if [ -f "${BACKUP_CONTENT_DIR}/users.txt" ]; then
        log "è­¦å‘Š: ç”¨æˆ·æ¢å¤éœ€è¦æ‰‹åŠ¨æ“ä½œï¼Œè¯·æŸ¥çœ‹ ${BACKUP_CONTENT_DIR}/users.txt"
    fi
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    rm -rf "${TEMP_DIR}"
}

# å¯åŠ¨RabbitMQé›†ç¾¤
start_rabbitmq_cluster() {
    log "å¯åŠ¨RabbitMQé›†ç¾¤..."
    
    REPLICAS=$(kubectl get statefulset -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE} -o jsonpath='{.spec.replicas}')
    
    # å¯åŠ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
    log "å¯åŠ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹..."
    kubectl exec -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE}-0 -- rabbitmqctl start_app
    sleep 10
    
    # å¯åŠ¨å…¶ä»–èŠ‚ç‚¹
    for i in $(seq 1 $((REPLICAS - 1))); do
        POD="${RABBITMQ_SERVICE}-${i}"
        log "å¯åŠ¨èŠ‚ç‚¹: ${POD}"
        
        # æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦éœ€è¦åŠ å…¥é›†ç¾¤
        if ! kubectl exec -n ${K8S_NAMESPACE} ${POD} -- rabbitmqctl cluster_status | grep -q "${POD}"; then
            kubectl exec -n ${K8S_NAMESPACE} ${POD} -- rabbitmqctl join_cluster rabbit@${RABBITMQ_SERVICE}-0.${RABBITMQ_SERVICE}-headless.${K8S_NAMESPACE}.svc.cluster.local
        fi
        
        kubectl exec -n ${K8S_NAMESPACE} ${POD} -- rabbitmqctl start_app
        sleep 5
    done
}

# éªŒè¯æ¢å¤ç»“æœ
verify_restore() {
    log "éªŒè¯æ¢å¤ç»“æœ..."
    
    # æ£€æŸ¥é›†ç¾¤çŠ¶æ€
    kubectl exec -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE}-0 -- rabbitmqctl cluster_status
    
    # æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€
    log "æ£€æŸ¥é˜Ÿåˆ—çŠ¶æ€..."
    kubectl exec -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE}-0 -- rabbitmqctl list_queues
    
    # æ£€æŸ¥äº¤æ¢å™¨çŠ¶æ€
    log "æ£€æŸ¥äº¤æ¢å™¨çŠ¶æ€..."
    kubectl exec -n ${K8S_NAMESPACE} ${RABBITMQ_SERVICE}-0 -- rabbitmqctl list_exchanges
}

# ä¸»å‡½æ•°
main() {
    log "å¼€å§‹RabbitMQæ¢å¤..."
    
    validate_backup
    stop_rabbitmq_cluster
    restore_data
    start_rabbitmq_cluster
    verify_restore
    
    log "RabbitMQæ¢å¤å®Œæˆ!"
}

# é”™è¯¯å¤„ç†
trap 'log "æ¢å¤è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œé€€å‡ºä»£ç : $?"' ERR

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"
```

### 7.2 æ€§èƒ½æµ‹è¯•å·¥å…·

#### è´Ÿè½½æµ‹è¯•è„šæœ¬
```python
#!/usr/bin/env python3
# load-test-rabbitmq.py - RabbitMQè´Ÿè½½æµ‹è¯•å·¥å…·

import asyncio
import aio_pika
import json
import time
import uuid
import statistics
from datetime import datetime, timedelta
from typing import List, Dict, Any
from dataclasses import dataclass
from concurrent.futures import ThreadPoolExecutor
import argparse


@dataclass
class TestConfig:
    host: str
    port: int
    username: str
    password: str
    queue_name: str
    message_size: int
    duration_seconds: int
    concurrent_producers: int
    concurrent_consumers: int
    prefetch_count: int


@dataclass
class TestResult:
    timestamp: datetime
    operation: str
    latency_ms: float
    success: bool
    error_message: str = None


class RabbitMQLoadTester:
    def __init__(self, config: TestConfig):
        self.config = config
        self.connection = None
        self.results: List[TestResult] = []
        self.stats = {
            'messages_sent': 0,
            'messages_received': 0,
            'send_errors': 0,
            'receive_errors': 0
        }
        
    async def connect(self):
        """è¿æ¥åˆ°RabbitMQ"""
        self.connection = await aio_pika.connect_robust(
            host=self.config.host,
            port=self.config.port,
            login=self.config.username,
            password=self.config.password
        )
        
    async def disconnect(self):
        """æ–­å¼€è¿æ¥"""
        if self.connection:
            await self.connection.close()
            
    def generate_message(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æ¶ˆæ¯"""
        message_id = str(uuid.uuid4())
        payload = "x" * (self.config.message_size - len(message_id) - 50)  # ç•™å‡ºæ—¶é—´æˆ³ç­‰å­—æ®µçš„ç©ºé—´
        
        return {
            'message_id': message_id,
            'timestamp': datetime.utcnow().isoformat(),
            'payload': payload,
            'test_data': True
        }
        
    async def publish_messages(self, producer_id: int) -> None:
        """å‘å¸ƒæ¶ˆæ¯"""
        channel = await self.connection.channel()
        await channel.set_qos(prefetch_count=self.config.prefetch_count)
        
        queue = await channel.declare_queue(
            self.config.queue_name,
            durable=True,
            arguments={
                'x-message-ttl': 3600000,  # 1å°æ—¶
                'x-dead-letter-exchange': 'dlx',
                'x-dead-letter-routing-key': f'{self.config.queue_name}.dlq'
            }
        )
        
        start_time = time.time()
        end_time = start_time + self.config.duration_seconds
        
        async with queue:
            while time.time() < end_time:
                try:
                    message_start = time.time()
                    
                    message_data = self.generate_message()
                    message_body = json.dumps(message_data).encode()
                    
                    await channel.default_exchange.publish(
                        aio_pika.Message(
                            message_body,
                            delivery_mode=aio_pika.DeliveryMode.PERSISTENT,
                            message_id=message_data['message_id'],
                            timestamp=datetime.utcnow(),
                            message_type='test'
                        ),
                        routing_key=self.config.queue_name
                    )
                    
                    latency = (time.time() - message_start) * 1000
                    self.results.append(TestResult(
                        timestamp=datetime.utcnow(),
                        operation='publish',
                        latency_ms=latency,
                        success=True
                    ))
                    
                    self.stats['messages_sent'] += 1
                    
                    # æ§åˆ¶å‘é€é€Ÿç‡
                    await asyncio.sleep(0.001)
                    
                except Exception as e:
                    self.results.append(TestResult(
                        timestamp=datetime.utcnow(),
                        operation='publish',
                        latency_ms=0,
                        success=False,
                        error_message=str(e)
                    ))
                    self.stats['send_errors'] += 1
                    await asyncio.sleep(0.1)
                    
    async def consume_messages(self, consumer_id: int) -> None:
        """æ¶ˆè´¹æ¶ˆæ¯"""
        channel = await self.connection.channel()
        await channel.set_qos(prefetch_count=self.config.prefetch_count)
        
        queue = await channel.declare_queue(
            self.config.queue_name,
            durable=True
        )
        
        start_time = time.time()
        end_time = start_time + self.config.duration_seconds
        
        async def message_handler(message: aio_pika.IncomingMessage):
            message_start = time.time()
            
            try:
                # å¤„ç†æ¶ˆæ¯
                message_data = json.loads(message.body.decode())
                
                # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†æ—¶é—´
                await asyncio.sleep(0.001)
                
                latency = (time.time() - message_start) * 1000
                self.results.append(TestResult(
                    timestamp=datetime.utcnow(),
                    operation='consume',
                    latency_ms=latency,
                    success=True
                ))
                
                self.stats['messages_received'] += 1
                
                # ç¡®è®¤æ¶ˆæ¯
                await message.ack()
                
            except Exception as e:
                self.results.append(TestResult(
                    timestamp=datetime.utcnow(),
                    operation='consume',
                    latency_ms=0,
                    success=False,
                    error_message=str(e)
                ))
                self.stats['receive_errors'] += 1
                await message.ack()
                
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if time.time() > end_time:
                raise asyncio.CancelledError()
                
        # å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯
        await queue.consume(message_handler, no_ack=False)
        
        try:
            while True:
                await asyncio.sleep(1)
        except asyncio.CancelledError:
            pass
            
    async def run_test(self) -> Dict[str, Any]:
        """è¿è¡Œè´Ÿè½½æµ‹è¯•"""
        await self.connect()
        
        # åˆ›å»ºç”Ÿäº§è€…åç¨‹
        producer_tasks = []
        for i in range(self.config.concurrent_producers):
            task = asyncio.create_task(self.publish_messages(i))
            producer_tasks.append(task)
            
        # åˆ›å»ºæ¶ˆè´¹è€…åç¨‹
        consumer_tasks = []
        for i in range(self.config.concurrent_consumers):
            task = asyncio.create_task(self.consume_messages(i))
            consumer_tasks.append(task)
            
        # è¿è¡Œæµ‹è¯•
        await asyncio.sleep(self.config.duration_seconds)
        
        # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
        for task in producer_tasks + consumer_tasks:
            task.cancel()
            
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        await asyncio.gather(*producer_tasks, *consumer_tasks, return_exceptions=True)
        
        await self.disconnect()
        
        return self.generate_report()
        
    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        publish_results = [r for r in self.results if r.operation == 'publish']
        consume_results = [r for r in self.results if r.operation == 'consume']
        
        report = {
            'test_config': {
                'host': self.config.host,
                'port': self.config.port,
                'queue_name': self.config.queue_name,
                'message_size': self.config.message_size,
                'duration_seconds': self.config.duration_seconds,
                'concurrent_producers': self.config.concurrent_producers,
                'concurrent_consumers': self.config.concurrent_consumers,
                'prefetch_count': self.config.prefetch_count
            },
            'statistics': self.stats.copy(),
            'performance_metrics': {}
        }
        
        if publish_results:
            successful_publishes = [r for r in publish_results if r.success]
            failed_publishes = [r for r in publish_results if not r.success]
            
            if successful_publishes:
                latencies = [r.latency_ms for r in successful_publishes]
                report['performance_metrics']['publish'] = {
                    'total_messages': len(publish_results),
                    'successful_messages': len(successful_publishes),
                    'failed_messages': len(failed_publishes),
                    'success_rate': len(successful_publishes) / len(publish_results) * 100,
                    'throughput_msg_per_sec': len(successful_publishes) / self.config.duration_seconds,
                    'latency_stats': {
                        'min_ms': min(latencies),
                        'max_ms': max(latencies),
                        'avg_ms': statistics.mean(latencies),
                        'median_ms': statistics.median(latencies),
                        'p95_ms': self._percentile(latencies, 95),
                        'p99_ms': self._percentile(latencies, 99)
                    }
                }
                
        if consume_results:
            successful_consumes = [r for r in consume_results if r.success]
            failed_consumes = [r for r in consume_results if not r.success]
            
            if successful_consumes:
                latencies = [r.latency_ms for r in successful_consumes]
                report['performance_metrics']['consume'] = {
                    'total_messages': len(consume_results),
                    'successful_messages': len(successful_consumes),
                    'failed_messages': len(failed_consumes),
                    'success_rate': len(successful_consumes) / len(consume_results) * 100,
                    'throughput_msg_per_sec': len(successful_consumes) / self.config.duration_seconds,
                    'latency_stats': {
                        'min_ms': min(latencies),
                        'max_ms': max(latencies),
                        'avg_ms': statistics.mean(latencies),
                        'median_ms': statistics.median(latencies),
                        'p95_ms': self._percentile(latencies, 95),
                        'p99_ms': self._percentile(latencies, 99)
                    }
                }
                
        return report
        
    def _percentile(self, data: List[float], percentile: float) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0.0
        sorted_data = sorted(data)
        index = (percentile / 100.0) * (len(sorted_data) - 1)
        lower_index = int(index)
        upper_index = min(lower_index + 1, len(sorted_data) - 1)
        weight = index - lower_index
        return sorted_data[lower_index] * (1 - weight) + sorted_data[upper_index] * weight


async def main():
    parser = argparse.ArgumentParser(description='RabbitMQè´Ÿè½½æµ‹è¯•å·¥å…·')
    parser.add_argument('--host', default='localhost', help='RabbitMQä¸»æœº')
    parser.add_argument('--port', type=int, default=5672, help='RabbitMQç«¯å£')
    parser.add_argument('--username', default='admin', help='ç”¨æˆ·å')
    parser.add_argument('--password', default='admin123', help='å¯†ç ')
    parser.add_argument('--queue', default='test-queue', help='æµ‹è¯•é˜Ÿåˆ—åç§°')
    parser.add_argument('--message-size', type=int, default=1024, help='æ¶ˆæ¯å¤§å°(å­—èŠ‚)')
    parser.add_argument('--duration', type=int, default=60, help='æµ‹è¯•æŒç»­æ—¶é—´(ç§’)')
    parser.add_argument('--producers', type=int, default=5, help='å¹¶å‘ç”Ÿäº§è€…æ•°é‡')
    parser.add_argument('--consumers', type=int, default=5, help='å¹¶å‘æ¶ˆè´¹è€…æ•°é‡')
    parser.add_argument('--prefetch', type=int, default=10, help='é¢„å–è®¡æ•°')
    parser.add_argument('--output', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶')
    
    args = parser.parse_args()
    
    config = TestConfig(
        host=args.host,
        port=args.port,
        username=args.username,
        password=args.password,
        queue_name=args.queue,
        message_size=args.message_size,
        duration_seconds=args.duration,
        concurrent_producers=args.producers,
        concurrent_consumers=args.consumers,
        prefetch_count=args.prefetch
    )
    
    print(f"å¼€å§‹RabbitMQè´Ÿè½½æµ‹è¯•...")
    print(f"é…ç½®: {config}")
    
    tester = RabbitMQLoadTester(config)
    report = await tester.run_test()
    
    # è¾“å‡ºæŠ¥å‘Š
    print("\n=== è´Ÿè½½æµ‹è¯•æŠ¥å‘Š ===")
    print(json.dumps(report, indent=2, default=str))
    
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, default=str)
        print(f"\næŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.output}")


if __name__ == '__main__':
    asyncio.run(main())
```

## 8. å¤šäº‘éƒ¨ç½²ä¸ç¾å¤‡

### 8.1 å¤šäº‘ç¯å¢ƒé…ç½®

#### äº‘æä¾›å•†é…ç½®æ–‡ä»¶
```yaml
# multi-cloud-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: rabbitmq-multi-cloud-config
  namespace: default
data:
  # AWSé…ç½®
  aws.conf: |
    cluster_formation.aws_use_private_ip = true
    cluster_formation.aws_instance_type = m5.xlarge
    cluster_formation.aws_region = us-west-2
    cluster_formation.aws_subnet_cidr = 10.0.1.0/24
    cluster_formation.aws_security_group_id = sg-12345678
    
  # Azureé…ç½®
  azure.conf: |
    cluster_formation.azure_use_private_ip = true
    cluster_formation.azure_instance_type = Standard_D4s_v3
    cluster_formation.azure_region = westus2
    cluster_formation.azure_subnet = subnet-12345678
    cluster_formation.azure_resource_group = rg-rabbitmq
    
  # GCPé…ç½®
  gcp.conf: |
    cluster_formation.gcp_use_private_ip = true
    cluster_formation.gcp_instance_type = n1-standard-4
    cluster_formation.gcp_region = us-central1
    cluster_formation.gcp_subnet = subnet-rabbitmq
    cluster_formation.gcp_project_id = my-gcp-project
    
---
apiVersion: v1
kind: Secret
metadata:
  name: rabbitmq-cloud-credentials
  namespace: default
type: Opaque
stringData:
  # AWSå‡­è¯
  aws-access-key-id: "AKIA..."
  aws-secret-access-key: "..."
  # Azureå‡­è¯
  azure-client-id: "..."
  azure-client-secret: "..."
  azure-tenant-id: "..."
  # GCPå‡­è¯
  gcp-service-account: |
    {
      "type": "service_account",
      "project_id": "my-gcp-project",
      "private_key_id": "...",
      "private_key": "-----BEGIN PRIVATE KEY-----\\n...\\n-----END PRIVATE KEY-----\\n",
      "client_email": "rabbitmq@my-gcp-project.iam.gserviceaccount.com"
    }
```

#### äº‘åŸç”Ÿå­˜å‚¨ç±»
```yaml
# cloud-storage-classes.yaml
# AWS EKS StorageClass
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rabbitmq-aws-gp3
  namespace: default
provisioner: ebs.csi.aws.com
parameters:
  type: gp3
  iops: "3000"
  throughput: "125"
  encrypted: "true"
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
---
# AKS StorageClass
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rabbitmq-azure-premium
  namespace: default
provisioner: kubernetes.io/azure-disk
parameters:
  kind: Managed
  storageaccounttype: Premium_LRS
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
---
# GKE StorageClass
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rabbitmq-gcp-ssd
  namespace: default
provisioner: kubernetes.io/gce-pd
parameters:
  type: pd-ssd
  disk-type: pd-ssd
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer
reclaimPolicy: Delete
```

### 8.2 è·¨åœ°åŸŸé›†ç¾¤éƒ¨ç½²

#### è·¨åœ°åŸŸé…ç½®
```yaml
# cross-region-deployment.yaml