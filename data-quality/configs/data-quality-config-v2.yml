# Data Quality Framework v2.0 Configuration File

# Default Database Configuration
database:
  type: "clickhouse"
  host: "localhost"
  port: 9000
  database: "data_quality_test"
  user: "admin"
  password: "admin"
  secure: false
  timeout: 60

# Multi-Database Configuration
databases:
  clickhouse_prod:
    type: "clickhouse"
    host: "clickhouse-prod.example.com"
    port: 9000
    database: "prod_data"
    user: "prod_user"
    password: "prod_password"
    secure: true
    timeout: 120
    
  mysql_test:
    type: "mysql"
    host: "mysql-test.example.com"
    port: 3306
    database: "test_data"
    user: "test_user"
    password: "test_password"
    charset: "utf8mb4"
    timeout: 60
    
  postgresql_dev:
    type: "postgresql"
    host: "postgresql-dev.example.com"
    port: 5432
    database: "dev_data"
    user: "dev_user"
    password: "dev_password"
    timeout: 60

# Rule Configuration
rules:
  paths:
    - "rules/"
    - "scenarios/"
    - "templates/"
  cache_enabled: true
  validation_strict: true
  auto_discovery: true

# Template Configuration
templates:
  base_dir: "templates/"
  cache_enabled: true
  auto_reload: true

# Execution Configuration
execution:
  max_parallel_jobs: 5
  timeout: 300
  fail_fast: false
  retry_failed: false
  retry_count: 1
  retry_delay: 5

# Report Configuration
report:
  formats:
    - "html"
    - "json"
    - "txt"
  output_dir: "reports/"
  include_samples: true
  max_samples: 5
  retention_days: 30
  
  # HTML Report Specific Configuration
  html:
    theme: "modern"
    auto_refresh: false
    embed_assets: true
    
  # JSON Report Specific Configuration
  json:
    pretty_print: true
    include_metadata: true

# Logging Configuration
logging:
  level: "INFO"
  file: "logs/data-quality.log"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  rotate: true
  max_size: 10485760  # 10MB
  backup_count: 5

# Notification Configuration
notifications:
  enabled: false
  channels:
    email:
      enabled: false
      smtp_server: "smtp.example.com"
      smtp_port: 587
      username: "alerts@example.com"
      password: "password"
      recipients:
        - "team@example.com"
      subject_template: "Data Quality Check Report - {scenario} - {status}"
      
    slack:
      enabled: false
      webhook_url: "https://hooks.slack.com/services/..."
      channel: "#data-quality"
      username: "DataQuality Bot"
      
    webhook:
      enabled: false
      url: "https://api.example.com/webhooks/data-quality"
      timeout: 30
      
  # Notification Trigger Conditions
  triggers:
    on_failure: true
    on_error: true
    on_success: false
    failure_threshold: 1
    error_threshold: 1

# Scenario Configuration
scenarios:
  smoke_test:
    name: "smoke_test"
    description: "Quick Smoke Test"
    enabled: true
    rules:
      paths:
        - "scenarios/smoke_test/"
      categories:
        - "completeness"
        - "accuracy"
      priorities:
        - "high"
    execution:
      max_parallel_jobs: 3
      timeout: 180
      
  regression:
    name: "regression"
    description: "Comprehensive Regression Test"
    enabled: true
    rules:
      paths:
        - "rules/"
        - "scenarios/regression/"
      categories:
        - "completeness"
        - "accuracy"
        - "consistency"
        - "timeliness"
      priorities:
        - "high"
        - "medium"
        - "low"
    execution:
      max_parallel_jobs: 8
      timeout: 600
      
  monitoring:
    name: "monitoring"
    description: "Continuous Monitoring Check"
    enabled: true
    rules:
      paths:
        - "scenarios/monitoring/"
      categories:
        - "completeness"
        - "accuracy"
      priorities:
        - "high"
    execution:
      max_parallel_jobs: 4
      timeout: 300
    schedule:
      enabled: true
      cron: "0 */2 * * *"  # Execute every 2 hours
      timezone: "Asia/Shanghai"

# Environment-Specific Configuration
environments:
  dev:
    database:
      type: "clickhouse"
      host: "clickhouse-dev"
      database: "dev_data_quality_test"
      user: "dev_user"
      password: "dev_password"
    logging:
      level: "DEBUG"
    execution:
      max_parallel_jobs: 2
      
  test:
    database:
      type: "clickhouse"
      host: "clickhouse-test"
      database: "test_data_quality_test"
      user: "test_user"
      password: "test_password"
    execution:
      max_parallel_jobs: 4
      
  prod:
    database:
      type: "clickhouse"
      host: "clickhouse-prod"
      database: "prod_data_quality_test"
      user: "prod_user"
      password: "prod_password"
      secure: true
      timeout: 120
    execution:
      max_parallel_jobs: 8
      fail_fast: true
    notifications:
      enabled: true
      channels:
        email:
          enabled: true
        slack:
          enabled: true
      triggers:
        on_failure: true
        on_error: true
        on_success: true

# Performance Optimization Configuration
performance:
  connection_pool:
    enabled: true
    max_connections: 10
    min_connections: 2
    connection_timeout: 30
    
  query_optimization:
    enabled: true
    query_timeout: 300
    batch_size: 1000
    parallel_queries: true
    
  caching:
    enabled: true
    cache_dir: ".cache/"
    ttl: 3600  # 1 hour
    max_size: "100MB"

# Security Configuration
security:
  encrypt_passwords: false
  password_key: "data-quality-secret-key"
  ssl_verify: true
  ssl_cert_path: ""
  ssl_key_path: ""

# Metadata Configuration
metadata:
  store_enabled: true
  store_type: "file"  # file, database, redis
  store_path: "metadata/"
  retention_days: 90
  
  # Track Execution History
  track_history: true
  max_history_records: 1000

