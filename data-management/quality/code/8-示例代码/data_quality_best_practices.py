#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¬¬8ç« ï¼šæ•°æ®è´¨é‡æœ€ä½³å®è·µä¸æ¡ˆä¾‹ç ”ç©¶ - ç¤ºä¾‹ä»£ç 
"""

import pandas as pd
import numpy as np
import re
import time
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Any, Callable
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


class DataQualityCulture:
    """æ•°æ®è´¨é‡æ–‡åŒ–å»ºè®¾å·¥å…·"""
    
    def __init__(self, organization_name: str):
        self.organization_name = organization_name
        self.initiatives = []
        self.metrics = {}
    
    def add_initiative(self, name: str, description: str, responsible_team: str, timeline: str):
        """æ·»åŠ æ–‡åŒ–å»ºè®¾ä¸¾æª"""
        initiative = {
            'name': name,
            'description': description,
            'responsible_team': responsible_team,
            'timeline': timeline,
            'status': 'planned'
        }
        self.initiatives.append(initiative)
        print(f"å·²æ·»åŠ æ–‡åŒ–å»ºè®¾ä¸¾æª: {name}")
    
    def set_metric(self, metric_name: str, target_value: float, current_value: float = 0):
        """è®¾ç½®æ•°æ®è´¨é‡æŒ‡æ ‡"""
        self.metrics[metric_name] = {
            'target': target_value,
            'current': current_value
        }
        print(f"å·²è®¾ç½®æŒ‡æ ‡ {metric_name}: {current_value}/{target_value}")
    
    def update_initiative_status(self, initiative_name: str, status: str):
        """æ›´æ–°ä¸¾æªçŠ¶æ€"""
        for initiative in self.initiatives:
            if initiative['name'] == initiative_name:
                initiative['status'] = status
                print(f"å·²æ›´æ–°ä¸¾æª {initiative_name} çŠ¶æ€ä¸º: {status}")
                break
    
    def generate_culture_report(self) -> str:
        """ç”Ÿæˆæ–‡åŒ–å»ºè®¾æŠ¥å‘Š"""
        report = f"""
{self.organization_name} æ•°æ®è´¨é‡æ–‡åŒ–å»ºè®¾æŠ¥å‘Š
====================================

æ–‡åŒ–å»ºè®¾ä¸¾æª:
"""
        for initiative in self.initiatives:
            report += f"- {initiative['name']} ({initiative['status']}): {initiative['description']}\n"
        
        report += "\nå…³é”®æŒ‡æ ‡è¿›å±•:\n"
        for metric_name, values in self.metrics.items():
            progress = (values['current'] / values['target']) * 100 if values['target'] > 0 else 0
            report += f"- {metric_name}: {values['current']}/{values['target']} ({progress:.1f}%)\n"
        
        return report


class DataQualityMetrics:
    """æ•°æ®è´¨é‡æŒ‡æ ‡ä½“ç³»"""
    
    def __init__(self):
        self.metrics = {}
        self.thresholds = {}
    
    def register_metric(self, name: str, description: str, threshold: float, 
                       calculation_function: Callable):
        """æ³¨å†Œç›‘æ§æŒ‡æ ‡"""
        self.metrics[name] = {
            'description': description,
            'calculation_function': calculation_function
        }
        self.thresholds[name] = threshold
        print(f"å·²æ³¨å†ŒæŒ‡æ ‡: {name}")
    
    def calculate_metrics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """è®¡ç®—æ‰€æœ‰æŒ‡æ ‡"""
        results = {}
        for name, config in self.metrics.items():
            try:
                value = config['calculation_function'](df)
                threshold = self.thresholds.get(name, 0)
                status = 'pass' if value >= threshold else 'fail'
                
                results[name] = {
                    'value': value,
                    'threshold': threshold,
                    'status': status,
                    'description': config['description']
                }
            except Exception as e:
                results[name] = {
                    'value': None,
                    'threshold': threshold,
                    'status': 'error',
                    'description': config['description'],
                    'error': str(e)
                }
        return results
    
    def generate_dashboard_data(self, metrics_results: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆä»ªè¡¨æ¿æ•°æ®"""
        dashboard = {
            'timestamp': datetime.now().isoformat(),
            'overall_score': self._calculate_overall_score(metrics_results),
            'metrics': metrics_results
        }
        return dashboard
    
    def _calculate_overall_score(self, metrics_results: Dict[str, Any]) -> float:
        """è®¡ç®—æ€»ä½“è´¨é‡åˆ†æ•°"""
        passed_metrics = sum(1 for result in metrics_results.values() 
                           if result.get('status') == 'pass')
        total_metrics = len([m for m in metrics_results.values() 
                           if m.get('status') in ['pass', 'fail']])
        return round(passed_metrics / total_metrics * 100, 2) if total_metrics > 0 else 0


class MonitoringFrequencyManager:
    """ç›‘æ§é¢‘ç‡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.frequencies = {}
    
    def set_frequency(self, table_name: str, frequency: str, priority: str = 'medium'):
        """
        è®¾ç½®ç›‘æ§é¢‘ç‡
        
        Args:
            table_name: è¡¨å
            frequency: ç›‘æ§é¢‘ç‡ ('realtime', 'hourly', 'daily', 'weekly')
            priority: ä¼˜å…ˆçº§ ('high', 'medium', 'low')
        """
        self.frequencies[table_name] = {
            'frequency': frequency,
            'priority': priority,
            'last_check': None
        }
        print(f"å·²è®¾ç½® {table_name} çš„ç›‘æ§é¢‘ç‡ä¸º {frequency}")
    
    def get_scheduling_plan(self) -> Dict[str, List[Dict]]:
        """è·å–è°ƒåº¦è®¡åˆ’"""
        plan = {
            'realtime': [],
            'hourly': [],
            'daily': [],
            'weekly': []
        }
        
        for table_name, config in self.frequencies.items():
            plan[config['frequency']].append({
                'table': table_name,
                'priority': config['priority']
            })
        
        return plan
    
    def should_check(self, table_name: str, current_time: datetime) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ£€æŸ¥"""
        if table_name not in self.frequencies:
            return False
        
        config = self.frequencies[table_name]
        last_check = config['last_check']
        
        if config['frequency'] == 'realtime':
            return True
        elif config['frequency'] == 'hourly':
            if not last_check or (current_time - last_check).seconds >= 3600:
                config['last_check'] = current_time
                return True
        elif config['frequency'] == 'daily':
            if not last_check or (current_time - last_check).days >= 1:
                config['last_check'] = current_time
                return True
        elif config['frequency'] == 'weekly':
            if not last_check or (current_time - last_check).days >= 7:
                config['last_check'] = current_time
                return True
        
        return False


class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self):
        self.alert_rules = []
        self.alert_history = []
    
    def add_alert_rule(self, metric_name: str, threshold: float, severity: str, 
                      notification_channels: List[str]):
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        rule = {
            'metric_name': metric_name,
            'threshold': threshold,
            'severity': severity,  # 'critical', 'high', 'medium', 'low'
            'channels': notification_channels,  # ['email', 'sms', 'slack']
            'enabled': True
        }
        self.alert_rules.append(rule)
        print(f"å·²æ·»åŠ å‘Šè­¦è§„åˆ™: {metric_name} < {threshold} ({severity})")
    
    def check_and_alert(self, metrics_results: Dict[str, Any]) -> List[Dict]:
        """æ£€æŸ¥æŒ‡æ ‡å¹¶è§¦å‘å‘Šè­¦"""
        alerts = []
        
        for rule in self.alert_rules:
            if not rule['enabled']:
                continue
                
            metric_name = rule['metric_name']
            if metric_name in metrics_results:
                result = metrics_results[metric_name]
                current_value = result.get('value', 0)
                
                if current_value < rule['threshold']:
                    alert = {
                        'timestamp': datetime.now().isoformat(),
                        'metric_name': metric_name,
                        'current_value': current_value,
                        'threshold': rule['threshold'],
                        'severity': rule['severity'],
                        'channels': rule['channels'],
                        'message': f"{metric_name} æŒ‡æ ‡å€¼ {current_value:.4f} ä½äºé˜ˆå€¼ {rule['threshold']}"
                    }
                    alerts.append(alert)
                    self.alert_history.append(alert)
                    self._send_alert(alert)
        
        return alerts
    
    def _send_alert(self, alert: Dict[str, Any]):
        """å‘é€å‘Šè­¦"""
        print(f"[{alert['severity'].upper()}] {alert['message']}")
        print(f"  é€šçŸ¥æ¸ é“: {', '.join(alert['channels'])}")
    
    def get_alert_statistics(self, hours: int = 24) -> Dict[str, Any]:
        """è·å–å‘Šè­¦ç»Ÿè®¡"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        recent_alerts = [
            alert for alert in self.alert_history
            if datetime.fromisoformat(alert['timestamp']) > cutoff_time
        ]
        
        severity_counts = {}
        for alert in recent_alerts:
            severity = alert['severity']
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        return {
            'total_alerts': len(recent_alerts),
            'severity_distribution': severity_counts,
            'most_common_metrics': self._get_most_common_metrics(recent_alerts)
        }
    
    def _get_most_common_metrics(self, alerts: List[Dict]) -> List[tuple]:
        """è·å–æœ€å¸¸è§çš„å‘Šè­¦æŒ‡æ ‡"""
        metric_counts = {}
        for alert in alerts:
            metric = alert['metric_name']
            metric_counts[metric] = metric_counts.get(metric, 0) + 1
        
        return sorted(metric_counts.items(), key=lambda x: x[1], reverse=True)[:5]


class BankCustomerDataQualityStandards:
    """é“¶è¡Œå®¢æˆ·æ•°æ®è´¨é‡æ ‡å‡†"""
    
    def __init__(self):
        self.standards = {
            'completeness': {
                'customer_name': 0.99,
                'id_number': 0.99,
                'phone': 0.95,
                'address': 0.90
            },
            'accuracy': {
                'phone_format': 0.99,
                'id_number_format': 1.0,
                'email_format': 0.95
            },
            'consistency': {
                'cross_system_consistency': 0.99
            },
            'timeliness': {
                'update_sync_time': 24  # å°æ—¶
            }
        }
    
    def validate_customer_data(self, customer_data: pd.DataFrame) -> Dict[str, Any]:
        """éªŒè¯å®¢æˆ·æ•°æ®è´¨é‡"""
        validation_results = {}
        
        # å®Œæ•´æ€§æ£€æŸ¥
        completeness_results = self._check_completeness(customer_data)
        validation_results['completeness'] = completeness_results
        
        # å‡†ç¡®æ€§æ£€æŸ¥
        accuracy_results = self._check_accuracy(customer_data)
        validation_results['accuracy'] = accuracy_results
        
        # ä¸€è‡´æ€§æ£€æŸ¥
        consistency_results = self._check_consistency(customer_data)
        validation_results['consistency'] = consistency_results
        
        # åŠæ—¶æ€§æ£€æŸ¥
        timeliness_results = self._check_timeliness(customer_data)
        validation_results['timeliness'] = timeliness_results
        
        return validation_results
    
    def _check_completeness(self, data: pd.DataFrame) -> Dict[str, Any]:
        """æ£€æŸ¥å®Œæ•´æ€§"""
        results = {}
        total_records = len(data)
        
        for field, threshold in self.standards['completeness'].items():
            if field in data.columns:
                missing_count = data[field].isnull().sum()
                completeness_rate = (total_records - missing_count) / total_records
                results[field] = {
                    'rate': completeness_rate,
                    'threshold': threshold,
                    'status': 'pass' if completeness_rate >= threshold else 'fail'
                }
        
        return results
    
    def _check_accuracy(self, data: pd.DataFrame) -> Dict[str, Any]:
        """æ£€æŸ¥å‡†ç¡®æ€§"""
        results = {}
        
        # æ£€æŸ¥èº«ä»½è¯å·ç æ ¼å¼
        if 'id_number' in data.columns:
            id_pattern = re.compile(r'^[1-9]\d{5}(18|19|20)\d{2}((0[1-9])|(1[0-2]))(([0-2][1-9])|10|20|30|31)\d{3}[0-9Xx]$')
            valid_format = data['id_number'].astype(str).apply(lambda x: bool(id_pattern.match(x)))
            accuracy_rate = valid_format.sum() / len(data)
            threshold = self.standards['accuracy']['id_number_format']
            results['id_number_format'] = {
                'rate': accuracy_rate,
                'threshold': threshold,
                'status': 'pass' if accuracy_rate >= threshold else 'fail'
            }
        
        # æ£€æŸ¥æ‰‹æœºå·ç æ ¼å¼
        if 'phone' in data.columns:
            phone_pattern = re.compile(r'^1[3-9]\d{9}$')
            valid_format = data['phone'].astype(str).apply(lambda x: bool(phone_pattern.match(x)))
            accuracy_rate = valid_format.sum() / len(data)
            threshold = self.standards['accuracy']['phone_format']
            results['phone_format'] = {
                'rate': accuracy_rate,
                'threshold': threshold,
                'status': 'pass' if accuracy_rate >= threshold else 'fail'
            }
        
        return results
    
    def _check_consistency(self, data: pd.DataFrame) -> Dict[str, Any]:
        """æ£€æŸ¥ä¸€è‡´æ€§"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦è·¨ç³»ç»Ÿæ¯”è¾ƒ
        return {'cross_system_consistency': {'rate': 0.95, 'threshold': 0.99, 'status': 'fail'}}
    
    def _check_timeliness(self, data: pd.DataFrame) -> Dict[str, Any]:
        """æ£€æŸ¥åŠæ—¶æ€§"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ£€æŸ¥æ•°æ®æ›´æ–°æ—¶é—´
        return {'update_sync_time': {'hours': 12, 'threshold': 24, 'status': 'pass'}}


class BankDataQualityDashboard:
    """é“¶è¡Œæ•°æ®è´¨é‡ç›‘æ§ä»ªè¡¨æ¿"""
    
    def __init__(self):
        self.metrics_history = []
        self.alerts = []
    
    def update_metrics(self, metrics_data: Dict[str, Any]):
        """æ›´æ–°æŒ‡æ ‡æ•°æ®"""
        timestamp = datetime.now()
        metrics_data['timestamp'] = timestamp
        self.metrics_history.append(metrics_data)
        print(f"å·²æ›´æ–°æŒ‡æ ‡æ•°æ®: {timestamp}")
    
    def check_thresholds_and_alert(self, current_metrics: Dict[str, float], 
                                  thresholds: Dict[str, float]):
        """æ£€æŸ¥é˜ˆå€¼å¹¶å‘Šè­¦"""
        for metric_name, current_value in current_metrics.items():
            if metric_name in thresholds:
                threshold = thresholds[metric_name]
                if current_value < threshold:
                    alert = {
                        'timestamp': datetime.now(),
                        'metric': metric_name,
                        'current_value': current_value,
                        'threshold': threshold,
                        'severity': self._determine_severity(metric_name),
                        'message': f'{metric_name} æŒ‡æ ‡ {current_value:.2%} ä½äºé˜ˆå€¼ {threshold:.2%}'
                    }
                    self.alerts.append(alert)
                    self._send_alert(alert)
    
    def _determine_severity(self, metric_name: str) -> str:
        """ç¡®å®šå‘Šè­¦ä¸¥é‡ç¨‹åº¦"""
        critical_metrics = ['id_number_format', 'customer_name_completeness']
        high_metrics = ['phone_format', 'phone_completeness']
        
        if metric_name in critical_metrics:
            return 'critical'
        elif metric_name in high_metrics:
            return 'high'
        else:
            return 'medium'
    
    def _send_alert(self, alert: Dict[str, Any]):
        """å‘é€å‘Šè­¦"""
        severity_colors = {'critical': 'ğŸ”´', 'high': 'ğŸŸ ', 'medium': 'ğŸŸ¡'}
        color = severity_colors.get(alert['severity'], 'âšª')
        print(f"{color} [{alert['severity'].upper()}] {alert['message']}")
    
    def generate_report(self, hours: int = 24) -> str:
        """ç”Ÿæˆç›‘æ§æŠ¥å‘Š"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        recent_metrics = [
            metric for metric in self.metrics_history
            if metric['timestamp'] > cutoff_time
        ]
        
        recent_alerts = [
            alert for alert in self.alerts
            if alert['timestamp'] > cutoff_time
        ]
        
        report = f"""
é“¶è¡Œæ•°æ®è´¨é‡ç›‘æ§æŠ¥å‘Š ({hours}å°æ—¶)
================================

æ•°æ®è´¨é‡æŒ‡æ ‡è¶‹åŠ¿:
"""
        if recent_metrics:
            latest_metrics = recent_metrics[-1]
            for key, value in latest_metrics.items():
                if key != 'timestamp':
                    report += f"- {key}: {value:.2%}\n"
        
        report += f"\nå‘Šè­¦ç»Ÿè®¡:\n"
        report += f"- æ€»å‘Šè­¦æ•°: {len(recent_alerts)}\n"
        
        severity_counts = {}
        for alert in recent_alerts:
            severity = alert['severity']
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
        
        for severity, count in severity_counts.items():
            report += f"- {severity}: {count}\n"
        
        return report


class OrderDataQualityRuleEngine:
    """è®¢å•æ•°æ®è´¨é‡è§„åˆ™å¼•æ“"""
    
    def __init__(self):
        self.rules = []
        self.rule_results = []
    
    def add_rule(self, name: str, description: str, condition_function: Callable, 
                action_function: Callable = None):
        """æ·»åŠ è§„åˆ™"""
        rule = {
            'name': name,
            'description': description,
            'condition': condition_function,
            'action': action_function or self._default_action,
            'enabled': True,
            'created_at': datetime.now()
        }
        self.rules.append(rule)
        print(f"å·²æ·»åŠ è§„åˆ™: {name}")
    
    def validate_order(self, order_data: Dict[str, Any]) -> List[Dict]:
        """éªŒè¯è®¢å•æ•°æ®"""
        violations = []
        
        for rule in self.rules:
            if not rule['enabled']:
                continue
            
            try:
                if rule['condition'](order_data):
                    violation = {
                        'rule_name': rule['name'],
                        'description': rule['description'],
                        'order_id': order_data.get('order_id'),
                        'timestamp': datetime.now(),
                        'status': 'violation'
                    }
                    violations.append(violation)
                    
                    # æ‰§è¡Œå¤„ç†åŠ¨ä½œ
                    rule['action'](order_data, violation)
                    
            except Exception as e:
                print(f"è§„åˆ™ {rule['name']} æ‰§è¡Œå‡ºé”™: {str(e)}")
        
        self.rule_results.extend(violations)
        return violations
    
    def _default_action(self, order_data: Dict[str, Any], violation: Dict[str, Any]):
        """é»˜è®¤å¤„ç†åŠ¨ä½œ"""
        print(f"è®¢å• {order_data.get('order_id')} è¿åè§„åˆ™: {violation['rule_name']}")
    
    def get_violation_statistics(self, hours: int = 24) -> Dict[str, Any]:
        """è·å–è¿è§„ç»Ÿè®¡"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        recent_violations = [
            v for v in self.rule_results
            if v['timestamp'] > cutoff_time
        ]
        
        rule_counts = {}
        for violation in recent_violations:
            rule_name = violation['rule_name']
            rule_counts[rule_name] = rule_counts.get(rule_name, 0) + 1
        
        return {
            'total_violations': len(recent_violations),
            'rule_distribution': rule_counts,
            'top_violations': sorted(rule_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        }


class RealTimeOrderQualityMonitor:
    """å®æ—¶è®¢å•æ•°æ®è´¨é‡ç›‘æ§å™¨"""
    
    def __init__(self, rule_engine: OrderDataQualityRuleEngine):
        self.rule_engine = rule_engine
        self.processed_orders = 0
        self.violation_count = 0
        self.performance_metrics = []
    
    def process_order_stream(self, order_stream: List[Dict], batch_size: int = 100):
        """å¤„ç†è®¢å•æµæ•°æ®"""
        batch = []
        start_time = time.time()
        
        for order in order_stream:
            batch.append(order)
            
            # æ‰¹é‡å¤„ç†ä»¥æé«˜æ€§èƒ½
            if len(batch) >= batch_size:
                self._process_batch(batch)
                batch = []
                
                # è®°å½•æ€§èƒ½æŒ‡æ ‡
                batch_time = time.time() - start_time
                self.performance_metrics.append({
                    'timestamp': datetime.now(),
                    'batch_size': batch_size,
                    'processing_time': batch_time,
                    'throughput': batch_size / batch_time if batch_time > 0 else 0
                })
                
                start_time = time.time()
        
        # å¤„ç†å‰©ä½™çš„è®¢å•
        if batch:
            self._process_batch(batch)
    
    def _process_batch(self, batch: List[Dict]):
        """å¤„ç†è®¢å•æ‰¹æ¬¡"""
        for order in batch:
            self.processed_orders += 1
            violations = self.rule_engine.validate_order(order)
            if violations:
                self.violation_count += len(violations)
    
    def get_monitoring_report(self) -> str:
        """è·å–ç›‘æ§æŠ¥å‘Š"""
        if not self.performance_metrics:
            return "æš‚æ— ç›‘æ§æ•°æ®"
        
        avg_throughput = sum(m['throughput'] for m in self.performance_metrics) / len(self.performance_metrics)
        latest_metrics = self.performance_metrics[-1]
        
        report = f"""
å®æ—¶è®¢å•æ•°æ®è´¨é‡ç›‘æ§æŠ¥å‘Š
========================

å¤„ç†ç»Ÿè®¡:
- å·²å¤„ç†è®¢å•æ•°: {self.processed_orders:,}
- å‘ç°è¿è§„æ•°: {self.violation_count:,}
- è¿è§„ç‡: {self.violation_count/self.processed_orders:.2%} (å¦‚æœå·²å¤„ç†è®¢å•>0)

æ€§èƒ½æŒ‡æ ‡:
- å¹³å‡ååé‡: {avg_throughput:.2f} è®¢å•/ç§’
- æœ€æ–°æ‰¹æ¬¡å¤„ç†æ—¶é—´: {latest_metrics['processing_time']:.3f} ç§’
- æœ€æ–°æ‰¹æ¬¡ååé‡: {latest_metrics['throughput']:.2f} è®¢å•/ç§’
        """
        
        return report
    
    def get_top_violations(self, top_n: int = 10) -> List[tuple]:
        """è·å–æœ€å¸¸è§çš„è¿è§„ç±»å‹"""
        stats = self.rule_engine.get_violation_statistics()
        return stats.get('top_violations', [])[:top_n]


class DataQualityMaturityAssessment:
    """æ•°æ®è´¨é‡ç®¡ç†æˆç†Ÿåº¦è¯„ä¼°"""
    
    def __init__(self):
        self.dimensions = {
            'strategy_and_governance': {
                'name': 'æˆ˜ç•¥ä¸æ²»ç†',
                'levels': {
                    1: 'æ— æ˜ç¡®çš„æ•°æ®è´¨é‡ç®¡ç†ç­–ç•¥å’Œæ²»ç†æœºåˆ¶',
                    2: 'æœ‰åˆæ­¥çš„æ•°æ®è´¨é‡ç®¡ç†æ„è¯†ï¼Œä½†ç¼ºä¹ç³»ç»Ÿæ€§',
                    3: 'å»ºç«‹äº†åŸºæœ¬çš„æ•°æ®è´¨é‡ç®¡ç†ç­–ç•¥å’Œæ²»ç†æ¡†æ¶',
                    4: 'æœ‰å®Œå–„çš„æ•°æ®è´¨é‡ç®¡ç†ç­–ç•¥å’Œæ²»ç†æœºåˆ¶',
                    5: 'æ•°æ®è´¨é‡ç®¡ç†æˆä¸ºç»„ç»‡æ ¸å¿ƒç«äº‰åŠ›ï¼ŒæŒç»­ä¼˜åŒ–'
                },
                'indicators': [
                    'æ˜¯å¦æœ‰æ˜ç¡®çš„æ•°æ®è´¨é‡ç®¡ç†ç­–ç•¥',
                    'æ˜¯å¦å»ºç«‹äº†æ•°æ®æ²»ç†ç»„ç»‡',
                    'æ˜¯å¦æœ‰æ•°æ®è´¨é‡ç®¡ç†ç›¸å…³çš„æ”¿ç­–å’Œæ ‡å‡†',
                    'æ•°æ®è´¨é‡ç®¡ç†æ˜¯å¦çº³å…¥ç»©æ•ˆè€ƒæ ¸'
                ]
            },
            'process_and_methodology': {
                'name': 'æµç¨‹ä¸æ–¹æ³•',
                'levels': {
                    1: 'æ•°æ®è´¨é‡ç®¡ç†æµç¨‹ç¼ºå¤±æˆ–ä¸è§„èŒƒ',
                    2: 'æœ‰é›¶æ•£çš„æ•°æ®è´¨é‡ç®¡ç†æ´»åŠ¨',
                    3: 'å»ºç«‹äº†åŸºæœ¬çš„æ•°æ®è´¨é‡ç®¡ç†æµç¨‹',
                    4: 'æœ‰æ ‡å‡†åŒ–çš„æ•°æ®è´¨é‡ç®¡ç†æµç¨‹å’Œæ–¹æ³•',
                    5: 'æµç¨‹æŒç»­ä¼˜åŒ–ï¼Œæ–¹æ³•ä¸æ–­åˆ›æ–°'
                },
                'indicators': [
                    'æ˜¯å¦æœ‰æ ‡å‡†åŒ–çš„æ•°æ®è´¨é‡æ£€æŸ¥æµç¨‹',
                    'æ˜¯å¦ä½¿ç”¨ç³»ç»ŸåŒ–çš„æ–¹æ³•è¿›è¡Œæ•°æ®è´¨é‡è¯„ä¼°',
                    'æ˜¯å¦æœ‰æ•°æ®è´¨é‡é—®é¢˜çš„å¤„ç†æµç¨‹',
                    'æ˜¯å¦å®šæœŸè¿›è¡Œæ•°æ®è´¨é‡æ”¹è¿›'
                ]
            },
            'technology_and_tools': {
                'name': 'æŠ€æœ¯ä¸å·¥å…·',
                'levels': {
                    1: 'ç¼ºä¹ä¸“é—¨çš„æ•°æ®è´¨é‡ç®¡ç†å·¥å…·',
                    2: 'ä½¿ç”¨ç®€å•çš„å·¥å…·è¿›è¡Œæ•°æ®è´¨é‡æ£€æŸ¥',
                    3: 'é…å¤‡äº†åŸºæœ¬çš„æ•°æ®è´¨é‡ç®¡ç†å·¥å…·',
                    4: 'æœ‰é›†æˆåŒ–çš„æ•°æ®è´¨é‡ç®¡ç†å¹³å°',
                    5: 'ä½¿ç”¨å…ˆè¿›çš„æŠ€æœ¯å’Œå·¥å…·ï¼Œæ”¯æŒæ™ºèƒ½åŒ–ç®¡ç†'
                },
                'indicators': [
                    'æ˜¯å¦ä½¿ç”¨ä¸“é—¨çš„æ•°æ®è´¨é‡ç®¡ç†å·¥å…·',
                    'æ˜¯å¦æœ‰è‡ªåŠ¨åŒ–çš„æ•°æ®è´¨é‡ç›‘æ§',
                    'æ˜¯å¦æ”¯æŒå®æ—¶æ•°æ®è´¨é‡æ£€æŸ¥',
                    'æ˜¯å¦å…·å¤‡é¢„æµ‹æ€§æ•°æ®è´¨é‡ç®¡ç†èƒ½åŠ›'
                ]
            },
            'organization_and_people': {
                'name': 'ç»„ç»‡ä¸äººå‘˜',
                'levels': {
                    1: 'æ— ä¸“é—¨çš„æ•°æ®è´¨é‡ç®¡ç†å›¢é˜Ÿ',
                    2: 'æœ‰å…¼èŒäººå‘˜è´Ÿè´£æ•°æ®è´¨é‡ç®¡ç†',
                    3: 'å»ºç«‹äº†ä¸“é—¨çš„æ•°æ®è´¨é‡ç®¡ç†å›¢é˜Ÿ',
                    4: 'å›¢é˜Ÿå…·å¤‡ä¸“ä¸šçš„æ•°æ®è´¨é‡ç®¡ç†èƒ½åŠ›',
                    5: 'å›¢é˜ŸæŒç»­å­¦ä¹ ï¼Œå¼•é¢†è¡Œä¸šå‘å±•'
                },
                'indicators': [
                    'æ˜¯å¦æœ‰ä¸“é—¨çš„æ•°æ®è´¨é‡ç®¡ç†å›¢é˜Ÿ',
                    'å›¢é˜Ÿæˆå‘˜æ˜¯å¦å…·å¤‡ä¸“ä¸šæŠ€èƒ½',
                    'æ˜¯å¦æœ‰å®šæœŸçš„åŸ¹è®­å’Œèƒ½åŠ›æå‡',
                    'æ˜¯å¦å»ºç«‹äº†çŸ¥è¯†ç®¡ç†ä½“ç³»'
                ]
            },
            'data_quality_outcomes': {
                'name': 'è´¨é‡æˆæœ',
                'levels': {
                    1: 'æ•°æ®è´¨é‡é—®é¢˜é¢‘å‘ï¼Œä¸¥é‡å½±å“ä¸šåŠ¡',
                    2: 'æ•°æ®è´¨é‡é—®é¢˜è¾ƒå¤šï¼Œå¯¹ä¸šåŠ¡æœ‰ä¸€å®šå½±å“',
                    3: 'æ•°æ®è´¨é‡åŸºæœ¬æ»¡è¶³ä¸šåŠ¡éœ€æ±‚',
                    4: 'æ•°æ®è´¨é‡è‰¯å¥½ï¼Œæ”¯æ’‘ä¸šåŠ¡å‘å±•',
                    5: 'æ•°æ®è´¨é‡æˆä¸ºä¸šåŠ¡ç«äº‰ä¼˜åŠ¿'
                },
                'indicators': [
                    'æ•°æ®è´¨é‡é—®é¢˜å‘ç”Ÿé¢‘ç‡',
                    'æ•°æ®è´¨é‡å¯¹ä¸šåŠ¡çš„å½±å“ç¨‹åº¦',
                    'æ•°æ®è´¨é‡æ”¹è¿›çš„æ•ˆæœ',
                    'æ•°æ®è´¨é‡å¸¦æ¥çš„ä¸šåŠ¡ä»·å€¼'
                ]
            }
        }
    
    def assess_dimension(self, dimension_name: str, scores: List[float]) -> Dict[str, Any]:
        """è¯„ä¼°å•ä¸ªç»´åº¦çš„æˆç†Ÿåº¦"""
        if dimension_name not in self.dimensions:
            raise ValueError(f"æœªçŸ¥çš„ç»´åº¦: {dimension_name}")
        
        # è®¡ç®—å¹³å‡åˆ†å¹¶ç¡®å®šæˆç†Ÿåº¦ç­‰çº§
        avg_score = sum(scores) / len(scores) if scores else 0
        level = min(5, max(1, round(avg_score)))
        
        return {
            'dimension': dimension_name,
            'dimension_name': self.dimensions[dimension_name]['name'],
            'average_score': round(avg_score, 2),
            'maturity_level': level,
            'level_description': self.dimensions[dimension_name]['levels'][level]
        }
    
    def assess_overall_maturity(self, dimension_assessments: List[Dict]) -> Dict[str, Any]:
        """è¯„ä¼°æ•´ä½“æˆç†Ÿåº¦"""
        total_score = sum(assess['average_score'] for assess in dimension_assessments)
        avg_score = total_score / len(dimension_assessments)
        overall_level = min(5, max(1, round(avg_score)))
        
        return {
            'overall_score': round(avg_score, 2),
            'overall_level': overall_level,
            'level_description': self._get_overall_level_description(overall_level),
            'dimension_details': dimension_assessments
        }
    
    def _get_overall_level_description(self, level: int) -> str:
        """è·å–æ•´ä½“ç­‰çº§æè¿°"""
        descriptions = {
            1: 'åˆå§‹çº§ï¼šæ•°æ®è´¨é‡ç®¡ç†å¤„äºèµ·æ­¥é˜¶æ®µï¼Œç¼ºä¹ç³»ç»Ÿæ€§',
            2: 'ç®¡ç†çº§ï¼šå¼€å§‹é‡è§†æ•°æ®è´¨é‡ç®¡ç†ï¼Œä½†è¿˜ä¸å¤Ÿæˆç†Ÿ',
            3: 'å®šä¹‰çº§ï¼šå»ºç«‹äº†åŸºæœ¬çš„æ•°æ®è´¨é‡ç®¡ç†ä½“ç³»',
            4: 'é‡åŒ–ç®¡ç†çº§ï¼šæ•°æ®è´¨é‡ç®¡ç†è¾¾åˆ°è¾ƒé«˜æ°´å¹³',
            5: 'ä¼˜åŒ–çº§ï¼šæ•°æ®è´¨é‡ç®¡ç†æˆä¸ºç»„ç»‡æ ¸å¿ƒç«äº‰åŠ›'
        }
        return descriptions.get(level, 'æœªçŸ¥ç­‰çº§')
    
    def generate_assessment_report(self, overall_assessment: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š"""
        report = f"""
æ•°æ®è´¨é‡ç®¡ç†æˆç†Ÿåº¦è¯„ä¼°æŠ¥å‘Š
========================

æ•´ä½“è¯„ä¼°ç»“æœ:
- æˆç†Ÿåº¦ç­‰çº§: {overall_assessment['overall_level']} çº§
- ç»¼åˆå¾—åˆ†: {overall_assessment['overall_score']}/5.0
- ç­‰çº§æè¿°: {overall_assessment['level_description']}

å„ç»´åº¦è¯„ä¼°è¯¦æƒ…:
"""
        
        for assess in overall_assessment['dimension_details']:
            report += f"\n{assess['dimension_name']}:\n"
            report += f"  - ç­‰çº§: {assess['maturity_level']} çº§\n"
            report += f"  - å¾—åˆ†: {assess['average_score']}/5.0\n"
            report += f"  - æè¿°: {assess['level_description']}\n"
        
        report += "\næ”¹è¿›å»ºè®®:\n"
        report += self._generate_improvement_recommendations(overall_assessment)
        
        return report
    
    def _generate_improvement_recommendations(self, overall_assessment: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        overall_level = overall_assessment['overall_level']
        
        if overall_level < 3:
            recommendations.append("1. å»ºç«‹å®Œå–„çš„æ•°æ®è´¨é‡ç®¡ç†ä½“ç³»å’Œæ²»ç†æœºåˆ¶")
            recommendations.append("2. ç»„å»ºä¸“ä¸šçš„æ•°æ®è´¨é‡ç®¡ç†å›¢é˜Ÿ")
            recommendations.append("3. å¼•å…¥åˆé€‚çš„æ•°æ®è´¨é‡ç®¡ç†å·¥å…·")
        
        if overall_level < 4:
            recommendations.append("4. å»ºç«‹æ ‡å‡†åŒ–çš„æ•°æ®è´¨é‡ç®¡ç†æµç¨‹")
            recommendations.append("5. åŠ å¼ºå›¢é˜ŸåŸ¹è®­å’Œèƒ½åŠ›å»ºè®¾")
            recommendations.append("6. å®æ–½æŒç»­çš„æ•°æ®è´¨é‡ç›‘æ§å’Œæ”¹è¿›")
        
        if overall_level < 5:
            recommendations.append("7. æ¨è¿›æ•°æ®è´¨é‡ç®¡ç†çš„æ™ºèƒ½åŒ–å’Œè‡ªåŠ¨åŒ–")
            recommendations.append("8. å»ºç«‹æ•°æ®è´¨é‡ä»·å€¼è¯„ä¼°ä½“ç³»")
            recommendations.append("9. æŒç»­ä¼˜åŒ–å’Œåˆ›æ–°æ•°æ®ç®¡ç†æ–¹æ³•")
        
        if not recommendations:
            recommendations.append("ç»§ç»­ä¿æŒå¹¶å¼•é¢†è¡Œä¸šå‘å±•")
        
        return "\n".join(recommendations)


# è¾…åŠ©å‡½æ•°å®šä¹‰
def calculate_completeness_rate(df: pd.DataFrame) -> float:
    """è®¡ç®—å®Œæ•´æ€§ç‡"""
    if df.empty:
        return 0.0
    total_cells = df.size
    null_cells = df.isnull().sum().sum()
    return (total_cells - null_cells) / total_cells

def calculate_uniqueness_rate(df: pd.DataFrame) -> float:
    """è®¡ç®—å”¯ä¸€æ€§ç‡"""
    if df.empty:
        return 0.0
    total_rows = len(df)
    duplicate_rows = df.duplicated().sum()
    return (total_rows - duplicate_rows) / total_rows

def calculate_timeliness_score(df: pd.DataFrame) -> float:
    """è®¡ç®—åŠæ—¶æ€§åˆ†æ•°"""
    # ç®€åŒ–å®ç°ï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦æ ¹æ®å…·ä½“ä¸šåŠ¡é€»è¾‘è®¡ç®—
    return 0.95

def amount_anomaly_condition(order: Dict[str, Any]) -> bool:
    """é‡‘é¢å¼‚å¸¸æ£€æµ‹æ¡ä»¶"""
    amount = order.get('amount', 0)
    return amount > 100000 or amount < 0

def invalid_sku_condition(order: Dict[str, Any]) -> bool:
    """æ— æ•ˆSKUæ£€æµ‹æ¡ä»¶"""
    sku = order.get('sku', '')
    return not sku or len(sku) < 3

def address_incomplete_condition(order: Dict[str, Any]) -> bool:
    """åœ°å€ä¸å®Œæ•´æ£€æµ‹æ¡ä»¶"""
    address = order.get('shipping_address', '')
    return not address or len(address.strip()) < 10

def email_format_condition(order: Dict[str, Any]) -> bool:
    """é‚®ç®±æ ¼å¼æ£€æµ‹æ¡ä»¶"""
    email = order.get('customer_email', '')
    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$'
    return email and not re.match(pattern, email)

def flag_suspicious_order(order: Dict[str, Any], violation: Dict[str, Any]):
    """æ ‡è®°å¯ç–‘è®¢å•"""
    order['status'] = 'suspicious'
    order['suspicious_reason'] = violation['rule_name']
    print(f"æ ‡è®°è®¢å• {order['order_id']} ä¸ºå¯ç–‘: {violation['rule_name']}")

def notify_finance_team(order: Dict[str, Any], violation: Dict[str, Any]):
    """é€šçŸ¥è´¢åŠ¡å›¢é˜Ÿ"""
    print(f"é€šçŸ¥è´¢åŠ¡å›¢é˜Ÿ: è®¢å• {order['order_id']} é‡‘é¢å¼‚å¸¸ ({order.get('amount', 0)})")

def generate_sample_customer_data(size: int = 1000) -> pd.DataFrame:
    """ç”Ÿæˆç¤ºä¾‹å®¢æˆ·æ•°æ®"""
    return pd.DataFrame({
        'customer_id': range(1, size + 1),
        'customer_name': ['Customer_' + str(i) for i in range(1, size + 1)],
        'id_number': ['11010119900101' + str(i).zfill(4) + ('0' if i % 2 == 0 else 'X') for i in range(1, size + 1)],
        'phone': ['138' + str(i).zfill(8) for i in range(1, size - 50)] + [None] * 50,  # 50ä¸ªç¼ºå¤±ç”µè¯
        'address': ['Address_' + str(i) for i in range(1, size - 100)] + [None] * 100,  # 100ä¸ªç¼ºå¤±åœ°å€
        'created_at': pd.date_range('2024-01-01', periods=size, freq='1H')
    })

def generate_order_stream(count: int = 1000) -> List[Dict]:
    """ç”Ÿæˆæ¨¡æ‹Ÿè®¢å•æµ"""
    orders = []
    for i in range(count):
        # å¤§éƒ¨åˆ†è®¢å•æ˜¯æ­£å¸¸çš„ï¼Œå°‘éƒ¨åˆ†æœ‰è´¨é‡é—®é¢˜
        is_anomaly = np.random.random() < 0.1  # 10%çš„æ¦‚ç‡æœ‰è´¨é‡é—®é¢˜
        
        order = {
            'order_id': f'ORD{i:06d}',
            'amount': np.random.normal(300, 100) if not is_anomaly else np.random.normal(300, 5000),
            'sku': f'SKU{np.random.randint(1000, 9999)}' if not is_anomaly or np.random.random() < 0.8 else '',
            'shipping_address': 'åŒ—äº¬å¸‚æœé˜³åŒºxxxè¡—é“xxxå·' if not is_anomaly or np.random.random() < 0.8 else 'åŒ—äº¬',
            'customer_email': f'customer{i}@example.com' if not is_anomaly or np.random.random() < 0.8 else 'invalid-email'
        }
        orders.append(order)
    return orders


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ‰€æœ‰åŠŸèƒ½"""
    print("=" * 60)
    print("ç¬¬8ç« ï¼šæ•°æ®è´¨é‡æœ€ä½³å®è·µä¸æ¡ˆä¾‹ç ”ç©¶ - ç¤ºä¾‹ä»£ç æ¼”ç¤º")
    print("=" * 60)
    
    # 1. æ•°æ®è´¨é‡æ–‡åŒ–å»ºè®¾æ¼”ç¤º
    print("\n1. æ•°æ®è´¨é‡æ–‡åŒ–å»ºè®¾æ¼”ç¤º")
    print("-" * 30)
    culture = DataQualityCulture("ç”µå•†å¹³å°å…¬å¸")
    culture.add_initiative(
        "æ•°æ®è´¨é‡æ„è¯†åŸ¹è®­",
        "ä¸ºå…¨ä½“å‘˜å·¥æä¾›æ•°æ®è´¨é‡åŸºç¡€çŸ¥è¯†åŸ¹è®­",
        "äººåŠ›èµ„æºéƒ¨",
        "2024å¹´Q1-Q2"
    )
    culture.add_initiative(
        "æ•°æ®è´¨é‡å¥–æƒ©æœºåˆ¶",
        "å»ºç«‹æ•°æ®è´¨é‡ç›¸å…³çš„å¥–åŠ±å’Œæƒ©ç½šæœºåˆ¶",
        "è´¨é‡ç®¡ç†éƒ¨é—¨",
        "2024å¹´Q2"
    )
    culture.set_metric("å‘˜å·¥æ•°æ®è´¨é‡çŸ¥è¯†æµ‹è¯•é€šè¿‡ç‡", 95, 75)
    culture.set_metric("æ•°æ®è´¨é‡é—®é¢˜æŠ¥å‘Šæ•°é‡", 50, 30)
    culture.update_initiative_status("æ•°æ®è´¨é‡æ„è¯†åŸ¹è®­", "è¿›è¡Œä¸­")
    print(culture.generate_culture_report())
    
    # 2. æ•°æ®è´¨é‡æŒ‡æ ‡ä½“ç³»æ¼”ç¤º
    print("\n2. æ•°æ®è´¨é‡æŒ‡æ ‡ä½“ç³»æ¼”ç¤º")
    print("-" * 30)
    dq_metrics = DataQualityMetrics()
    dq_metrics.register_metric(
        'completeness_rate',
        'æ•°æ®å®Œæ•´æ€§ç‡',
        0.95,
        calculate_completeness_rate
    )
    dq_metrics.register_metric(
        'uniqueness_rate',
        'æ•°æ®å”¯ä¸€æ€§ç‡',
        0.99,
        calculate_uniqueness_rate
    )
    dq_metrics.register_metric(
        'timeliness_score',
        'æ•°æ®åŠæ—¶æ€§åˆ†æ•°',
        0.90,
        calculate_timeliness_score
    )
    
    sample_data = pd.DataFrame({
        'id': range(1, 1001),
        'name': ['User_' + str(i) for i in range(1, 1001)],
        'email': ['user' + str(i) + '@example.com' for i in range(1, 951)] + [np.nan] * 50
    })
    
    metrics_results = dq_metrics.calculate_metrics(sample_data)
    dashboard_data = dq_metrics.generate_dashboard_data(metrics_results)
    print(f"æ€»ä½“æ•°æ®è´¨é‡åˆ†æ•°: {dashboard_data['overall_score']}")
    for metric_name, result in metrics_results.items():
        print(f"  {metric_name}: {result['value']:.4f} ({result['status']})")
    
    # 3. é“¶è¡Œå®¢æˆ·æ•°æ®è´¨é‡æ ‡å‡†æ¼”ç¤º
    print("\n3. é“¶è¡Œå®¢æˆ·æ•°æ®è´¨é‡æ ‡å‡†æ¼”ç¤º")
    print("-" * 30)
    bank_standards = BankCustomerDataQualityStandards()
    customer_data = generate_sample_customer_data(1000)
    validation_results = bank_standards.validate_customer_data(customer_data)
    
    print("é“¶è¡Œå®¢æˆ·æ•°æ®è´¨é‡éªŒè¯ç»“æœ:")
    for category, results in validation_results.items():
        print(f"\n{category.upper()} æ£€æŸ¥:")
        for field, result in results.items():
            status_icon = "âœ“" if result['status'] == 'pass' else "âœ—"
            print(f"  {status_icon} {field}: {result['rate']:.2%} (é˜ˆå€¼: {result['threshold']})")
    
    # 4. é“¶è¡Œæ•°æ®è´¨é‡ç›‘æ§ä»ªè¡¨æ¿æ¼”ç¤º
    print("\n4. é“¶è¡Œæ•°æ®è´¨é‡ç›‘æ§ä»ªè¡¨æ¿æ¼”ç¤º")
    print("-" * 30)
    dashboard = BankDataQualityDashboard()
    sample_metrics = {
        'customer_name_completeness': 0.995,
        'id_number_completeness': 0.992,
        'phone_completeness': 0.945,  # ä½äºé˜ˆå€¼
        'id_number_format_accuracy': 0.998,
        'phone_format_accuracy': 0.92  # ä½äºé˜ˆå€¼
    }
    
    thresholds = {
        'customer_name_completeness': 0.99,
        'id_number_completeness': 0.99,
        'phone_completeness': 0.95,
        'id_number_format_accuracy': 0.99,
        'phone_format_accuracy': 0.95
    }
    
    dashboard.update_metrics(sample_metrics)
    dashboard.check_thresholds_and_alert(sample_metrics, thresholds)
    report = dashboard.generate_report()
    print(report)
    
    # 5. ç”µå•†è®¢å•æ•°æ®è´¨é‡è§„åˆ™å¼•æ“æ¼”ç¤º
    print("\n5. ç”µå•†è®¢å•æ•°æ®è´¨é‡è§„åˆ™å¼•æ“æ¼”ç¤º")
    print("-" * 30)
    rule_engine = OrderDataQualityRuleEngine()
    rule_engine.add_rule(
        'amount_anomaly',
        'è®¢å•é‡‘é¢å¼‚å¸¸æ£€æµ‹',
        amount_anomaly_condition,
        notify_finance_team
    )
    rule_engine.add_rule(
        'invalid_sku',
        'æ— æ•ˆSKUæ£€æµ‹',
        invalid_sku_condition,
        flag_suspicious_order
    )
    rule_engine.add_rule(
        'address_incomplete',
        'åœ°å€ä¸å®Œæ•´æ£€æµ‹',
        address_incomplete_condition,
        flag_suspicious_order
    )
    rule_engine.add_rule(
        'email_format',
        'é‚®ç®±æ ¼å¼æ£€æµ‹',
        email_format_condition,
        flag_suspicious_order
    )
    
    test_orders = [
        {
            'order_id': 'ORD001',
            'amount': 150000,  # é‡‘é¢å¼‚å¸¸
            'sku': 'ABC123',
            'shipping_address': 'åŒ—äº¬å¸‚æœé˜³åŒºxxxè¡—é“',
            'customer_email': 'customer@example.com'
        },
        {
            'order_id': 'ORD002',
            'amount': 299.99,
            'sku': '',  # æ— æ•ˆSKU
            'shipping_address': 'ä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒºxxxè·¯',
            'customer_email': 'customer@example.com'
        },
        {
            'order_id': 'ORD003',
            'amount': 199.99,
            'sku': 'XYZ789',
            'shipping_address': 'å¹¿å·',  # åœ°å€ä¸å®Œæ•´
            'customer_email': 'invalid-email'  # é‚®ç®±æ ¼å¼é”™è¯¯
        }
    ]
    
    for order in test_orders:
        violations = rule_engine.validate_order(order)
        if violations:
            print(f"è®¢å• {order['order_id']} å‘ç° {len(violations)} ä¸ªè¿è§„")
    
    stats = rule_engine.get_violation_statistics()
    print(f"\nè¿è§„ç»Ÿè®¡: {stats}")
    
    # 6. å®æ—¶è®¢å•æ•°æ®è´¨é‡ç›‘æ§æ¼”ç¤º
    print("\n6. å®æ—¶è®¢å•æ•°æ®è´¨é‡ç›‘æ§æ¼”ç¤º")
    print("-" * 30)
    monitor = RealTimeOrderQualityMonitor(rule_engine)
    order_stream = generate_order_stream(500)
    monitor.process_order_stream(order_stream, batch_size=50)
    report = monitor.get_monitoring_report()
    print(report)
    
    top_violations = monitor.get_top_violations()
    print("\næœ€å¸¸è§çš„è¿è§„ç±»å‹:")
    for rule_name, count in top_violations:
        print(f"- {rule_name}: {count} æ¬¡")
    
    # 7. æ•°æ®è´¨é‡ç®¡ç†æˆç†Ÿåº¦è¯„ä¼°æ¼”ç¤º
    print("\n7. æ•°æ®è´¨é‡ç®¡ç†æˆç†Ÿåº¦è¯„ä¼°æ¼”ç¤º")
    print("-" * 30)
    assessment = DataQualityMaturityAssessment()
    dimension_scores = {
        'strategy_and_governance': [2, 3, 2, 3],  # å„é¡¹æŒ‡æ ‡å¾—åˆ†
        'process_and_methodology': [3, 3, 4, 3],
        'technology_and_tools': [2, 2, 3, 3],
        'organization_and_people': [2, 3, 2, 3],
        'data_quality_outcomes': [3, 3, 3, 4]
    }
    
    dimension_assessments = []
    for dimension, scores in dimension_scores.items():
        assess = assessment.assess_dimension(dimension, scores)
        dimension_assessments.append(assess)
    
    overall_assessment = assessment.assess_overall_maturity(dimension_assessments)
    report = assessment.generate_assessment_report(overall_assessment)
    print(report)
    
    print("\n" + "=" * 60)
    print("æ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()