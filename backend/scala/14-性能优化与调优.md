# 第14章：性能优化与调优

## 14.1 性能分析工具

### 14.1.1 JVM性能监控

Scala运行在JVM上，可以使用Java性能分析工具：

```bash
# JVM自带的性能监控工具
# JVisualVM - 图形化性能分析工具
jvisualvm

# JConsole - 监控Java应用程序
jconsole <pid>

# JMap - 内存映射工具
jmap -dump:format=b,file=heap.bin <pid>

# JStack - Java堆栈跟踪工具
jstack -l <pid>

# JStat - JVM统计监控工具
jstat -gc <pid> 1000 10  # 每秒采样一次，共10次
```

### 14.1.2 Scala特有性能分析

```scala
// 使用ScalaMeter进行性能测试
import org.scalameter._

object PerformanceTest extends Bench.ForkedTime {
  // 测试List和Vector的性能差异
  def testListAccess(): Unit = {
    val size = 100000
    val list = (1 to size).toList
    val vector = (1 to size).toVector
    
    // List随机访问
    val listTime = measure {
      for (_ <- 1 to 1000) {
        list(scala.util.Random.nextInt(size))
      }
    }
    
    // Vector随机访问
    val vectorTime = measure {
      for (_ <- 1 to 1000) {
        vector(scala.util.Random.nextInt(size))
      }
    }
    
    println(s"List access time: $listTime")
    println(s"Vector access time: $vectorTime")
  }
}
```

### 14.1.3 内存分析

```scala
// 内存使用分析
object MemoryAnalyzer {
  def measureMemoryUsage[T](block: => T): (T, Long) = {
    val runtime = Runtime.getRuntime
    System.gc()  // 触发垃圾回收
    val before = runtime.totalMemory() - runtime.freeMemory()
    
    val result = block
    
    System.gc()
    val after = runtime.totalMemory() - runtime.freeMemory()
    
    (result, after - before)
  }
  
  def compareCollectionMemory(): Unit = {
    val size = 100000
    
    // List内存使用
    val (_, listMemory) = measureMemoryUsage {
      (1 to size).toList
    }
    
    // Vector内存使用
    val (_, vectorMemory) = measureMemoryUsage {
      (1 to size).toVector
    }
    
    // Array内存使用
    val (_, arrayMemory) = measureMemoryUsage {
      (1 to size).toArray
    }
    
    println(s"List memory usage: ${listMemory / 1024} KB")
    println(s"Vector memory usage: ${vectorMemory / 1024} KB")
    println(s"Array memory usage: ${arrayMemory / 1024} KB")
  }
}
```

## 14.2 集合性能优化

### 14.2.1 集合类型选择

```scala
// 不同集合类型的性能特点

// 1. List - 适合头部操作，不适合随机访问
val list = List(1, 2, 3, 4, 5)
val newList = 0 :: list  // O(1) 时间复杂度
val element = list(2)    // O(n) 时间复杂度

// 2. Vector - 适合随机访问，平衡的结构
val vector = Vector(1, 2, 3, 4, 5)
val newVector = vector :+ 6  // O(log n) 时间复杂度
val element2 = vector(2)     // O(log n) 时间复杂度

// 3. ArrayBuffer - 可变数组，尾部操作快
import scala.collection.mutable.ArrayBuffer
val buffer = ArrayBuffer(1, 2, 3)
buffer += 4  // O(1) 平均时间复杂度
val element3 = buffer(2)  // O(1) 时间复杂度

// 4. HashSet - 快速查找
import scala.collection.mutable.HashSet
val set = HashSet(1, 2, 3)
set += 4  // O(1) 平均时间复杂度
val contains = set.contains(3)  // O(1) 平均时间复杂度
```

### 14.2.2 高效的集合操作

```scala
// 使用适当的方法和转换
object CollectionOptimization {
  // 避免不必要的转换
  def avoidUnnecessaryConversions(strings: Seq[String]): Seq[Int] = {
    // 不好的做法：多次转换
    // strings.toList.map(_.length).toSeq
    
    // 好的做法：保持原始类型
    strings.map(_.length)
  }
  
  // 使用视图避免中间集合
  def processLargeCollection(data: List[Int]): List[Int] = {
    // 不好的做法：创建多个中间集合
    // data.filter(_ > 0)
    //     .map(_ * 2)
    //     .filter(_ < 100)
    
    // 好的做法：使用视图
    data.view
        .filter(_ > 0)
        .map(_ * 2)
        .filter(_ < 100)
        .toList
  }
  
  // 使用并行集合处理大数据
  def parallelProcessing(data: Vector[Int]): Vector[Int] = {
    // 对于大数据集，使用并行集合
    data.par
        .filter(_ > 0)
        .map(_ * 2)
        .seq  // 转回顺序集合
  }
  
  // 使用集合构建器
  def efficientCollectionBuilding(): List[Int] = {
    val builder = List.newBuilder[Int]
    for (i <- 1 to 100000) {
      if (i % 2 == 0) {
        builder += i * i
      }
    }
    builder.result()
  }
}
```

### 14.2.3 集合大小优化

```scala
// 预分配集合大小
object CollectionSizeOptimization {
  // 预分配ArrayBuffer大小
  import scala.collection.mutable.ArrayBuffer
  
  def preallocatedBuffer(): ArrayBuffer[Int] = {
    // 知道最终大小时，预分配
    val buffer = ArrayBuffer[Int](10000)
    
    for (i <- 1 to 10000) {
      buffer += i * i
    }
    
    buffer
  }
  
  // 比较预分配和动态扩容的性能
  def compareAllocation(): Unit = {
    val size = 1000000
    
    // 预分配
    val preallocatedTime = {
      val start = System.nanoTime()
      val buffer = ArrayBuffer[Int](size)
      for (i <- 1 to size) buffer += i
      System.nanoTime() - start
    }
    
    // 动态扩容
    val dynamicTime = {
      val start = System.nanoTime()
      val buffer = ArrayBuffer[Int]()
      for (i <- 1 to size) buffer += i
      System.nanoTime() - start
    }
    
    println(s"Preallocated time: ${preallocatedTime / 1000000} ms")
    println(s"Dynamic allocation time: ${dynamicTime / 1000000} ms")
    println(s"Performance improvement: ${dynamicTime.toDouble / preallocatedTime}x")
  }
}
```

## 14.3 内存管理

### 14.3.1 内存泄漏检测

```scala
// 潜在的内存泄漏示例
object MemoryLeakExamples {
  // 闭包导致内存泄漏
  def closureLeak(): () => Unit = {
    val largeArray = Array.ofDim[Byte](10 * 1024 * 1024) // 10MB
    
    // 闭包持有largeArray的引用
    () => {
      println(s"Large array length: ${largeArray.length}")
    }
  }
  
  // 使用弱引用避免内存泄漏
  import java.lang.ref.WeakReference
  
  def avoidClosureLeak(): () => Unit = {
    val largeArray = Array.ofDim[Byte](10 * 1024 * 1024)
    val weakRef = new WeakReference(largeArray)
    
    () => {
      val array = weakRef.get()
      if (array != null) {
        println(s"Large array length: ${array.length}")
      } else {
        println("Array has been garbage collected")
      }
    }
  }
  
  // 集合持有对象导致内存泄漏
  import scala.collection.mutable
  
  def collectionLeak(): Unit = {
    val cache = mutable.Map[String, Any]()
    
    // 添加大量对象到缓存
    for (i <- 1 to 100000) {
      val largeObject = Array.ofDim[Byte](1024)
      cache(s"key$i") = largeObject
    }
    
    println(s"Cache size: ${cache.size}")
    
    // 手动清理
    cache.clear()
    System.gc()
    println("Cache cleared and garbage collected")
  }
  
  // 使用弱引用集合避免内存泄漏
  import java.util.WeakHashMap
  import scala.jdk.CollectionConverters._
  
  def avoidCollectionLeak(): Unit = {
    val weakCache = new WeakHashMap[String, Array[Byte]]()
    
    // 添加对象到弱引用缓存
    for (i <- 1 to 100000) {
      val largeObject = Array.ofDim[Byte](1024)
      weakCache.put(s"key$i", largeObject)
    }
    
    println(s"Weak cache size: ${weakCache.size()}")
    
    System.gc()
    println(s"Weak cache size after GC: ${weakCache.size()}")
  }
}
```

### 14.3.2 对象池模式

```scala
// 对象池实现
object ObjectPooling {
  import java.util.concurrent.ConcurrentLinkedQueue
  import java.util.concurrent.atomic.AtomicInteger
  
  class ObjectPool[T <: AnyRef](create: () => T, reset: T => Unit = (_: T) => ()) {
    private val pool = new ConcurrentLinkedQueue[T]()
    private val created = new AtomicInteger(0)
    
    def borrow(): T = {
      val obj = pool.poll()
      if (obj != null) obj
      else {
        created.incrementAndGet()
        create()
      }
    }
    
    def returnObject(obj: T): Unit = {
      reset(obj)
      pool.offer(obj)
    }
    
    def size(): Int = pool.size()
    def createdCount(): Int = created.get()
  }
  
  // 使用对象池
  def demonstrateObjectPool(): Unit = {
    // 字节数组池
    val byteArrayPool = new ObjectPool[Array[Byte]](
      () => Array.ofDim[Byte](1024),
      array => java.util.Arrays.fill(array.asInstanceOf[Array[AnyRef]], null)
    )
    
    // 使用池中的对象
    val array1 = byteArrayPool.borrow()
    array1(0) = 1
    println(s"Array first byte: ${array1(0)}")
    
    // 归还对象
    byteArrayPool.returnObject(array1)
    println(s"Pool size: ${byteArrayPool.size()}, Created: ${byteArrayPool.createdCount()}")
    
    // 再次借用
    val array2 = byteArrayPool.borrow()
    println(s"Reused array first byte: ${array2(0)}")
  }
}
```

### 14.3.3 内存高效的数据结构

```scala
// 使用更节省内存的数据结构
object MemoryEfficientStructures {
  // 使用原始类型集合
  import scala.collection.mutable.ArrayBuffer
  
  def primitiveCollections(): Unit = {
    // 使用Array[Int]而不是List[Int]以节省内存
    val primitiveArray = Array.ofDim[Int](1000000)
    
    // 使用Java的原始类型集合
    import java.util.ArrayList
    val javaArrayList = new java.util.ArrayList[Int]()
    
    for (i <- 1 to 1000000) {
      javaArrayList.add(i)
    }
    
    println(s"Primitive array size: ${primitiveArray.length}")
    println(s"Java array list size: ${javaArrayList.size()}")
  }
  
  // 使用更紧凑的集合实现
  import scala.collection.immutable.Vector
  
  def compactCollections(): Unit = {
    // Vector比List更节省内存
    val list = List.range(0, 1000000)
    val vector = Vector.range(0, 1000000)
    
    // 获取内存使用情况
    val runtime = Runtime.getRuntime
    System.gc()
    val before = runtime.totalMemory() - runtime.freeMemory()
    
    val listCopy = list.map(_ * 2)
    
    System.gc()
    val afterList = runtime.totalMemory() - runtime.freeMemory()
    
    System.gc()
    val vectorCopy = vector.map(_ * 2)
    
    System.gc()
    val afterVector = runtime.totalMemory() - runtime.freeMemory()
    
    println(s"List memory usage: ${(afterList - before) / 1024} KB")
    println(s"Vector memory usage: ${(afterVector - before) / 1024} KB")
  }
  
  // 使用flyweight模式减少对象数量
  sealed trait Color {
    def name: String
    def rgb: (Int, Int, Int)
  }
  
  object Color {
    case object Red extends Color {
      val name = "Red"
      val rgb = (255, 0, 0)
    }
    
    case object Green extends Color {
      val name = "Green"
      val rgb = (0, 255, 0)
    }
    
    case object Blue extends Color {
      val name = "Blue"
      val rgb = (0, 0, 255)
    }
    
    def fromString(s: String): Color = s.toLowerCase match {
      case "red" => Red
      case "green" => Green
      case "blue" => Blue
      case _ => throw new IllegalArgumentException(s"Unknown color: $s")
    }
  }
  
  def flyweightPattern(): Unit = {
    // 使用共享的颜色对象而不是每次创建新对象
    val pixels = Array.fill(1000000)(Color.Red)
    println(s"Created ${pixels.length} pixels with shared color objects")
  }
}
```

## 14.4 并发性能优化

### 14.4.1 线程池优化

```scala
// 线程池配置与优化
import java.util.concurrent.{Executors, ThreadPoolExecutor, TimeUnit}
import scala.concurrent.{ExecutionContext, Future, Await}
import scala.concurrent.duration._

object ThreadPoolOptimization {
  // 自定义线程池
  def createOptimizedThreadPool(): ExecutionContext = {
    val corePoolSize = Runtime.getRuntime.availableProcessors()
    val maxPoolSize = corePoolSize * 2
    val keepAliveTime = 60L
    val workQueue = new java.util.concurrent.LinkedBlockingQueue[Runnable](1000)
    
    val threadFactory = new java.util.concurrent.ThreadFactory {
      private val counter = new java.util.concurrent.atomic.AtomicInteger(0)
      
      def newThread(r: Runnable): Thread = {
        val thread = new Thread(r, s"custom-pool-${counter.incrementAndGet()}")
        thread.setDaemon(true)
        thread
      }
    }
    
    val executor = new ThreadPoolExecutor(
      corePoolSize,
      maxPoolSize,
      keepAliveTime,
      TimeUnit.SECONDS,
      workQueue,
      threadFactory,
      new ThreadPoolExecutor.CallerRunsPolicy()
    )
    
    ExecutionContext.fromExecutor(executor)
  }
  
  // 使用自定义线程池执行任务
  def executeTasks(): Unit = {
    implicit val ec = createOptimizedThreadPool()
    
    val tasks = (1 to 100).map { i =>
      Future {
        // 模拟计算密集型任务
        Thread.sleep(100)
        i * i
      }
    }
    
    val results = Future.sequence(tasks)
    
    try {
      val squares = Await.result(results, 15.seconds)
      println(s"Computed ${squares.length} squares")
    } finally {
      ec.shutdown()
    }
  }
  
  // 比较不同线程池配置
  def compareThreadPools(): Unit = {
    val taskCount = 1000
    
    // 固定大小线程池
    val fixedPool = Executors.newFixedThreadPool(8)
    val fixedTime = measureExecutionTime(() => {
      val futures = (1 to taskCount).map(i => 
        scala.concurrent.Future {
          Thread.sleep(1)
          i * i
        }(ExecutionContext.fromExecutor(fixedPool))
      )
      Await.ready(scala.concurrent.Future.sequence(futures)(ExecutionContext.fromExecutor(fixedPool)), 60.seconds)
    })
    fixedPool.shutdown()
    
    // 缓存线程池
    val cachedPool = Executors.newCachedThreadPool()
    val cachedTime = measureExecutionTime(() => {
      val futures = (1 to taskCount).map(i => 
        scala.concurrent.Future {
          Thread.sleep(1)
          i * i
        }(ExecutionContext.fromExecutor(cachedPool))
      )
      Await.ready(scala.concurrent.Future.sequence(futures)(ExecutionContext.fromExecutor(cachedPool)), 60.seconds)
    })
    cachedPool.shutdown()
    
    println(s"Fixed thread pool time: $fixedTime ms")
    println(s"Cached thread pool time: $cachedTime ms")
  }
  
  private def measureExecutionTime(block: () => Unit): Long = {
    val start = System.currentTimeMillis()
    block()
    System.currentTimeMillis() - start
  }
}
```

### 14.4.2 避免锁竞争

```scala
// 减少锁竞争的技术
object LockContentionAvoidance {
  import java.util.concurrent.ConcurrentHashMap
  import java.util.concurrent.atomic.{AtomicLong, AtomicInteger}
  import scala.concurrent.stm._
  
  // 1. 使用无锁数据结构
  def lockFreeDataStructure(): Unit = {
    // 使用ConcurrentHashMap替代同步HashMap
    val concurrentMap = new ConcurrentHashMap[String, AtomicLong]()
    
    // 并发更新
    val futures = (1 to 100).map { i =>
      Future {
        for (j <- 1 to 1000) {
          val key = s"key$j"
          concurrentMap.computeIfAbsent(key, _ => new AtomicLong(0))
                         .incrementAndGet()
        }
      }(ExecutionContext.global)
    }
    
    Await.ready(Future.sequence(futures), 10.seconds)
    println(s"Concurrent map size: ${concurrentMap.size()}")
  }
  
  // 2. 使用STM（软件事务内存）
  def stmExample(): Unit = {
    // 创建事务性引用
    val counter = Ref(0)
    val results = Ref(List.empty[Int])
    
    // 并发事务
    val futures = (1 to 100).map { i =>
      Future {
        atomic { implicit txn =>
          counter.transform(_ + 1)
          results.transform(i :: _)
        }
      }(ExecutionContext.global)
    }
    
    Await.ready(Future.sequence(futures), 10.seconds)
    
    atomic { implicit txn =>
      println(s"Counter value: ${counter()}")
      println(s"Results size: ${results().size}")
    }
  }
  
  // 3. 减小锁的范围
  object FineGrainedLocking {
    private val userLocks = new ConcurrentHashMap[String, Object]()
    
    def updateUser(userId: String, updateFn: String => String): Unit = {
      // 获取用户特定的锁
      val lock = userLocks.computeIfAbsent(userId, _ => new Object())
      
      // 只锁定特定用户的更新
      lock.synchronized {
        val user = getUser(userId)
        val updatedUser = updateFn(user)
        saveUser(userId, updatedUser)
      }
    }
    
    def getUser(userId: String): String = s"User$userId"
    
    def saveUser(userId: String, userData: String): Unit = {
      // 模拟保存用户数据
    }
    
    def concurrentUserUpdates(): Unit = {
      val userIds = (1 to 100).map(_.toString)
      
      val futures = userIds.map { userId =>
        Future {
          updateUser(userId, user => s"${user}_updated")
        }(ExecutionContext.global)
      }
      
      Await.ready(Future.sequence(futures), 10.seconds)
      println("Completed concurrent user updates")
    }
  }
  
  // 4. 读写锁
  import java.util.concurrent.locks.ReentrantReadWriteLock
  
  object ReadWriteLocking {
    private val rwLock = new ReentrantReadWriteLock()
    private var data = Map.empty[String, String]
    
    def readData(key: String): Option[String] = {
      rwLock.readLock().lock()
      try {
        data.get(key)
      } finally {
        rwLock.readLock().unlock()
      }
    }
    
    def writeData(key: String, value: String): Unit = {
      rwLock.writeLock().lock()
      try {
        data = data + (key -> value)
      } finally {
        rwLock.writeLock().unlock()
      }
    }
    
    def demonstrateReadWriteLock(): Unit = {
      // 写入数据
      writeData("key1", "value1")
      writeData("key2", "value2")
      
      // 并发读取
      val readFutures = (1 to 100).map { _ =>
        Future {
          val value1 = readData("key1")
          val value2 = readData("key2")
          (value1, value2)
        }(ExecutionContext.global)
      }
      
      Await.ready(Future.sequence(readFutures), 5.seconds)
      println("Completed concurrent reads")
    }
  }
}
```

### 14.4.3 异步编程优化

```scala
// 异步编程最佳实践
import scala.concurrent.{Future, ExecutionContext, Promise}
import scala.util.{Success, Failure}
import scala.concurrent.duration._

object AsyncOptimization {
  // 1. 避免阻塞操作
  def nonBlockingIO(): Future[String] = {
    val promise = Promise[String]()
    
    // 使用非阻塞IO操作（模拟）
    Future {
      Thread.sleep(1000)  // 模拟IO操作
      promise.success("Result from non-blocking IO")
    }(ExecutionContext.global)
    
    promise.future
  }
  
  // 2. 组合Future而非嵌套
  def avoidNestedFutures(): Future[Int] = {
    // 不好的做法：嵌套Future
    /*
    val future1 = Future { 1 + 2 }
    val futureResult = future1.map { result1 =>
      val future2 = Future { result1 * 3 }
      // 这里会返回Future[Int]而不是Int
      future2
    }
    */
    
    // 好的做法：使用flatMap
    val future1 = Future { 1 + 2 }
    val future2 = future1.flatMap { result1 =>
      Future { result1 * 3 }
    }
    
    future2
  }
  
  // 3. 批量操作
  def batchOperation(items: List[Int]): Future[List[Int]] = {
    // 不好：为每个项目创建一个Future
    // val futures = items.map(item => Future { item * 2 })
    // Future.sequence(futures)
    
    // 好：使用单个Future处理所有项目
    Future {
      items.map(item => item * 2)
    }(ExecutionContext.global)
  }
  
  // 4. 错误处理
  def errorHandling(): Future[Int] = {
    val future = Future {
      // 可能失败的操作
      if (scala.util.Random.nextDouble() < 0.5) {
        42
      } else {
        throw new RuntimeException("Random failure")
      }
    }(ExecutionContext.global)
    
    // 使用recover处理错误
    future.recover {
      case ex: RuntimeException => {
        println(s"Caught exception: ${ex.getMessage}")
        0  // 默认值
      }
    }
  }
  
  // 5. 超时控制
  def timeoutControl(): Future[String] = {
    val operation = Future {
      Thread.sleep(2000)  // 模拟长时间操作
      "Operation result"
    }(ExecutionContext.global)
    
    // 设置超时
    operation.recoverWith {
      case _: java.util.concurrent.TimeoutException =>
        Future.successful("Timeout occurred")
    }(ExecutionContext.global)
  }
  
  // 6. 资源管理
  def resourceManagement(): Future[String] = {
    val resource = new Resource()
    
    val operation = Future {
      resource.performOperation()
    }(ExecutionContext.global)
    
    // 确保资源被释放
    operation.andThen { _ =>
      resource.cleanup()
    }
  }
  
  // 模拟资源类
  class Resource {
    def performOperation(): String = {
      "Operation result"
    }
    
    def cleanup(): Unit = {
      println("Resource cleaned up")
    }
  }
}
```

## 14.5 JVM调优

### 14.5.1 垃圾收集优化

```bash
# 针对不同应用场景的JVM参数配置

# 1. 低延迟应用
java -Xms2g -Xmx2g \
     -XX:+UseG1GC \
     -XX:MaxGCPauseMillis=200 \
     -XX:G1HeapRegionSize=16m \
     -XX:InitiatingHeapOccupancyPercent=35 \
     -XX:+ParallelRefProcEnabled \
     YourScalaApp

# 2. 高吞吐量应用
java -Xms4g -Xmx4g \
     -XX:+UseParallelGC \
     -XX:ParallelGCThreads=4 \
     -XX:MaxGCPauseMillis=1000 \
     YourScalaApp

# 3. 大内存应用
java -Xms8g -Xmx8g \
     -XX:+UseG1GC \
     -XX:MaxGCPauseMillis=500 \
     -XX:G1HeapRegionSize=32m \
     -XX:InitiatingHeapOccupancyPercent=30 \
     YourScalaApp
```

### 14.5.2 内存参数调整

```scala
// 内存使用监控与调优
object JVMMemoryTuning {
  def printMemoryUsage(): Unit = {
    val runtime = Runtime.getRuntime
    val totalMemory = runtime.totalMemory()
    val freeMemory = runtime.freeMemory()
    val usedMemory = totalMemory - freeMemory
    val maxMemory = runtime.maxMemory()
    
    println(s"Max memory: ${maxMemory / (1024 * 1024)} MB")
    println(s"Total memory: ${totalMemory / (1024 * 1024)} MB")
    println(s"Used memory: ${usedMemory / (1024 * 1024)} MB")
    println(s"Free memory: ${freeMemory / (1024 * 1024)} MB")
    println(s"Memory usage: ${(usedMemory.toDouble / maxMemory) * 100}%")
  }
  
  def testMemoryUsage(): Unit = {
    println("=== Before allocation ===")
    printMemoryUsage()
    
    // 分配大量内存
    val arrays = Array.fill(100)(Array.ofDim[Byte](1024 * 1024)) // 100MB
    
    println("=== After allocation ===")
    printMemoryUsage()
    
    // 释放引用
    for (i <- arrays.indices) {
      arrays(i) = null
    }
    
    System.gc()
    println("=== After GC ===")
    printMemoryUsage()
  }
}
```

### 14.5.3 JIT编译优化

```scala
// JIT编译器优化示例
object JITOptimization {
  // 1. 热点方法
  def hotspotMethod(): Unit = {
    var sum = 0L
    val start = System.nanoTime()
    
    // 大量重复调用，触发JIT编译
    for (i <- 1 to 100000000) {
      sum += i
    }
    
    val end = System.nanoTime()
    println(s"Sum: $sum, Time: ${(end - start) / 1000000} ms")
  }
  
  // 2. 内联优化
  @inline
  def addInline(a: Int, b: Int): Int = a + b
  
  def testInlining(): Unit = {
    var sum = 0
    val start = System.nanoTime()
    
    // 内联函数会被JIT优化
    for (i <- 1 to 100000000) {
      sum = addInline(sum, i)
    }
    
    val end = System.nanoTime()
    println(s"Sum: $sum, Time with inline: ${(end - start) / 1000000} ms")
  }
  
  // 3. 逃逸分析
  def escapeAnalysis(): Unit = {
    // 创建不逃逸的对象，JIT可能会在栈上分配
    def calculateSum(n: Int): Long = {
      var sum = 0L
      for (i <- 1 to n) {
        // 局部对象，不会逃逸
        val localObj = new Object()
        sum += i
      }
      sum
    }
    
    val start = System.nanoTime()
    val sum = calculateSum(100000000)
    val end = System.nanoTime()
    
    println(s"Sum: $sum, Time with escape analysis: ${(end - start) / 1000000} ms")
  }
}
```

## 14.6 性能优化案例分析

### 14.6.1 大数据处理优化

```scala
// 大数据处理性能优化
object BigDataOptimization {
  // 1. 使用合适的数据结构
  def processLargeData(): Unit = {
    // 不好的做法：使用List处理大数据
    // val numbers = (1 to 10000000).toList
    // val result = numbers.filter(_ % 2 == 0).map(_ * 2).filter(_ < 100)
    
    // 好的做法：使用Vector
    val numbers = Vector.range(1, 10000001)
    val result = numbers.filter(_ % 2 == 0).map(_ * 2).filter(_ < 100)
    
    println(s"Processed ${numbers.length} numbers, got ${result.length} results")
  }
  
  // 2. 批处理优化
  def batchProcessing(data: Vector[Int]): Vector[Int] = {
    // 使用视图进行批处理，避免中间集合
    data.view
      .filter(_ % 2 == 0)
      .map(_ * 2)
      .filter(_ < 100)
      .toVector
  }
  
  // 3. 并行处理
  def parallelProcessing(data: Vector[Int]): Vector[Int] = {
    // 对于大数据集，使用并行集合
    data.par
      .filter(_ % 2 == 0)
      .map(_ * 2)
      .filter(_ < 100)
      .toVector
  }
  
  // 4. 内存映射文件处理
  def memoryMappedFile(): Unit = {
    import java.nio.{ByteBuffer, MappedByteBuffer}
    import java.nio.channels.FileChannel
    import java.nio.file.{Paths, StandardOpenOption}
    
    // 创建大文件
    val path = Paths.get("large_file.dat")
    val file = FileChannel.open(path, 
      StandardOpenOption.READ, 
      StandardOpenOption.WRITE,
      StandardOpenOption.CREATE)
    
    // 内存映射文件
    val buffer: MappedByteBuffer = file.map(
      FileChannel.MapMode.READ_WRITE, 
      0, 
      1024 * 1024 * 100  // 100MB
    )
    
    // 处理内存映射文件
    var sum = 0L
    for (i <- 0 until buffer.limit() / 4) {
      sum += buffer.getInt(i * 4)
    }
    
    println(s"Sum of mapped file: $sum")
    file.close()
  }
}
```

### 14.6.2 Web服务优化

```scala
// Web服务性能优化
object WebServiceOptimization {
  import scala.concurrent.Future
  import scala.concurrent.ExecutionContext
  
  // 1. 连接池优化
  import java.sql.{Connection, DriverManager}
  import javax.sql.DataSource
  import com.zaxxer.hikari.{HikariConfig, HikariDataSource}
  
  def createOptimizedDataSource(): DataSource = {
    val config = new HikariConfig()
    config.setJdbcUrl("jdbc:mysql://localhost:3306/mydb")
    config.setUsername("user")
    config.setPassword("password")
    config.setMaximumPoolSize(20)
    config.setMinimumIdle(5)
    config.setConnectionTimeout(30000)
    config.setIdleTimeout(600000)
    config.setMaxLifetime(1800000)
    
    new HikariDataSource(config)
  }
  
  // 2. 缓存优化
  import scala.collection.concurrent.TrieMap
  
  object CacheManager {
    private val cache = TrieMap.empty[String, (Long, Any)]
    private val ttl = 60 * 1000  // 60秒TTL
    
    def get(key: String): Option[Any] = {
      cache.get(key).filter {
        case (timestamp, _) => (System.currentTimeMillis() - timestamp) < ttl
      }.map(_._2)
    }
    
    def put(key: String, value: Any): Unit = {
      cache.put(key, (System.currentTimeMillis(), value))
    }
  }
  
  // 3. 异步数据库操作
  def asyncDatabaseOperation(query: String)(implicit ec: ExecutionContext): Future[Seq[Map[String, Any]]] = {
    Future {
      // 模拟数据库查询
      Thread.sleep(100)
      List(Map("id" -> 1, "name" -> "John"), Map("id" -> 2, "name" -> "Jane"))
    }
  }
  
  // 4. 请求合并
  import scala.collection.mutable
  import java.util.concurrent.{ScheduledThreadPoolExecutor, TimeUnit}
  
  object RequestBatcher {
    private val batchSize = 50
    private val batchTimeout = 10  // 毫秒
    private val pendingRequests = mutable.Queue[(String, Promise[Seq[Map[String, Any]]])]()
    private val executor = new ScheduledThreadPoolExecutor(1)
    
    def execute(query: String): Future[Seq[Map[String, Any]]] = {
      val promise = Promise[Seq[Map[String, Any]]]()
      pendingRequests.enqueue((query, promise))
      
      if (pendingRequests.size >= batchSize) {
        processBatch()
      } else if (pendingRequests.size == 1) {
        executor.schedule(new Runnable {
          def run(): Unit = processBatch()
        }, batchTimeout, TimeUnit.MILLISECONDS)
      }
      
      promise.future
    }
    
    private def processBatch(): Unit = {
      if (pendingRequests.nonEmpty) {
        val batch = mutable.ListBuffer.empty[(String, Promise[Seq[Map[String, Any]]])]
        while (pendingRequests.nonEmpty && batch.size < batchSize) {
          batch += pendingRequests.dequeue()
        }
        
        // 批量处理请求
        Future {
          // 模拟批量处理
          Thread.sleep(10)
          batch.foreach { case (_, promise) =>
            promise.success(List(Map("id" -> 1, "name" -> "BatchResult")))
          }
        }(ExecutionContext.global)
      }
    }
  }
  
  // 5. 响应压缩
  import java.io.{ByteArrayInputStream, ByteArrayOutputStream}
  import java.util.zip.{GZIPInputStream, GZIPOutputStream}
  
  def compressResponse(data: String): Array[Byte] = {
    val bos = new ByteArrayOutputStream()
    val gzos = new GZIPOutputStream(bos)
    
    gzos.write(data.getBytes("UTF-8"))
    gzos.close()
    
    bos.toByteArray
  }
  
  def decompressRequest(data: Array[Byte]): String = {
    val bis = new ByteArrayInputStream(data)
    val gzis = new GZIPInputStream(bis)
    val reader = new java.io.InputStreamReader(gzis, "UTF-8")
    
    val result = new StringBuilder()
    val buffer = new Array[Char](1024)
    var read = reader.read(buffer)
    
    while (read != -1) {
      result.appendAll(buffer, 0, read)
      read = reader.read(buffer)
    }
    
    reader.close()
    result.toString()
  }
}
```

## 14.7 性能测试与基准

### 14.7.1 微基准测试

```scala
// 使用JMH进行微基准测试
import org.openjdk.jmh.annotations._

@State(Scope.Thread)
@BenchmarkMode(Array(Mode.AverageTime))
@OutputTimeUnit(java.util.concurrent.TimeUnit.NANOSECONDS)
class ScalaBenchmark {
  
  @Param(Array("10", "100", "1000"))
  var size: Int = _
  
  var list: List[Int] = _
  var vector: Vector[Int] = _
  
  @Setup
  def setup(): Unit = {
    list = (1 to size).toList
    vector = (1 to size).toVector
  }
  
  @Benchmark
  def listHeadAccess(): Int = list.head
  
  @Benchmark
  def vectorHeadAccess(): Int = vector.head
  
  @Benchmark
  def listLastAccess(): Int = list.last
  
  @Benchmark
  def vectorLastAccess(): Int = vector.last
  
  @Benchmark
  def listRandomAccess(): Int = list(scala.util.Random.nextInt(size))
  
  @Benchmark
  def vectorRandomAccess(): Int = vector(scala.util.Random.nextInt(size))
  
  @Benchmark
  def listPrepend(): List[Int] = 0 :: list
  
  @Benchmark
  def vectorPrepend(): Vector[Int] = 0 +: vector
  
  @Benchmark
  def listAppend(): List[Int] = list :+ 0
  
  @Benchmark
  def vectorAppend(): Vector[Int] = vector :+ 0
}
```

### 14.7.2 性能测试最佳实践

```scala
// 性能测试工具与最佳实践
object PerformanceTesting {
  import java.util.concurrent.TimeUnit
  
  // 1. JVM预热
  def warmup(): Unit = {
    println("JVM warmup...")
    for (i <- 1 to 10000) {
      var sum = 0
      for (j <- 1 to 1000) {
        sum += j
      }
    }
    System.gc()
    println("Warmup completed")
  }
  
  // 2. 性能测量
  def measureTime[T](name: String, iterations: Int = 1000)(block: => T): Unit = {
    warmup()
    
    val totalTime = {
      var sum = 0L
      for (i <- 1 to iterations) {
        val start = System.nanoTime()
        block
        val end = System.nanoTime()
        sum += (end - start)
      }
      sum
    }
    
    val avgTime = totalTime / iterations
    println(s"$name: average time = ${TimeUnit.NANOSECONDS.toMicros(avgTime)} μs")
  }
  
  // 3. 内存测量
  def measureMemory[T](name: String, iterations: Int = 10)(block: => T): Unit = {
    warmup()
    
    val runtime = Runtime.getRuntime
    System.gc()
    val before = runtime.totalMemory() - runtime.freeMemory()
    
    for (i <- 1 to iterations) {
      block
    }
    
    System.gc()
    val after = runtime.totalMemory() - runtime.freeMemory()
    
    val memoryUsage = (after - before) / iterations
    println(s"$name: average memory usage = ${memoryUsage / 1024} KB")
  }
  
  // 4. 吞吐量测量
  def measureThroughput[T](name: String, durationMs: Long = 5000)(block: => T): Unit = {
    warmup()
    
    val startTime = System.currentTimeMillis()
    val endTime = startTime + durationMs
    var count = 0
    
    while (System.currentTimeMillis() < endTime) {
      block
      count += 1
    }
    
    val actualDuration = System.currentTimeMillis() - startTime
    val throughput = (count.toDouble / actualDuration) * 1000
    
    println(s"$name: throughput = ${throughput.formatted("%.2f")} ops/sec")
  }
  
  // 5. 集合性能比较
  def compareCollections(): Unit = {
    val size = 100000
    
    println("=== List vs Vector performance comparison ===")
    
    // 创建性能
    measureTime("List creation") {
      (1 to size).toList
    }
    
    measureTime("Vector creation") {
      (1 to size).toVector
    }
    
    // 随机访问性能
    val list = (1 to size).toList
    val vector = (1 to size).toVector
    
    measureTime("List random access") {
      list(scala.util.Random.nextInt(size))
    }
    
    measureTime("Vector random access") {
      vector(scala.util.Random.nextInt(size))
    }
    
    // 头部添加性能
    measureTime("List prepend") {
      0 :: list
    }
    
    measureTime("Vector prepend") {
      0 +: vector
    }
    
    // 尾部添加性能
    measureTime("List append") {
      list :+ 0
    }
    
    measureTime("Vector append") {
      vector :+ 0
    }
  }
  
  // 6. 并行性能比较
  def compareSequentialVsParallel(): Unit = {
    val size = 1000000
    val data = (1 to size).toVector
    
    println("=== Sequential vs Parallel performance comparison ===")
    
    // 顺序处理
    measureTime("Sequential filter") {
      data.filter(_ % 2 == 0)
    }
    
    measureTime("Sequential map") {
      data.map(_ * 2)
    }
    
    measureTime("Sequential reduce") {
      data.reduce(_ + _)
    }
    
    // 并行处理
    measureTime("Parallel filter") {
      data.par.filter(_ % 2 == 0)
    }
    
    measureTime("Parallel map") {
      data.par.map(_ * 2)
    }
    
    measureTime("Parallel reduce") {
      data.par.reduce(_ + _)
    }
  }
}
```

本章详细介绍了Scala性能优化与调优的各个方面，包括性能分析工具、集合性能优化、内存管理、并发性能优化、JVM调优以及性能测试与基准。通过这些技术，可以显著提高Scala应用程序的性能，满足不同场景下的性能需求。在实际开发中，需要根据具体应用场景选择合适的优化策略，并通过性能测试验证优化效果。