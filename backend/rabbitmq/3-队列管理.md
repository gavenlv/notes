# 第3章：队列管理

## 1. 队列概述

### 1.1 什么是队列

在RabbitMQ中，队列(Queue)是消息的容器，它存储从交换机路由过来的消息，直到消费者从队列中取出这些消息。队列是RabbitMQ中消息存储和传输的基本单位，充当消息的缓冲区。

### 1.2 队列的基本特性

队列具有以下基本特性：

- **FIFO（先进先出）**：消息按照它们进入队列的顺序被消费者取出
- **持久性**：队列可以配置为持久化，即使RabbitMQ服务器重启也不会丢失
- **独占性**：队列可以配置为独占，只能被声明它的连接使用
- **自动删除**：队列可以配置为在最后一个消费者断开连接后自动删除

### 1.3 队列的核心组件

队列由以下核心组件组成：

- **名称**：队列的唯一标识符
- **属性**：控制队列行为的配置参数
- **消息**：存储在队列中的消息集合
- **消费者**：从队列中获取消息的应用程序
- **绑定**：队列与交换机之间的关联关系

## 2. 队列属性详解

### 2.1 基本队列属性

```python
# Python示例：声明队列时的基本属性
channel.queue_declare(
    queue='queue_name',        # 队列名称
    durable=True,              # 持久化，True表示队列会在服务器重启后仍然存在
    exclusive=False,           # 独占队列，True表示只能被声明它的连接使用
    auto_delete=False,         # 自动删除，True表示在最后一个消费者断开后删除队列
    arguments=None             # 其他参数，如TTL、消息TTL、最大长度等
)
```

#### 2.1.1 持久性（Durable）

持久性决定了队列是否在RabbitMQ服务器重启后仍然存在：

```python
# 持久化队列 - 服务器重启后仍然存在
channel.queue_declare(
    queue='durable_queue',
    durable=True    # 持久化队列
)

# 非持久化队列 - 服务器重启后会消失
channel.queue_declare(
    queue='transient_queue',
    durable=False   # 非持久化队列
)
```

**使用场景**：
- **持久化队列**：用于存储重要的业务数据，如订单、交易记录等
- **非持久化队列**：用于临时数据或可重发数据，如日志、统计数据等

#### 2.1.2 独占性（Exclusive）

独占队列只能被声明它的连接使用，当连接关闭时队列会被自动删除：

```python
# 独占队列
channel.queue_declare(
    queue='exclusive_queue',
    exclusive=True   # 独占队列
)
```

**使用场景**：
- **临时处理**：用于特定连接的临时数据处理
- **点对点通信**：实现一对一的通信模式
- **资源隔离**：确保队列不会被其他连接意外访问

#### 2.1.3 自动删除（Auto-delete）

自动删除队列在最后一个消费者断开连接后会被自动删除：

```python
# 自动删除队列
channel.queue_declare(
    queue='auto_delete_queue',
    auto_delete=True   # 自动删除队列
)
```

**使用场景**：
- **临时任务队列**：用于短期存在的任务处理
- **动态资源管理**：根据实际需求动态创建和销毁队列
- **资源清理**：避免手动清理不再使用的队列

### 2.2 高级队列属性

#### 2.2.1 消息TTL（Time-To-Live）

消息TTL指定消息在队列中的存活时间，超过时间后消息会被自动删除：

```python
# 设置消息TTL为10分钟（60000毫秒）
channel.queue_declare(
    queue='ttl_queue',
    arguments={
        'x-message-ttl': 60000  # 消息TTL，单位毫秒
    }
)

# 设置消息TTL为24小时（86400000毫秒）
channel.queue_declare(
    queue='daily_queue',
    arguments={
        'x-message-ttl': 86400000  # 24小时TTL
    }
)
```

#### 2.2.2 队列TTL（Queue TTL）

队列TTL指定队列在不活跃状态下的存活时间，超过时间后队列会被自动删除：

```python
# 设置队列TTL为30分钟（1800000毫秒）
channel.queue_declare(
    queue='queue_ttl',
    arguments={
        'x-expires': 1800000  # 队列TTL，单位毫秒
    }
)
```

#### 2.2.3 队列最大长度

队列最大长度限制了队列中可以存储的消息数量：

```python
# 设置队列最大长度为1000条消息
channel.queue_declare(
    queue='length_limited_queue',
    arguments={
        'x-max-length': 1000  # 最大消息数量
    }
)

# 设置队列最大长度为10000条消息，并指定溢出行为
channel.queue_declare(
    queue='overflow_queue',
    arguments={
        'x-max-length': 10000,
        'x-overflow': 'drop-head'  # 溢出行为：删除队列头部消息
    }
)
```

溢出行为选项：
- `drop-head`：删除队列头部消息（默认行为）
- `reject-publish`：拒绝新消息
- `reject-publish-dlx`：将拒绝的消息发送到死信交换机

#### 2.2.4 队列大小限制

队列大小限制了队列中可以存储的消息总大小（以字节为单位）：

```python
# 设置队列最大大小为100MB
channel.queue_declare(
    queue='size_limited_queue',
    arguments={
        'x-max-length-bytes': 100 * 1024 * 1024  # 100MB
    }
)
```

#### 2.2.5 死信交换机（Dead Letter Exchange）

死信交换机处理无法被正常消费的消息：

```python
# 声明死信交换机和队列
channel.exchange_declare(exchange='dlx_exchange', exchange_type='direct')
channel.queue_declare(queue='dlx_queue')

# 绑定死信队列到死信交换机
channel.queue_bind(exchange='dlx_exchange', queue='dlx_queue', routing_key='dlx_routing_key')

# 声明主队列并配置死信交换机
channel.queue_declare(
    queue='main_queue',
    arguments={
        'x-dead-letter-exchange': 'dlx_exchange',      # 死信交换机名称
        'x-dead-letter-routing-key': 'dlx_routing_key' # 死信路由键
    }
)
```

死信情况包括：
- 消息被消费者拒绝（basic_reject或basic_nack）且requeue=false
- 消息TTL过期
- 队列达到最大长度限制

#### 2.2.6 优先级队列

优先级队列支持消息的优先级处理：

```python
# 声明优先级队列，支持0-10的优先级
channel.queue_declare(
    queue='priority_queue',
    arguments={
        'x-max-priority': 10  # 最大优先级
    }
)

# 发送带优先级的消息
channel.basic_publish(
    exchange='',
    routing_key='priority_queue',
    body='High priority message',
    properties=pika.BasicProperties(
        priority=5  # 消息优先级
    )
)
```

## 3. 队列类型与特殊队列

### 3.1 经典队列（Classic Queue）

经典队列是RabbitMQ的传统队列类型，适用于大多数场景：

```python
# 声明经典队列（默认类型）
channel.queue_declare(queue='classic_queue')

# 显式声明经典队列
channel.queue_declare(
    queue='explicit_classic_queue',
    arguments={'x-queue-type': 'classic'}
)
```

**特点**：
- 成熟稳定
- 支持所有RabbitMQ功能
- 适用于大多数应用场景

### 3.2 仲裁队列（Quorum Queue）

仲裁队列是基于Raft协议的高可用队列，提供强一致性和故障恢复能力：

```python
# 声明仲裁队列
channel.queue_declare(
    queue='quorum_queue',
    arguments={
        'x-queue-type': 'quorum'  # 指定为仲裁队列
    }
)

# 声明仲裁队列并设置副本数
channel.queue_declare(
    queue='replicated_quorum_queue',
    arguments={
        'x-queue-type': 'quorum',
        'x-quorum-initial-group-size': 3  # 初始副本数
    }
)
```

**特点**：
- 数据多副本存储
- 强一致性保证
- 故障自动恢复
- 适用于关键业务数据

**适用场景**：
- 订单处理
- 交易记录
- 用户数据
- 关键业务事件

### 3.3 流队列（Stream Queue）

流队列是RabbitMQ 3.9引入的新队列类型，专为高吞吐量的日志和事件流设计：

```python
# 声明流队列
channel.queue_declare(
    queue='stream_queue',
    arguments={
        'x-queue-type': 'stream',
        'x-max-length-bytes': 5 * 1024 * 1024 * 1024  # 5GB
    }
)

# 设置流队列的其他参数
channel.queue_declare(
    queue='advanced_stream_queue',
    arguments={
        'x-queue-type': 'stream',
        'x-max-age': '7d',                                    # 消息保留7天
        'x-stream-max-segment-size-bytes': 500 * 1024 * 1024, # 段大小500MB
        'x-initial-cluster-size': 3                           # 初始集群大小
    }
)
```

**特点**：
- 高吞吐量
- 基于偏移量的消息访问
- 非破坏性消费
- 消息长期保留
- 时间旅行查询

**适用场景**：
- 日志收集
- 事件流处理
- 物联网数据
- 监控指标

### 3.4 惰性队列（Lazy Queue）

惰性队列将消息尽可能存储在磁盘上，减少内存使用：

```python
# 声明惰性队列
channel.queue_declare(
    queue='lazy_queue',
    arguments={
        'x-queue-mode': 'lazy'  # 惰性队列模式
    }
)
```

**特点**：
- 低内存占用
- 适合大消息或长时间存储
- 吞吐量可能略低于普通队列

**适用场景**：
- 大消息存储
- 长时间保留
- 内存受限环境

## 4. 队列生命周期管理

### 4.1 队列创建

队列可以通过多种方式创建：

#### 4.1.1 主动创建

```python
# 主动创建队列
channel.queue_declare(queue='my_queue')
```

#### 4.1.2 被动创建

```python
# 检查队列是否存在，如果不存在则报错
try:
    channel.queue_declare(queue='existing_queue', passive=True)
    print("队列存在")
except pika.exceptions.ChannelClosedByBroker as e:
    if e.reply_code == 404:
        print("队列不存在")
```

#### 4.1.3 自动创建

```python
# 消费时如果队列不存在，RabbitMQ会自动创建队列
channel.basic_consume(
    queue='auto_created_queue',  # 如果队列不存在会被自动创建
    on_message_callback=callback
)
```

### 4.2 队列状态查询

```python
# 查询队列状态
def get_queue_info(channel, queue_name):
    try:
        # 获取队列信息
        method_frame = channel.queue_declare(queue=queue_name, passive=True)
        
        # 获取队列消息数
        message_count = method_frame.method.message_count
        consumer_count = method_frame.method.consumer_count
        
        print(f"队列 '{queue_name}' 状态:")
        print(f"  消息数: {message_count}")
        print(f"  消费者数: {consumer_count}")
        
        return {
            'message_count': message_count,
            'consumer_count': consumer_count
        }
    except pika.exceptions.ChannelClosedByBroker as e:
        if e.reply_code == 404:
            print(f"队列 '{queue_name}' 不存在")
            return None
```

### 4.3 队列清空

```python
# 清空队列中的所有消息
channel.queue_purge(queue='my_queue')
print("队列已清空")
```

### 4.4 队列删除

```python
# 删除队列
channel.queue_delete(queue='my_queue')

# 如果队列为空则删除
channel.queue_delete(queue='my_queue', if_empty=True)

# 如果没有消费者则删除
channel.queue_delete(queue='my_queue', if_unused=True)
```

## 5. 消费者管理

### 5.1 消费者确认机制

#### 5.1.1 自动确认（Auto Ack）

```python
# 自动确认模式（默认）
def callback(ch, method, properties, body):
    print(f"收到消息: {body.decode('utf-8')}")
    # 消息处理完成后自动被确认，无需手动调用basic_ack

channel.basic_consume(
    queue='auto_ack_queue',
    on_message_callback=callback,
    auto_ack=True  # 自动确认
)
```

#### 5.1.2 手动确认（Manual Ack）

```python
# 手动确认模式
def callback(ch, method, properties, body):
    try:
        print(f"处理消息: {body.decode('utf-8')}")
        
        # 模拟消息处理
        process_message(body)
        
        # 处理成功，确认消息
        ch.basic_ack(delivery_tag=method.delivery_tag)
    except Exception as e:
        print(f"处理消息失败: {e}")
        
        # 处理失败，拒绝消息，不重新入队
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)

channel.basic_consume(
    queue='manual_ack_queue',
    on_message_callback=callback,
    auto_ack=False  # 手动确认
)
```

### 5.2 消费者预取（Prefetch）

```python
# 设置消费者预取数量
channel.basic_qos(prefetch_count=10)  # 每个消费者最多预取10条消息

# 设置全局预取（适用于新版本RabbitMQ）
channel.basic_qos(prefetch_count=10, global_qos=True)

# 在消费者中使用预取
def callback(ch, method, properties, body):
    print(f"处理消息: {body.decode('utf-8')}")
    
    # 模拟耗时操作
    time.sleep(1)
    
    # 确认消息
    ch.basic_ack(delivery_tag=method.delivery_tag)

# 设置预取后创建消费者
channel.basic_consume(
    queue='prefetch_queue',
    on_message_callback=callback,
    auto_ack=False
)
```

### 5.3 消费者取消

```python
# 启动消费者
consumer_tag = channel.basic_consume(
    queue='my_queue',
    on_message_callback=callback
)

# 取消消费者
channel.basic_cancel(consumer_tag)

# 停止消费
channel.stop_consuming(consumer_tag)
```

### 5.4 消费者标签（Consumer Tag）

```python
# 使用自定义消费者标签
def callback(ch, method, properties, body):
    print(f"消费者 {method.consumer_tag} 收到消息: {body.decode('utf-8')}")
    ch.basic_ack(delivery_tag=method.delivery_tag)

consumer_tag = channel.basic_consume(
    queue='tagged_queue',
    on_message_callback=callback,
    consumer_tag='my_custom_consumer'  # 自定义消费者标签
)

print(f"启动消费者，标签: {consumer_tag}")
```

## 6. 队列监控与运维

### 6.1 队列状态监控

```python
# 队列状态监控工具
class QueueMonitor:
    def __init__(self, connection):
        self.connection = connection
        self.channel = connection.channel()
    
    def get_queue_stats(self, queue_name):
        """获取队列统计信息"""
        try:
            method_frame = self.channel.queue_declare(queue=queue_name, passive=True)
            
            return {
                'queue': queue_name,
                'message_count': method_frame.method.message_count,
                'consumer_count': method_frame.method.consumer_count
            }
        except pika.exceptions.ChannelClosedByBroker as e:
            if e.reply_code == 404:
                return {'queue': queue_name, 'error': 'Queue not found'}
    
    def monitor_queues(self, queue_names, interval=5, count=10):
        """监控多个队列的状态"""
        for i in range(count):
            print(f"\n=== 监控轮次 {i+1}/{count} ===")
            
            for queue_name in queue_names:
                stats = self.get_queue_stats(queue_name)
                if 'error' in stats:
                    print(f"{queue_name}: {stats['error']}")
                else:
                    print(f"{queue_name}: 消息数={stats['message_count']}, 消费者数={stats['consumer_count']}")
            
            if i < count - 1:  # 不是最后一轮
                time.sleep(interval)
    
    def get_queue_depth_history(self, queue_name, interval=2, duration=30):
        """获取队列深度历史"""
        history = []
        end_time = time.time() + duration
        
        while time.time() < end_time:
            stats = self.get_queue_stats(queue_name)
            if 'error' not in stats:
                history.append({
                    'timestamp': time.time(),
                    'message_count': stats['message_count']
                })
            
            time.sleep(interval)
        
        return history
```

### 6.2 队列性能指标

```python
# 队列性能指标收集
class QueueMetrics:
    def __init__(self, connection):
        self.connection = connection
        self.channel = connection.channel()
    
    def get_queue_metrics(self, queue_name):
        """获取队列性能指标"""
        try:
            # 注意：这些指标需要通过管理API获取，这里只做概念演示
            stats = self.channel.queue_declare(queue=queue_name, passive=True)
            
            # 在实际应用中，需要使用HTTP API获取详细指标
            return {
                'message_count': stats.method.message_count,
                'consumer_count': stats.method.consumer_count,
                'memory_usage': '需要通过API获取',
                'message_rates': {
                    'publish_rate': '需要通过API获取',
                    'deliver_rate': '需要通过API获取',
                    'ack_rate': '需要通过API获取'
                }
            }
        except pika.exceptions.ChannelClosedByBroker as e:
            if e.reply_code == 404:
                return {'error': 'Queue not found'}
    
    def track_queue_performance(self, queue_name, duration=60):
        """跟踪队列性能"""
        print(f"开始跟踪队列 '{queue_name}' 的性能，持续时间: {duration}秒")
        
        start_time = time.time()
        metrics_history = []
        
        while time.time() - start_time < duration:
            metrics = self.get_queue_metrics(queue_name)
            if 'error' not in metrics:
                metrics['timestamp'] = time.time()
                metrics_history.append(metrics)
            
            time.sleep(5)
        
        # 分析性能数据
        if metrics_history:
            message_counts = [m['message_count'] for m in metrics_history]
            consumer_counts = [m['consumer_count'] for m in metrics_history]
            
            analysis = {
                'queue': queue_name,
                'duration': duration,
                'min_messages': min(message_counts),
                'max_messages': max(message_counts),
                'avg_messages': sum(message_counts) / len(message_counts),
                'min_consumers': min(consumer_counts),
                'max_consumers': max(consumer_counts),
                'avg_consumers': sum(consumer_counts) / len(consumer_counts)
            }
            
            return analysis
        
        return None
```

## 7. 队列优化最佳实践

### 7.1 队列设计原则

#### 7.1.1 持久化策略

```python
# 关键业务数据使用持久化队列
channel.queue_declare(
    queue='critical_business_queue',
    durable=True  # 确保数据不丢失
)

# 临时数据使用非持久化队列
channel.queue_declare(
    queue='temporary_logs_queue',
    durable=False  # 减少I/O开销
)
```

#### 7.1.2 消息过期策略

```python
# 设置合理的消息TTL
channel.queue_declare(
    queue='notification_queue',
    arguments={
        'x-message-ttl': 86400000  # 24小时过期，避免消息积压
    }
)

# 重要消息不设置TTL或设置较长时间
channel.queue_declare(
    queue='important_data_queue',
    arguments={
        'x-message-ttl': 604800000  # 7天过期，确保数据可用性
    }
)
```

#### 7.1.3 队列大小限制

```python
# 限制队列大小避免内存溢出
channel.queue_declare(
    queue='size_limited_queue',
    arguments={
        'x-max-length': 10000,  # 最大1万条消息
        'x-max-length-bytes': 100 * 1024 * 1024,  # 最大100MB
        'x-overflow': 'drop-head'  # 丢弃旧消息
    }
)
```

### 7.2 消费者优化

#### 7.2.1 预取设置

```python
# 根据消息处理时间调整预取数量
# 快速处理：大批量预取
channel.basic_qos(prefetch_count=100)  # 快速处理，减少网络往返

# 慢速处理：小批量预取
channel.basic_qos(prefetch_count=1)  # 慢速处理，确保负载均衡

# 中速处理：中等批量预取
channel.basic_qos(prefetch_count=10)  # 中速处理，平衡吞吐量和负载均衡
```

#### 7.2.2 确认策略

```python
# 对于可能失败的处理，使用手动确认
def reliable_callback(ch, method, properties, body):
    try:
        # 处理消息
        process_message(body)
        # 处理成功后确认
        ch.basic_ack(delivery_tag=method.delivery_tag)
    except Exception as e:
        # 处理失败，拒绝消息
        print(f"处理失败: {e}")
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)

channel.basic_consume(
    queue='reliable_queue',
    on_message_callback=reliable_callback,
    auto_ack=False
)

# 对于快速、无状态的处理，可以使用自动确认
def fast_callback(ch, method, properties, body):
    # 快速处理消息
    fast_process(body)
    # 无需手动确认

channel.basic_consume(
    queue='fast_queue',
    on_message_callback=fast_callback,
    auto_ack=True
)
```

### 7.3 队列类型选择

```python
# 根据业务需求选择合适的队列类型

# 1. 普通业务逻辑 - 使用经典队列
channel.queue_declare(
    queue='business_logic_queue',
    durable=True
)

# 2. 关键业务数据 - 使用仲裁队列
channel.queue_declare(
    queue='critical_data_queue',
    durable=True,
    arguments={
        'x-queue-type': 'quorum',
        'x-quorum-initial-group-size': 3
    }
)

# 3. 日志和事件流 - 使用流队列
channel.queue_declare(
    queue='log_stream_queue',
    arguments={
        'x-queue-type': 'stream',
        'x-max-age': '7d'  # 保留7天
    }
)

# 4. 大消息存储 - 使用惰性队列
channel.queue_declare(
    queue='large_message_queue',
    durable=True,
    arguments={
        'x-queue-mode': 'lazy'
    }
)
```

## 8. 队列故障排除

### 8.1 常见问题与解决方案

#### 问题1：消息积压

**症状**：队列中消息数持续增长，消费者无法及时处理

**可能原因**：
- 消费者处理速度慢
- 消费者数量不足
- 消息处理过程中出现异常

**解决方案**：
```python
# 1. 增加消费者数量
for i in range(5):  # 启动5个消费者
    create_consumer()

# 2. 优化消费者性能
#    - 使用更高效的处理逻辑
#    - 增加预取数量（如果处理速度快）
#    - 使用多线程/协程处理

# 3. 实现消息优先级处理
#    先处理重要消息，后处理普通消息

# 4. 设置消息TTL
channel.queue_declare(
    queue='my_queue',
    arguments={
        'x-message-ttl': 3600000  # 1小时过期，防止无限积压
    }
)
```

#### 问题2：消费者消费速度慢

**症状**：消费者处理消息的速度远低于消息生产速度

**可能原因**：
- 消费者处理逻辑复杂
- 网络延迟
- 数据库操作慢
- 外部服务调用延迟

**解决方案**：
```python
# 1. 优化处理逻辑
def optimized_callback(ch, method, properties, body):
    # 避免在回调中执行耗时操作
    message = json.loads(body.decode('utf-8'))
    
    # 将处理逻辑移到后台线程
    threading.Thread(
        target=process_in_background,
        args=(message, ch, method.delivery_tag)
    ).start()
    
    # 立即确认消息
    ch.basic_ack(delivery_tag=method.delivery_tag)

def process_in_background(message, channel, delivery_tag):
    try:
        # 在后台处理消息
        process_message(message)
    except Exception as e:
        print(f"后台处理失败: {e}")

# 2. 调整预取数量
channel.basic_qos(prefetch_count=1)  # 减少预取，避免消费者过载

# 3. 使用异步处理
#    - 使用异步框架如asyncio
#    - 使用消息队列处理机制
```

#### 问题3：消息丢失

**症状**：消息发送成功但消费者未收到

**可能原因**：
- 队列未持久化
- 消息未持久化
- 消费者使用自动确认但处理失败
- 队列被意外删除

**解决方案**：
```python
# 1. 使用持久化队列和消息
channel.queue_declare(queue='durable_queue', durable=True)

channel.basic_publish(
    exchange='',
    routing_key='durable_queue',
    body=message,
    properties=pika.BasicProperties(
        delivery_mode=2  # 持久化消息
    )
)

# 2. 使用手动确认机制
def reliable_callback(ch, method, properties, body):
    try:
        process_message(body)
        ch.basic_ack(delivery_tag=method.delivery_tag)
    except Exception as e:
        print(f"处理失败: {e}")
        ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)

channel.basic_consume(
    queue='reliable_queue',
    on_message_callback=reliable_callback,
    auto_ack=False
)

# 3. 使用发布者确认机制
channel.confirm_delivery()  # 启用发布者确认

# 4. 设置死信交换机处理失败消息
channel.queue_declare(
    queue='main_queue',
    arguments={
        'x-dead-letter-exchange': 'dlx_exchange'
    }
)
```

#### 问题4：内存使用过高

**症状**：RabbitMQ服务器内存使用持续增长

**可能原因**：
- 队列中消息过多
- 未使用惰性队列存储大消息
- 预取数量过高

**解决方案**：
```python
# 1. 使用惰性队列
channel.queue_declare(
    queue='large_message_queue',
    arguments={
        'x-queue-mode': 'lazy'
    }
)

# 2. 设置队列大小限制
channel.queue_declare(
    queue='size_limited_queue',
    arguments={
        'x-max-length': 10000,
        'x-max-length-bytes': 100 * 1024 * 1024,  # 100MB
        'x-overflow': 'drop-head'
    }
)

# 3. 调整预取数量
channel.basic_qos(prefetch_count=10)  # 适中的预取数量

# 4. 设置消息TTL
channel.queue_declare(
    queue='ttl_queue',
    arguments={
        'x-message-ttl': 3600000  # 1小时过期
    }
)
```

### 8.2 诊断工具

```python
# 队列诊断工具
class QueueDiagnostics:
    def __init__(self, connection):
        self.connection = connection
        self.channel = connection.channel()
    
    def diagnose_queue(self, queue_name):
        """诊断队列问题"""
        print(f"诊断队列: {queue_name}")
        
        try:
            # 获取队列信息
            method_frame = self.channel.queue_declare(queue=queue_name, passive=True)
            message_count = method_frame.method.message_count
            consumer_count = method_frame.method.consumer_count
            
            print(f"  消息数: {message_count}")
            print(f"  消费者数: {consumer_count}")
            
            # 诊断建议
            if message_count > 1000:
                print("  警告: 消息积压严重")
                print("    建议: 增加消费者或优化处理逻辑")
            
            if consumer_count == 0:
                print("  警告: 没有活跃的消费者")
                print("    建议: 检查消费者是否正常运行")
            
            # 测试消息发布和消费
            self._test_queue_flow(queue_name)
            
        except pika.exceptions.ChannelClosedByBroker as e:
            if e.reply_code == 404:
                print(f"  错误: 队列 '{queue_name}' 不存在")
    
    def _test_queue_flow(self, queue_name):
        """测试队列消息流"""
        print("  测试消息流...")
        
        test_message = f"诊断测试消息 - {time.time()}"
        
        try:
            # 发送测试消息
            self.channel.basic_publish(
                exchange='',
                routing_key=queue_name,
                body=test_message,
                properties=pika.BasicProperties(
                    delivery_mode=1,  # 非持久化测试消息
                    message_id=str(uuid.uuid4())
                )
            )
            
            # 尝试获取消息
            method, properties, body = self.channel.basic_get(queue=queue_name)
            
            if method and body.decode('utf-8') == test_message:
                print("    消息流测试: 成功")
            else:
                print("    消息流测试: 失败，消息不匹配")
                
                if method:
                    # 将消息放回队列
                    self.channel.basic_nack(method.delivery_tag, requeue=True)
        except Exception as e:
            print(f"    消息流测试: 失败 - {e}")
    
    def check_queue_health(self, queue_name):
        """检查队列健康状态"""
        print(f"检查队列健康: {queue_name}")
        
        try:
            # 获取队列统计信息
            method_frame = self.channel.queue_declare(queue=queue_name, passive=True)
            
            message_count = method_frame.method.message_count
            consumer_count = method_frame.method.consumer_count
            
            # 健康评分
            health_score = 100
            
            # 消息积压扣分
            if message_count > 10000:
                health_score -= 30
            elif message_count > 1000:
                health_score -= 15
            elif message_count > 100:
                health_score -= 5
            
            # 缺少消费者扣分
            if consumer_count == 0:
                health_score -= 40
            elif consumer_count < 3:
                health_score -= 10
            
            # 输出健康状态
            if health_score >= 80:
                print(f"  状态: 健康 ({health_score}/100)")
            elif health_score >= 60:
                print(f"  状态: 警告 ({health_score}/100)")
            else:
                print(f"  状态: 危险 ({health_score}/100)")
            
            return health_score
        except pika.exceptions.ChannelClosedByBroker as e:
            if e.reply_code == 404:
                print("  状态: 队列不存在 (0/100)")
                return 0
```

## 9. 实际应用案例

### 9.1 任务队列系统

```python
# 任务队列系统示例
class TaskQueueSystem:
    def __init__(self, connection):
        self.connection = connection
        self.channel = connection.channel()
        
    def setup_task_queues(self):
        """设置任务队列系统"""
        # 高优先级任务队列
        self.channel.queue_declare(
            queue='high_priority_tasks',
            durable=True,
            arguments={
                'x-max-priority': 10,
                'x-queue-mode': 'lazy'  # 任务可能较大，使用惰性队列
            }
        )
        
        # 普通任务队列
        self.channel.queue_declare(
            queue='normal_tasks',
            durable=True
        )
        
        # 延迟任务队列
        self.channel.exchange_declare(exchange='delayed_exchange', exchange_type='x-delayed-message')
        self.channel.queue_declare(queue='delayed_tasks', durable=True)
        self.channel.queue_bind(exchange='delayed_exchange', queue='delayed_tasks')
        
        # 失败任务队列（死信队列）
        self.channel.exchange_declare(exchange='failed_tasks_exchange', exchange_type='direct')
        self.channel.queue_declare(queue='failed_tasks', durable=True)
        self.channel.queue_bind(exchange='failed_tasks_exchange', queue='failed_tasks')
        
        # 为主队列设置死信交换机
        for queue in ['high_priority_tasks', 'normal_tasks']:
            self.channel.queue_declare(
                queue=queue,
                durable=True,
                arguments={
                    'x-dead-letter-exchange': 'failed_tasks_exchange',
                    'x-message-ttl': 86400000  # 24小时TTL
                }
            )
        
        print("任务队列系统设置完成")
    
    def submit_task(self, task_data, priority='normal', delay=0):
        """提交任务"""
        import json
        
        task_json = json.dumps(task_data)
        
        if priority == 'high':
            queue = 'high_priority_tasks'
            priority_value = 10
        else:
            queue = 'normal_tasks'
            priority_value = 5
        
        properties = pika.BasicProperties(
            delivery_mode=2,  # 持久化
            priority=priority_value
        )
        
        if delay > 0:
            # 使用延迟交换机
            properties.headers = {'x-delay': delay * 1000}  # 毫秒
            self.channel.basic_publish(
                exchange='delayed_exchange',
                routing_key='',
                body=task_json,
                properties=properties
            )
        else:
            # 直接发送到队列
            self.channel.basic_publish(
                exchange='',
                routing_key=queue,
                body=task_json,
                properties=properties
            )
        
        print(f"任务已提交: {task_data.get('task_id', 'unknown')}")
    
    def create_task_worker(self, queue, worker_id=None):
        """创建任务工作者"""
        if worker_id is None:
            worker_id = f"worker_{uuid.uuid4().hex[:8]}"
        
        def task_callback(ch, method, properties, body):
            try:
                import json
                task = json.loads(body.decode('utf-8'))
                
                print(f"[{worker_id}] 开始处理任务: {task.get('task_id', 'unknown')}")
                
                # 模拟任务处理
                process_task(task)
                
                print(f"[{worker_id}] 完成任务: {task.get('task_id', 'unknown')}")
                
                # 确认任务完成
                ch.basic_ack(delivery_tag=method.delivery_tag)
            except Exception as e:
                print(f"[{worker_id}] 任务处理失败: {e}")
                # 拒绝任务，不重新入队（将发送到死信队列）
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=False)
        
        # 设置预取数量
        self.channel.basic_qos(prefetch_count=1)
        
        # 创建消费者
        self.channel.basic_consume(
            queue=queue,
            on_message_callback=task_callback,
            auto_ack=False
        )
        
        # 在单独线程中运行消费者
        consumer = threading.Thread(target=self.channel.start_consuming)
        consumer.daemon = True
        consumer.start()
        
        print(f"任务工作者已启动: {worker_id} (队列: {queue})")
        
        return consumer

def process_task(task):
    """处理任务的实际逻辑"""
    task_type = task.get('type', 'unknown')
    
    if task_type == 'email':
        # 模拟发送邮件
        time.sleep(1)
        print(f"  发送邮件给: {task.get('recipient', 'unknown')}")
    elif task_type == 'report':
        # 模拟生成报告
        time.sleep(3)
        print(f"  生成报告: {task.get('report_name', 'unknown')}")
    else:
        # 通用任务处理
        time.sleep(0.5)
        print(f"  处理通用任务: {task.get('description', 'unknown')}")
```

### 9.2 日志收集系统

```python
# 日志收集系统示例
class LogCollectionSystem:
    def __init__(self, connection):
        self.connection = connection
        self.channel = connection.channel()
    
    def setup_log_system(self):
        """设置日志收集系统"""
        # 创建不同级别的日志交换机
        self.channel.exchange_declare(exchange='log_direct', exchange_type='direct')
        self.channel.exchange_declare(exchange='log_topic', exchange_type='topic')
        
        # 创建日志队列
        log_levels = ['debug', 'info', 'warning', 'error', 'critical']
        for level in log_levels:
            # 按级别分类的队列
            self.channel.queue_declare(
                queue=f'logs.{level}',
                durable=True,
                arguments={
                    'x-message-ttl': 7 * 24 * 3600 * 1000  # 7天过期
                }
            )
            
            # 绑定到直接交换机
            self.channel.queue_bind(
                exchange='log_direct',
                queue=f'logs.{level}',
                routing_key=level
            )
            
            # 绑定到主题交换机
            self.channel.queue_bind(
                exchange='log_topic',
                queue=f'logs.{level}',
                routing_key=f'*.{level}'
            )
        
        # 创建按应用分类的队列
        applications = ['web', 'api', 'database', 'payment']
        for app in applications:
            self.channel.queue_declare(
                queue=f'logs.app.{app}',
                durable=True,
                arguments={
                    'x-message-ttl': 7 * 24 * 3600 * 1000  # 7天过期
                }
            )
            
            # 绑定到主题交换机
            self.channel.queue_bind(
                exchange='log_topic',
                queue=f'logs.app.{app}',
                routing_key=f'{app}.*'
            )
        
        # 创建错误日志的持久化存储（使用仲裁队列）
        self.channel.queue_declare(
            queue='logs.error_archive',
            durable=True,
            arguments={
                'x-queue-type': 'quorum',
                'x-quorum-initial-group-size': 3
            }
        )
        
        # 绑定到主题交换机
        self.channel.queue_bind(
            exchange='log_topic',
            queue='logs.error_archive',
            routing_key='*.error'
        )
        
        # 创建日志流（使用流队列）
        self.channel.queue_declare(
            queue='logs.stream',
            durable=True,
            arguments={
                'x-queue-type': 'stream',
                'x-max-age': '7d'  # 保留7天
            }
        )
        
        # 绑定所有日志到流队列
        for level in log_levels:
            self.channel.queue_bind(
                exchange='log_direct',
                queue='logs.stream',
                routing_key=level
            )
        
        print("日志收集系统设置完成")
    
    def send_log(self, application, level, message, timestamp=None):
        """发送日志消息"""
        import json
        
        if timestamp is None:
            timestamp = int(time.time())
        
        log_data = {
            'application': application,
            'level': level,
            'message': message,
            'timestamp': timestamp
        }
        
        # 发送到直接交换机
        self.channel.basic_publish(
            exchange='log_direct',
            routing_key=level,
            body=json.dumps(log_data),
            properties=pika.BasicProperties(
                delivery_mode=1,  # 日志通常不需要持久化
                timestamp=timestamp
            )
        )
        
        # 发送到主题交换机
        self.channel.basic_publish(
            exchange='log_topic',
            routing_key=f'{application}.{level}',
            body=json.dumps(log_data),
            properties=pika.BasicProperties(
                delivery_mode=1,
                timestamp=timestamp
            )
        )
        
        # 发送到流队列
        self.channel.basic_publish(
            exchange='log_direct',
            routing_key=level,
            body=json.dumps(log_data),
            properties=pika.BasicProperties(
                delivery_mode=1,
                timestamp=timestamp,
                headers={'stream': 'true'}
            )
        )
    
    def create_log_consumer(self, queue_name, callback=None):
        """创建日志消费者"""
        if callback is None:
            def default_callback(ch, method, properties, body):
                import json
                log_data = json.loads(body.decode('utf-8'))
                level = log_data.get('level', 'unknown')
                app = log_data.get('application', 'unknown')
                message = log_data.get('message', '')
                timestamp = log_data.get('timestamp', 0)
                
                formatted_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(timestamp))
                print(f"[{formatted_time}] [{app}] [{level.upper()}] {message}")
                
                ch.basic_ack(delivery_tag=method.delivery_tag)
            
            callback = default_callback
        
        self.channel.basic_consume(
            queue=queue_name,
            on_message_callback=callback,
            auto_ack=False
        )
        
        # 在单独线程中运行消费者
        consumer = threading.Thread(target=self.channel.start_consuming)
        consumer.daemon = True
        consumer.start()
        
        print(f"日志消费者已启动: {queue_name}")
        
        return consumer
```

## 10. 总结

本章详细介绍了RabbitMQ中队列管理的各个方面，包括队列的基本概念、属性设置、不同类型的队列、消费者管理以及监控和优化方法。

### 关键知识点回顾

1. **队列基本属性**：
   - 持久性(durable)：控制队列是否在服务器重启后仍然存在
   - 独占性(exclusive)：限制队列只能被声明它的连接使用
   - 自动删除(auto_delete)：控制队列在最后一个消费者断开后的行为

2. **高级队列属性**：
   - 消息TTL：控制消息在队列中的存活时间
   - 队列TTL：控制队列的存活时间
   - 最大长度：限制队列中的消息数量
   - 死信交换机：处理无法被正常消费的消息
   - 优先级：支持消息的优先级处理

3. **队列类型**：
   - 经典队列：适用于大多数场景
   - 仲裁队列：提供高可用性和强一致性
   - 流队列：专为高吞吐量的日志和事件流设计
   - 惰性队列：减少内存使用，适合大消息存储

4. **消费者管理**：
   - 确认机制：自动确认与手动确认
   - 预取设置：控制消费者预取的消息数量
   - 消费者取消：动态管理消费者生命周期

5. **队列监控与运维**：
   - 状态查询：获取队列的基本信息
   - 性能监控：跟踪队列的吞吐量和资源使用
   - 健康检查：评估队列的健康状况

### 最佳实践

1. **队列设计**：
   - 根据业务需求选择合适的队列类型
   - 设置合理的TTL和大小限制
   - 使用死信交换机处理异常消息

2. **消费者优化**：
   - 根据消息处理时间调整预取数量
   - 使用手动确认确保消息可靠处理
   - 实现合理的错误处理和重试机制

3. **性能优化**：
   - 对于大消息使用惰性队列
   - 设置适当的TTL避免消息积压
   - 监控队列状态及时发现问题

通过本章的学习，您应该能够设计和管理高效的RabbitMQ队列系统，为构建可靠的分布式应用提供坚实的基础。下一章将介绍RabbitMQ中的消息确认与可靠性机制，确保消息在分布式系统中的可靠传递。