# Day 9: ClickHouse ç›‘æ§å’Œè¿ç»´å…¨æ”»ç•¥

## å­¦ä¹ ç›®æ ‡ ğŸ¯
- æŒæ¡ClickHouseç›‘æ§ä½“ç³»è®¾è®¡å’Œå®æ–½
- å­¦ä¼šä½¿ç”¨ç³»ç»Ÿè¡¨è¿›è¡Œæ€§èƒ½ç›‘æ§
- æŒæ¡Prometheus + Grafanaç›‘æ§æ–¹æ¡ˆ
- ç†è§£æ—¥å¿—ç®¡ç†å’Œåˆ†ææŠ€å·§
- å­¦ä¼šé…ç½®å‘Šè­¦å’Œæ•…éšœå¤„ç†
- æŒæ¡è¿ç»´æœ€ä½³å®è·µå’Œè‡ªåŠ¨åŒ–
- äº†è§£å®¹é‡è§„åˆ’å’Œæ€§èƒ½è°ƒä¼˜

## ä¸ºä»€ä¹ˆDay 9å­¦ç›‘æ§å’Œè¿ç»´ï¼Ÿ ğŸ¤”

ç»è¿‡å‰8å¤©çš„å­¦ä¹ ï¼š
- âœ… Day 1-3: ç¯å¢ƒæ­å»ºåˆ°äº‘ç«¯éƒ¨ç½² - åŸºç¡€è®¾æ–½
- âœ… Day 4-6: SQLè¯­æ³•åˆ°æŸ¥è¯¢ä¼˜åŒ– - æ ¸å¿ƒæŠ€èƒ½
- âœ… Day 7-8: æ•°æ®æ“ä½œåˆ°é›†ç¾¤ç®¡ç† - åˆ†å¸ƒå¼èƒ½åŠ›

ç°åœ¨å­¦ä¹ **ç›‘æ§å’Œè¿ç»´**ï¼Œè¿™æ˜¯ClickHouseç”Ÿäº§ç¯å¢ƒç¨³å®šè¿è¡Œçš„å…³é”®ï¼

### å­¦ä¹ è·¯å¾„å›é¡¾
```
åŸºç¡€ç¯‡(1-3) â†’ æŠ€èƒ½ç¯‡(4-6) â†’ è¿›é˜¶ç¯‡(7-8) â†’ è¿ç»´ç¯‡(9-11) â†’ å®æˆ˜ç¯‡(12-14)
```

## çŸ¥è¯†è¦ç‚¹ ğŸ“š

### 1. ClickHouseç›‘æ§ä½“ç³»æ¦‚è§ˆ

#### 1.1 ç›‘æ§å±‚æ¬¡æ¶æ„

```mermaid
graph TB
    subgraph "åº”ç”¨å±‚ç›‘æ§"
        A1[ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§]
        A2[æŸ¥è¯¢æ€§èƒ½ç›‘æ§]
        A3[æ•°æ®è´¨é‡ç›‘æ§]
    end
    
    subgraph "æœåŠ¡å±‚ç›‘æ§"
        B1[ClickHouseæŒ‡æ ‡]
        B2[è¿æ¥æ± ç›‘æ§]
        B3[æŸ¥è¯¢é˜Ÿåˆ—ç›‘æ§]
    end
    
    subgraph "ç³»ç»Ÿå±‚ç›‘æ§"
        C1[CPU/å†…å­˜/ç£ç›˜]
        C2[ç½‘ç»œIOç›‘æ§]
        C3[æ–‡ä»¶ç³»ç»Ÿç›‘æ§]
    end
    
    subgraph "åŸºç¡€è®¾æ–½ç›‘æ§"
        D1[æœåŠ¡å™¨ç¡¬ä»¶]
        D2[ç½‘ç»œè®¾å¤‡]
        D3[å­˜å‚¨ç³»ç»Ÿ]
    end
    
    A1 --> B1
    A2 --> B1
    A3 --> B1
    B1 --> C1
    B2 --> C1
    B3 --> C1
    C1 --> D1
    C2 --> D1
    C3 --> D1
```

#### 1.2 ç›‘æ§æŒ‡æ ‡åˆ†ç±»

| ç›‘æ§ç±»å‹ | å…³é”®æŒ‡æ ‡ | ç›‘æ§é¢‘ç‡ | å‘Šè­¦é˜ˆå€¼ |
|----------|----------|----------|----------|
| **æ€§èƒ½æŒ‡æ ‡** | QPSã€å“åº”æ—¶é—´ã€ååé‡ | 1åˆ†é’Ÿ | æ ¹æ®ä¸šåŠ¡éœ€æ±‚ |
| **èµ„æºæŒ‡æ ‡** | CPUã€å†…å­˜ã€ç£ç›˜ã€ç½‘ç»œ | 30ç§’ | >80%ä½¿ç”¨ç‡ |
| **å¯ç”¨æ€§æŒ‡æ ‡** | æœåŠ¡çŠ¶æ€ã€è¿æ¥æ•°ã€é”™è¯¯ç‡ | 30ç§’ | >5%é”™è¯¯ç‡ |
| **ä¸šåŠ¡æŒ‡æ ‡** | æ•°æ®å»¶è¿Ÿã€æ•°æ®é‡ã€è´¨é‡ | 5åˆ†é’Ÿ | æ ¹æ®SLA |

### 2. ClickHouseç³»ç»Ÿè¡¨ç›‘æ§

#### 2.1 æ ¸å¿ƒç³»ç»Ÿè¡¨

**query_log - æŸ¥è¯¢æ—¥å¿—è¡¨**ï¼š
```sql
-- æŸ¥çœ‹æ…¢æŸ¥è¯¢
SELECT 
    query_start_time,
    query_duration_ms,
    read_rows,
    read_bytes,
    result_rows,
    memory_usage,
    query
FROM system.query_log 
WHERE event_date = today()
  AND type = 'QueryFinish'
  AND query_duration_ms > 10000
ORDER BY query_duration_ms DESC
LIMIT 10;

-- æŸ¥è¯¢é”™è¯¯ç»Ÿè®¡
SELECT 
    toStartOfHour(event_time) as hour,
    count() as error_count,
    uniq(query) as unique_queries,
    groupArray(exception) as errors
FROM system.query_log 
WHERE event_date = today()
  AND type = 'ExceptionWhileProcessing'
GROUP BY hour
ORDER BY hour DESC;
```

**metric_log - æŒ‡æ ‡æ—¥å¿—è¡¨**ï¼š
```sql
-- ç³»ç»Ÿèµ„æºä½¿ç”¨è¶‹åŠ¿
SELECT 
    toStartOfMinute(event_time) as minute,
    avg(CurrentMetric_Query) as avg_queries,
    avg(CurrentMetric_TCPConnection) as avg_connections,
    avg(CurrentMetric_MemoryTracking) as avg_memory
FROM system.metric_log 
WHERE event_date = today()
  AND event_time >= now() - INTERVAL 1 HOUR
GROUP BY minute
ORDER BY minute DESC
LIMIT 60;
```

**parts - æ•°æ®åˆ†åŒºè¡¨**ï¼š
```sql
-- è¡¨å­˜å‚¨åˆ†æ
SELECT 
    database,
    table,
    count() as part_count,
    sum(rows) as total_rows,
    formatReadableSize(sum(data_compressed_bytes)) as compressed_size,
    formatReadableSize(sum(data_uncompressed_bytes)) as uncompressed_size,
    round(avg(compression_ratio), 2) as avg_compression_ratio
FROM system.parts 
WHERE active = 1
GROUP BY database, table
ORDER BY total_rows DESC;

-- åˆ†åŒºå¤§å°åˆ†å¸ƒ
SELECT 
    table,
    partition,
    rows,
    formatReadableSize(data_compressed_bytes) as size,
    compression_ratio,
    modification_time
FROM system.parts 
WHERE database = 'default'
  AND active = 1
ORDER BY data_compressed_bytes DESC
LIMIT 20;
```

#### 2.2 è‡ªå®šä¹‰ç›‘æ§è§†å›¾

```sql
-- åˆ›å»ºæ€§èƒ½ç›‘æ§è§†å›¾
CREATE VIEW performance_overview AS
SELECT 
    toStartOfMinute(event_time) as time_window,
    count() as query_count,
    avg(query_duration_ms) as avg_duration,
    quantile(0.95)(query_duration_ms) as p95_duration,
    sum(read_rows) as total_rows_read,
    sum(read_bytes) as total_bytes_read,
    sum(result_rows) as total_rows_returned
FROM system.query_log 
WHERE type = 'QueryFinish'
  AND event_date >= today() - 7
GROUP BY time_window
ORDER BY time_window DESC;

-- åˆ›å»ºé”™è¯¯ç›‘æ§è§†å›¾
CREATE VIEW error_monitoring AS
SELECT 
    toStartOfHour(event_time) as hour,
    count() as error_count,
    uniq(query) as unique_error_queries,
    groupArray(DISTINCT exception) as error_types,
    groupArray(user) as affected_users
FROM system.query_log 
WHERE type IN ('ExceptionBeforeStart', 'ExceptionWhileProcessing')
  AND event_date >= today() - 7
GROUP BY hour
ORDER BY hour DESC;
```

### 3. Prometheus + Grafanaç›‘æ§æ–¹æ¡ˆ

#### 3.1 Prometheusé…ç½®

**ClickHouse Exporteré…ç½®**ï¼š
```yaml
# clickhouse-exporter.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "clickhouse_rules.yml"

scrape_configs:
  - job_name: 'clickhouse'
    static_configs:
      - targets: ['localhost:8123']
    metrics_path: '/metrics'
    scrape_interval: 30s
    params:
      query: 
        - 'SELECT * FROM system.metrics'
        - 'SELECT * FROM system.events'
        - 'SELECT * FROM system.asynchronous_metrics'

  - job_name: 'clickhouse-query-log'
    static_configs:
      - targets: ['localhost:8123']
    metrics_path: '/query'
    scrape_interval: 60s
    params:
      query: 
        - |
          SELECT 
            'clickhouse_queries_total' as metric,
            toString(count()) as value,
            'type=' || type as labels
          FROM system.query_log 
          WHERE event_time >= now() - INTERVAL 1 MINUTE
          GROUP BY type
```

**å‘Šè­¦è§„åˆ™é…ç½®**ï¼š
```yaml
# clickhouse_rules.yml
groups:
- name: clickhouse
  rules:
  - alert: ClickHouseDown
    expr: up{job="clickhouse"} == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "ClickHouse instance is down"
      description: "ClickHouse {{ $labels.instance }} has been down for more than 1 minute"

  - alert: ClickHouseHighQueryDuration
    expr: clickhouse_query_duration_95percentile > 10000
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "ClickHouse high query duration"
      description: "95th percentile query duration is {{ $value }}ms"

  - alert: ClickHouseHighMemoryUsage
    expr: clickhouse_memory_usage_ratio > 0.9
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "ClickHouse high memory usage"
      description: "Memory usage is {{ $value }}%"

  - alert: ClickHouseHighDiskUsage
    expr: clickhouse_disk_usage_ratio > 0.85
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "ClickHouse high disk usage"
      description: "Disk usage is {{ $value }}%"

  - alert: ClickHouseReplicationLag
    expr: clickhouse_replica_delay_seconds > 300
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "ClickHouse replication lag"
      description: "Replica {{ $labels.replica }} is lagging by {{ $value }} seconds"
```

#### 3.2 Grafanaä»ªè¡¨æ¿

**ä¸»è¦ç›‘æ§é¢æ¿**ï¼š
```json
{
  "dashboard": {
    "title": "ClickHouse ç›‘æ§ä»ªè¡¨æ¿",
    "panels": [
      {
        "title": "æŸ¥è¯¢æ€§èƒ½",
        "type": "graph",
        "targets": [
          {
            "query": "rate(clickhouse_queries_total[5m])",
            "legend": "QPS"
          },
          {
            "query": "clickhouse_query_duration_95percentile",
            "legend": "P95 Duration"
          }
        ]
      },
      {
        "title": "ç³»ç»Ÿèµ„æº",
        "type": "graph", 
        "targets": [
          {
            "query": "clickhouse_cpu_usage_ratio * 100",
            "legend": "CPU %"
          },
          {
            "query": "clickhouse_memory_usage_ratio * 100",
            "legend": "Memory %"
          }
        ]
      },
      {
        "title": "ç£ç›˜IO",
        "type": "graph",
        "targets": [
          {
            "query": "rate(clickhouse_disk_read_bytes[5m])",
            "legend": "Read Bytes/s"
          },
          {
            "query": "rate(clickhouse_disk_write_bytes[5m])",
            "legend": "Write Bytes/s"
          }
        ]
      }
    ]
  }
}
```

### 4. æ—¥å¿—ç®¡ç†å’Œåˆ†æ

#### 4.1 ClickHouseæ—¥å¿—é…ç½®

**æ—¥å¿—çº§åˆ«å’Œè¾“å‡ºé…ç½®**ï¼š
```xml
<!-- config.xml -->
<logger>
    <level>information</level>
    <log>/var/log/clickhouse-server/clickhouse-server.log</log>
    <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
    <size>1000M</size>
    <count>10</count>
    <flush_interval_milliseconds>3000</flush_interval_milliseconds>
</logger>

<!-- æŸ¥è¯¢æ—¥å¿—é…ç½® -->
<query_log>
    <database>system</database>
    <table>query_log</table>
    <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    <max_size_rows>1048576</max_size_rows>
    <reserved_size_rows>8192</reserved_size_rows>
    <buffer_size_rows_flush_threshold>524288</buffer_size_rows_flush_threshold>
</query_log>

<!-- æŒ‡æ ‡æ—¥å¿—é…ç½® -->
<metric_log>
    <database>system</database>
    <table>metric_log</table>
    <flush_interval_milliseconds>7500</flush_interval_milliseconds>
    <collect_interval_milliseconds>1000</collect_interval_milliseconds>
</metric_log>
```

#### 4.2 æ—¥å¿—åˆ†ææŸ¥è¯¢

**é”™è¯¯æ—¥å¿—åˆ†æ**ï¼š
```sql
-- åˆ†æé”™è¯¯æ¨¡å¼
SELECT 
    toStartOfHour(event_time) as hour,
    count() as error_count,
    exception,
    groupArray(DISTINCT user) as affected_users,
    groupArray(DISTINCT initial_address) as source_ips
FROM system.query_log 
WHERE event_date >= today() - 1
  AND type = 'ExceptionWhileProcessing'
  AND exception != ''
GROUP BY hour, exception
ORDER BY hour DESC, error_count DESC;

-- æ…¢æŸ¥è¯¢åˆ†æ
SELECT 
    query_duration_ms,
    read_rows,
    read_bytes,
    memory_usage,
    user,
    initial_address,
    substring(query, 1, 100) as query_preview
FROM system.query_log 
WHERE event_date = today()
  AND type = 'QueryFinish'
  AND query_duration_ms > 30000
ORDER BY query_duration_ms DESC
LIMIT 20;
```

**ç”¨æˆ·è¡Œä¸ºåˆ†æ**ï¼š
```sql
-- ç”¨æˆ·æŸ¥è¯¢ç»Ÿè®¡
SELECT 
    user,
    count() as query_count,
    avg(query_duration_ms) as avg_duration,
    sum(read_rows) as total_rows_read,
    formatReadableSize(sum(read_bytes)) as total_bytes_read,
    count() / (24 * 60) as queries_per_minute
FROM system.query_log 
WHERE event_date = today()
  AND type = 'QueryFinish'
GROUP BY user
ORDER BY query_count DESC;
```

### 5. æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–

#### 5.1 å…³é”®æ€§èƒ½æŒ‡æ ‡(KPIs)

**æŸ¥è¯¢æ€§èƒ½æŒ‡æ ‡**ï¼š
```sql
-- å®æ—¶æŸ¥è¯¢æ€§èƒ½ç»Ÿè®¡
SELECT 
    toStartOfMinute(now()) as current_time,
    count() as current_queries,
    avg(elapsed) as avg_elapsed_time,
    sum(read_rows) as rows_per_second,
    formatReadableSize(sum(read_bytes)) as bytes_per_second
FROM system.processes 
WHERE query != '';

-- å†å²æ€§èƒ½è¶‹åŠ¿
SELECT 
    toStartOfHour(event_time) as hour,
    count() as queries_per_hour,
    avg(query_duration_ms) as avg_duration_ms,
    quantile(0.50)(query_duration_ms) as median_duration,
    quantile(0.95)(query_duration_ms) as p95_duration,
    quantile(0.99)(query_duration_ms) as p99_duration
FROM system.query_log 
WHERE event_date >= today() - 7
  AND type = 'QueryFinish'
GROUP BY hour
ORDER BY hour DESC;
```

**èµ„æºä½¿ç”¨ç›‘æ§**ï¼š
```sql
-- å†…å­˜ä½¿ç”¨ç»Ÿè®¡
SELECT 
    formatReadableSize(total_memory) as total_memory,
    formatReadableSize(free_memory) as free_memory,
    round((total_memory - free_memory) * 100.0 / total_memory, 2) as memory_usage_percent,
    formatReadableSize(MemoryTracking) as query_memory
FROM system.asynchronous_metrics
WHERE metric IN ('MemoryTotal', 'MemoryAvailable', 'MemoryTracking');

-- ç£ç›˜ä½¿ç”¨åˆ†æ
SELECT 
    database,
    formatReadableSize(sum(bytes_on_disk)) as disk_usage,
    sum(rows) as total_rows,
    count() as part_count
FROM system.parts 
WHERE active = 1
GROUP BY database
ORDER BY sum(bytes_on_disk) DESC;
```

#### 5.2 æ€§èƒ½ç“¶é¢ˆè¯†åˆ«

**æŸ¥è¯¢ç“¶é¢ˆåˆ†æ**ï¼š
```sql
-- è¯†åˆ«èµ„æºæ¶ˆè€—æœ€å¤§çš„æŸ¥è¯¢
SELECT 
    normalizeQuery(query) as normalized_query,
    count() as execution_count,
    avg(query_duration_ms) as avg_duration,
    sum(read_rows) as total_rows_read,
    sum(read_bytes) as total_bytes_read,
    avg(memory_usage) as avg_memory_usage
FROM system.query_log 
WHERE event_date >= today() - 1
  AND type = 'QueryFinish'
  AND query_duration_ms > 1000
GROUP BY normalized_query
ORDER BY avg_duration DESC
LIMIT 10;

-- è¡¨è®¿é—®çƒ­åº¦åˆ†æ
SELECT 
    concat(database, '.', table) as full_table_name,
    count() as access_count,
    sum(read_rows) as total_rows_read,
    avg(query_duration_ms) as avg_query_time
FROM (
    SELECT 
        database,
        table,
        read_rows,
        query_duration_ms
    FROM system.query_log 
    ARRAY JOIN tables.database as database, tables.name as table
    WHERE event_date >= today() - 1
      AND type = 'QueryFinish'
) 
GROUP BY full_table_name
ORDER BY access_count DESC
LIMIT 20;
```

### 6. å‘Šè­¦é…ç½®å’Œæ•…éšœå¤„ç†

#### 6.1 å‘Šè­¦é…ç½®ç­–ç•¥

**åˆ†çº§å‘Šè­¦ä½“ç³»**ï¼š

| å‘Šè­¦çº§åˆ« | å“åº”æ—¶é—´ | é€šçŸ¥æ–¹å¼ | å¤„ç†ç­–ç•¥ |
|----------|----------|----------|----------|
| **Critical** | ç«‹å³ | ç”µè¯+çŸ­ä¿¡+é‚®ä»¶ | ç«‹å³å¤„ç† |
| **Warning** | 15åˆ†é’Ÿå†… | çŸ­ä¿¡+é‚®ä»¶ | ä¼˜å…ˆå¤„ç† |
| **Info** | 1å°æ—¶å†… | é‚®ä»¶ | è®¡åˆ’å¤„ç† |

**å‘Šè­¦è§„åˆ™ç¤ºä¾‹**ï¼š
```sql
-- æœåŠ¡å¯ç”¨æ€§å‘Šè­¦
CREATE TABLE alert_rules (
    rule_name String,
    metric_query String,
    threshold Float64,
    operator String,
    severity String,
    description String
) ENGINE = Memory;

INSERT INTO alert_rules VALUES
('service_down', 'SELECT count() FROM system.processes', 0, '=', 'critical', 'ClickHouseæœåŠ¡ä¸å¯ç”¨'),
('high_query_duration', 'SELECT quantile(0.95)(query_duration_ms) FROM system.query_log WHERE event_time >= now() - 300', 10000, '>', 'warning', 'æŸ¥è¯¢å“åº”æ—¶é—´è¿‡é•¿'),
('high_memory_usage', 'SELECT (total_memory - free_memory) / total_memory FROM system.asynchronous_metrics WHERE metric = \'MemoryTotal\'', 0.9, '>', 'warning', 'å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜'),
('replica_lag', 'SELECT max(absolute_delay) FROM system.replicas', 300, '>', 'warning', 'å‰¯æœ¬åŒæ­¥å»¶è¿Ÿ');
```

#### 6.2 è‡ªåŠ¨åŒ–å‘Šè­¦è„šæœ¬

**å‘Šè­¦æ£€æŸ¥è„šæœ¬**ï¼š
```bash
#!/bin/bash
# ClickHouse å‘Šè­¦æ£€æŸ¥è„šæœ¬

CLICKHOUSE_HOST="localhost"
CLICKHOUSE_PORT="8123"
ALERT_WEBHOOK="https://hooks.slack.com/your-webhook"

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
check_service_status() {
    result=$(curl -s "http://$CLICKHOUSE_HOST:$CLICKHOUSE_PORT/" || echo "FAILED")
    if [[ "$result" == "FAILED" ]]; then
        send_alert "CRITICAL" "ClickHouseæœåŠ¡ä¸å¯ç”¨" "$CLICKHOUSE_HOST:$CLICKHOUSE_PORT"
        return 1
    fi
    return 0
}

# æ£€æŸ¥æŸ¥è¯¢æ€§èƒ½
check_query_performance() {
    query="SELECT quantile(0.95)(query_duration_ms) FROM system.query_log WHERE event_time >= now() - INTERVAL 5 MINUTE AND type = 'QueryFinish'"
    result=$(curl -s "http://$CLICKHOUSE_HOST:$CLICKHOUSE_PORT/" -d "query=$query" | head -1)
    
    if (( $(echo "$result > 10000" | bc -l) )); then
        send_alert "WARNING" "æŸ¥è¯¢æ€§èƒ½å‘Šè­¦" "P95å“åº”æ—¶é—´: ${result}ms"
    fi
}

# å‘é€å‘Šè­¦
send_alert() {
    local severity=$1
    local title=$2
    local message=$3
    
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"text\":\"[$severity] $title: $message\"}" \
        $ALERT_WEBHOOK
}

# ä¸»ç¨‹åº
main() {
    echo "$(date): å¼€å§‹ClickHouseå¥åº·æ£€æŸ¥"
    
    if check_service_status; then
        check_query_performance
    fi
    
    echo "$(date): å¥åº·æ£€æŸ¥å®Œæˆ"
}

main "$@"
```

### 7. è¿ç»´æœ€ä½³å®è·µ

#### 7.1 æ—¥å¸¸è¿ç»´æ£€æŸ¥æ¸…å•

**æ¯æ—¥æ£€æŸ¥é¡¹ç›®**ï¼š
- âœ… æœåŠ¡å¯ç”¨æ€§å’Œå“åº”æ—¶é—´
- âœ… æŸ¥è¯¢é”™è¯¯ç‡å’Œæ…¢æŸ¥è¯¢
- âœ… èµ„æºä½¿ç”¨ç‡(CPU/å†…å­˜/ç£ç›˜)
- âœ… å‰¯æœ¬åŒæ­¥çŠ¶æ€
- âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
- âœ… å¤‡ä»½ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€

**æ¯å‘¨æ£€æŸ¥é¡¹ç›®**ï¼š
- âœ… æ€§èƒ½è¶‹åŠ¿åˆ†æ
- âœ… å®¹é‡è§„åˆ’è¯„ä¼°
- âœ… æ—¥å¿—æ–‡ä»¶æ¸…ç†
- âœ… ç³»ç»Ÿæ›´æ–°æ£€æŸ¥
- âœ… ç›‘æ§æŒ‡æ ‡å›é¡¾
- âœ… å‘Šè­¦è§„åˆ™ä¼˜åŒ–

#### 7.2 è‡ªåŠ¨åŒ–è¿ç»´è„šæœ¬

**è‡ªåŠ¨æ¸…ç†è„šæœ¬**ï¼š
```sql
-- æ¸…ç†è¿‡æœŸæ—¥å¿—
ALTER TABLE system.query_log DELETE WHERE event_date < today() - 30;
ALTER TABLE system.metric_log DELETE WHERE event_date < today() - 7;

-- ä¼˜åŒ–è¡¨æ€§èƒ½
OPTIMIZE TABLE system.query_log FINAL;
OPTIMIZE TABLE system.metric_log FINAL;

-- æ¸…ç†ä¸´æ—¶æ–‡ä»¶
SYSTEM DROP FILESYSTEM CACHE;
```

**å¥åº·æ£€æŸ¥æŠ¥å‘Š**ï¼š
```sql
-- ç”Ÿæˆæ¯æ—¥å¥åº·æŠ¥å‘Š
SELECT 
    'ClickHouse å¥åº·æŠ¥å‘Š' as report_title,
    today() as report_date,
    hostName() as server_name,
    version() as version,
    uptime() as uptime_seconds,
    (
        SELECT count() 
        FROM system.query_log 
        WHERE event_date = today() 
          AND type = 'QueryFinish'
    ) as daily_queries,
    (
        SELECT count() 
        FROM system.query_log 
        WHERE event_date = today() 
          AND type = 'ExceptionWhileProcessing'
    ) as daily_errors,
    (
        SELECT formatReadableSize(sum(bytes_on_disk))
        FROM system.parts 
        WHERE active = 1
    ) as total_data_size;
```

## å®è·µç»ƒä¹  ğŸ› ï¸

### ç»ƒä¹ 1ï¼šè®¾ç½®åŸºç¡€ç›‘æ§
1. é…ç½®æŸ¥è¯¢æ—¥å¿—è®°å½•
2. åˆ›å»ºæ€§èƒ½ç›‘æ§è§†å›¾
3. è®¾ç½®åŸºæœ¬å‘Šè­¦è§„åˆ™

### ç»ƒä¹ 2ï¼šPrometheusé›†æˆ
1. å®‰è£…ClickHouse Exporter
2. é…ç½®Prometheusé‡‡é›†
3. åˆ›å»ºGrafanaä»ªè¡¨æ¿

### ç»ƒä¹ 3ï¼šæ•…éšœæ¨¡æ‹Ÿ
1. æ¨¡æ‹Ÿé«˜è´Ÿè½½åœºæ™¯
2. è§¦å‘å‘Šè­¦æœºåˆ¶
3. éªŒè¯æ•…éšœæ¢å¤æµç¨‹

## å¸¸è§é—®é¢˜ â“

### Q1: å¦‚ä½•é€‰æ‹©åˆé€‚çš„ç›‘æ§æŒ‡æ ‡ï¼Ÿ
**A**: ç›‘æ§æŒ‡æ ‡é€‰æ‹©åŸåˆ™ï¼š
- å…³æ³¨ä¸šåŠ¡å…³é”®æŒ‡æ ‡(QPSã€å“åº”æ—¶é—´)
- ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ(CPUã€å†…å­˜ã€ç£ç›˜)
- è·Ÿè¸ªé”™è¯¯ç‡å’Œå¯ç”¨æ€§
- æ ¹æ®å®é™…ä½¿ç”¨åœºæ™¯è°ƒæ•´

### Q2: å‘Šè­¦é¢‘ç‡è¿‡é«˜æ€ä¹ˆåŠï¼Ÿ
**A**: å‘Šè­¦ä¼˜åŒ–ç­–ç•¥ï¼š
- è°ƒæ•´å‘Šè­¦é˜ˆå€¼é¿å…è¯¯æŠ¥
- è®¾ç½®å‘Šè­¦æŠ‘åˆ¶å’Œèšåˆè§„åˆ™
- ä½¿ç”¨è¶‹åŠ¿åˆ†æè€Œéç¬æ—¶å€¼
- å»ºç«‹å‘Šè­¦å‡çº§æœºåˆ¶

### Q3: å¦‚ä½•å¤„ç†å†å²ç›‘æ§æ•°æ®ï¼Ÿ
**A**: æ•°æ®ä¿ç•™ç­–ç•¥ï¼š
- è®¾ç½®åˆç†çš„æ•°æ®ä¿ç•™æœŸé™
- å¯¹å†å²æ•°æ®è¿›è¡Œèšåˆå‹ç¼©
- å®šæœŸæ¸…ç†è¿‡æœŸæ•°æ®
- é‡è¦æ•°æ®é•¿æœŸå½’æ¡£å­˜å‚¨

## ä»Šæ—¥æ€»ç»“ ğŸ“‹

ä»Šå¤©æˆ‘ä»¬å…¨é¢å­¦ä¹ äº†ï¼š
- âœ… ClickHouseç›‘æ§ä½“ç³»è®¾è®¡å’Œå®æ–½
- âœ… ç³»ç»Ÿè¡¨ä½¿ç”¨å’Œæ€§èƒ½åˆ†æ
- âœ… Prometheus + Grafanaç›‘æ§æ–¹æ¡ˆ
- âœ… æ—¥å¿—ç®¡ç†å’Œé”™è¯¯åˆ†æ
- âœ… å‘Šè­¦é…ç½®å’Œæ•…éšœå¤„ç†
- âœ… è¿ç»´æœ€ä½³å®è·µå’Œè‡ªåŠ¨åŒ–

**ä¸‹ä¸€æ­¥**: Day 10 - æ€§èƒ½ä¼˜åŒ–ï¼Œæ·±å…¥å­¦ä¹ ClickHouseæ€§èƒ½è°ƒä¼˜æŠ€å·§

---
*å­¦ä¹ è¿›åº¦: Day 9/14 å®Œæˆ* ğŸ‰ 