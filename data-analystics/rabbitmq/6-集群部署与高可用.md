# ç¬¬6ç« ï¼šé›†ç¾¤éƒ¨ç½²ä¸é«˜å¯ç”¨

## æ¦‚è¿°

RabbitMQé›†ç¾¤æ˜¯å®ç°é«˜å¯ç”¨å’Œå¯æ‰©å±•æ€§çš„å…³é”®ç»„ä»¶ã€‚é€šè¿‡é›†ç¾¤éƒ¨ç½²ï¼Œå¯ä»¥ç¡®ä¿æ¶ˆæ¯ç³»ç»Ÿåœ¨èŠ‚ç‚¹æ•…éšœæ—¶ä»èƒ½ç»§ç»­æœåŠ¡ï¼Œå®ç°è´Ÿè½½å‡è¡¡å’Œæ€§èƒ½æå‡ã€‚æœ¬ç« å°†æ·±å…¥æ¢è®¨RabbitMQé›†ç¾¤çš„æ¶æ„è®¾è®¡ã€éƒ¨ç½²ç­–ç•¥ã€é«˜å¯ç”¨æœºåˆ¶å’Œæ•…éšœæ¢å¤æ–¹æ³•ã€‚

## 6.1 é›†ç¾¤åŸºç¡€æ¶æ„

### 6.1.1 é›†ç¾¤èŠ‚ç‚¹ç±»å‹

#### å†…å­˜èŠ‚ç‚¹ï¼ˆRAM Nodeï¼‰
- **ç‰¹æ€§**ï¼šé˜Ÿåˆ—ã€äº¤æ¢å™¨ã€è·¯ç”±è¡¨ç­‰ä¿¡æ¯å­˜å‚¨åœ¨å†…å­˜ä¸­
- **ä¼˜åŠ¿**ï¼šé«˜æ€§èƒ½ã€é€Ÿåº¦å¿«
- **åŠ£åŠ¿**ï¼šé‡å¯åæ•°æ®ä¸¢å¤±ã€å†…å­˜é™åˆ¶
- **é€‚ç”¨åœºæ™¯**ï¼šé«˜æ€§èƒ½è¦æ±‚çš„éå…³é”®ä»»åŠ¡

#### ç£ç›˜èŠ‚ç‚¹ï¼ˆDisk Nodeï¼‰
- **ç‰¹æ€§**ï¼šæŒä¹…åŒ–å­˜å‚¨é˜Ÿåˆ—ã€äº¤æ¢å™¨ã€ç”¨æˆ·æƒé™ç­‰é…ç½®ä¿¡æ¯
- **ä¼˜åŠ¿**ï¼šæ•°æ®æŒä¹…ã€æ•…éšœæ¢å¤èƒ½åŠ›
- **åŠ£åŠ¿**ï¼šç›¸å¯¹è¾ƒæ…¢çš„I/Oæ€§èƒ½
- **é€‚ç”¨åœºæ™¯**ï¼šé›†ç¾¤é…ç½®èŠ‚ç‚¹ã€æ ¸å¿ƒä¸šåŠ¡

```erlang
% RabbitMQé›†ç¾¤é…ç½®ç¤ºä¾‹
[
  {rabbit, [
    {cluster_nodes, {['rabbit@node1', 'rabbit@node2', 'rabbit@node3'], disc}},
    {default_user, <<"admin">>},
    {default_pass, <<"admin123">>}
  ]}
].
```

### 6.1.2 é›†ç¾¤æ‹“æ‰‘ç»“æ„

#### å¹³é¢æ‹“æ‰‘ï¼ˆFlat Topologyï¼‰
```
Node1 <-> Node2 <-> Node3
```
- æ‰€æœ‰èŠ‚ç‚¹å¯¹ç­‰è¿æ¥
- ç®€å•ã€æ˜“äºç®¡ç†
- é€‚ç”¨äºå°è§„æ¨¡é›†ç¾¤ï¼ˆ3-5èŠ‚ç‚¹ï¼‰

#### åˆ†å±‚æ‹“æ‰‘ï¼ˆHierarchical Topologyï¼‰
```
     Node1(Master)
      /    |    \
   Node2  Node3  Node4
```
- ä¸»ä»ç»“æ„
- ä¸»èŠ‚ç‚¹è´Ÿè´£ä»»åŠ¡åˆ†å‘
- é€‚ç”¨äºå¤§è§„æ¨¡éƒ¨ç½²

#### ç½‘çŠ¶æ‹“æ‰‘ï¼ˆMesh Topologyï¼‰
```
Node1 -- Node2 -- Node3
  |   \   |    /   |
  |    \  |   /    |
Node4 -- Node5 -- Node6
```
- å…¨äº’è¿ç»“æ„
- é«˜å¯ç”¨æ€§ã€é«˜æ€§èƒ½
- é€‚ç”¨äºå¤§è§„æ¨¡é›†ç¾¤

## 6.2 é›†ç¾¤éƒ¨ç½²æ–¹æ³•

### 6.2.1 é™æ€é›†ç¾¤é…ç½®

#### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£…Erlangå’ŒRabbitMQ
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install erlang-base erlang-asn1 erlang-crypto erlang-eldap erlang-ftp erlang-inets erlang-mnesia erlang-os-mon erlang-parsetools erlang-public-key erlang-runtime-tools erlang-snmp erlang-ssl erlang-syntax-tools erlang-tftp erlang-tools erlang-xmerl

# CentOS/RHEL
sudo yum install erlang rabbitmq-server

# å¯åŠ¨RabbitMQæœåŠ¡
sudo systemctl enable rabbitmq-server
sudo systemctl start rabbitmq-server
```

#### 2. èŠ‚ç‚¹é…ç½®

**Node1é…ç½®ï¼ˆä¸»èŠ‚ç‚¹ï¼‰ï¼š**
```bash
# è®¾ç½®hostname
sudo hostnamectl set-hostname rabbitmq-node1

# é…ç½®æ–‡ä»¶ /etc/rabbitmq/rabbitmq-env.conf
RABBITMQ_NODENAME=rabbit@rabbitmq-node1
RABBITMQ_NODE_PORT=5672
RABBITMQ_DIST_PORT=25672

# é…ç½®æ–‡ä»¶ /etc/rabbitmq/rabbitmq.conf
default_user = admin
default_pass = admin123
default_permissions = .*
loopback_users = none
listeners.tcp.default = 5672
cluster_formation.peer_discovery_backend = classic_config
cluster_formation.classic_config.nodes.1 = rabbit@rabbitmq-node1
cluster_formation.classic_config.nodes.2 = rabbit@rabbitmq-node2
cluster_formation.classic_config.nodes.3 = rabbit@rabbitmq-node3
```

**Node2é…ç½®ï¼ˆä»èŠ‚ç‚¹ï¼‰ï¼š**
```bash
# è®¾ç½®hostname
sudo hostnamectl set-hostname rabbitmq-node2

# é…ç½®æ–‡ä»¶ /etc/rabbitmq/rabbitmq-env.conf
RABBITMQ_NODENAME=rabbit@rabbitmq-node2
RABBITMQ_NODE_PORT=5672
RABBITMQ_DIST_PORT=25672

# é…ç½®æ–‡ä»¶ /etc/rabbitmq/rabbitmq.conf
default_user = admin
default_pass = admin123
default_permissions = .*
loopback_users = none
listeners.tcp.default = 5672
cluster_formation.peer_discovery_backend = classic_config
cluster_formation.classic_config.nodes.1 = rabbit@rabbitmq-node1
cluster_formation.classic_config.nodes.2 = rabbit@rabbitmq-node2
cluster_formation.classic_config.nodes.3 = rabbit@rabbitmq-node3
```

**Node3é…ç½®ï¼ˆä»èŠ‚ç‚¹ï¼‰ï¼š**
```bash
# è®¾ç½®hostname
sudo hostnamectl set-hostname rabbitmq-node3

# é…ç½®æ–‡ä»¶ /etc/rabbitmq/rabbitmq-env.conf
RABBITMQ_NODENAME=rabbit@rabbitmq-node3
RABBITMQ_NODE_PORT=5672
RABBITMQ_DIST_PORT=25672

# é…ç½®æ–‡ä»¶ /etc/rabbitmq/rabbitmq.conf
default_user = admin
default_pass = admin123
default_permissions = .*
loopback_users = none
listeners.tcp.default = 5672
cluster_formation.peer_discovery_backend = classic_config
cluster_formation.classic_config.nodes.1 = rabbit@rabbitmq-node1
cluster_formation.classic_config.nodes.2 = rabbit@rabbitmq-node2
cluster_formation.classic_config.nodes.3 = rabbit@rabbitmq-node3
```

#### 3. é›†ç¾¤ç»„è£…

```bash
# åœ¨Node1å¯åŠ¨æœåŠ¡
sudo systemctl start rabbitmq-server

# åœ¨Node2åŠ å…¥é›†ç¾¤
sudo rabbitmqctl join_cluster rabbit@rabbitmq-node1

# åœ¨Node3åŠ å…¥é›†ç¾¤
sudo rabbitmqctl join_cluster rabbit@rabbitmq-node1

# è®¾ç½®é›†ç¾¤åç§°
sudo rabbitmqctl set_cluster_name rabbitmq-cluster

# æŸ¥çœ‹é›†ç¾¤çŠ¶æ€
sudo rabbitmqctl cluster_status
```

#### 4. éªŒè¯é›†ç¾¤

```bash
# æ£€æŸ¥é›†ç¾¤èŠ‚ç‚¹
sudo rabbitmqctl cluster_status

# è¾“å‡ºç¤ºä¾‹
Cluster status of node rabbit@rabbitmq-node1 ...
[{nodes,[{disc,[rabbit@rabbitmq-node1,rabbit@rabbitmq-node2,rabbit@rabbitmq-node3]}]},
 {running_nodes,[rabbit@rabbitmq-node3,rabbit@rabbitmq-node2,rabbit@rabbitmq-node1]},
 {cluster_name,<<"rabbitmq-cluster">>},
 {partitions,[]},
 {alarms,[{rabbit@rabbitmq-node3,[]},
          {rabbit@rabbitmq-node2,[]},
          {rabbit@rabbitmq-node1,[]}]}]
```

### 6.2.2 åŠ¨æ€é›†ç¾¤å‘ç°

#### 1. ä½¿ç”¨DNSå‘ç°

```erlang
% RabbitMQé…ç½®æ–‡ä»¶rabbitmq.conf
cluster_formation.peer_discovery_backend = dns
cluster_formation.dns.hostname = rabbitmq-cluster.local
cluster_formation.dns.api_port = 5672
```

#### 2. ä½¿ç”¨é™æ€æ–‡ä»¶å‘ç°

```bash
# åˆ›å»ºé›†ç¾¤æˆå‘˜åˆ—è¡¨æ–‡ä»¶
cat > /etc/rabbitmq/cluster_discovered.conf << EOF
rabbit@rabbitmq-node1
rabbit@rabbitmq-node2
rabbit@rabbitmq-node3
EOF

# é…ç½®æ–‡ä»¶rabbitmq.conf
cluster_formation.peer_discovery_backend = static
cluster_formation.static.cluster_members.1 = rabbit@rabbitmq-node1
cluster_formation.static.cluster_members.2 = rabbit@rabbitmq-node2
cluster_formation.static.cluster_members.3 = rabbit@rabbitmq-node3
```

#### 3. ä½¿ç”¨etcdå‘ç°

```erlang
% ä½¿ç”¨etcdè¿›è¡ŒæœåŠ¡å‘ç°
cluster_formation.peer_discovery_backend = etcd
cluster_formation.etcd.host = etcd-cluster.local
cluster_formation.etcd.port = 2379
cluster_formation.etcd.prefix = /rabbitmq
cluster_formation.etcd.node_ttl = 30
```

#### 4. ä½¿ç”¨AWSå‘ç°

```erlang
% AWS EC2å®ä¾‹å‘ç°
cluster_formation.peer_discovery_backend = aws
cluster_formation.aws.region = us-west-2
cluster_formation.aws.auto_publish = false
cluster_formation.aws.subnet_tag = rabbitmq-subnet
cluster_formation.aws.instance_tag = rabbitmq-cluster
cluster_formation.aws.instance_tag_value = production
```

## 6.3 é«˜å¯ç”¨æœºåˆ¶

### 6.3.1 é•œåƒé˜Ÿåˆ—ï¼ˆMirrored Queuesï¼‰

#### é•œåƒç­–ç•¥é…ç½®

```bash
# è®¾ç½®é•œåƒé˜Ÿåˆ—ç­–ç•¥
sudo rabbitmqctl set_policy ha-all "^ha\." '{
  "ha-mode": "all",
  "ha-sync-mode": "automatic",
  "ha-params": 2,
  "ha-promote-on-startup": "when-synced"
}'

# è§£é‡Šï¼š
# ha-mode: all - åœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šé•œåƒ
# ha-sync-mode: automatic - è‡ªåŠ¨åŒæ­¥é•œåƒ
# ha-params: 2 - è‡³å°‘2ä¸ªé•œåƒ
# ha-promote-on-startup: when-synced - å¯åŠ¨æ—¶åŒæ­¥
```

#### Pythoné•œåƒé˜Ÿåˆ—ç¤ºä¾‹

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é•œåƒé˜Ÿåˆ—é…ç½®ç¤ºä¾‹
"""

import pika
import sys

def setup_mirrored_queue(host='localhost', username='admin', password='admin123'):
    """è®¾ç½®é•œåƒé˜Ÿåˆ—"""
    
    credentials = pika.PlainCredentials(username, password)
    connection_params = pika.ConnectionParameters(
        host=host,
        credentials=credentials,
        heartbeat=30,
        blocked_connection_timeout=300
    )
    
    try:
        connection = pika.BlockingConnection(connection_params)
        channel = connection.channel()
        
        # å£°æ˜é•œåƒé˜Ÿåˆ—
        channel.queue_declare(
            queue='ha-mirror-queue',
            durable=True,
            arguments={
                'x-ha-policy': 'all',
                'x-ha-sync-batch-size': 500
            }
        )
        
        # ç»‘å®šäº¤æ¢æœº
        channel.queue_bind(
            exchange='ha-direct-exchange',
            queue='ha-mirror-queue',
            routing_key='ha.messages'
        )
        
        print(f"âœ… é•œåƒé˜Ÿåˆ—åˆ›å»ºæˆåŠŸ: {host}")
        
        return channel, connection
        
    except Exception as e:
        print(f"âŒ é•œåƒé˜Ÿåˆ—åˆ›å»ºå¤±è´¥: {e}")
        return None, None

def send_ha_messages(channel, exchange_name='ha-direct-exchange'):
    """å‘é€HAæ¶ˆæ¯"""
    
    for i in range(10):
        message = f'HAæ¶ˆæ¯ {i}'
        properties = pika.BasicProperties(
            delivery_mode=2,  # æŒä¹…åŒ–
            message_id=str(i),
            correlation_id=f'cor-{i}'
        )
        
        channel.basic_publish(
            exchange=exchange_name,
            routing_key='ha.messages',
            body=message,
            properties=properties
        )
        
        print(f'ğŸ“¤ å‘é€æ¶ˆæ¯: {message}')
    
    print(f"âœ… å…±å‘é€10æ¡HAæ¶ˆæ¯")

def consume_ha_messages(channel, queue='ha-mirror-queue'):
    """æ¶ˆè´¹HAæ¶ˆæ¯"""
    
    def callback(ch, method, properties, body):
        print(f'ğŸ“¥ æ”¶åˆ°æ¶ˆæ¯: {body.decode()}')
        ch.basic_ack(delivery_tag=method.delivery_tag)
    
    # å¯ç”¨æ‰‹åŠ¨ç¡®è®¤
    channel.basic_qos(prefetch_count=1)
    
    channel.basic_consume(
        queue=queue,
        on_message_callback=callback,
        auto_ack=False
    )
    
    print('ğŸ‘¥ å¼€å§‹æ¶ˆè´¹HAæ¶ˆæ¯...')
    channel.start_consuming()

if __name__ == '__main__':
    host = sys.argv[1] if len(sys.argv) > 1 else 'localhost'
    
    # åˆ›å»ºé•œåƒé˜Ÿåˆ—
    channel, connection = setup_mirrored_queue(host)
    
    if channel and connection:
        try:
            # å‘é€æ¶ˆæ¯
            send_ha_messages(channel)
            
            # æ¶ˆè´¹æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
            consume_choice = input("æ˜¯å¦å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯ï¼Ÿ(y/N): ")
            if consume_choice.lower() == 'y':
                consume_ha_messages(channel)
                
        except KeyboardInterrupt:
            print('\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­')
        finally:
            connection.close()
```

### 6.3.2 è´Ÿè½½å‡è¡¡é…ç½®

#### HAProxyè´Ÿè½½å‡è¡¡é…ç½®

```bash
# /etc/haproxy/haproxy.cfg
global
    log stdout local0
    chroot /var/lib/haproxy
    stats socket /run/haproxy/admin.sock mode 660 level admin
    stats timeout 30s
    user haproxy
    group haproxy
    daemon

defaults
    log global
    mode tcp
    timeout connect 5000
    timeout client  50000
    timeout server  50000

frontend rabbitmq_frontend
    bind *:5672
    default_backend rabbitmq_servers

backend rabbitmq_servers
    balance roundrobin
    option tcp-check
    tcp-check connect port 5672
    server rabbit1 rabbitmq-node1:5672 check inter 5s rise 2 fall 3
    server rabbit2 rabbitmq-node2:5672 check inter 5s rise 2 fall 3
    server rabbit3 rabbitmq-node3:5672 check inter 5s rise 2 fall 3

# ç®¡ç†ç•Œé¢è´Ÿè½½å‡è¡¡
frontend rabbitmq_mgmt_frontend
    bind *:15672
    default_backend rabbitmq_mgmt_servers

backend rabbitmq_mgmt_servers
    balance roundrobin
    server rabbit1 rabbitmq-node1:15672 check inter 5s rise 2 fall 3
    server rabbit2 rabbitmq-node2:15672 check inter 5s rise 2 fall 3
    server rabbit3 rabbitmq-node3:15672 check inter 5s rise 2 fall 3

# ç»Ÿè®¡é¡µé¢
listen stats
    bind *:8404
    stats enable
    stats uri /stats
    stats refresh 30s
    stats admin if TRUE
```

#### Nginxè´Ÿè½½å‡è¡¡é…ç½®

```nginx
# /etc/nginx/conf.d/rabbitmq.conf

upstream rabbitmq_backend {
    least_conn;
    server rabbitmq-node1:5672 max_fails=3 fail_timeout=30s;
    server rabbitmq-node2:5672 max_fails=3 fail_timeout=30s;
    server rabbitmq-node3:5672 max_fails=3 fail_timeout=30s;
    
    keepalive 32;
}

server {
    listen 5672;
    proxy_pass rabbitmq_backend;
    
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # TCPå±‚è½¬å‘
    proxy_buffering off;
    proxy_request_buffering off;
    
    # è¿æ¥è¶…æ—¶è®¾ç½®
    proxy_connect_timeout 5s;
    proxy_send_timeout 60s;
    proxy_read_timeout 60s;
}

# è´Ÿè½½å‡è¡¡ç»Ÿè®¡
server {
    listen 8080;
    location /nginx_status {
        stub_status on;
        access_log off;
        allow 127.0.0.1;
        allow 10.0.0.0/8;
        allow 172.16.0.0/12;
        allow 192.168.0.0/16;
        deny all;
    }
}
```

### 6.3.3 æ•…éšœæ£€æµ‹ä¸æ¢å¤

#### å¥åº·æ£€æŸ¥è„šæœ¬

```bash
#!/bin/bash
# rabbitmq-health-check.sh

NODES=("rabbitmq-node1" "rabbitmq-node2" "rabbitmq-node3")
RABBITMQ_USER="admin"
RABBITMQ_PASSWORD="admin123"

health_check() {
    local node=$1
    local status="DOWN"
    
    # æ£€æŸ¥ç«¯å£
    if nc -z $node 5672 >/dev/null 2>&1; then
        status="UP"
    fi
    
    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    rabbitmqctl -n rabbit@$node status >/dev/null 2>&1
    if [ $? -eq 0 ]; then
        status="UP"
    fi
    
    echo "$node: $status"
}

# æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹
for node in "${NODES[@]}"; do
    health_check $node
done

# æ£€æŸ¥é›†ç¾¤çŠ¶æ€
echo "é›†ç¾¤çŠ¶æ€:"
rabbitmqctl cluster_status
```

#### è‡ªåŠ¨æ•…éšœè½¬ç§»

```bash
#!/bin/bash
# auto-failover.sh

WATCHDOG_INTERVAL=10  # ç›‘æ§é—´éš”ï¼ˆç§’ï¼‰
MAX_FAILURES=3        # æœ€å¤§å¤±è´¥æ¬¡æ•°

check_cluster() {
    local failures=0
    
    while true; do
        # æ£€æŸ¥æ¯ä¸ªèŠ‚ç‚¹çš„å¥åº·çŠ¶æ€
        for node in rabbitmq-node1 rabbitmq-node2 rabbitmq-node3; do
            if ! rabbitmqctl -n rabbit@$node status >/dev/null 2>&1; then
                echo "$(date): $node èŠ‚ç‚¹æ•…éšœ"
                failures=$((failures + 1))
                
                if [ $failures -ge $MAX_FAILURES ]; then
                    echo "$(date): è§¦å‘æ•…éšœè½¬ç§»"
                    trigger_failover
                    failures=0
                fi
            else
                failures=0
            fi
        done
        
        sleep $WATCHDOG_INTERVAL
    done
}

trigger_failover() {
    echo "$(date): å¼€å§‹æ•…éšœè½¬ç§»..."
    
    # é‡æ–°å¯åŠ¨å¤±è´¥çš„èŠ‚ç‚¹
    for node in rabbitmq-node1 rabbitmq-node2 rabbitmq-node3; do
        if ! rabbitmqctl -n rabbit@$node status >/dev/null 2>&1; then
            echo "$(date): é‡å¯èŠ‚ç‚¹ $node"
            sudo systemctl restart rabbitmq-server
            sleep 30
        fi
    done
    
    # éªŒè¯é›†ç¾¤æ¢å¤
    sleep 10
    if rabbitmqctl cluster_status >/dev/null 2>&1; then
        echo "$(date): é›†ç¾¤æ¢å¤æ­£å¸¸"
    else
        echo "$(date): é›†ç¾¤æ¢å¤å¤±è´¥"
        alert_admin
    fi
}

alert_admin() {
    # å‘é€å‘Šè­¦é€šçŸ¥
    echo "$(date): é›†ç¾¤å‘Šè­¦" | mail -s "RabbitMQ Cluster Alert" admin@company.com
    
    # æˆ–ä½¿ç”¨Slack/é’‰é’‰ç­‰webhook
    curl -X POST -H 'Content-type: application/json' \
        --data '{"text":"RabbitMQé›†ç¾¤æ•…éšœï¼Œè¯·ç«‹å³æ£€æŸ¥!"}' \
        $SLACK_WEBHOOK_URL
}

# å¯åŠ¨æ•…éšœè½¬ç§»ç›‘æ§
check_cluster
```

## 6.4 é›†ç¾¤ç›‘æ§ä¸ç®¡ç†

### 6.4.1 ç›‘æ§æŒ‡æ ‡æ”¶é›†

#### Prometheusé›†æˆ

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RabbitMQé›†ç¾¤ç›‘æ§æŒ‡æ ‡æ”¶é›†
"""

import pika
import json
import time
import requests
from prometheus_client import start_http_server, Gauge, Counter

# PrometheusæŒ‡æ ‡
queue_messages_gauge = Gauge('rabbitmq_queue_messages', 'Queue message count', ['node', 'vhost', 'queue'])
queue_consumers_gauge = Gauge('rabbitmq_queue_consumers', 'Queue consumer count', ['node', 'vhost', 'queue'])
node_memory_gauge = Gauge('rabbitmq_node_memory', 'Node memory usage', ['node'])
cluster_nodes_gauge = Gauge('rabbitmq_cluster_nodes', 'Cluster node status', ['node', 'status'])

class RabbitMQClusterMonitor:
    def __init__(self, nodes, username='admin', password='admin123'):
        self.nodes = nodes
        self.username = username
        self.password = password
        self.connections = {}
    
    def connect_nodes(self):
        """è¿æ¥åˆ°æ‰€æœ‰é›†ç¾¤èŠ‚ç‚¹"""
        for node in self.nodes:
            try:
                credentials = pika.PlainCredentials(self.username, self.password)
                connection_params = pika.ConnectionParameters(
                    host=node,
                    credentials=credentials,
                    heartbeat=30,
                    connection_attempts=3,
                    retry_delay=5
                )
                
                connection = pika.BlockingConnection(connection_params)
                self.connections[node] = connection
                print(f"âœ… è¿æ¥åˆ°èŠ‚ç‚¹: {node}")
                
            except Exception as e:
                print(f"âŒ è¿æ¥èŠ‚ç‚¹å¤±è´¥ {node}: {e}")
    
    def collect_queue_metrics(self, node):
        """æ”¶é›†é˜Ÿåˆ—æŒ‡æ ‡"""
        try:
            channel = self.connections[node].channel()
            
            # è·å–é˜Ÿåˆ—ä¿¡æ¯
            result = channel.queue_declare('', exclusive=True, auto_delete=True)
            
            # è·å–é˜Ÿåˆ—ç»Ÿè®¡
            queues = channel.queue_declare('', exclusive=True, passive=True)
            
            print(f"ğŸ“Š æ”¶é›†èŠ‚ç‚¹ {node} çš„é˜Ÿåˆ—æŒ‡æ ‡")
            
        except Exception as e:
            print(f"âŒ æ”¶é›†é˜Ÿåˆ—æŒ‡æ ‡å¤±è´¥ {node}: {e}")
    
    def collect_cluster_metrics(self, node):
        """æ”¶é›†é›†ç¾¤æŒ‡æ ‡"""
        try:
            # è¿™é‡Œä½¿ç”¨HTTP APIè·å–æ›´è¯¦ç»†çš„æŒ‡æ ‡
            import requests
            
            api_url = f"http://{node}:15672/api/overview"
            auth = (self.username, self.password)
            
            response = requests.get(api_url, auth=auth, timeout=10)
            if response.status_code == 200:
                data = response.json()
                
                # æå–å†…å­˜ä½¿ç”¨
                memory = data.get('memory', {})
                memory_usage = memory.get('used', 0)
                node_memory_gauge.labels(node=node).set(memory_usage)
                
                # æå–é›†ç¾¤ä¿¡æ¯
                cluster_nodes = data.get('cluster_nodes', [])
                for cluster_node in cluster_nodes:
                    node_name = cluster_node.get('name', '')
                    running = cluster_node.get('running', False)
                    status = 'running' if running else 'down'
                    cluster_nodes_gauge.labels(node=node_name, status=status).set(1 if running else 0)
                
        except Exception as e:
            print(f"âŒ æ”¶é›†é›†ç¾¤æŒ‡æ ‡å¤±è´¥ {node}: {e}")
    
    def monitoring_loop(self, interval=30):
        """ç›‘æ§å¾ªç¯"""
        while True:
            try:
                for node in self.connections.keys():
                    self.collect_queue_metrics(node)
                    self.collect_cluster_metrics(node)
                
                time.sleep(interval)
                
            except Exception as e:
                print(f"âŒ ç›‘æ§å¼‚å¸¸: {e}")
                time.sleep(5)
    
    def close_connections(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        for node, connection in self.connections.items():
            if connection and not connection.is_closed:
                connection.close()
                print(f"ğŸ”Œ å…³é—­è¿æ¥: {node}")

def main():
    # é›†ç¾¤èŠ‚ç‚¹åˆ—è¡¨
    nodes = ['rabbitmq-node1', 'rabbitmq-node2', 'rabbitmq-node3']
    
    # å¯åŠ¨PrometheusæŒ‡æ ‡æœåŠ¡å™¨
    start_http_server(8000)
    
    # å¯åŠ¨ç›‘æ§
    monitor = RabbitMQClusterMonitor(nodes)
    
    try:
        monitor.connect_nodes()
        monitor.monitoring_loop()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç›‘æ§åœæ­¢")
    finally:
        monitor.close_connections()

if __name__ == '__main__':
    main()
```

#### Grafanaä»ªè¡¨æ¿é…ç½®

```json
{
  "dashboard": {
    "id": null,
    "title": "RabbitMQé›†ç¾¤ç›‘æ§",
    "tags": ["rabbitmq", "cluster"],
    "style": "dark",
    "timezone": "browser",
    "refresh": "30s",
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "panels": [
      {
        "id": 1,
        "title": "é›†ç¾¤èŠ‚ç‚¹çŠ¶æ€",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rabbitmq_cluster_nodes{status=\"running\"})",
            "legendFormat": "è¿è¡ŒèŠ‚ç‚¹æ•°"
          },
          {
            "expr": "sum(rabbitmq_cluster_nodes{status=\"down\"})",
            "legendFormat": "æ•…éšœèŠ‚ç‚¹æ•°"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "red", "value": null},
                {"color": "green", "value": 3},
                {"color": "yellow", "value": 2}
              ]
            }
          }
        }
      },
      {
        "id": 2,
        "title": "é˜Ÿåˆ—æ¶ˆæ¯æ•°",
        "type": "timeseries",
        "targets": [
          {
            "expr": "sum(rabbitmq_queue_messages) by (vhost)",
            "legendFormat": "{{vhost}}"
          }
        ],
        "yAxes": [
          {
            "label": "æ¶ˆæ¯æ•°",
            "min": 0
          }
        ]
      },
      {
        "id": 3,
        "title": "æ¶ˆè´¹è€…æ•°é‡",
        "type": "timeseries", 
        "targets": [
          {
            "expr": "sum(rabbitmq_queue_consumers) by (queue)",
            "legendFormat": "{{queue}}"
          }
        ]
      },
      {
        "id": 4,
        "title": "èŠ‚ç‚¹å†…å­˜ä½¿ç”¨",
        "type": "timeseries",
        "targets": [
          {
            "expr": "rabbitmq_node_memory / 1024 / 1024 / 1024",
            "legendFormat": "{{node}} GB"
          }
        ],
        "yAxes": [
          {
            "label": "å†…å­˜(GB)",
            "min": 0
          }
        ]
      }
    ]
  }
}
```

### 6.4.2 é›†ç¾¤ç®¡ç†æ“ä½œ

#### èŠ‚ç‚¹ç®¡ç†è„šæœ¬

```bash
#!/bin/bash
# cluster-management.sh

RABBITMQ_CLUSTER_NAME="rabbitmq-cluster"
NODE1="rabbitmq-node1"
NODE2="rabbitmq-node2" 
NODE3="rabbitmq-node3"

case $1 in
    "status")
        echo "é›†ç¾¤çŠ¶æ€:"
        rabbitmqctl cluster_status
        ;;
    
    "join")
        echo "å°†èŠ‚ç‚¹åŠ å…¥é›†ç¾¤..."
        case $2 in
            $NODE2)
                ssh root@$NODE2 "rabbitmqctl stop_app; rabbitmqctl join_cluster rabbit@$NODE1"
                ;;
            $NODE3)
                ssh root@$NODE3 "rabbitmqctl stop_app; rabbitmqctl join_cluster rabbit@$NODE1"
                ;;
            *)
                echo "æœªçŸ¥èŠ‚ç‚¹: $2"
                exit 1
                ;;
        esac
        ;;
    
    "leave")
        echo "èŠ‚ç‚¹ç¦»å¼€é›†ç¾¤..."
        rabbitmqctl stop_app
        rabbitmqctl reset
        rabbitmqctl start_app
        ;;
    
    "forget")
        echo "ä»é›†ç¾¤ä¸­ç§»é™¤èŠ‚ç‚¹..."
        rabbitmqctl forget_cluster_node rabbit@$2
        ;;
    
    "rename")
        echo "é‡å‘½åé›†ç¾¤..."
        rabbitmqctl stop_app
        rabbitmqctl set_cluster_name $RABBITMQ_CLUSTER_NAME
        rabbitmqctl start_app
        ;;
    
    "backup")
        echo "å¤‡ä»½é›†ç¾¤é…ç½®..."
        timestamp=$(date +%Y%m%d_%H%M%S)
        backup_dir="/tmp/rabbitmq_backup_$timestamp"
        mkdir -p $backup_dir
        
        # å¤‡ä»½é˜Ÿåˆ—ä¿¡æ¯
        rabbitmqctl export_definitions $backup_dir/definitions.json
        echo "é…ç½®å·²å¤‡ä»½åˆ°: $backup_dir"
        ;;
    
    "restore")
        echo "æ¢å¤é›†ç¾¤é…ç½®..."
        if [ -z "$2" ]; then
            echo "è¯·æŒ‡å®šå¤‡ä»½æ–‡ä»¶è·¯å¾„"
            exit 1
        fi
        rabbitmqctl import_definitions $2
        ;;
    
    "stop")
        echo "å®‰å…¨åœæ­¢é›†ç¾¤..."
        rabbitmqctl stop_app
        ;;
    
    "start")
        echo "å¯åŠ¨é›†ç¾¤..."
        rabbitmqctl start_app
        ;;
    
    "health")
        echo "å¥åº·æ£€æŸ¥..."
        for node in $NODE1 $NODE2 $NODE3; do
            echo "æ£€æŸ¥èŠ‚ç‚¹: $node"
            rabbitmqctl -n rabbit@$node status | grep -E "(memory|file_descriptors|processes)"
        done
        ;;
    
    *)
        echo "ç”¨æ³•: $0 {status|join|leave|forget|rename|backup|restore|stop|start|health}"
        echo "  status    - æŸ¥çœ‹é›†ç¾¤çŠ¶æ€"
        echo "  join <node> - å°†èŠ‚ç‚¹åŠ å…¥é›†ç¾¤"
        echo "  leave     - å½“å‰èŠ‚ç‚¹ç¦»å¼€é›†ç¾¤"
        echo "  forget <node> - ä»é›†ç¾¤ä¸­ç§»é™¤èŠ‚ç‚¹"
        echo "  rename    - é‡å‘½åé›†ç¾¤"
        echo "  backup    - å¤‡ä»½é›†ç¾¤é…ç½®"
        echo "  restore <file> - æ¢å¤é›†ç¾¤é…ç½®"
        echo "  stop      - å®‰å…¨åœæ­¢é›†ç¾¤"
        echo "  start     - å¯åŠ¨é›†ç¾¤"
        echo "  health    - å¥åº·æ£€æŸ¥"
        exit 1
        ;;
esac
```

## 6.5 æ€§èƒ½è°ƒä¼˜ä¸æœ€ä½³å®è·µ

### 6.5.1 é›†ç¾¤æ€§èƒ½è°ƒä¼˜

#### æ“ä½œç³»ç»Ÿä¼˜åŒ–

```bash
# /etc/sysctl.conf ä¼˜åŒ–å‚æ•°

# æ–‡ä»¶æè¿°ç¬¦é™åˆ¶
fs.file-max = 2097152
fs.nr_open = 1048576

# ç½‘ç»œå‚æ•°ä¼˜åŒ–
net.core.somaxconn = 4096
net.core.netdev_max_backlog = 5000
net.ipv4.tcp_max_syn_backlog = 4096
net.core.rmem_max = 16777216
net.core.wmem_max = 16777216
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216

# TCPè¿æ¥ä¼˜åŒ–
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 0
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_keepalive_time = 1200
net.ipv4.tcp_keepalive_intvl = 30
net.ipv4.tcp_keepalive_probes = 3

# åº”ç”¨ä¼˜åŒ–
kernel.pid_max = 4194304
vm.max_map_count = 262144

# åº”ç”¨è®¾ç½®
sudo sysctl -p
```

#### RabbitMQé…ç½®ä¼˜åŒ–

```erlang
% /etc/rabbitmq/rabbitmq.conf æ€§èƒ½ä¼˜åŒ–é…ç½®

# å†…å­˜é™åˆ¶
vm_memory_high_watermark.relative = 0.6
vm_memory_high_watermark_paging_ratio = 0.75

# ç£ç›˜ç©ºé—´é™åˆ¶
disk_free_limit.absolute = 2GB

# è¿æ¥å’Œé€šé“é™åˆ¶
channel_max = 2048
connection_max_channels = 10000
heartbeat = 60

# é˜Ÿåˆ—å‚æ•°
default_queue_spec_modes = all
default_prefetch_count = 1000

# å¹¶å‘æ§åˆ¶
amqp_default_created_at_utc = true
cluster_formation.discovery_retry_limit = 5
cluster_formation.discovery_retry_interval = 5000

# TLSé…ç½®
ssl_options.cacertfile = /etc/rabbitmq/ssl/cacert.pem
ssl_options.certfile = /etc/rabbitmq/ssl/cert.pem
ssl_options.keyfile = /etc/rabbitmq/ssl/key.pem
ssl_options.verify = verify_peer
ssl_options.fail_if_no_peer_cert = false

# ç›‘æ§é…ç½®
default_user = admin
default_pass = admin123
default_permissions.configure = .*
default_permissions.read = .*
default_permissions.write = .*
loopback_users = none
```

### 6.5.2 ç›‘æ§ä¸å‘Šè­¦é…ç½®

#### Zabbixç›‘æ§æ¨¡æ¿

```xml
<?xml version="1.0" encoding="UTF-8"?>
<zabbix_export>
    <version>4.0</version>
    <date>2023-01-01T00:00:00Z</description>RabbitMQ Cluster Monitoring</description>
    
    <items>
        <item>
            <name>RabbitMQ Node Memory Usage</name>
            <key>rabbitmq.node.memory</key>
            <type>7</type>
            <value_type>3</value_type>
            <units>%</units>
            <formula>($last/#3)*100</formula>
        </item>
        
        <item>
            <name>RabbitMQ Queue Messages</name>
            <key>rabbitmq.queue.messages</key>
            <type>7</type>
            <value_type>3</value_type>
        </item>
        
        <item>
            <name>RabbitMQ Cluster Nodes</name>
            <key>rabbitmq.cluster.nodes</key>
            <type>7</type>
            <value_type>3</value_type>
        </item>
    </items>
    
    <triggers>
        <trigger>
            <name>RabbitMQ Node Memory High</name>
            <expression>{Template RabbitMQ:rabbitmq.node.memory.last()} > 80</expression>
            <severity>warning</severity>
            <description>Node memory usage is above 80%</description>
        </trigger>
        
        <trigger>
            <name>RabbitMQ Queue Backlog</name>
            <expression>{Template RabbitMQ:rabbitmq.queue.messages.last()} > 1000</expression>
            <severity>warning</severity>
            <description>Queue has significant message backlog</description>
        </trigger>
        
        <trigger>
            <name>RabbitMQ Cluster Node Down</name>
            <expression>{Template RabbitMQ:rabbitmq.cluster.nodes.last()} < 3</expression>
            <severity>critical</severity>
            <description>RabbitMQ cluster node is down</description>
        </trigger>
    </triggers>
</zabbix_export>
```

### 6.5.3 å¤‡ä»½ä¸æ¢å¤ç­–ç•¥

#### è‡ªåŠ¨å¤‡ä»½è„šæœ¬

```bash
#!/bin/bash
# auto-backup-rabbitmq.sh

BACKUP_DIR="/var/backups/rabbitmq"
RETENTION_DAYS=30
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

create_backup() {
    echo "$(date): å¼€å§‹åˆ›å»ºå¤‡ä»½..."
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    mkdir -p "$BACKUP_DIR/$TIMESTAMP"
    cd "$BACKUP_DIR"
    
    # 1. å¯¼å‡ºé›†ç¾¤å®šä¹‰
    rabbitmqctl export_definitions definitions.json
    echo "âœ… é›†ç¾¤å®šä¹‰å·²å¯¼å‡º"
    
    # 2. å¤‡ä»½é›†ç¾¤çŠ¶æ€
    rabbitmqctl cluster_status > cluster_status.txt
    echo "âœ… é›†ç¾¤çŠ¶æ€å·²å¤‡ä»½"
    
    # 3. å¤‡ä»½ç”¨æˆ·å’Œæƒé™
    rabbitmqctl list_users > users.txt
    rabbitmqctl list_permissions > permissions.txt
    echo "âœ… ç”¨æˆ·æƒé™å·²å¤‡ä»½"
    
    # 4. å¤‡ä»½vhosté…ç½®
    rabbitmqctl list_vhosts > vhosts.txt
    echo "âœ… VHosté…ç½®å·²å¤‡ä»½"
    
    # 5. å‹ç¼©å¤‡ä»½
    tar -czf "rabbitmq_backup_$TIMESTAMP.tar.gz" "$TIMESTAMP"
    rm -rf "$TIMESTAMP"
    
    echo "âœ… å¤‡ä»½å®Œæˆ: rabbitmq_backup_$TIMESTAMP.tar.gz"
    
    # ä¸Šä¼ åˆ°è¿œç¨‹å­˜å‚¨ï¼ˆå¯é€‰ï¼‰
    # upload_to_s3 "rabbitmq_backup_$TIMESTAMP.tar.gz"
    
    # æ¸…ç†æ—§å¤‡ä»½
    cleanup_old_backups
}

cleanup_old_backups() {
    echo "$(date): æ¸…ç†è¿‡æœŸå¤‡ä»½..."
    
    find "$BACKUP_DIR" -name "rabbitmq_backup_*.tar.gz" -mtime +$RETENTION_DAYS -delete
    
    # ä¿ç•™æœ€è¿‘çš„7ä¸ªå¤‡ä»½
    ls -t "$BACKUP_DIR"/rabbitmq_backup_*.tar.gz | tail -n +8 | xargs -r rm
    
    echo "âœ… å¤‡ä»½æ¸…ç†å®Œæˆ"
}

upload_to_s3() {
    local backup_file=$1
    
    if command -v aws >/dev/null 2>&1; then
        aws s3 cp "$backup_file" "s3://rabbitmq-backups/$(basename $backup_file)"
        echo "âœ… å¤‡ä»½å·²ä¸Šä¼ åˆ°S3: s3://rabbitmq-backups/$(basename $backup_file)"
    else
        echo "âš ï¸  AWS CLIæœªå®‰è£…ï¼Œè·³è¿‡S3ä¸Šä¼ "
    fi
}

# ä¸»ç¨‹åº
case $1 in
    "backup")
        create_backup
        ;;
    "cleanup")
        cleanup_old_backups
        ;;
    "restore")
        if [ -z "$2" ]; then
            echo "ç”¨æ³•: $0 restore <backup_file>"
            exit 1
        fi
        rabbitmqctl import_definitions "$2"
        echo "âœ… é…ç½®æ¢å¤å®Œæˆ"
        ;;
    *)
        echo "ç”¨æ³•: $0 {backup|cleanup|restore <file>}"
        echo "  backup   - åˆ›å»ºå¤‡ä»½"
        echo "  cleanup  - æ¸…ç†è¿‡æœŸå¤‡ä»½"
        echo "  restore  - æ¢å¤é…ç½®"
        exit 1
        ;;
esac

# å®šæ—¶ä»»åŠ¡é…ç½®ç¤ºä¾‹
# 0 2 * * * /path/to/auto-backup-rabbitmq.sh backup
```

## 6.6 å®é™…åº”ç”¨åœºæ™¯

### 6.6.1 é‡‘èäº¤æ˜“ç³»ç»Ÿ

#### åœºæ™¯æè¿°
- é«˜é¢‘äº¤æ˜“ç³»ç»Ÿ
- æ¯«ç§’çº§å»¶è¿Ÿè¦æ±‚
- 99.99%å¯ç”¨æ€§
- æ•°æ®ä¸€è‡´æ€§è¦æ±‚

#### æ¶æ„è®¾è®¡
```yaml
# docker-compose.yml
version: '3.8'

services:
  rabbitmq-node1:
    image: rabbitmq:3-management
    environment:
      RABBITMQ_NODENAME: rabbit@rabbitmq-node1
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin123
    ports:
      - "5672:5672"
      - "15672:15672"
    volumes:
      - rabbitmq_data1:/var/lib/rabbitmq
      - ./config/rabbitmq1.conf:/etc/rabbitmq/rabbitmq.conf
    networks:
      - rabbitmq_cluster

  rabbitmq-node2:
    image: rabbitmq:3-management
    environment:
      RABBITMQ_NODENAME: rabbit@rabbitmq-node2
    depends_on:
      - rabbitmq-node1
    volumes:
      - rabbitmq_data2:/var/lib/rabbitmq
      - ./config/rabbitmq2.conf:/etc/rabbitmq/rabbitmq.conf
    networks:
      - rabbitmq_cluster

  rabbitmq-node3:
    image: rabbitmq:3-management
    environment:
      RABBITMQ_NODENAME: rabbit@rabbitmq-node3
    depends_on:
      - rabbitmq-node1
    volumes:
      - rabbitmq_data3:/var/lib/rabbitmq
      - ./config/rabbitmq3.conf:/etc/rabbitmq/rabbitmq.conf
    networks:
      - rabbitmq_cluster

  haproxy:
    image: haproxy:2.0
    ports:
      - "5673:5672"
      - "8404:8404"
    volumes:
      - ./config/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg
    depends_on:
      - rabbitmq-node1
      - rabbitmq-node2
      - rabbitmq-node3
    networks:
      - rabbitmq_cluster

networks:
  rabbitmq_cluster:
    driver: bridge

volumes:
  rabbitmq_data1:
  rabbitmq_data2:
  rabbitmq_data3:
```

### 6.6.2 ç”µå•†è®¢å•ç³»ç»Ÿ

#### åœºæ™¯ç‰¹ç‚¹
- è®¢å•å¤„ç†æµç¨‹
- åº“å­˜ç®¡ç†
- æ”¯ä»˜é›†æˆ
- ç‰©æµè·Ÿè¸ª

#### è®¢å•å¤„ç†æµç¨‹
```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç”µå•†è®¢å•ç³»ç»ŸRabbitMQé›†ç¾¤åº”ç”¨
"""

import pika
import json
import time
from datetime import datetime
import uuid

class OrderProcessingSystem:
    def __init__(self):
        self.cluster_nodes = [
            'rabbitmq-node1',
            'rabbitmq-node2', 
            'rabbitmq-node3'
        ]
        self.haproxy_port = 5673
        self.setup_connection()
    
    def setup_connection(self):
        """è®¾ç½®è¿æ¥"""
        # ä½¿ç”¨HAProxyè¿›è¡Œè´Ÿè½½å‡è¡¡
        credentials = pika.PlainCredentials('admin', 'admin123')
        connection_params = pika.ConnectionParameters(
            host='localhost',
            port=self.haproxy_port,
            credentials=credentials,
            heartbeat=30,
            blocked_connection_timeout=300,
            connection_attempts=3,
            retry_delay=5
        )
        
        self.connection = pika.BlockingConnection(connection_params)
        self.channel = self.connection.channel()
        
        # è®¾ç½®é•œåƒé˜Ÿåˆ—ç­–ç•¥
        self.setup_mirrored_queues()
    
    def setup_mirrored_queues(self):
        """è®¾ç½®é•œåƒé˜Ÿåˆ—"""
        queues = [
            'order.create',
            'order.payment',
            'order.inventory',
            'order.shipping',
            'order.notification'
        ]
        
        for queue in queues:
            # åˆ›å»ºé•œåƒé˜Ÿåˆ—
            self.channel.queue_declare(
                queue=queue,
                durable=True,
                arguments={
                    'x-ha-policy': 'all',  # æ‰€æœ‰èŠ‚ç‚¹é•œåƒ
                    'x-ha-sync-batch-size': 100,
                    'x-message-ttl': 300000  # 5åˆ†é’ŸTTL
                }
            )
    
    def publish_order_created(self, order_data):
        """å‘å¸ƒè®¢å•åˆ›å»ºäº‹ä»¶"""
        event = {
            'event_type': 'order.created',
            'order_id': order_data['order_id'],
            'user_id': order_data['user_id'],
            'items': order_data['items'],
            'total_amount': order_data['total_amount'],
            'timestamp': datetime.now().isoformat()
        }
        
        self.channel.basic_publish(
            exchange='',
            routing_key='order.create',
            body=json.dumps(event),
            properties=pika.BasicProperties(
                delivery_mode=2,  # æŒä¹…åŒ–
                message_id=str(uuid.uuid4()),
                correlation_id=order_data['order_id']
            )
        )
        
        print(f"ğŸ“¤ è®¢å•åˆ›å»ºäº‹ä»¶å·²å‘å¸ƒ: {order_data['order_id']}")
    
    def publish_payment_result(self, order_id, payment_status, amount):
        """å‘å¸ƒæ”¯ä»˜ç»“æœäº‹ä»¶"""
        event = {
            'event_type': 'order.payment',
            'order_id': order_id,
            'payment_status': payment_status,
            'amount': amount,
            'timestamp': datetime.now().isoformat()
        }
        
        self.channel.basic_publish(
            exchange='',
            routing_key='order.payment',
            body=json.dumps(event),
            properties=pika.BasicProperties(
                delivery_mode=2,
                message_id=str(uuid.uuid4()),
                correlation_id=order_id
            )
        )
        
        print(f"ğŸ“¤ æ”¯ä»˜ç»“æœäº‹ä»¶å·²å‘å¸ƒ: {order_id} - {payment_status}")
    
    def process_orders(self):
        """å¤„ç†è®¢å•æµç¨‹"""
        def order_created_callback(ch, method, properties, body):
            """è®¢å•åˆ›å»ºå¤„ç†å™¨"""
            try:
                event = json.loads(body.decode())
                order_id = event['order_id']
                
                print(f"ğŸ“¥ å¤„ç†è®¢å•åˆ›å»º: {order_id}")
                
                # éªŒè¯åº“å­˜
                if self.check_inventory(event['items']):
                    # åº“å­˜å……è¶³ï¼Œç»§ç»­æ”¯ä»˜æµç¨‹
                    print(f"âœ… è®¢å• {order_id} åº“å­˜æ£€æŸ¥é€šè¿‡")
                    self.publish_inventory_reserved(order_id)
                    self.publish_payment_request(order_id, event['total_amount'])
                else:
                    # åº“å­˜ä¸è¶³
                    print(f"âŒ è®¢å• {order_id} åº“å­˜ä¸è¶³")
                    self.publish_inventory_insufficient(order_id)
                
                ch.basic_ack(delivery_tag=method.delivery_tag)
                
            except Exception as e:
                print(f"âŒ å¤„ç†è®¢å•åˆ›å»ºå¼‚å¸¸: {e}")
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
        
        def payment_callback(ch, method, properties, body):
            """æ”¯ä»˜å¤„ç†å™¨"""
            try:
                event = json.loads(body.decode())
                order_id = event['order_id']
                payment_status = event['payment_status']
                
                print(f"ğŸ“¥ å¤„ç†æ”¯ä»˜ç»“æœ: {order_id} - {payment_status}")
                
                if payment_status == 'success':
                    # æ”¯ä»˜æˆåŠŸï¼Œç»§ç»­é…é€æµç¨‹
                    self.publish_order_shipped(order_id)
                else:
                    # æ”¯ä»˜å¤±è´¥ï¼Œå–æ¶ˆè®¢å•
                    self.publish_order_cancelled(order_id)
                
                ch.basic_ack(delivery_tag=method.delivery_tag)
                
            except Exception as e:
                print(f"âŒ å¤„ç†æ”¯ä»˜å¼‚å¸¸: {e}")
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
        
        # å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯
        self.channel.basic_consume(
            queue='order.create',
            on_message_callback=order_created_callback,
            auto_ack=False
        )
        
        self.channel.basic_consume(
            queue='order.payment',
            on_message_callback=payment_callback,
            auto_ack=False
        )
        
        print("ğŸ‘¥ å¼€å§‹å¤„ç†è®¢å•...")
        self.channel.start_consuming()
    
    def check_inventory(self, items):
        """æ£€æŸ¥åº“å­˜"""
        # æ¨¡æ‹Ÿåº“å­˜æ£€æŸ¥
        return True
    
    def publish_inventory_reserved(self, order_id):
        """å‘å¸ƒåº“å­˜é¢„ç•™äº‹ä»¶"""
        event = {
            'event_type': 'order.inventory_reserved',
            'order_id': order_id,
            'timestamp': datetime.now().isoformat()
        }
        
        self.channel.basic_publish(
            exchange='',
            routing_key='order.inventory',
            body=json.dumps(event)
        )
    
    def publish_inventory_insufficient(self, order_id):
        """å‘å¸ƒåº“å­˜ä¸è¶³äº‹ä»¶"""
        event = {
            'event_type': 'order.inventory_insufficient',
            'order_id': order_id,
            'timestamp': datetime.now().isoformat()
        }
        
        self.channel.basic_publish(
            exchange='',
            routing_key='order.inventory',
            body=json.dumps(event)
        )
    
    def publish_payment_request(self, order_id, amount):
        """å‘å¸ƒæ”¯ä»˜è¯·æ±‚"""
        event = {
            'event_type': 'order.payment_request',
            'order_id': order_id,
            'amount': amount,
            'timestamp': datetime.now().isoformat()
        }
        
        self.channel.basic_publish(
            exchange='',
            routing_key='order.payment',
            body=json.dumps(event)
        )
    
    def publish_order_shipped(self, order_id):
        """å‘å¸ƒè®¢å•å‘è´§äº‹ä»¶"""
        event = {
            'event_type': 'order.shipped',
            'order_id': order_id,
            'timestamp': datetime.now().isoformat()
        }
        
        self.channel.basic_publish(
            exchange='',
            routing_key='order.shipping',
            body=json.dumps(event)
        )
    
    def publish_order_cancelled(self, order_id):
        """å‘å¸ƒè®¢å•å–æ¶ˆäº‹ä»¶"""
        event = {
            'event_type': 'order.cancelled',
            'order_id': order_id,
            'timestamp': datetime.now().isoformat()
        }
        
        self.channel.basic_publish(
            exchange='',
            routing_key='order.notification',
            body=json.dumps(event)
        )

def main():
    """ä¸»å‡½æ•°"""
    system = OrderProcessingSystem()
    
    try:
        # å‘å¸ƒæµ‹è¯•è®¢å•
        test_order = {
            'order_id': str(uuid.uuid4()),
            'user_id': 'user123',
            'items': [
                {'product_id': 'p001', 'quantity': 2},
                {'product_id': 'p002', 'quantity': 1}
            ],
            'total_amount': 299.99
        }
        
        # æ¨¡æ‹Ÿè®¢å•æµç¨‹
        system.publish_order_created(test_order)
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´åå‘å¸ƒæ”¯ä»˜ç»“æœ
        time.sleep(2)
        system.publish_payment_result(test_order['order_id'], 'success', test_order['total_amount'])
        
        # å¼€å§‹å¤„ç†è®¢å•ï¼ˆå¦‚æœéœ€è¦ï¼‰
        # system.process_orders()
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ç³»ç»Ÿåœæ­¢")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿå¼‚å¸¸: {e}")
    finally:
        system.connection.close()

if __name__ == '__main__':
    main()
```

## æ€»ç»“

RabbitMQé›†ç¾¤éƒ¨ç½²ä¸é«˜å¯ç”¨æ¶æ„æ˜¯æ„å»ºå¯é æ¶ˆæ¯ç³»ç»Ÿçš„æ ¸å¿ƒã€‚æœ¬ç« æ¶µç›–äº†ï¼š

1. **é›†ç¾¤åŸºç¡€æ¶æ„**ï¼šèŠ‚ç‚¹ç±»å‹ã€æ‹“æ‰‘ç»“æ„ã€è¿æ¥æ–¹å¼
2. **éƒ¨ç½²æ–¹æ³•**ï¼šé™æ€é…ç½®ã€åŠ¨æ€å‘ç°ã€æœåŠ¡ç¼–æ’
3. **é«˜å¯ç”¨æœºåˆ¶**ï¼šé•œåƒé˜Ÿåˆ—ã€è´Ÿè½½å‡è¡¡ã€æ•…éšœæ£€æµ‹
4. **ç›‘æ§ç®¡ç†**ï¼šæŒ‡æ ‡æ”¶é›†ã€å¥åº·æ£€æŸ¥ã€æ€§èƒ½ä¼˜åŒ–
5. **æœ€ä½³å®è·µ**ï¼šæ€§èƒ½è°ƒä¼˜ã€å¤‡ä»½æ¢å¤ã€å®‰å…¨é…ç½®
6. **å®é™…åº”ç”¨**ï¼šé‡‘èäº¤æ˜“ã€ç”µå•†è®¢å•ç­‰ä¸šåŠ¡åœºæ™¯

é€šè¿‡åˆç†çš„é›†ç¾¤è®¾è®¡å’Œè¿ç»´ç®¡ç†ï¼Œå¯ä»¥å®ç°99.99%çš„é«˜å¯ç”¨æ€§ï¼Œæ»¡è¶³ä¼ä¸šçº§åº”ç”¨çš„ä¸¥æ ¼è¦æ±‚ã€‚åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œéœ€è¦æ ¹æ®ä¸šåŠ¡ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„æ¶æ„æ–¹æ¡ˆï¼Œå¹¶å»ºç«‹å®Œå–„çš„ç›‘æ§å’Œè¿ç»´ä½“ç³»ã€‚