# 第9章：监控与运维

## 监控架构概述

RabbitMQ作为企业级消息中间件，监控与运维是确保系统稳定运行的关键。本章将深入介绍RabbitMQ的监控体系、运维实践和故障处理方法。

### 监控体系架构

监控体系主要分为三个层次：

1. **基础设施监控**：服务器、网络、磁盘、内存、CPU等基础资源监控
2. **RabbitMQ服务监控**：队列、连接、交换器、消息处理等应用层监控
3. **业务监控**：消息吞吐量、延迟、错误率等业务指标监控

```python
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional, Any
from enum import Enum
import json
import logging
from collections import defaultdict, deque
import time

class AlertLevel(Enum):
    """告警级别"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"

@dataclass
class MetricData:
    """监控指标数据"""
    name: str
    value: float
    timestamp: datetime
    unit: str
    tags: Dict[str, str]

@dataclass
class Alert:
    """告警信息"""
    level: AlertLevel
    title: str
    message: str
    metric_name: str
    current_value: float
    threshold: float
    timestamp: datetime
    resolved: bool = False
```

## 监控指标体系

### 系统级指标

监控服务器基础资源使用情况：

```python
class SystemMonitor:
    """系统资源监控器"""
    
    def __init__(self):
        self.metrics_history = defaultdict(lambda: deque(maxlen=1000))
    
    def get_system_metrics(self) -> Dict[str, float]:
        """获取系统指标"""
        import psutil
        
        return {
            'cpu_percent': psutil.cpu_percent(interval=1),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_percent': psutil.disk_usage('/').percent,
            'network_bytes_sent': psutil.net_io_counters().bytes_sent,
            'network_bytes_recv': psutil.net_io_counters().bytes_recv,
            'process_count': len(psutil.pids()),
            'load_average': psutil.getloadavg()[0] if hasattr(psutil, 'getloadavg') else 0.0
        }
    
    def get_system_health_score(self) -> float:
        """计算系统健康度分数（0-100）"""
        metrics = self.get_system_metrics()
        
        # CPU分数 (40%权重)
        cpu_score = max(0, 100 - metrics['cpu_percent'])
        
        # 内存分数 (30%权重)
        memory_score = max(0, 100 - metrics['memory_percent'])
        
        # 磁盘分数 (20%权重)
        disk_score = max(0, 100 - metrics['disk_percent'])
        
        # 负载分数 (10%权重)
        load_score = max(0, 100 - min(metrics['load_average'] * 20, 100))
        
        health_score = (cpu_score * 0.4 + 
                       memory_score * 0.3 + 
                       disk_score * 0.2 + 
                       load_score * 0.1)
        
        return round(health_score, 2)
    
    def check_system_alerts(self) -> List[Alert]:
        """检查系统告警"""
        alerts = []
        metrics = self.get_system_metrics()
        
        # CPU告警
        if metrics['cpu_percent'] > 80:
            alerts.append(Alert(
                level=AlertLevel.WARNING,
                title="高CPU使用率",
                message=f"CPU使用率超过阈值: {metrics['cpu_percent']:.1f}%",
                metric_name="cpu_percent",
                current_value=metrics['cpu_percent'],
                threshold=80,
                timestamp=datetime.now()
            ))
        
        # 内存告警
        if metrics['memory_percent'] > 85:
            alerts.append(Alert(
                level=AlertLevel.CRITICAL,
                title="高内存使用率",
                message=f"内存使用率超过阈值: {metrics['memory_percent']:.1f}%",
                metric_name="memory_percent",
                current_value=metrics['memory_percent'],
                threshold=85,
                timestamp=datetime.now()
            ))
        
        # 磁盘告警
        if metrics['disk_percent'] > 90:
            alerts.append(Alert(
                level=AlertLevel.CRITICAL,
                title="高磁盘使用率",
                message=f"磁盘使用率超过阈值: {metrics['disk_percent']:.1f}%",
                metric_name="disk_percent",
                current_value=metrics['disk_percent'],
                threshold=90,
                timestamp=datetime.now()
            ))
        
        return alerts
```

### RabbitMQ服务指标

监控RabbitMQ核心服务指标：

```python
class RabbitMQMonitor:
    """RabbitMQ服务监控器"""
    
    def __init__(self, host='localhost', port=15672, user='guest', password='guest'):
        self.host = host
        self.port = port
        self.user = user
        self.password = password
        self.base_url = f"http://{host}:{port}/api"
        
    def get_overview_metrics(self) -> Dict[str, Any]:
        """获取RabbitMQ概览指标"""
        try:
            import requests
            auth = (self.user, self.password)
            response = requests.get(f"{self.base_url}/overview", auth=auth, timeout=5)
            return response.json()
        except Exception as e:
            logging.error(f"获取概览指标失败: {e}")
            return {}
    
    def get_queue_metrics(self) -> List[Dict[str, Any]]:
        """获取队列指标"""
        try:
            import requests
            auth = (self.user, self.password)
            response = requests.get(f"{self.base_url}/queues", auth=auth, timeout=5)
            return response.json()
        except Exception as e:
            logging.error(f"获取队列指标失败: {e}")
            return []
    
    def get_connection_metrics(self) -> List[Dict[str, Any]]:
        """获取连接指标"""
        try:
            import requests
            auth = (self.user, self.password)
            response = requests.get(f"{self.base_url}/connections", auth=auth, timeout=5)
            return response.json()
        except Exception as e:
            logging.error(f"获取连接指标失败: {e}")
            return []
    
    def get_node_metrics(self) -> List[Dict[str, Any]]:
        """获取节点指标"""
        try:
            import requests
            auth = (self.user, self.password)
            response = requests.get(f"{self.base_url}/nodes", auth=auth, timeout=5)
            return response.json()
        except Exception as e:
            logging.error(f"获取节点指标失败: {e}")
            return []
    
    def get_rabbitmq_health_score(self) -> float:
        """计算RabbitMQ健康度分数"""
        overview = self.get_overview_metrics()
        queues = self.get_queue_metrics()
        connections = self.get_connection_metrics()
        nodes = self.get_node_metrics()
        
        if not overview:
            return 0.0
        
        scores = []
        
        # 连接健康度 (30%权重)
        total_connections = overview.get('object_totals', {}).get('connections', 0)
        if total_connections < 100:
            connection_score = 100
        elif total_connections < 500:
            connection_score = 80
        else:
            connection_score = 50
        scores.append(connection_score * 0.3)
        
        # 队列健康度 (25%权重)
        total_queues = overview.get('object_totals', {}).get('queues', 0)
        if total_queues < 50:
            queue_score = 100
        elif total_queues < 200:
            queue_score = 85
        else:
            queue_score = 60
        scores.append(queue_score * 0.25)
        
        # 消息健康度 (25%权重)
        total_messages = overview.get('queue_totals', {}).get('messages', 0)
        if total_messages < 1000:
            message_score = 100
        elif total_messages < 10000:
            message_score = 80
        else:
            message_score = 50
        scores.append(message_score * 0.25)
        
        # 节点健康度 (20%权重)
        if nodes:
            running_nodes = sum(1 for node in nodes if node.get('running', False))
            node_health_ratio = running_nodes / len(nodes)
            node_score = node_health_ratio * 100
        else:
            node_score = 0
        scores.append(node_score * 0.2)
        
        return round(sum(scores), 2)
```

### 业务指标监控

监控业务相关的消息处理指标：

```python
class BusinessMonitor:
    """业务指标监控器"""
    
    def __init__(self):
        self.metrics_history = defaultdict(lambda: deque(maxlen=1000))
        self.performance_counter = defaultdict(int)
        self.error_counter = defaultdict(int)
    
    def record_message_processed(self, queue_name: str, processing_time: float):
        """记录消息处理"""
        timestamp = datetime.now()
        
        # 处理时间指标
        self._add_metric('message_processing_time', queue_name, processing_time, 
                        'milliseconds', timestamp)
        
        # 吞吐指标
        self._increment_counter('messages_processed', queue_name, timestamp)
    
    def record_message_failed(self, queue_name: str, error_type: str):
        """记录消息处理失败"""
        self.error_counter[f"{queue_name}:{error_type}"] += 1
    
    def get_message_throughput(self, queue_name: str, time_window_minutes: int = 5) -> float:
        """获取消息吞吐量 (消息/分钟)"""
        end_time = datetime.now()
        start_time = end_time - timedelta(minutes=time_window_minutes)
        
        messages_in_window = 0
        for metric in self.metrics_history['messages_processed']:
            if (metric.name == f"messages_processed:{queue_name}" and 
                start_time <= metric.timestamp <= end_time):
                messages_in_window += metric.value
        
        return messages_in_window / time_window_minutes
    
    def get_processing_latency(self, queue_name: str, percentile: float = 95.0) -> float:
        """获取处理延迟百分位数"""
        latencies = []
        for metric in self.metrics_history['message_processing_time']:
            if metric.name == f"message_processing_time:{queue_name}":
                latencies.append(metric.value)
        
        if not latencies:
            return 0.0
        
        latencies.sort()
        index = int(len(latencies) * percentile / 100)
        return latencies[min(index, len(latencies) - 1)]
    
    def get_error_rate(self, queue_name: str, time_window_minutes: int = 5) -> float:
        """获取错误率"""
        total_processed = self.get_message_throughput(queue_name, time_window_minutes) * time_window_minutes
        total_errors = 0
        
        for error_type, count in self.error_counter.items():
            if error_type.startswith(queue_name + ":"):
                total_errors += count
        
        if total_processed == 0:
            return 0.0
        
        return (total_errors / total_processed) * 100
    
    def get_business_health_score(self, queue_name: str) -> float:
        """计算业务健康度分数"""
        # 吞吐量分数 (40%权重)
        throughput = self.get_message_throughput(queue_name)
        throughput_score = min(throughput / 1000 * 100, 100)  # 假设1000消息/分钟为满分
        
        # 延迟分数 (30%权重)
        latency = self.get_processing_latency(queue_name, 95)
        if latency <= 100:  # <=100ms为满分
            latency_score = 100
        elif latency <= 500:
            latency_score = 80
        elif latency <= 1000:
            latency_score = 60
        else:
            latency_score = 30
        latency_score = max(0, 100 - (latency - 100) / 10)
        
        # 错误率分数 (30%权重)
        error_rate = self.get_error_rate(queue_name)
        error_score = max(0, 100 - error_rate * 10)  # 错误率每增加1%，分数减少10分
        
        business_score = (throughput_score * 0.4 + 
                         latency_score * 0.3 + 
                         error_score * 0.3)
        
        return round(business_score, 2)
    
    def _add_metric(self, metric_name: str, queue_name: str, value: float, 
                   unit: str, timestamp: datetime):
        """添加指标数据"""
        full_name = f"{metric_name}:{queue_name}"
        metric = MetricData(
            name=full_name,
            value=value,
            timestamp=timestamp,
            unit=unit,
            tags={'queue': queue_name}
        )
        self.metrics_history[full_name].append(metric)
    
    def _increment_counter(self, counter_name: str, queue_name: str, timestamp: datetime):
        """增加计数器"""
        full_name = f"{counter_name}:{queue_name}"
        self.metrics_history[full_name].append(MetricData(
            name=full_name,
            value=1,
            timestamp=timestamp,
            unit='count',
            tags={'queue': queue_name}
        ))
```

## 实时监控面板

创建综合监控面板，整合所有监控指标：

```python
class MonitoringDashboard:
    """监控面板"""
    
    def __init__(self):
        self.system_monitor = SystemMonitor()
        self.rabbitmq_monitor = RabbitMQMonitor()
        self.business_monitor = BusinessMonitor()
        self.alerts = []
        
    def collect_all_metrics(self) -> Dict[str, Any]:
        """收集所有监控指标"""
        dashboard_data = {
            'timestamp': datetime.now(),
            'system': {},
            'rabbitmq': {},
            'business': {}
        }
        
        # 系统指标
        dashboard_data['system'] = {
            'metrics': self.system_monitor.get_system_metrics(),
            'health_score': self.system_monitor.get_system_health_score(),
            'alerts': self.system_monitor.check_system_alerts()
        }
        
        # RabbitMQ指标
        dashboard_data['rabbitmq'] = {
            'overview': self.rabbitmq_monitor.get_overview_metrics(),
            'queues': self.rabbitmq_monitor.get_queue_metrics(),
            'connections': self.rabbitmq_monitor.get_connection_metrics(),
            'nodes': self.rabbitmq_monitor.get_node_metrics(),
            'health_score': self.rabbitmq_monitor.get_rabbitmq_health_score()
        }
        
        # 业务指标（示例队列）
        queue_names = ['order_queue', 'notification_queue', 'log_queue']
        business_metrics = {}
        for queue in queue_names:
            business_metrics[queue] = {
                'throughput': self.business_monitor.get_message_throughput(queue),
                'latency_p95': self.business_monitor.get_processing_latency(queue, 95),
                'error_rate': self.business_monitor.get_error_rate(queue),
                'health_score': self.business_monitor.get_business_health_score(queue)
            }
        
        dashboard_data['business'] = business_metrics
        
        return dashboard_data
    
    def generate_health_report(self) -> Dict[str, Any]:
        """生成健康报告"""
        system_health = self.system_monitor.get_system_health_score()
        rabbitmq_health = self.rabbitmq_monitor.get_rabbitmq_health_score()
        
        # 整体健康度（加权平均）
        overall_health = system_health * 0.3 + rabbitmq_health * 0.7
        
        return {
            'timestamp': datetime.now(),
            'overall_health_score': round(overall_health, 2),
            'system_health_score': system_health,
            'rabbitmq_health_score': rabbitmq_health,
            'health_level': self._get_health_level(overall_health),
            'recommendations': self._generate_recommendations()
        }
    
    def _get_health_level(self, score: float) -> str:
        """获取健康等级"""
        if score >= 90:
            return "excellent"
        elif score >= 80:
            return "good"
        elif score >= 70:
            return "fair"
        elif score >= 60:
            return "poor"
        else:
            return "critical"
    
    def _generate_recommendations(self) -> List[str]:
        """生成优化建议"""
        recommendations = []
        
        # 系统建议
        system_metrics = self.system_monitor.get_system_metrics()
        if system_metrics['cpu_percent'] > 70:
            recommendations.append("CPU使用率偏高，建议优化RabbitMQ配置或增加服务器资源")
        
        if system_metrics['memory_percent'] > 80:
            recommendations.append("内存使用率过高，建议增加内存或优化RabbitMQ内存设置")
        
        # RabbitMQ建议
        queue_metrics = self.rabbitmq_monitor.get_queue_metrics()
        for queue in queue_metrics:
            if queue.get('messages', 0) > 10000:
                recommendations.append(f"队列 {queue.get('name', 'unknown')} 消息积压严重，建议增加消费者数量")
        
        return recommendations
```

## 告警系统

实现完善的告警机制：

```python
class AlertManager:
    """告警管理器"""
    
    def __init__(self):
        self.alert_rules = []
        self.alert_handlers = []
        self.active_alerts = {}
        self.alert_history = []
    
    def add_alert_rule(self, rule: Dict[str, Any]):
        """添加告警规则"""
        self.alert_rules.append({
            'name': rule['name'],
            'metric': rule['metric'],
            'condition': rule['condition'],  # '>', '<', '>=', '<='
            'threshold': rule['threshold'],
            'level': AlertLevel(rule['level']),
            'description': rule['description'],
            'enabled': rule.get('enabled', True)
        })
    
    def add_alert_handler(self, handler_func):
        """添加告警处理器"""
        self.alert_handlers.append(handler_func)
    
    def evaluate_alerts(self, metrics: Dict[str, float]) -> List[Alert]:
        """评估告警"""
        new_alerts = []
        
        for rule in self.alert_rules:
            if not rule['enabled']:
                continue
            
            metric_value = metrics.get(rule['metric'])
            if metric_value is None:
                continue
            
            # 检查告警条件
            triggered = False
            if rule['condition'] == '>' and metric_value > rule['threshold']:
                triggered = True
            elif rule['condition'] == '<' and metric_value < rule['threshold']:
                triggered = True
            elif rule['condition'] == '>=' and metric_value >= rule['threshold']:
                triggered = True
            elif rule['condition'] == '<=' and metric_value <= rule['threshold']:
                triggered = True
            
            if triggered:
                alert = Alert(
                    level=rule['level'],
                    title=rule['name'],
                    message=rule['description'].format(value=metric_value, threshold=rule['threshold']),
                    metric_name=rule['metric'],
                    current_value=metric_value,
                    threshold=rule['threshold'],
                    timestamp=datetime.now()
                )
                
                # 检查是否是重复告警
                alert_key = f"{rule['metric']}:{rule['name']}"
                if alert_key not in self.active_alerts:
                    self.active_alerts[alert_key] = alert
                    new_alerts.append(alert)
                    self.alert_history.append(alert)
            
            else:
                # 告警恢复
                alert_key = f"{rule['metric']}:{rule['name']}"
                if alert_key in self.active_alerts:
                    # 创建恢复告警
                    recovery_alert = Alert(
                        level=AlertLevel.INFO,
                        title=f"{rule['name']} - 已恢复",
                        message=f"{rule['name']} 已恢复正常",
                        metric_name=rule['metric'],
                        current_value=metric_value,
                        threshold=rule['threshold'],
                        timestamp=datetime.now()
                    )
                    new_alerts.append(recovery_alert)
                    del self.active_alerts[alert_key]
        
        # 处理告警
        for alert in new_alerts:
            self._process_alert(alert)
        
        return new_alerts
    
    def _process_alert(self, alert: Alert):
        """处理告警"""
        for handler in self.alert_handlers:
            try:
                handler(alert)
            except Exception as e:
                logging.error(f"告警处理器执行失败: {e}")
    
    def send_email_alert(self, alert: Alert):
        """发送邮件告警"""
        if alert.level == AlertLevel.CRITICAL:
            # 这里实现邮件发送逻辑
            logging.critical(f"邮件告警: {alert.title} - {alert.message}")
    
    def send_webhook_alert(self, alert: Alert):
        """发送Webhook告警"""
        if alert.level in [AlertLevel.CRITICAL, AlertLevel.WARNING]:
            # 这里实现Webhook发送逻辑
            webhook_data = {
                'title': alert.title,
                'message': alert.message,
                'level': alert.level.value,
                'timestamp': alert.timestamp.isoformat(),
                'metric': alert.metric_name,
                'value': alert.current_value,
                'threshold': alert.threshold
            }
            logging.warning(f"Webhook告警: {webhook_data}")
    
    def get_alert_statistics(self) -> Dict[str, Any]:
        """获取告警统计"""
        total_alerts = len(self.alert_history)
        critical_alerts = sum(1 for alert in self.alert_history if alert.level == AlertLevel.CRITICAL)
        warning_alerts = sum(1 for alert in self.alert_history if alert.level == AlertLevel.WARNING)
        
        return {
            'total_alerts': total_alerts,
            'critical_alerts': critical_alerts,
            'warning_alerts': warning_alerts,
            'active_alerts': len(self.active_alerts),
            'alert_frequency': total_alerts / max(1, (datetime.now() - self._get_first_alert_time()).days)
        }
    
    def _get_first_alert_time(self) -> datetime:
        """获取首次告警时间"""
        if self.alert_history:
            return self.alert_history[0].timestamp
        return datetime.now()
```

## 日志管理

实现集中的日志管理：

```python
import logging
from logging.handlers import RotatingFileHandler
import json
from datetime import datetime
from pathlib import Path

class LogManager:
    """日志管理器"""
    
    def __init__(self, log_dir: str = "logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # 配置RabbitMQ相关日志
        self.setup_rabbitmq_logging()
        
    def setup_rabbitmq_logging(self):
        """设置RabbitMQ日志"""
        # RabbitMQ连接日志
        self.connection_logger = logging.getLogger('rabbitmq.connection')
        self.connection_logger.setLevel(logging.INFO)
        
        connection_handler = RotatingFileHandler(
            self.log_dir / 'rabbitmq_connection.log',
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )
        connection_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        connection_handler.setFormatter(connection_formatter)
        self.connection_logger.addHandler(connection_handler)
        
        # 消息处理日志
        self.message_logger = logging.getLogger('rabbitmq.messages')
        self.message_logger.setLevel(logging.INFO)
        
        message_handler = RotatingFileHandler(
            self.log_dir / 'rabbitmq_messages.log',
            maxBytes=20*1024*1024,  # 20MB
            backupCount=10
        )
        message_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'
        )
        message_handler.setFormatter(message_formatter)
        self.message_logger.addHandler(message_handler)
        
        # 性能监控日志
        self.performance_logger = logging.getLogger('rabbitmq.performance')
        self.performance_logger.setLevel(logging.INFO)
        
        performance_handler = RotatingFileHandler(
            self.log_dir / 'rabbitmq_performance.log',
            maxBytes=50*1024*1024,  # 50MB
            backupCount=5
        )
        performance_handler.setFormatter(message_formatter)
        self.performance_logger.addHandler(performance_handler)
    
    def log_message_event(self, event_type: str, queue_name: str, message_id: str, 
                         processing_time: float = None, success: bool = True, 
                         error_message: str = None):
        """记录消息事件"""
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'event_type': event_type,
            'queue_name': queue_name,
            'message_id': message_id,
            'processing_time_ms': processing_time,
            'success': success,
            'error_message': error_message
        }
        
        if success:
            self.message_logger.info(f"Message Event: {json.dumps(log_data)}")
        else:
            self.message_logger.error(f"Message Event: {json.dumps(log_data)}")
    
    def log_performance_metric(self, metric_name: str, value: float, 
                             tags: Dict[str, str] = None):
        """记录性能指标"""
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'metric_name': metric_name,
            'value': value,
            'tags': tags or {}
        }
        
        self.performance_logger.info(f"Performance Metric: {json.dumps(log_data)}")
    
    def log_system_alert(self, alert_type: str, message: str, severity: str):
        """记录系统告警"""
        log_data = {
            'timestamp': datetime.now().isoformat(),
            'alert_type': alert_type,
            'message': message,
            'severity': severity
        }
        
        if severity == 'critical':
            logging.critical(f"System Alert: {json.dumps(log_data)}")
        elif severity == 'warning':
            logging.warning(f"System Alert: {json.dumps(log_data)}")
        else:
            logging.info(f"System Alert: {json.dumps(log_data)}")
```

## 性能分析与诊断

实现性能问题诊断工具：

```python
class PerformanceAnalyzer:
    """性能分析器"""
    
    def __init__(self, monitor: MonitoringDashboard):
        self.monitor = monitor
        
    def analyze_performance_bottleneck(self) -> Dict[str, Any]:
        """分析性能瓶颈"""
        dashboard_data = self.monitor.collect_all_metrics()
        bottlenecks = []
        
        # 系统资源分析
        system_metrics = dashboard_data['system']['metrics']
        
        if system_metrics['cpu_percent'] > 80:
            bottlenecks.append({
                'type': 'cpu',
                'severity': 'high',
                'description': 'CPU使用率过高',
                'current_value': system_metrics['cpu_percent'],
                'recommendation': '优化消息处理逻辑或增加CPU资源'
            })
        
        if system_metrics['memory_percent'] > 85:
            bottlenecks.append({
                'type': 'memory',
                'severity': 'high',
                'description': '内存使用率过高',
                'current_value': system_metrics['memory_percent'],
                'recommendation': '增加内存或优化RabbitMQ内存配置'
            })
        
        # RabbitMQ队列分析
        queue_metrics = dashboard_data['rabbitmq']['queues']
        for queue in queue_metrics:
            queue_name = queue.get('name', 'unknown')
            messages = queue.get('messages', 0)
            
            if messages > 5000:
                bottlenecks.append({
                    'type': 'queue_backlog',
                    'severity': 'medium',
                    'description': f'队列 {queue_name} 消息积压严重',
                    'current_value': messages,
                    'recommendation': f'增加队列 {queue_name} 的消费者数量'
                })
        
        # 业务指标分析
        business_metrics = dashboard_data['business']
        for queue_name, metrics in business_metrics.items():
            latency = metrics.get('latency_p95', 0)
            if latency > 1000:  # >1秒
                bottlenecks.append({
                    'type': 'high_latency',
                    'severity': 'medium',
                    'description': f'队列 {queue_name} 处理延迟过高',
                    'current_value': latency,
                    'recommendation': f'优化队列 {queue_name} 的消息处理逻辑'
                })
            
            error_rate = metrics.get('error_rate', 0)
            if error_rate > 5:  # >5%
                bottlenecks.append({
                    'type': 'high_error_rate',
                    'severity': 'high',
                    'description': f'队列 {queue_name} 错误率过高',
                    'current_value': error_rate,
                    'recommendation': f'检查队列 {queue_name} 的错误处理机制'
                })
        
        return {
            'analysis_time': datetime.now(),
            'bottlenecks': bottlenecks,
            'total_bottlenecks': len(bottlenecks),
            'severity_distribution': self._get_severity_distribution(bottlenecks)
        }
    
    def _get_severity_distribution(self, bottlenecks: List[Dict]) -> Dict[str, int]:
        """获取瓶颈严重程度分布"""
        distribution = {'high': 0, 'medium': 0, 'low': 0}
        for bottleneck in bottlenecks:
            distribution[bottleneck['severity']] += 1
        return distribution
    
    def generate_performance_report(self, time_range_hours: int = 24) -> Dict[str, Any]:
        """生成性能报告"""
        dashboard_data = self.monitor.collect_all_metrics()
        bottleneck_analysis = self.analyze_performance_bottleneck()
        
        # 计算性能趋势
        performance_trend = self._calculate_performance_trend(time_range_hours)
        
        # 生成建议
        recommendations = self._generate_optimization_recommendations(bottleneck_analysis)
        
        return {
            'report_time': datetime.now(),
            'time_range_hours': time_range_hours,
            'system_health': dashboard_data['system']['health_score'],
            'rabbitmq_health': dashboard_data['rabbitmq']['health_score'],
            'performance_trend': performance_trend,
            'bottleneck_analysis': bottleneck_analysis,
            'recommendations': recommendations,
            'key_metrics': self._extract_key_metrics(dashboard_data)
        }
    
    def _calculate_performance_trend(self, hours: int) -> Dict[str, str]:
        """计算性能趋势"""
        # 这里可以实现更复杂的趋势分析逻辑
        return {
            'throughput_trend': 'stable',
            'latency_trend': 'improving',
            'error_rate_trend': 'stable',
            'system_load_trend': 'increasing'
        }
    
    def _generate_optimization_recommendations(self, bottleneck_analysis: Dict) -> List[str]:
        """生成优化建议"""
        recommendations = []
        
        bottlenecks = bottleneck_analysis['bottlenecks']
        
        high_severity_bottlenecks = [b for b in bottlenecks if b['severity'] == 'high']
        
        if high_severity_bottlenecks:
            recommendations.append("优先处理高严重性性能瓶颈")
        
        # 根据瓶颈类型生成具体建议
        bottleneck_types = [b['type'] for b in bottlenecks]
        
        if 'cpu' in bottleneck_types:
            recommendations.append("考虑CPU升级或优化消息处理算法")
        
        if 'memory' in bottleneck_types:
            recommendations.append("增加内存容量或调整RabbitMQ内存配置")
        
        if 'queue_backlog' in bottleneck_types:
            recommendations.append("增加消费者实例或优化消息处理速度")
        
        if 'high_latency' in bottleneck_types:
            recommendations.append("优化消息处理逻辑，减少计算复杂度")
        
        if 'high_error_rate' in bottleneck_types:
            recommendations.append("加强错误处理和重试机制")
        
        return recommendations
    
    def _extract_key_metrics(self, dashboard_data: Dict) -> Dict[str, float]:
        """提取关键指标"""
        return {
            'system_cpu_percent': dashboard_data['system']['metrics']['cpu_percent'],
            'system_memory_percent': dashboard_data['system']['metrics']['memory_percent'],
            'total_messages': dashboard_data['rabbitmq']['overview'].get('queue_totals', {}).get('messages', 0),
            'total_connections': dashboard_data['rabbitmq']['overview'].get('object_totals', {}).get('connections', 0),
            'avg_queue_throughput': sum(
                metrics['throughput'] for metrics in dashboard_data['business'].values()
            ) / max(1, len(dashboard_data['business']))
        }
```

## 运维自动化

实现自动化运维功能：

```python
class AutoOperationManager:
    """自动化运维管理器"""
    
    def __init__(self, monitor: MonitoringDashboard, alert_manager: AlertManager):
        self.monitor = monitor
        self.alert_manager = alert_manager
        self.operation_rules = []
        self.is_running = False
        
    def add_operation_rule(self, rule: Dict[str, Any]):
        """添加自动化运维规则"""
        self.operation_rules.append({
            'name': rule['name'],
            'condition': rule['condition'],
            'action': rule['action'],
            'threshold': rule['threshold'],
            'cooldown_minutes': rule.get('cooldown_minutes', 5),
            'enabled': rule.get('enabled', True),
            'last_triggered': None
        })
    
    def start_auto_operation(self):
        """启动自动化运维"""
        self.is_running = True
        while self.is_running:
            try:
                self._check_and_execute_operations()
                time.sleep(30)  # 每30秒检查一次
            except Exception as e:
                logging.error(f"自动化运维执行失败: {e}")
    
    def stop_auto_operation(self):
        """停止自动化运维"""
        self.is_running = False
    
    def _check_and_execute_operations(self):
        """检查并执行运维操作"""
        dashboard_data = self.monitor.collect_all_metrics()
        
        for rule in self.operation_rules:
            if not rule['enabled']:
                continue
            
            # 检查冷却时间
            if rule['last_triggered']:
                time_since_last = (datetime.now() - rule['last_triggered']).total_seconds() / 60
                if time_since_last < rule['cooldown_minutes']:
                    continue
            
            # 检查触发条件
            if self._check_condition(rule['condition'], dashboard_data, rule['threshold']):
                self._execute_action(rule['action'], rule)
                rule['last_triggered'] = datetime.now()
                
                # 发送通知
                self._send_operation_notification(rule)
    
    def _check_condition(self, condition: str, dashboard_data: Dict, threshold: float) -> bool:
        """检查触发条件"""
        system_health = dashboard_data['system']['health_score']
        rabbitmq_health = dashboard_data['rabbitmq']['health_score']
        
        if condition == 'system_health_below':
            return system_health < threshold
        elif condition == 'rabbitmq_health_below':
            return rabbitmq_health < threshold
        elif condition == 'queue_backlog_high':
            queues = dashboard_data['rabbitmq']['queues']
            return any(queue.get('messages', 0) > threshold for queue in queues)
        elif condition == 'error_rate_high':
            business_metrics = dashboard_data['business']
            return any(
                metrics.get('error_rate', 0) > threshold 
                for metrics in business_metrics.values()
            )
        
        return False
    
    def _execute_action(self, action: str, rule: Dict[str, Any]):
        """执行运维操作"""
        if action == 'scale_up_consumers':
            self._scale_up_consumers()
        elif action == 'restart_rabbitmq_service':
            self._restart_rabbitmq_service()
        elif action == 'clear_queue_backlog':
            self._clear_queue_backlog()
        elif action == 'increase_memory_limit':
            self._increase_memory_limit()
        elif action == 'send_alert':
            self._send_alert_notification(rule)
    
    def _scale_up_consumers(self):
        """扩展消费者"""
        logging.info("自动运维：扩展消费者实例")
        # 这里实现消费者扩容逻辑
    
    def _restart_rabbitmq_service(self):
        """重启RabbitMQ服务"""
        logging.warning("自动运维：重启RabbitMQ服务")
        # 这里实现服务重启逻辑
    
    def _clear_queue_backlog(self):
        """清理队列积压"""
        logging.info("自动运维：清理队列积压")
        # 这里实现队列清理逻辑
    
    def _increase_memory_limit(self):
        """增加内存限制"""
        logging.info("自动运维：增加内存限制")
        # 这里实现内存配置调整逻辑
    
    def _send_alert_notification(self, rule: Dict[str, Any]):
        """发送告警通知"""
        alert = Alert(
            level=AlertLevel.CRITICAL,
            title=f"自动运维触发: {rule['name']}",
            message=f"运维规则 {rule['name']} 已自动执行",
            metric_name="auto_operation",
            current_value=0,
            threshold=0,
            timestamp=datetime.now()
        )
        self.alert_manager._process_alert(alert)
    
    def _send_operation_notification(self, rule: Dict[str, Any]):
        """发送运维操作通知"""
        logging.info(f"运维操作执行: {rule['name']} - {rule['action']}")
```

## 监控最佳实践

### 监控配置建议

1. **合理设置监控频率**
   - 关键指标：每30秒采集一次
   - 一般指标：每5分钟采集一次
   - 历史数据：每小时聚合一次

2. **告警阈值设置**
   - 告警阈值应该是历史数据的95%分位数
   - 避免误报，设置合理的缓冲区间
   - 不同级别使用不同的阈值

3. **监控数据存储**
   - 实时数据：保留24小时
   - 聚合数据：保留30天
   - 历史数据：保留1年

### 运维流程标准化

1. **日常巡检流程**
   - 检查系统健康度
   - 查看告警列表
   - 分析性能趋势
   - 更新运维日志

2. **故障处理流程**
   - 告警响应时间：紧急5分钟，严重15分钟
   - 问题诊断时间：紧急30分钟，严重2小时
   - 故障恢复时间：紧急1小时，严重4小时

3. **性能优化流程**
   - 定期性能基准测试
   - 瓶颈分析报告
   - 优化方案评审
   - 优化效果验证

## 实战案例

### 案例1：消息积压处理

```python
class QueueBacklogHandler:
    """队列积压处理工具"""
    
    def __init__(self, rabbitmq_monitor: RabbitMQMonitor):
        self.rabbitmq_monitor = rabbitmq_monitor
    
    def analyze_queue_backlog(self) -> Dict[str, Any]:
        """分析队列积压情况"""
        queues = self.rabbitmq_monitor.get_queue_metrics()
        backlog_analysis = {}
        
        for queue in queues:
            queue_name = queue.get('name')
            messages = queue.get('messages', 0)
            consumers = queue.get('consumers', 0)
            
            if messages > 1000:  # 积压阈值
                # 计算积压时间估算
                if consumers > 0:
                    # 假设每秒处理10条消息
                    estimated_processing_time = messages / (consumers * 10)
                else:
                    estimated_processing_time = float('inf')
                
                backlog_analysis[queue_name] = {
                    'backlog_size': messages,
                    'consumer_count': consumers,
                    'estimated_processing_hours': round(estimated_processing_time / 3600, 2),
                    'urgency': self._get_backlog_urgency(messages, consumers)
                }
        
        return backlog_analysis
    
    def suggest_solutions(self, queue_name: str, backlog_info: Dict[str, Any]) -> List[str]:
        """建议解决方案"""
        solutions = []
        
        backlog_size = backlog_info['backlog_size']
        consumer_count = backlog_info['consumer_count']
        
        if consumer_count == 0:
            solutions.append("立即增加消费者实例")
        elif backlog_size > consumer_count * 100:
            solutions.append("大幅增加消费者数量")
        elif backlog_size > consumer_count * 50:
            solutions.append("适度增加消费者数量")
        
        if 'estimated_processing_hours' in backlog_info:
            processing_hours = backlog_info['estimated_processing_hours']
            if processing_hours > 2:
                solutions.append("考虑临时扩展RabbitMQ集群资源")
        
        solutions.append("检查消费者处理逻辑，优化处理速度")
        solutions.append("设置队列消息TTL，自动清理过期消息")
        
        return solutions
    
    def _get_backlog_urgency(self, backlog_size: int, consumer_count: int) -> str:
        """获取积压紧急程度"""
        if backlog_size > 10000:
            return "critical"
        elif backlog_size > 5000:
            return "high"
        elif backlog_size > 1000:
            return "medium"
        else:
            return "low"
```

这个第9章的监控与运维文档涵盖了：

1. **监控架构概述** - 三层监控体系架构
2. **监控指标体系** - 系统、RabbitMQ和业务指标监控
3. **实时监控面板** - 综合监控面板实现
4. **告警系统** - 完善的告警机制
5. **日志管理** - 集中化日志管理
6. **性能分析与诊断** - 性能瓶颈分析工具
7. **运维自动化** - 自动化运维管理器
8. **监控最佳实践** - 配置建议和运维流程
9. **实战案例** - 队列积压处理案例

这些内容为RabbitMQ的生产环境监控与运维提供了全面的指导和实践工具。