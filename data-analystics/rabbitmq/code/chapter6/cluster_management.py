#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RabbitMQé›†ç¾¤ç®¡ç†ä¸é…ç½®æ¼”ç¤º

è¿™ä¸ªæ¨¡å—å±•ç¤ºäº†å¦‚ä½•åœ¨Pythonä¸­ç®¡ç†RabbitMQé›†ç¾¤ï¼š
- é›†ç¾¤èŠ‚ç‚¹è¿æ¥ç®¡ç†
- é•œåƒé˜Ÿåˆ—é…ç½®
- è´Ÿè½½å‡è¡¡ç­–ç•¥
- æ•…éšœæ£€æµ‹ä¸æ¢å¤
- æ€§èƒ½ç›‘æ§
"""

import pika
import time
import json
import threading
from datetime import datetime
from typing import List, Dict, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ClusterNode:
    """é›†ç¾¤èŠ‚ç‚¹ä¿¡æ¯ç±»"""
    
    def __init__(self, hostname: str, port: int = 5672, is_master: bool = False):
        self.hostname = hostname
        self.port = port
        self.is_master = is_master
        self.connection = None
        self.channel = None
        self.is_connected = False
        self.last_heartbeat = None
        self.message_count = 0
        self.consumer_count = 0
    
    def connect(self, username: str = 'admin', password: str = 'admin123') -> bool:
        """è¿æ¥èŠ‚ç‚¹"""
        try:
            credentials = pika.PlainCredentials(username, password)
            connection_params = pika.ConnectionParameters(
                host=self.hostname,
                port=self.port,
                credentials=credentials,
                heartbeat=30,
                connection_attempts=3,
                retry_delay=5
            )
            
            self.connection = pika.BlockingConnection(connection_params)
            self.channel = self.connection.channel()
            self.is_connected = True
            self.last_heartbeat = datetime.now()
            
            logger.info(f"âœ… æˆåŠŸè¿æ¥åˆ°èŠ‚ç‚¹: {self.hostname}:{self.port}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ è¿æ¥åˆ°èŠ‚ç‚¹å¤±è´¥ {self.hostname}: {e}")
            self.is_connected = False
            return False
    
    def disconnect(self):
        """æ–­å¼€èŠ‚ç‚¹è¿æ¥"""
        if self.connection and not self.connection.is_closed:
            self.connection.close()
            self.is_connected = False
            logger.info(f"ğŸ”Œ æ–­å¼€èŠ‚ç‚¹è¿æ¥: {self.hostname}")
    
    def get_queue_stats(self, queue_name: str) -> Dict:
        """è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        if not self.is_connected:
            return {}
        
        try:
            # å£°æ˜é˜Ÿåˆ—ä»¥è·å–ç»Ÿè®¡ä¿¡æ¯
            result = self.channel.queue_declare(queue=queue_name, passive=True)
            
            stats = {
                'queue': queue_name,
                'messages': result.method.message_count,
                'consumers': result.method.consumer_count,
                'node': self.hostname,
                'timestamp': datetime.now().isoformat()
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ è·å–é˜Ÿåˆ—ç»Ÿè®¡å¤±è´¥ {self.hostname}: {e}")
            return {}
    
    def create_mirrored_queue(self, queue_name: str, ha_policy: str = 'all') -> bool:
        """åˆ›å»ºé•œåƒé˜Ÿåˆ—"""
        if not self.is_connected:
            return False
        
        try:
            arguments = {
                'x-ha-policy': ha_policy,
                'x-ha-sync-batch-size': 100
            }
            
            self.channel.queue_declare(
                queue=queue_name,
                durable=True,
                arguments=arguments
            )
            
            logger.info(f"âœ… é•œåƒé˜Ÿåˆ—åˆ›å»ºæˆåŠŸ: {queue_name} on {self.hostname}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºé•œåƒé˜Ÿåˆ—å¤±è´¥ {self.hostname}: {e}")
            return False

class RabbitMQClusterManager:
    """RabbitMQé›†ç¾¤ç®¡ç†å™¨"""
    
    def __init__(self, nodes: List[str], cluster_name: str = "rabbitmq-cluster"):
        self.nodes = [ClusterNode(node) for node in nodes]
        self.cluster_name = cluster_name
        self.mirror_queues = []
        self.connections = {}
        self.monitoring_active = False
        self.heartbeat_interval = 30
        
    def connect_all_nodes(self, username: str = 'admin', password: str = 'admin123') -> Dict[str, bool]:
        """è¿æ¥åˆ°æ‰€æœ‰é›†ç¾¤èŠ‚ç‚¹"""
        results = {}
        threads = []
        
        def connect_node(node):
            results[node.hostname] = node.connect(username, password)
        
        # å¹¶è¡Œè¿æ¥æ‰€æœ‰èŠ‚ç‚¹
        for node in self.nodes:
            thread = threading.Thread(target=connect_node, args=(node,))
            thread.start()
            threads.append(thread)
        
        # ç­‰å¾…æ‰€æœ‰è¿æ¥å®Œæˆ
        for thread in threads:
            thread.join()
        
        successful_nodes = sum(results.values())
        logger.info(f"ğŸ“Š é›†ç¾¤è¿æ¥ç»“æœ: {successful_nodes}/{len(self.nodes)} èŠ‚ç‚¹è¿æ¥æˆåŠŸ")
        
        return results
    
    def setup_cluster(self, queue_name: str, ha_policy: str = 'all') -> bool:
        """è®¾ç½®é›†ç¾¤é•œåƒé˜Ÿåˆ—"""
        if not self.nodes:
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„é›†ç¾¤èŠ‚ç‚¹")
            return False
        
        # åœ¨ç¬¬ä¸€ä¸ªèŠ‚ç‚¹ä¸Šåˆ›å»ºé•œåƒé˜Ÿåˆ—
        master_node = self.nodes[0]
        if master_node.is_connected:
            success = master_node.create_mirrored_queue(queue_name, ha_policy)
            if success:
                self.mirror_queues.append(queue_name)
                logger.info(f"âœ… é›†ç¾¤é•œåƒé˜Ÿåˆ—è®¾ç½®å®Œæˆ: {queue_name}")
            return success
        
        return False
    
    def publish_to_cluster(self, queue_name: str, messages: List[str], 
                          exchange: str = '') -> bool:
        """å‘é›†ç¾¤å‘å¸ƒæ¶ˆæ¯"""
        # é€‰æ‹©å½“å‰å¯ç”¨çš„èŠ‚ç‚¹
        available_nodes = [node for node in self.nodes if node.is_connected]
        if not available_nodes:
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„é›†ç¾¤èŠ‚ç‚¹")
            return False
        
        # ä½¿ç”¨ä¸»èŠ‚ç‚¹å‘å¸ƒæ¶ˆæ¯
        master_node = available_nodes[0]
        
        try:
            for i, message in enumerate(messages):
                properties = pika.BasicProperties(
                    delivery_mode=2,  # æŒä¹…åŒ–
                    message_id=f"msg-{i}",
                    timestamp=int(time.time())
                )
                
                master_node.channel.basic_publish(
                    exchange=exchange,
                    routing_key=queue_name,
                    body=json.dumps(message),
                    properties=properties
                )
                
                master_node.message_count += 1
                logger.info(f"ğŸ“¤ å‘å¸ƒæ¶ˆæ¯åˆ°é›†ç¾¤: {message}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å‘å¸ƒæ¶ˆæ¯åˆ°é›†ç¾¤å¤±è´¥: {e}")
            return False
    
    def consume_from_cluster(self, queue_name: str, max_messages: int = 10):
        """ä»é›†ç¾¤æ¶ˆè´¹æ¶ˆæ¯"""
        available_nodes = [node for node in self.nodes if node.is_connected]
        if not available_nodes:
            logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„é›†ç¾¤èŠ‚ç‚¹")
            return
        
        # ä½¿ç”¨æ¶ˆè´¹è€…èŠ‚ç‚¹
        consumer_node = available_nodes[-1]  # é€‰æ‹©æœ€åä¸€ä¸ªå¯ç”¨èŠ‚ç‚¹
        
        def callback(ch, method, properties, body):
            try:
                message_data = json.loads(body.decode())
                logger.info(f"ğŸ“¥ æ¶ˆè´¹æ¶ˆæ¯: {message_data}")
                
                # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†
                time.sleep(0.1)
                
                ch.basic_ack(delivery_tag=method.delivery_tag)
                
            except Exception as e:
                logger.error(f"âŒ å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
        
        # è®¾ç½®QOSå’Œæ‰‹åŠ¨ç¡®è®¤
        consumer_node.channel.basic_qos(prefetch_count=1)
        
        # å¼€å§‹æ¶ˆè´¹
        consumer_node.channel.basic_consume(
            queue=queue_name,
            on_message_callback=callback,
            auto_ack=False
        )
        
        logger.info(f"ğŸ‘¥ å¼€å§‹ä»é›†ç¾¤æ¶ˆè´¹æ¶ˆæ¯: {queue_name}")
        
        try:
            # æ¶ˆè´¹æŒ‡å®šæ•°é‡çš„æ¶ˆæ¯
            message_count = 0
            while message_count < max_messages:
                consumer_node.channel.connection.process_data_events(time_limit=1)
                if not consumer_node.channel._consumer_tags:
                    break
                message_count += 1
            
        except KeyboardInterrupt:
            logger.info("â¹ï¸  ç”¨æˆ·ä¸­æ–­æ¶ˆè´¹")
        finally:
            consumer_node.channel.stop_consuming()
    
    def get_cluster_status(self) -> Dict:
        """è·å–é›†ç¾¤çŠ¶æ€"""
        status = {
            'cluster_name': self.cluster_name,
            'total_nodes': len(self.nodes),
            'connected_nodes': 0,
            'nodes': [],
            'mirror_queues': self.mirror_queues,
            'total_messages': 0,
            'timestamp': datetime.now().isoformat()
        }
        
        for node in self.nodes:
            node_status = {
                'hostname': node.hostname,
                'is_connected': node.is_connected,
                'is_master': node.is_master,
                'message_count': node.message_count,
                'consumer_count': node.consumer_count,
                'last_heartbeat': node.last_heartbeat.isoformat() if node.last_heartbeat else None
            }
            
            if node.is_connected:
                status['connected_nodes'] += 1
                status['total_messages'] += node.message_count
            
            status['nodes'].append(node_status)
        
        return status
    
    def monitor_cluster_health(self, duration: int = 300):
        """ç›‘æ§é›†ç¾¤å¥åº·çŠ¶æ€"""
        logger.info(f"ğŸ” å¼€å§‹é›†ç¾¤å¥åº·ç›‘æ§ (æŒç»­ {duration} ç§’)")
        self.monitoring_active = True
        
        start_time = time.time()
        health_logs = []
        
        while self.monitoring_active and (time.time() - start_time) < duration:
            try:
                # è·å–å½“å‰é›†ç¾¤çŠ¶æ€
                cluster_status = self.get_cluster_status()
                
                # æ£€æŸ¥èŠ‚ç‚¹å¥åº·
                unhealthy_nodes = []
                for node_info in cluster_status['nodes']:
                    if not node_info['is_connected']:
                        unhealthy_nodes.append(node_info['hostname'])
                
                # è®°å½•å¥åº·çŠ¶æ€
                health_log = {
                    'timestamp': datetime.now().isoformat(),
                    'connected_nodes': cluster_status['connected_nodes'],
                    'total_nodes': cluster_status['total_nodes'],
                    'unhealthy_nodes': unhealthy_nodes,
                    'total_messages': cluster_status['total_messages']
                }
                
                health_logs.append(health_log)
                
                # è¾“å‡ºçŠ¶æ€æ‘˜è¦
                logger.info(f"ğŸ“Š é›†ç¾¤çŠ¶æ€: {cluster_status['connected_nodes']}/{cluster_status['total_nodes']} èŠ‚ç‚¹åœ¨çº¿")
                
                if unhealthy_nodes:
                    logger.warning(f"âš ï¸  ä¸å¥åº·èŠ‚ç‚¹: {unhealthy_nodes}")
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
                time.sleep(self.heartbeat_interval)
                
            except Exception as e:
                logger.error(f"âŒ é›†ç¾¤ç›‘æ§å¼‚å¸¸: {e}")
                time.sleep(5)
        
        self.monitoring_active = False
        logger.info("ğŸ é›†ç¾¤å¥åº·ç›‘æ§ç»“æŸ")
        
        return health_logs
    
    def perform_failover_test(self, target_node_hostname: str):
        """æ‰§è¡Œæ•…éšœè½¬ç§»æµ‹è¯•"""
        logger.info(f"ğŸ§ª å¼€å§‹æ•…éšœè½¬ç§»æµ‹è¯•ï¼Œç›®æ ‡èŠ‚ç‚¹: {target_node_hostname}")
        
        # æŸ¥æ‰¾ç›®æ ‡èŠ‚ç‚¹
        target_node = next((node for node in self.nodes if node.hostname == target_node_hostname), None)
        if not target_node:
            logger.error(f"âŒ æœªæ‰¾åˆ°ç›®æ ‡èŠ‚ç‚¹: {target_node_hostname}")
            return False
        
        # è®°å½•åˆå§‹çŠ¶æ€
        initial_status = self.get_cluster_status()
        logger.info(f"ğŸ“Š åˆå§‹é›†ç¾¤çŠ¶æ€: {initial_status}")
        
        # æ¨¡æ‹ŸèŠ‚ç‚¹æ•…éšœ - æ–­å¼€ç›®æ ‡èŠ‚ç‚¹è¿æ¥
        logger.info(f"ğŸ’¥ æ¨¡æ‹ŸèŠ‚ç‚¹æ•…éšœ: {target_node_hostname}")
        target_node.disconnect()
        
        # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©é›†ç¾¤æ£€æµ‹åˆ°æ•…éšœ
        time.sleep(10)
        
        # æ£€æŸ¥æ•…éšœåçš„çŠ¶æ€
        failover_status = self.get_cluster_status()
        logger.info(f"ğŸ“Š æ•…éšœè½¬ç§»åçŠ¶æ€: {failover_status}")
        
        # æ¢å¤èŠ‚ç‚¹è¿æ¥
        logger.info(f"ğŸ”§ æ¢å¤èŠ‚ç‚¹è¿æ¥: {target_node_hostname}")
        reconnected = target_node.connect()
        
        if reconnected:
            logger.info("âœ… æ•…éšœè½¬ç§»æµ‹è¯•æˆåŠŸ")
            return True
        else:
            logger.error("âŒ æ•…éšœè½¬ç§»æµ‹è¯•å¤±è´¥")
            return False
    
    def optimize_cluster_performance(self):
        """ä¼˜åŒ–é›†ç¾¤æ€§èƒ½"""
        logger.info("âš¡ å¼€å§‹é›†ç¾¤æ€§èƒ½ä¼˜åŒ–")
        
        optimizations = []
        
        for node in self.nodes:
            if node.is_connected:
                try:
                    # è®¾ç½®prefetch countä¼˜åŒ–
                    node.channel.basic_qos(prefetch_count=100)
                    optimizations.append(f"è®¾ç½® {node.hostname} prefetch_count=100")
                    
                    # å¯ç”¨publisher confirms
                    node.channel.confirm_delivery()
                    optimizations.append(f"å¯ç”¨ {node.hostname} publisher confirms")
                    
                    # è®¾ç½®ack timeout
                    node.connection.heartbeat = 30
                    optimizations.append(f"è®¾ç½® {node.hostname} heartbeat=30")
                    
                except Exception as e:
                    logger.error(f"âŒ èŠ‚ç‚¹æ€§èƒ½ä¼˜åŒ–å¤±è´¥ {node.hostname}: {e}")
        
        logger.info(f"âœ… é›†ç¾¤æ€§èƒ½ä¼˜åŒ–å®Œæˆ: {optimizations}")
        return optimizations
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†é›†ç¾¤èµ„æº...")
        
        for node in self.nodes:
            node.disconnect()
        
        self.monitoring_active = False
        logger.info("âœ… é›†ç¾¤èµ„æºæ¸…ç†å®Œæˆ")

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºé›†ç¾¤ç®¡ç†åŠŸèƒ½"""
    
    # é›†ç¾¤èŠ‚ç‚¹é…ç½®
    cluster_nodes = [
        'rabbitmq-node1',  # ä¸»èŠ‚ç‚¹
        'rabbitmq-node2',  # ä»èŠ‚ç‚¹1
        'rabbitmq-node3'   # ä»èŠ‚ç‚¹2
    ]
    
    # åˆ›å»ºé›†ç¾¤ç®¡ç†å™¨
    cluster_manager = RabbitMQClusterManager(cluster_nodes, "demo-cluster")
    
    try:
        # 1. è¿æ¥æ‰€æœ‰é›†ç¾¤èŠ‚ç‚¹
        logger.info("ğŸ”— è¿æ¥é›†ç¾¤èŠ‚ç‚¹...")
        connection_results = cluster_manager.connect_all_nodes()
        
        # 2. è®¾ç½®é•œåƒé˜Ÿåˆ—
        logger.info("ğŸª è®¾ç½®é•œåƒé˜Ÿåˆ—...")
        queue_name = "cluster-demo-queue"
        cluster_manager.setup_cluster(queue_name, ha_policy='all')
        
        # 3. å‘å¸ƒæµ‹è¯•æ¶ˆæ¯
        logger.info("ğŸ“¤ å‘å¸ƒæµ‹è¯•æ¶ˆæ¯...")
        test_messages = [
            {'id': 1, 'content': 'é›†ç¾¤æµ‹è¯•æ¶ˆæ¯1'},
            {'id': 2, 'content': 'é›†ç¾¤æµ‹è¯•æ¶ˆæ¯2'},
            {'id': 3, 'content': 'é›†ç¾¤æµ‹è¯•æ¶ˆæ¯3'}
        ]
        cluster_manager.publish_to_cluster(queue_name, test_messages)
        
        # 4. ä¼˜åŒ–é›†ç¾¤æ€§èƒ½
        logger.info("âš¡ ä¼˜åŒ–é›†ç¾¤æ€§èƒ½...")
        cluster_manager.optimize_cluster_performance()
        
        # 5. ç›‘æ§é›†ç¾¤å¥åº·ï¼ˆåå°è¿è¡Œï¼‰
        logger.info("ğŸ” å¯åŠ¨é›†ç¾¤å¥åº·ç›‘æ§...")
        monitoring_thread = threading.Thread(
            target=cluster_manager.monitor_cluster_health,
            args=(60,)  # ç›‘æ§60ç§’
        )
        monitoring_thread.start()
        
        # 6. æ¶ˆè´¹æ¶ˆæ¯
        logger.info("ğŸ‘¥ æ¶ˆè´¹æ¶ˆæ¯...")
        time.sleep(2)  # ç­‰å¾…æ¶ˆæ¯å®Œå…¨å‘å¸ƒ
        cluster_manager.consume_from_cluster(queue_name, max_messages=3)
        
        # 7. è·å–é›†ç¾¤çŠ¶æ€
        logger.info("ğŸ“Š è·å–é›†ç¾¤çŠ¶æ€...")
        cluster_status = cluster_manager.get_cluster_status()
        logger.info(f"ğŸ“ˆ æœ€ç»ˆé›†ç¾¤çŠ¶æ€: {json.dumps(cluster_status, indent=2, ensure_ascii=False)}")
        
        # 8. æ•…éšœè½¬ç§»æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
        if len(cluster_nodes) > 1:
            failover_choice = input("æ˜¯å¦æ‰§è¡Œæ•…éšœè½¬ç§»æµ‹è¯•ï¼Ÿ(y/N): ")
            if failover_choice.lower() == 'y':
                target_node = cluster_nodes[1]  # æµ‹è¯•ç¬¬äºŒä¸ªèŠ‚ç‚¹
                cluster_manager.perform_failover_test(target_node)
        
        # ç­‰å¾…ç›‘æ§çº¿ç¨‹å®Œæˆ
        monitoring_thread.join()
        
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error(f"âŒ é›†ç¾¤ç®¡ç†å¼‚å¸¸: {e}")
    finally:
        # æ¸…ç†èµ„æº
        cluster_manager.cleanup()

if __name__ == '__main__':
    main()