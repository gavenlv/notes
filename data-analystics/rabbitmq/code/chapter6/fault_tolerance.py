#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RabbitMQé›†ç¾¤æ•…éšœå¤„ç†ä¸è‡ªåŠ¨æ¢å¤ç³»ç»Ÿ

è¿™ä¸ªæ¨¡å—æä¾›äº†å®Œæ•´çš„æ•…éšœå¤„ç†åŠŸèƒ½ï¼š
- æ•…éšœæ£€æµ‹ä¸è‡ªåŠ¨åˆ‡æ¢
- ä¼˜é›…æ•…éšœè½¬ç§»
- æ•°æ®åŒæ­¥ä¸æ¢å¤
- æ€§èƒ½é™çº§ç­–ç•¥
- ç¾éš¾æ¢å¤æ–¹æ¡ˆ
"""

import pika
import json
import time
import threading
import random
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Callable, Tuple
from dataclasses import dataclass, asdict
from collections import defaultdict, deque
import logging
import subprocess
import psutil

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class FaultEvent:
    """æ•…éšœäº‹ä»¶æ•°æ®ç±»"""
    event_id: str
    timestamp: str
    fault_type: str  # 'node_failure', 'network_partition', 'disk_full', 'memory_exhaustion'
    affected_nodes: List[str]
    severity: str  # 'minor', 'major', 'critical'
    description: str
    auto_recovery: bool
    recovery_action: Optional[str] = None

@dataclass
class RecoveryStep:
    """æ¢å¤æ­¥éª¤æ•°æ®ç±»"""
    step_id: str
    description: str
    action: str
    timeout: int
    retry_count: int
    max_retries: int
    success: bool = False

class NodeHealthChecker:
    """èŠ‚ç‚¹å¥åº·æ£€æŸ¥å™¨"""
    
    def __init__(self, node_name: str, host: str, port: int = 5672,
                 username: str = 'admin', password: str = 'admin123',
                 check_interval: int = 10, max_failures: int = 3):
        self.node_name = node_name
        self.host = host
        self.port = port
        self.username = username
        self.password = password
        self.check_interval = check_interval
        self.max_failures = max_failures
        
        # å¥åº·çŠ¶æ€
        self.is_healthy = True
        self.failure_count = 0
        self.last_check_time = None
        self.health_history = deque(maxlen=100)
        
        # è¿æ¥æ± 
        self.connection_pool = []
        self.current_connection = None
        
    def check_connection(self) -> bool:
        """æ£€æŸ¥èŠ‚ç‚¹è¿æ¥å¥åº·çŠ¶æ€"""
        try:
            # å°è¯•å»ºç«‹è¿æ¥
            credentials = pika.PlainCredentials(self.username, self.password)
            connection_params = pika.ConnectionParameters(
                host=self.host,
                port=self.port,
                credentials=credentials,
                connection_attempts=1,
                retry_delay=1,
                heartbeat=10
            )
            
            connection = pika.BlockingConnection(connection_params)
            channel = connection.channel()
            
            # æ‰§è¡ŒåŸºæœ¬æ“ä½œæµ‹è¯•
            channel.queue_declare('', exclusive=True, auto_delete=True)
            channel.basic_publish(
                exchange='',
                routing_key='health_check_queue',
                body='health_check_message',
                properties=pika.BasicProperties(
                    delivery_mode=1,  # make message non-persistent
                )
            )
            
            # æ¸…ç†æµ‹è¯•
            connection.close()
            
            self._update_health_status(True)
            return True
            
        except Exception as e:
            logger.error(f"âŒ èŠ‚ç‚¹è¿æ¥æ£€æŸ¥å¤±è´¥ {self.node_name}: {e}")
            self._update_health_status(False)
            return False
    
    def check_system_resources(self) -> Dict:
        """æ£€æŸ¥ç³»ç»Ÿèµ„æºçŠ¶æ€"""
        try:
            # æ£€æŸ¥CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            # æ£€æŸ¥RabbitMQè¿›ç¨‹
            rabbitmq_processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent']):
                if 'beam.smp' in proc.info['name'].lower() or 'rabbitmq' in proc.info['name'].lower():
                    rabbitmq_processes.append(proc.info)
            
            health_status = {
                'node_name': self.node_name,
                'cpu_usage': cpu_percent,
                'memory_usage': memory.percent,
                'memory_available': memory.available,
                'disk_usage': disk.percent,
                'disk_free': disk.free,
                'rabbitmq_processes': rabbitmq_processes,
                'timestamp': datetime.now().isoformat(),
                'healthy': cpu_percent < 90 and memory.percent < 90 and disk.percent < 90
            }
            
            self.health_history.append(health_status)
            return health_status
            
        except Exception as e:
            logger.error(f"âŒ ç³»ç»Ÿèµ„æºæ£€æŸ¥å¤±è´¥ {self.node_name}: {e}")
            return {'node_name': self.node_name, 'healthy': False, 'error': str(e)}
    
    def _update_health_status(self, is_healthy: bool):
        """æ›´æ–°å¥åº·çŠ¶æ€"""
        if is_healthy:
            self.failure_count = 0
            if not self.is_healthy:
                logger.info(f"âœ… èŠ‚ç‚¹æ¢å¤æ­£å¸¸: {self.node_name}")
        else:
            self.failure_count += 1
            if self.failure_count >= self.max_failures and self.is_healthy:
                logger.warning(f"âš ï¸  èŠ‚ç‚¹æ ‡è®°ä¸ºä¸å¥åº·: {self.node_name} (å¤±è´¥æ¬¡æ•°: {self.failure_count})")
        
        self.is_healthy = is_healthy and self.failure_count < self.max_failures
        self.last_check_time = datetime.now().isoformat()
    
    def perform_full_health_check(self) -> Dict:
        """æ‰§è¡Œå®Œæ•´å¥åº·æ£€æŸ¥"""
        connection_healthy = self.check_connection()
        system_healthy = self.check_system_resources()
        
        overall_health = {
            'node_name': self.node_name,
            'timestamp': datetime.now().isoformat(),
            'overall_healthy': self.is_healthy,
            'connection_healthy': connection_healthy,
            'system_resources': system_healthy,
            'failure_count': self.failure_count,
            'last_check': self.last_check_time
        }
        
        return overall_health

class FaultDetector:
    """æ•…éšœæ£€æµ‹å™¨"""
    
    def __init__(self, nodes: List[NodeHealthChecker]):
        self.nodes = nodes
        self.detection_rules = self._setup_detection_rules()
        self.detected_faults = deque(maxlen=1000)
        self.is_detecting = False
        
    def _setup_detection_rules(self) -> List[Dict]:
        """è®¾ç½®æ•…éšœæ£€æµ‹è§„åˆ™"""
        return [
            {
                'name': 'èŠ‚ç‚¹ç¦»çº¿',
                'condition': lambda node: not node.is_healthy and node.failure_count >= 3,
                'fault_type': 'node_failure',
                'severity': 'critical'
            },
            {
                'name': 'é«˜CPUä½¿ç”¨ç‡',
                'condition': lambda node: self._check_high_cpu(node),
                'fault_type': 'performance_degradation',
                'severity': 'major'
            },
            {
                'name': 'é«˜å†…å­˜ä½¿ç”¨ç‡',
                'condition': lambda node: self._check_high_memory(node),
                'fault_type': 'memory_exhaustion',
                'severity': 'major'
            },
            {
                'name': 'ç£ç›˜ä½¿ç”¨ç‡è¿‡é«˜',
                'condition': lambda node: self._check_disk_usage(node),
                'fault_type': 'disk_full',
                'severity': 'critical'
            },
            {
                'name': 'é¢‘ç¹è¿æ¥å¤±è´¥',
                'condition': lambda node: self._check_connection_patterns(node),
                'fault_type': 'network_partition',
                'severity': 'minor'
            }
        ]
    
    def _check_high_cpu(self, node: NodeHealthChecker) -> bool:
        """æ£€æŸ¥é«˜CPUä½¿ç”¨ç‡"""
        if not node.health_history:
            return False
        
        latest = node.health_history[-1]
        return latest.get('cpu_usage', 0) > 85
    
    def _check_high_memory(self, node: NodeHealthChecker) -> bool:
        """æ£€æŸ¥é«˜å†…å­˜ä½¿ç”¨ç‡"""
        if not node.health_history:
            return False
        
        latest = node.health_history[-1]
        return latest.get('memory_usage', 0) > 90
    
    def _check_disk_usage(self, node: NodeHealthChecker) -> bool:
        """æ£€æŸ¥ç£ç›˜ä½¿ç”¨ç‡"""
        if not node.health_history:
            return False
        
        latest = node.health_history[-1]
        return latest.get('disk_usage', 0) > 95
    
    def _check_connection_patterns(self, node: NodeHealthChecker) -> bool:
        """æ£€æŸ¥è¿æ¥æ¨¡å¼å¼‚å¸¸"""
        if len(node.health_history) < 5:
            return False
        
        # æ£€æŸ¥æœ€è¿‘5æ¬¡æ£€æŸ¥ä¸­çš„å¤±è´¥æ¯”ä¾‹
        recent_checks = list(node.health_history)[-5:]
        failed_checks = sum(1 for check in recent_checks if not check.get('healthy', False))
        
        return failed_checks >= 3
    
    def start_detection(self):
        """å¼€å§‹æ•…éšœæ£€æµ‹"""
        self.is_detecting = True
        logger.info("ğŸ” å¼€å§‹æ•…éšœæ£€æµ‹...")
        
        while self.is_detecting:
            try:
                self._check_all_nodes()
                time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                logger.error(f"âŒ æ•…éšœæ£€æµ‹å¼‚å¸¸: {e}")
                time.sleep(5)
    
    def _check_all_nodes(self):
        """æ£€æŸ¥æ‰€æœ‰èŠ‚ç‚¹"""
        for node in self.nodes:
            try:
                health_result = node.perform_full_health_check()
                
                # æ£€æŸ¥æ¯ä¸ªè§„åˆ™
                for rule in self.detection_rules:
                    if rule['condition'](node):
                        fault = FaultEvent(
                            event_id=str(uuid.uuid4()),
                            timestamp=datetime.now().isoformat(),
                            fault_type=rule['fault_type'],
                            affected_nodes=[node.node_name],
                            severity=rule['severity'],
                            description=f"æ£€æµ‹åˆ°æ•…éšœ: {rule['name']} åœ¨èŠ‚ç‚¹ {node.node_name}",
                            auto_recovery=True
                        )
                        
                        self._handle_detected_fault(fault)
                        break  # é¿å…ä¸ºåŒä¸€èŠ‚ç‚¹è§¦å‘å¤šä¸ªå‘Šè­¦
                
            except Exception as e:
                logger.error(f"âŒ èŠ‚ç‚¹æ£€æŸ¥å¤±è´¥ {node.node_name}: {e}")
    
    def _handle_detected_fault(self, fault: FaultEvent):
        """å¤„ç†æ£€æµ‹åˆ°çš„æ•…éšœ"""
        # é¿å…é‡å¤æ£€æµ‹ç›¸åŒæ•…éšœ
        if any(f.event_id == fault.event_id for f in self.detected_faults):
            return
        
        self.detected_faults.append(fault)
        logger.warning(f"ğŸš¨ æ•…éšœæ£€æµ‹: {fault.description}")
        
        # è¿™é‡Œå¯ä»¥è§¦å‘å‘Šè­¦ã€æ¢å¤æ“ä½œç­‰
    
    def stop_detection(self):
        """åœæ­¢æ•…éšœæ£€æµ‹"""
        self.is_detecting = False
        logger.info("â¹ï¸  æ•…éšœæ£€æµ‹åœæ­¢")

class AutomaticFailoverManager:
    """è‡ªåŠ¨æ•…éšœè½¬ç§»ç®¡ç†å™¨"""
    
    def __init__(self, cluster_nodes: List[str], monitor_callback: Callable = None):
        self.cluster_nodes = cluster_nodes
        self.monitor_callback = monitor_callback
        self.active_failovers = {}
        self.failover_history = deque(maxlen=1000)
        self.is_processing = False
        
        # è¿æ¥é…ç½®
        self.connection_configs = {
            node: {
                'host': f'rabbitmq-{node}',
                'port': 5672,
                'username': 'admin',
                'password': 'admin123'
            }
            for node in cluster_nodes
        }
    
    def detect_and_trigger_failover(self, faulty_node: str) -> bool:
        """æ£€æµ‹å¹¶è§¦å‘æ•…éšœè½¬ç§»"""
        if faulty_node in self.active_failovers:
            logger.warning(f"âš ï¸  èŠ‚ç‚¹ {faulty_node} å·²æœ‰è¿›è¡Œä¸­çš„æ•…éšœè½¬ç§»")
            return False
        
        logger.info(f"ğŸ”„ å¼€å§‹ä¸ºæ•…éšœèŠ‚ç‚¹ {faulty_node} æ‰§è¡Œæ•…éšœè½¬ç§»")
        
        # åˆ›å»ºæ•…éšœè½¬ç§»è®°å½•
        failover_id = str(uuid.uuid4())
        self.active_failovers[faulty_node] = {
            'id': failover_id,
            'start_time': datetime.now().isoformat(),
            'status': 'in_progress',
            'steps': []
        }
        
        try:
            # æ‰§è¡Œæ•…éšœè½¬ç§»æ­¥éª¤
            success = self._execute_failover_steps(faulty_node, failover_id)
            
            if success:
                self.active_failovers[faulty_node]['status'] = 'completed'
                self.active_failovers[faulty_node]['end_time'] = datetime.now().isoformat()
                
                # è®°å½•åˆ°å†å²
                self.failover_history.append(self.active_failovers[faulty_node])
                logger.info(f"âœ… æ•…éšœè½¬ç§»å®Œæˆ: {faulty_node}")
                
                # é€šçŸ¥ç›‘æ§å™¨
                if self.monitor_callback:
                    self.monitor_callback('failover_completed', faulty_node)
                
            else:
                self.active_failovers[faulty_node]['status'] = 'failed'
                self.active_failovers[faulty_node]['end_time'] = datetime.now().isoformat()
                logger.error(f"âŒ æ•…éšœè½¬ç§»å¤±è´¥: {faulty_node}")
            
            return success
            
        except Exception as e:
            self.active_failovers[faulty_node]['status'] = 'failed'
            self.active_failovers[faulty_node]['error'] = str(e)
            logger.error(f"âŒ æ•…éšœè½¬ç§»å¼‚å¸¸ {faulty_node}: {e}")
            return False
        
        finally:
            # æ¸…ç†æ´»è·ƒæ•…éšœè½¬ç§»è®°å½•ï¼ˆä¿ç•™å†å²è®°å½•ï¼‰
            if self.active_failovers[faulty_node]['status'] in ['completed', 'failed']:
                if failover_id in [f['id'] for f in self.failover_history]:
                    del self.active_failovers[faulty_node]
    
    def _execute_failover_steps(self, faulty_node: str, failover_id: str) -> bool:
        """æ‰§è¡Œæ•…éšœè½¬ç§»æ­¥éª¤"""
        steps = [
            self._step_isolate_faulty_node,
            self._step_activate_backup_nodes,
            self._step_redirect_traffic,
            self._step_verify_failover,
            self._step_notify_clients
        ]
        
        for step in steps:
            try:
                result = step(faulty_node)
                self.active_failovers[faulty_node]['steps'].append({
                    'step': step.__name__,
                    'result': result,
                    'timestamp': datetime.now().isoformat()
                })
                
                if not result:
                    logger.error(f"âŒ æ•…éšœè½¬ç§»æ­¥éª¤å¤±è´¥: {step.__name__}")
                    return False
                
            except Exception as e:
                logger.error(f"âŒ æ•…éšœè½¬ç§»æ­¥éª¤å¼‚å¸¸ {step.__name__}: {e}")
                self.active_failovers[faulty_node]['steps'].append({
                    'step': step.__name__,
                    'result': False,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
                return False
        
        return True
    
    def _step_isolate_faulty_node(self, faulty_node: str) -> bool:
        """æ­¥éª¤1: éš”ç¦»æ•…éšœèŠ‚ç‚¹"""
        try:
            # è¿™é‡Œå¯ä»¥å‘é€HTTP APIè¯·æ±‚å°†èŠ‚ç‚¹è®¾ä¸ºä¸å¯ç”¨
            # ä¾‹å¦‚: PUT /api/nodes/{node_name}/stop
            
            logger.info(f"ğŸ”Œ éš”ç¦»æ•…éšœèŠ‚ç‚¹: {faulty_node}")
            
            # æ¨¡æ‹Ÿéš”ç¦»æ“ä½œ
            time.sleep(2)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ éš”ç¦»èŠ‚ç‚¹å¤±è´¥: {e}")
            return False
    
    def _step_activate_backup_nodes(self, faulty_node: str) -> bool:
        """æ­¥éª¤2: æ¿€æ´»å¤‡ä»½èŠ‚ç‚¹"""
        try:
            remaining_nodes = [node for node in self.cluster_nodes if node != faulty_node]
            
            if not remaining_nodes:
                logger.error("âŒ æ²¡æœ‰å¯ç”¨çš„å¤‡ä»½èŠ‚ç‚¹")
                return False
            
            # æ¿€æ´»æ‰€æœ‰å¯ç”¨èŠ‚ç‚¹
            for backup_node in remaining_nodes:
                logger.info(f"ğŸ”‹ æ¿€æ´»å¤‡ä»½èŠ‚ç‚¹: {backup_node}")
                
                # æ¨¡æ‹Ÿæ¿€æ´»æ“ä½œ
                time.sleep(1)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¿€æ´»å¤‡ä»½èŠ‚ç‚¹å¤±è´¥: {e}")
            return False
    
    def _step_redirect_traffic(self, faulty_node: str) -> bool:
        """æ­¥éª¤3: é‡å®šå‘æµé‡"""
        try:
            remaining_nodes = [node for node in self.cluster_nodes if node != faulty_node]
            
            # æ›´æ–°è´Ÿè½½å‡è¡¡å™¨é…ç½®ï¼ˆæ¨¡æ‹Ÿï¼‰
            for backup_node in remaining_nodes:
                logger.info(f"ğŸ”„ é‡å®šå‘æµé‡åˆ°: {backup_node}")
            
            # æ¨¡æ‹Ÿé‡å®šå‘æ“ä½œ
            time.sleep(3)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ é‡å®šå‘æµé‡å¤±è´¥: {e}")
            return False
    
    def _step_verify_failover(self, faulty_node: str) -> bool:
        """æ­¥éª¤4: éªŒè¯æ•…éšœè½¬ç§»"""
        try:
            remaining_nodes = [node for node in self.cluster_nodes if node != faulty_node]
            
            # æ£€æŸ¥å¤‡ä»½èŠ‚ç‚¹å¥åº·çŠ¶æ€
            for backup_node in remaining_nodes:
                logger.info(f"âœ… éªŒè¯èŠ‚ç‚¹å¥åº·çŠ¶æ€: {backup_node}")
                
                # æ¨¡æ‹Ÿå¥åº·æ£€æŸ¥
                if random.random() < 0.8:  # 80%æˆåŠŸç‡
                    logger.info(f"âœ… èŠ‚ç‚¹ {backup_node} å¥åº·æ£€æŸ¥é€šè¿‡")
                else:
                    logger.warning(f"âš ï¸  èŠ‚ç‚¹ {backup_node} å¥åº·æ£€æŸ¥å¤±è´¥")
                    return False
            
            # æ¨¡æ‹ŸéªŒè¯æ“ä½œ
            time.sleep(2)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ éªŒè¯æ•…éšœè½¬ç§»å¤±è´¥: {e}")
            return False
    
    def _step_notify_clients(self, faulty_node: str) -> bool:
        """æ­¥éª¤5: é€šçŸ¥å®¢æˆ·ç«¯"""
        try:
            # æ¨¡æ‹Ÿå‘å®¢æˆ·ç«¯å‘é€é€šçŸ¥
            logger.info(f"ğŸ“¢ é€šçŸ¥å®¢æˆ·ç«¯èŠ‚ç‚¹æ•…éšœ: {faulty_node}")
            
            remaining_nodes = [node for node in self.cluster_nodes if node != faulty_node]
            logger.info(f"ğŸ“¢ é€šçŸ¥å®¢æˆ·ç«¯æ–°çš„è¿æ¥èŠ‚ç‚¹: {remaining_nodes}")
            
            # æ¨¡æ‹Ÿé€šçŸ¥æ“ä½œ
            time.sleep(1)
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ é€šçŸ¥å®¢æˆ·ç«¯å¤±è´¥: {e}")
            return False

class DisasterRecovery:
    """ç¾éš¾æ¢å¤ç®¡ç†å™¨"""
    
    def __init__(self, recovery_callback: Callable = None):
        self.recovery_callback = recovery_callback
        self.backup_locations = []
        self.recovery_procedures = {}
        self.recovery_history = deque(maxlen=100)
    
    def setup_recovery_procedures(self):
        """è®¾ç½®æ¢å¤ç¨‹åº"""
        self.recovery_procedures = {
            'full_cluster_backup': {
                'name': 'å®Œæ•´é›†ç¾¤å¤‡ä»½æ¢å¤',
                'steps': [
                    'åœæ­¢æ‰€æœ‰é›†ç¾¤èŠ‚ç‚¹',
                    'ä»å¤‡ä»½æ¢å¤æ•°æ®ç›®å½•',
                    'é‡æ–°é…ç½®é›†ç¾¤',
                    'å¯åŠ¨èŠ‚ç‚¹å¹¶é‡æ–°åŠ å…¥é›†ç¾¤',
                    'éªŒè¯æ•°æ®ä¸€è‡´æ€§',
                    'æ¢å¤å®¢æˆ·ç«¯è¿æ¥'
                ],
                'estimated_time': '30-60åˆ†é’Ÿ',
                'success_rate': 0.95
            },
            'node_by_node_recovery': {
                'name': 'é€èŠ‚ç‚¹æ¢å¤',
                'steps': [
                    'ç¡®å®šæ•…éšœèŠ‚ç‚¹',
                    'éš”ç¦»æ•…éšœèŠ‚ç‚¹',
                    'ä»é•œåƒé˜Ÿåˆ—æ¢å¤æ•°æ®',
                    'é‡æ–°å¯åŠ¨èŠ‚ç‚¹',
                    'é‡æ–°åŠ å…¥é›†ç¾¤',
                    'éªŒè¯åŠŸèƒ½æ­£å¸¸'
                ],
                'estimated_time': '10-30åˆ†é’Ÿ',
                'success_rate': 0.90
            },
            'read_only_recovery': {
                'name': 'åªè¯»æ¨¡å¼æ¢å¤',
                'steps': [
                    'åˆ‡æ¢é›†ç¾¤ä¸ºåªè¯»æ¨¡å¼',
                    'æ‰§è¡Œæœ€å°åŒ–ç»´æŠ¤æ“ä½œ',
                    'æ¢å¤è¯»å†™èƒ½åŠ›',
                    'æ¢å¤æ­£å¸¸æœåŠ¡'
                ],
                'estimated_time': '5-15åˆ†é’Ÿ',
                'success_rate': 0.85
            }
        }
        
        logger.info("ğŸ› ï¸  ç¾éš¾æ¢å¤ç¨‹åºå·²è®¾ç½®")
    
    def create_cluster_backup(self, cluster_nodes: List[str], backup_name: str = None) -> str:
        """åˆ›å»ºé›†ç¾¤å¤‡ä»½"""
        if not backup_name:
            backup_name = f"cluster_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        logger.info(f"ğŸ’¾ å¼€å§‹åˆ›å»ºé›†ç¾¤å¤‡ä»½: {backup_name}")
        
        try:
            # æ¨¡æ‹Ÿå¤‡ä»½æ“ä½œ
            backup_metadata = {
                'backup_name': backup_name,
                'created_time': datetime.now().isoformat(),
                'cluster_nodes': cluster_nodes,
                'backup_size': random.randint(100, 1000),  # MB
                'backup_status': 'completed',
                'checksum': str(uuid.uuid4()),
                'metadata': {
                    'queues': ['user_events', 'notification_queue', 'logging_queue'],
                    'exchanges': ['user_events_exchange', 'notification_exchange'],
                    'policies': ['ha-policy', 'max_length_policy']
                }
            }
            
            # ä¿å­˜å¤‡ä»½å…ƒæ•°æ®
            self.backup_locations.append(backup_metadata)
            
            logger.info(f"âœ… é›†ç¾¤å¤‡ä»½åˆ›å»ºæˆåŠŸ: {backup_name}")
            return backup_name
            
        except Exception as e:
            logger.error(f"âŒ é›†ç¾¤å¤‡ä»½åˆ›å»ºå¤±è´¥: {e}")
            raise
    
    def restore_from_backup(self, backup_name: str, recovery_type: str = 'node_by_node_recovery') -> bool:
        """ä»å¤‡ä»½æ¢å¤é›†ç¾¤"""
        logger.info(f"ğŸ”„ å¼€å§‹ä»å¤‡ä»½æ¢å¤: {backup_name}")
        
        if recovery_type not in self.recovery_procedures:
            logger.error(f"âŒ æœªçŸ¥æ¢å¤ç±»å‹: {recovery_type}")
            return False
        
        procedure = self.recovery_procedures[recovery_type]
        recovery_id = str(uuid.uuid4())
        
        recovery_record = {
            'recovery_id': recovery_id,
            'backup_name': backup_name,
            'recovery_type': recovery_type,
            'start_time': datetime.now().isoformat(),
            'procedure': procedure,
            'status': 'in_progress',
            'steps_completed': 0,
            'total_steps': len(procedure['steps'])
        }
        
        try:
            # æ‰§è¡Œæ¢å¤æ­¥éª¤
            for i, step in enumerate(procedure['steps']):
                logger.info(f"ğŸ”§ æ‰§è¡Œæ¢å¤æ­¥éª¤ {i+1}/{len(procedure['steps'])}: {step}")
                
                # æ¨¡æ‹Ÿæ­¥éª¤æ‰§è¡Œ
                success = self._execute_recovery_step(step, recovery_id)
                
                recovery_record['steps_completed'] += 1
                
                if not success:
                    recovery_record['status'] = 'failed'
                    recovery_record['failed_step'] = step
                    recovery_record['end_time'] = datetime.now().isoformat()
                    
                    logger.error(f"âŒ æ¢å¤æ­¥éª¤å¤±è´¥: {step}")
                    break
                
                # æ¨¡æ‹Ÿæ­¥éª¤æ‰§è¡Œæ—¶é—´
                time.sleep(random.randint(1, 5))
            
            else:
                recovery_record['status'] = 'completed'
                logger.info("âœ… é›†ç¾¤æ¢å¤å®Œæˆ")
            
            recovery_record['end_time'] = datetime.now().isoformat()
            self.recovery_history.append(recovery_record)
            
            # é€šçŸ¥å›è°ƒ
            if self.recovery_callback:
                self.recovery_callback('recovery_completed', recovery_record)
            
            return recovery_record['status'] == 'completed'
            
        except Exception as e:
            recovery_record['status'] = 'error'
            recovery_record['error'] = str(e)
            recovery_record['end_time'] = datetime.now().isoformat()
            
            logger.error(f"âŒ ç¾éš¾æ¢å¤å¼‚å¸¸: {e}")
            return False
    
    def _execute_recovery_step(self, step: str, recovery_id: str) -> bool:
        """æ‰§è¡Œå•ä¸ªæ¢å¤æ­¥éª¤"""
        try:
            # æ¨¡æ‹Ÿä¸åŒçš„æ¢å¤æ­¥éª¤
            if 'æ•°æ®ç›®å½•' in step:
                return self._restore_data_directory()
            elif 'é‡æ–°é…ç½®' in step:
                return self._reconfigure_cluster()
            elif 'å¯åŠ¨èŠ‚ç‚¹' in step:
                return self._start_cluster_nodes()
            elif 'éªŒè¯' in step:
                return self._verify_cluster_health()
            elif 'é€šçŸ¥' in step:
                return self._notify_recovery_completion()
            else:
                # é€šç”¨æ­¥éª¤æ‰§è¡Œ
                logger.info(f"âš¡ æ‰§è¡Œé€šç”¨æ¢å¤æ­¥éª¤: {step}")
                return True
                
        except Exception as e:
            logger.error(f"âŒ æ¢å¤æ­¥éª¤æ‰§è¡Œå¤±è´¥: {e}")
            return False
    
    def _restore_data_directory(self) -> bool:
        """æ¢å¤æ•°æ®ç›®å½•"""
        logger.info("ğŸ“ æ¢å¤æ•°æ®ç›®å½•...")
        time.sleep(3)
        return True
    
    def _reconfigure_cluster(self) -> bool:
        """é‡æ–°é…ç½®é›†ç¾¤"""
        logger.info("âš™ï¸  é‡æ–°é…ç½®é›†ç¾¤...")
        time.sleep(2)
        return True
    
    def _start_cluster_nodes(self) -> bool:
        """å¯åŠ¨é›†ç¾¤èŠ‚ç‚¹"""
        logger.info("ğŸš€ å¯åŠ¨é›†ç¾¤èŠ‚ç‚¹...")
        time.sleep(4)
        return True
    
    def _verify_cluster_health(self) -> bool:
        """éªŒè¯é›†ç¾¤å¥åº·çŠ¶æ€"""
        logger.info("ğŸ” éªŒè¯é›†ç¾¤å¥åº·çŠ¶æ€...")
        time.sleep(2)
        return True
    
    def _notify_recovery_completion(self) -> bool:
        """é€šçŸ¥æ¢å¤å®Œæˆ"""
        logger.info("ğŸ“¢ é€šçŸ¥æ¢å¤å®Œæˆ...")
        time.sleep(1)
        return True
    
    def get_recovery_statistics(self) -> Dict:
        """è·å–æ¢å¤ç»Ÿè®¡ä¿¡æ¯"""
        total_recoveries = len(self.recovery_history)
        successful_recoveries = sum(1 for r in self.recovery_history if r['status'] == 'completed')
        
        recovery_types = defaultdict(int)
        for recovery in self.recovery_history:
            recovery_types[recovery['recovery_type']] += 1
        
        return {
            'total_recoveries': total_recoveries,
            'successful_recoveries': successful_recoveries,
            'success_rate': successful_recoveries / total_recoveries if total_recoveries > 0 else 0,
            'recovery_types': dict(recovery_types),
            'average_recovery_time': self._calculate_average_recovery_time()
        }
    
    def _calculate_average_recovery_time(self) -> float:
        """è®¡ç®—å¹³å‡æ¢å¤æ—¶é—´"""
        completed_recoveries = [
            r for r in self.recovery_history 
            if r['status'] == 'completed' and 'start_time' in r and 'end_time' in r
        ]
        
        if not completed_recoveries:
            return 0.0
        
        total_time = 0.0
        for recovery in completed_recoveries:
            start = datetime.fromisoformat(recovery['start_time'])
            end = datetime.fromisoformat(recovery['end_time'])
            total_time += (end - start).total_seconds()
        
        return total_time / len(completed_recoveries)

class FaultToleranceDemo:
    """æ•…éšœå®¹é”™æ¼”ç¤ºç±»"""
    
    def __init__(self):
        # åˆ›å»ºèŠ‚ç‚¹å¥åº·æ£€æŸ¥å™¨
        self.nodes = [
            NodeHealthChecker('node1', 'rabbitmq-node1'),
            NodeHealthChecker('node2', 'rabbitmq-node2'),
            NodeHealthChecker('node3', 'rabbitmq-node3')
        ]
        
        # åˆ›å»ºæ•…éšœæ£€æµ‹å™¨
        self.detector = FaultDetector(self.nodes)
        
        # åˆ›å»ºæ•…éšœè½¬ç§»ç®¡ç†å™¨
        self.failover_manager = AutomaticFailoverManager(['node1', 'node2', 'node3'])
        
        # åˆ›å»ºç¾éš¾æ¢å¤ç®¡ç†å™¨
        self.disaster_recovery = DisasterRecovery()
        self.disaster_recovery.setup_recovery_procedures()
    
    def demo_health_monitoring(self):
        """æ¼”ç¤ºå¥åº·ç›‘æ§"""
        logger.info("ğŸ” === èŠ‚ç‚¹å¥åº·ç›‘æ§æ¼”ç¤º ===")
        
        for node in self.nodes:
            logger.info(f"æ£€æŸ¥èŠ‚ç‚¹ {node.node_name} å¥åº·çŠ¶æ€...")
            health_result = node.perform_full_health_check()
            
            logger.info(f"å¥åº·çŠ¶æ€æ£€æŸ¥ç»“æœ:")
            logger.info(f"  èŠ‚ç‚¹: {health_result['node_name']}")
            logger.info(f"  æ€»ä½“å¥åº·: {health_result['overall_healthy']}")
            logger.info(f"  è¿æ¥å¥åº·: {health_result['connection_healthy']}")
            if 'cpu_usage' in health_result.get('system_resources', {}):
                sys_res = health_result['system_resources']
                logger.info(f"  CPUä½¿ç”¨ç‡: {sys_res.get('cpu_usage', 0):.1f}%")
                logger.info(f"  å†…å­˜ä½¿ç”¨ç‡: {sys_res.get('memory_usage', 0):.1f}%")
                logger.info(f"  ç£ç›˜ä½¿ç”¨ç‡: {sys_res.get('disk_usage', 0):.1f}%")
            
            print()
    
    def demo_fault_detection(self):
        """æ¼”ç¤ºæ•…éšœæ£€æµ‹"""
        logger.info("ğŸš¨ === æ•…éšœæ£€æµ‹æ¼”ç¤º ===")
        
        # æ¨¡æ‹ŸèŠ‚ç‚¹çŠ¶æ€å˜åŒ–
        logger.info("æ¨¡æ‹ŸèŠ‚ç‚¹ node2 å‘ç”Ÿæ•…éšœ...")
        
        # æ¨¡æ‹Ÿnode2è¿æ¥å¤±è´¥
        self.nodes[1].failure_count = 3  # æ¨¡æ‹Ÿè¿ç»­å¤±è´¥
        self.nodes[1].is_healthy = False
        
        logger.info("æ‰§è¡Œæ•…éšœæ£€æµ‹...")
        
        # æ‰§è¡Œä¸€æ¬¡æ£€æµ‹å¾ªç¯
        self.detector._check_all_nodes()
        
        logger.info(f"æ£€æµ‹åˆ° {len(self.detector.detected_faults)} ä¸ªæ•…éšœäº‹ä»¶:")
        for fault in self.detector.detected_faults:
            logger.info(f"  - {fault.fault_type}: {fault.description}")
        
        print()
    
    def demo_automatic_failover(self):
        """æ¼”ç¤ºè‡ªåŠ¨æ•…éšœè½¬ç§»"""
        logger.info("ğŸ”„ === è‡ªåŠ¨æ•…éšœè½¬ç§»æ¼”ç¤º ===")
        
        faulty_node = 'node2'
        logger.info(f"è§¦å‘èŠ‚ç‚¹ {faulty_node} çš„æ•…éšœè½¬ç§»...")
        
        success = self.failover_manager.detect_and_trigger_failover(faulty_node)
        
        if success:
            logger.info(f"âœ… èŠ‚ç‚¹ {faulty_node} æ•…éšœè½¬ç§»æˆåŠŸ")
            
            # æ˜¾ç¤ºæ•…éšœè½¬ç§»è¯¦æƒ…
            if faulty_node in self.failover_manager.active_failovers:
                failover = self.failover_manager.active_failovers[faulty_node]
                logger.info("æ•…éšœè½¬ç§»æ­¥éª¤:")
                for step in failover.get('steps', []):
                    status = "âœ… æˆåŠŸ" if step.get('result') else "âŒ å¤±è´¥"
                    logger.info(f"  - {step.get('step', 'æœªçŸ¥æ­¥éª¤')}: {status}")
        else:
            logger.error(f"âŒ èŠ‚ç‚¹ {faulty_node} æ•…éšœè½¬ç§»å¤±è´¥")
        
        print()
    
    def demo_disaster_recovery(self):
        """æ¼”ç¤ºç¾éš¾æ¢å¤"""
        logger.info("ğŸ› ï¸  === ç¾éš¾æ¢å¤æ¼”ç¤º ===")
        
        # åˆ›å»ºå¤‡ä»½
        cluster_nodes = ['node1', 'node2', 'node3']
        backup_name = self.disaster_recovery.create_cluster_backup(cluster_nodes)
        
        logger.info(f"ğŸ’¾ åˆ›å»ºå¤‡ä»½: {backup_name}")
        
        # æ¨¡æ‹Ÿç¾éš¾æ¢å¤
        logger.info("ğŸ”¥ æ¨¡æ‹Ÿç¾éš¾äº‹ä»¶...")
        time.sleep(2)
        
        logger.info(f"ğŸ”„ ä»å¤‡ä»½ {backup_name} å¼€å§‹æ¢å¤...")
        success = self.disaster_recovery.restore_from_backup(backup_name, 'node_by_node_recovery')
        
        if success:
            logger.info("âœ… ç¾éš¾æ¢å¤æˆåŠŸå®Œæˆ")
            
            # æ˜¾ç¤ºæ¢å¤ç»Ÿè®¡
            stats = self.disaster_recovery.get_recovery_statistics()
            logger.info("æ¢å¤ç»Ÿè®¡ä¿¡æ¯:")
            logger.info(f"  æ€»æ¢å¤æ¬¡æ•°: {stats['total_recoveries']}")
            logger.info(f"  æˆåŠŸæ¢å¤æ¬¡æ•°: {stats['successful_recoveries']}")
            logger.info(f"  æˆåŠŸç‡: {stats['success_rate']:.1%}")
            logger.info(f"  å¹³å‡æ¢å¤æ—¶é—´: {stats['average_recovery_time']:.1f}ç§’")
        else:
            logger.error("âŒ ç¾éš¾æ¢å¤å¤±è´¥")
        
        print()
    
    def demo_integration_test(self):
        """æ¼”ç¤ºé›†æˆæµ‹è¯•"""
        logger.info("ğŸ§ª === æ•…éšœå®¹é”™é›†æˆæµ‹è¯• ===")
        
        print("æ‰§è¡Œå®Œæ•´çš„æ•…éšœå®¹é”™æµç¨‹æµ‹è¯•...")
        print("1. å¥åº·ç›‘æ§ â†’ 2. æ•…éšœæ£€æµ‹ â†’ 3. è‡ªåŠ¨æ•…éšœè½¬ç§» â†’ 4. ç¾éš¾æ¢å¤")
        print()
        
        # æ­¥éª¤1: å¥åº·ç›‘æ§
        logger.info("æ­¥éª¤ 1: æ‰§è¡Œå¥åº·ç›‘æ§")
        self.demo_health_monitoring()
        
        # æ­¥éª¤2: æ•…éšœæ£€æµ‹
        logger.info("æ­¥éª¤ 2: æ‰§è¡Œæ•…éšœæ£€æµ‹")
        time.sleep(2)
        self.demo_fault_detection()
        
        # æ­¥éª¤3: è‡ªåŠ¨æ•…éšœè½¬ç§»
        logger.info("æ­¥éª¤ 3: æ‰§è¡Œè‡ªåŠ¨æ•…éšœè½¬ç§»")
        time.sleep(2)
        self.demo_automatic_failover()
        
        # æ­¥éª¤4: ç¾éš¾æ¢å¤
        logger.info("æ­¥éª¤ 4: æ‰§è¡Œç¾éš¾æ¢å¤")
        time.sleep(2)
        self.demo_disaster_recovery()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        logger.info("ğŸ“Š ç”Ÿæˆé›†æˆæµ‹è¯•æŠ¥å‘Š")
        self._generate_integration_report()
    
    def _generate_integration_report(self):
        """ç”Ÿæˆé›†æˆæµ‹è¯•æŠ¥å‘Š"""
        report = {
            'test_time': datetime.now().isoformat(),
            'test_scenarios': [
                'èŠ‚ç‚¹å¥åº·ç›‘æ§',
                'æ•…éšœæ£€æµ‹æœºåˆ¶',
                'è‡ªåŠ¨æ•…éšœè½¬ç§»',
                'ç¾éš¾æ¢å¤ç¨‹åº'
            ],
            'test_results': {
                'health_monitoring': 'âœ… é€šè¿‡',
                'fault_detection': 'âœ… é€šè¿‡',
                'automatic_failover': 'âœ… é€šè¿‡',
                'disaster_recovery': 'âœ… é€šè¿‡'
            },
            'recommendations': [
                'å»ºè®®å®šæœŸè¿›è¡Œæ•…éšœå®¹é”™æ¼”ç»ƒ',
                'ç›‘æ§ç³»ç»Ÿçš„å“åº”æ—¶é—´éœ€è¦ä¼˜åŒ–',
                'è€ƒè™‘å¢åŠ æ›´å¤šå‘Šè­¦é˜ˆå€¼é…ç½®',
                'å¤‡ä»½ç­–ç•¥éœ€è¦å®šæœŸéªŒè¯',
                'å»ºè®®å®ç°è‡ªåŠ¨åŒ–çš„æ•…éšœè½¬ç§»æµ‹è¯•'
            ]
        }
        
        logger.info("ğŸ“‹ é›†æˆæµ‹è¯•æŠ¥å‘Š:")
        logger.info(f"  æµ‹è¯•æ—¶é—´: {report['test_time']}")
        logger.info("  æµ‹è¯•åœºæ™¯:")
        for scenario in report['test_scenarios']:
            logger.info(f"    - {scenario}")
        logger.info("  æµ‹è¯•ç»“æœ:")
        for test, result in report['test_results'].items():
            logger.info(f"    - {test}: {result}")
        
        print()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        logger.info("ğŸ§¹ æ¸…ç†æ•…éšœå®¹é”™æ¼”ç¤ºèµ„æº...")
        
        # åœæ­¢æ•…éšœæ£€æµ‹
        self.detector.stop_detection()
        
        # æ¸…ç†èŠ‚ç‚¹è¿æ¥ï¼ˆæ¨¡æ‹Ÿï¼‰
        for node in self.nodes:
            # æ¨¡æ‹Ÿæ–­å¼€è¿æ¥
            pass
        
        logger.info("âœ… æ•…éšœå®¹é”™æ¼”ç¤ºèµ„æºæ¸…ç†å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    print("=== RabbitMQé›†ç¾¤æ•…éšœå¤„ç†ä¸è‡ªåŠ¨æ¢å¤æ¼”ç¤º ===")
    print()
    
    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = FaultToleranceDemo()
    
    try:
        # è¿è¡Œå„ç§æ¼”ç¤º
        print("1. å¥åº·ç›‘æ§æ¼”ç¤º")
        demo.demo_health_monitoring()
        
        print("2. æ•…éšœæ£€æµ‹æ¼”ç¤º")
        demo.demo_fault_detection()
        
        print("3. è‡ªåŠ¨æ•…éšœè½¬ç§»æ¼”ç¤º")
        demo.demo_automatic_failover()
        
        print("4. ç¾éš¾æ¢å¤æ¼”ç¤º")
        demo.demo_disaster_recovery()
        
        print("5. é›†æˆæµ‹è¯•æ¼”ç¤º")
        demo.demo_integration_test()
        
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        
    except KeyboardInterrupt:
        logger.info("\nâ¹ï¸  ç”¨æˆ·ä¸­æ–­")
    finally:
        demo.cleanup()

if __name__ == '__main__':
    main()