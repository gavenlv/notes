#!/usr/bin/env python3
"""
ç¬¬8ç« ï¼šé›†ç¾¤ä¼˜åŒ–ç¤ºä¾‹
 RabbitMQ é›†ç¾¤æ€§èƒ½ä¼˜åŒ–å’Œé…ç½®è°ƒä¼˜å·¥å…·
"""

import time
import threading
import json
from typing import Dict, List, Optional, Any, Callable, Set
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
from collections import deque, defaultdict
import logging
import heapq
import uuid
import statistics
from concurrent.futures import ThreadPoolExecutor, as_completed


class OptimizationType(Enum):
    """ä¼˜åŒ–ç±»å‹"""
    THROUGHPUT = "throughput"
    LATENCY = "latency"
    RELIABILITY = "reliability"
    MEMORY = "memory"
    BALANCED = "balanced"


class NetworkType(Enum):
    """ç½‘ç»œç±»å‹"""
    GIGABIT = "gigabit"
    TEN_GIGABIT = "10gigabit"
    INFINIBAND = "infiniband"
    LOCALHOST = "localhost"


@dataclass
class NodeConfig:
    """èŠ‚ç‚¹é…ç½®"""
    name: str
    host: str
    port: int
    rabbitmq_version: str = "3.8.0"
    erlang_version: str = "23.0"
    cpu_cores: int = 4
    memory_gb: int = 8
    disk_gb: int = 100
    network_type: NetworkType = NetworkType.GIGABIT
    role: str = "disc"  # "disc", "ram"
    management_enabled: bool = True


@dataclass
class ClusterMetrics:
    """é›†ç¾¤æŒ‡æ ‡"""
    timestamp: float
    total_nodes: int
    running_nodes: int
    total_queues: int
    total_connections: int
    total_channels: int
    total_messages: int
    ready_messages: int
    unacked_messages: int
    memory_usage_bytes: int
    disk_usage_bytes: int
    cpu_usage_percent: float
    network_io_mbps: float
    cluster_load: float
    queue_depth_avg: float
    message_rate_in: float
    message_rate_out: float


@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœ"""
    optimization_type: str
    before_metrics: ClusterMetrics
    after_metrics: ClusterMetrics
    improvement_percent: float
    applied_settings: Dict[str, Any]
    performance_gain: float
    timestamp: float


class ClusterOptimizer:
    """é›†ç¾¤ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.node_configs = {}
        self.optimization_history = []
        self.current_metrics = None
        self.optimization_rules = {
            'memory_optimization': self._optimize_memory,
            'cpu_optimization': self._optimize_cpu,
            'disk_optimization': self._optimize_disk,
            'network_optimization': self._optimize_network,
            'queue_optimization': self._optimize_queues,
            'connection_optimization': self._optimize_connections,
            'cluster_balance': self._balance_cluster_load
        }
    
    def add_node(self, node_config: NodeConfig):
        """æ·»åŠ èŠ‚ç‚¹"""
        self.node_configs[node_config.name] = node_config
        print(f"æ·»åŠ èŠ‚ç‚¹: {node_config.name} ({node_config.host}:{node_config.port})")
    
    def analyze_current_state(self) -> Dict[str, Any]:
        """åˆ†æå½“å‰é›†ç¾¤çŠ¶æ€"""
        if not self.node_configs:
            return {'error': 'æ²¡æœ‰é…ç½®èŠ‚ç‚¹'}
        
        analysis = {
            'cluster_info': {
                'total_nodes': len(self.node_configs),
                'roles': self._analyze_node_roles(),
                'resource_distribution': self._analyze_resource_distribution(),
                'network_topology': self._analyze_network_topology()
            },
            'performance_baseline': {
                'estimated_throughput': self._estimate_throughput(),
                'estimated_latency': self._estimate_latency(),
                'max_capacity': self._estimate_max_capacity()
            },
            'recommendations': self._generate_cluster_recommendations()
        }
        
        return analysis
    
    def _analyze_node_roles(self) -> Dict[str, int]:
        """åˆ†æèŠ‚ç‚¹è§’è‰²åˆ†å¸ƒ"""
        roles = defaultdict(int)
        for config in self.node_configs.values():
            roles[config.role] += 1
        return dict(roles)
    
    def _analyze_resource_distribution(self) -> Dict[str, Any]:
        """åˆ†æèµ„æºåˆ†å¸ƒ"""
        total_cpu = sum(node.cpu_cores for node in self.node_configs.values())
        total_memory = sum(node.memory_gb for node in self.node_configs.values())
        total_disk = sum(node.disk_gb for node in self.node_configs.values())
        
        return {
            'cpu_distribution': [node.cpu_cores for node in self.node_configs.values()],
            'memory_distribution': [node.memory_gb for node in self.node_configs.values()],
            'disk_distribution': [node.disk_gb for node in self.node_configs.values()],
            'avg_cpu_per_node': total_cpu / len(self.node_configs),
            'avg_memory_per_node': total_memory / len(self.node_configs),
            'avg_disk_per_node': total_disk / len(self.node_configs)
        }
    
    def _analyze_network_topology(self) -> Dict[str, Any]:
        """åˆ†æç½‘ç»œæ‹“æ‰‘"""
        network_types = defaultdict(int)
        for config in self.node_configs.values():
            network_types[config.network_type.value] += 1
        
        return {
            'network_types': dict(network_types),
            'mixed_networks': len(set(config.network_type for config in self.node_configs.values())) > 1
        }
    
    def _estimate_throughput(self) -> float:
        """ä¼°ç®—é›†ç¾¤ååé‡"""
        total_cpu = sum(node.cpu_cores for node in self.node_configs.values())
        total_memory = sum(node.memory_gb for node in self.node_configs.values())
        
        # åŸºäºCPUå’Œå†…å­˜ä¼°ç®—ååé‡
        cpu_factor = min(total_cpu / 8, 1.0)  # æ ‡å‡†åŒ–åˆ°8æ ¸å¿ƒ
        memory_factor = min(total_memory / 32, 1.0)  # æ ‡å‡†åŒ–åˆ°32GB
        
        # åŸºç¡€ååé‡ä¼°ç®—ï¼šæ¯ä¸ªCPUæ ¸å¿ƒçº¦1000æ¶ˆæ¯/ç§’
        base_throughput = total_cpu * 1000
        optimized_throughput = base_throughput * cpu_factor * memory_factor
        
        return optimized_throughput
    
    def _estimate_latency(self) -> float:
        """ä¼°ç®—é›†ç¾¤å»¶è¿Ÿ"""
        # åŸºäºç½‘ç»œç±»å‹ä¼°ç®—åŸºç¡€å»¶è¿Ÿ
        network_latencies = {
            NetworkType.LOCALHOST: 0.001,    # 1ms
            NetworkType.GIGABIT: 0.010,      # 10ms
            NetworkType.TEN_GIGABIT: 0.005,  # 5ms
            NetworkType.INFINIBAND: 0.001    # 1ms
        }
        
        # è®¡ç®—åŠ æƒå¹³å‡å»¶è¿Ÿ
        total_weight = 0
        weighted_latency = 0
        
        for config in self.node_configs.values():
            weight = config.cpu_cores * config.memory_gb  # CPUå’Œå†…å­˜ä½œä¸ºæƒé‡
            latency = network_latencies[config.network_type]
            weighted_latency += weight * latency
            total_weight += weight
        
        avg_latency = weighted_latency / total_weight if total_weight > 0 else 0.1
        
        # æ·»åŠ èŠ‚ç‚¹é—´é€šä¿¡å»¶è¿Ÿ
        node_communication_factor = max(1.0, (len(self.node_configs) - 1) * 0.1)
        
        return avg_latency * node_communication_factor
    
    def _estimate_max_capacity(self) -> Dict[str, int]:
        """ä¼°ç®—é›†ç¾¤æœ€å¤§å®¹é‡"""
        total_memory = sum(node.memory_gb for node in self.node_configs.values())
        total_disk = sum(node.disk_gb for node in self.node_configs.values())
        
        # åŸºäºå†…å­˜å’Œç£ç›˜ä¼°ç®—å®¹é‡
        # å‡è®¾æ¯GBå†…å­˜å¯å­˜å‚¨çº¦10ä¸‡æ¡æ¶ˆæ¯ï¼ˆ1KBå¤§å°ï¼‰
        memory_capacity = total_memory * 100000
        
        # å‡è®¾æ¯GBç£ç›˜å¯å­˜å‚¨çº¦100ä¸‡æ¡æ¶ˆæ¯
        disk_capacity = total_disk * 1000000
        
        return {
            'memory_based_capacity': memory_capacity,
            'disk_based_capacity': disk_capacity,
            'max_safe_capacity': min(memory_capacity, disk_capacity)
        }
    
    def _generate_cluster_recommendations(self) -> List[str]:
        """ç”Ÿæˆé›†ç¾¤å»ºè®®"""
        recommendations = []
        
        # æ£€æŸ¥èŠ‚ç‚¹æ•°é‡
        if len(self.node_configs) < 3:
            recommendations.append("å»ºè®®è‡³å°‘éƒ¨ç½²3ä¸ªèŠ‚ç‚¹ä»¥ä¿è¯é«˜å¯ç”¨æ€§")
        
        # æ£€æŸ¥è§’è‰²åˆ†å¸ƒ
        roles = self._analyze_node_roles()
        if roles.get('ram', 0) > len(self.node_configs) * 0.5:
            recommendations.append("RAMèŠ‚ç‚¹æ¯”ä¾‹è¿‡é«˜ï¼Œå»ºè®®å¢åŠ ç£ç›˜èŠ‚ç‚¹")
        
        if roles.get('disc', 0) == len(self.node_configs):
            recommendations.append("æ‰€æœ‰èŠ‚ç‚¹éƒ½æ˜¯ç£ç›˜èŠ‚ç‚¹ï¼Œå¯è€ƒè™‘éƒ¨åˆ†èŠ‚ç‚¹æ”¹ä¸ºRAMä»¥æé«˜æ€§èƒ½")
        
        # æ£€æŸ¥èµ„æºå‡è¡¡
        resource_dist = self._analyze_resource_distribution()
        cpu_variance = statistics.variance(resource_dist['cpu_distribution'])
        memory_variance = statistics.variance(resource_dist['memory_distribution'])
        
        if cpu_variance > 2:
            recommendations.append("CPUé…ç½®ä¸å‡è¡¡ï¼Œå»ºè®®ç»Ÿä¸€èŠ‚ç‚¹é…ç½®")
        
        if memory_variance > 4:
            recommendations.append("å†…å­˜é…ç½®ä¸å‡è¡¡ï¼Œå»ºè®®ç»Ÿä¸€èŠ‚ç‚¹é…ç½®")
        
        # æ£€æŸ¥ç½‘ç»œç±»å‹
        topology = self._analyze_network_topology()
        if topology['mixed_networks']:
            recommendations.append("æ··åˆç½‘ç»œç±»å‹å¯èƒ½å½±å“æ€§èƒ½ï¼Œå»ºè®®ç»Ÿä¸€ç½‘ç»œè§„æ ¼")
        
        return recommendations
    
    def optimize_cluster(self, 
                        optimization_type: OptimizationType,
                        target_improvement: float = 0.2,
                        apply_settings: bool = True) -> OptimizationResult:
        """ä¼˜åŒ–é›†ç¾¤"""
        print(f"å¼€å§‹{optimization_type.value}ä¼˜åŒ–...")
        
        # è·å–ä¼˜åŒ–å‰æŒ‡æ ‡
        before_metrics = self._collect_cluster_metrics()
        
        # é€‰æ‹©ä¼˜åŒ–ç­–ç•¥
        strategies = self._get_optimization_strategies(optimization_type)
        applied_settings = {}
        
        print(f"åº”ç”¨ä¼˜åŒ–ç­–ç•¥: {', '.join(strategies.keys())}")
        
        # åº”ç”¨ä¼˜åŒ–è®¾ç½®
        for strategy_name, strategy_func in strategies.items():
            settings = strategy_func(target_improvement)
            applied_settings.update(settings)
            print(f"  - {strategy_name}: {settings}")
        
        # æ¨¡æ‹Ÿç­‰å¾…ä¼˜åŒ–ç”Ÿæ•ˆ
        time.sleep(2)
        
        # è·å–ä¼˜åŒ–åæŒ‡æ ‡
        after_metrics = self._collect_cluster_metrics()
        
        # è®¡ç®—æ”¹è¿›å¹…åº¦
        improvement_percent = self._calculate_improvement(before_metrics, after_metrics)
        performance_gain = after_metrics.message_rate_in - before_metrics.message_rate_in
        
        result = OptimizationResult(
            optimization_type=optimization_type.value,
            before_metrics=before_metrics,
            after_metrics=after_metrics,
            improvement_percent=improvement_percent,
            applied_settings=applied_settings,
            performance_gain=performance_gain,
            timestamp=time.time()
        )
        
        self.optimization_history.append(result)
        
        print(f"âœ… {optimization_type.value}ä¼˜åŒ–å®Œæˆ")
        print(f"  æ€§èƒ½æå‡: {improvement_percent:.1%}")
        print(f"  ååé‡æå‡: {performance_gain:.0f} æ¶ˆæ¯/ç§’")
        print()
        
        return result
    
    def _get_optimization_strategies(self, opt_type: OptimizationType) -> Dict[str, Callable]:
        """è·å–ä¼˜åŒ–ç­–ç•¥"""
        strategies = {}
        
        if opt_type == OptimizationType.THROUGHPUT:
            strategies.update({
                'memory_optimization': self._optimize_memory,
                'cpu_optimization': self._optimize_cpu,
                'network_optimization': self._optimize_network,
                'queue_optimization': self._optimize_queues
            })
        elif opt_type == OptimizationType.LATENCY:
            strategies.update({
                'network_optimization': self._optimize_network,
                'connection_optimization': self._optimize_connections,
                'cluster_balance': self._balance_cluster_load
            })
        elif opt_type == OptimizationType.RELIABILITY:
            strategies.update({
                'disk_optimization': self._optimize_disk,
                'cluster_balance': self._balance_cluster_load,
                'queue_optimization': self._optimize_queues
            })
        elif opt_type == OptimizationType.MEMORY:
            strategies.update({
                'memory_optimization': self._optimize_memory,
                'queue_optimization': self._optimize_queues
            })
        elif opt_type == OptimizationType.BALANCED:
            strategies.update(self.optimization_rules)
        
        return strategies
    
    def _optimize_memory(self, target_improvement: float) -> Dict[str, Any]:
        """å†…å­˜ä¼˜åŒ–"""
        settings = {
            'vm_memory_high_watermark': 0.7,  # é™ä½å†…å­˜æ°´ä½
            'vm_memory_calculation_strategy': 'rss',  # ä½¿ç”¨RSSè®¡ç®—
            'disk_free_limit': 100000000,  # 100MBç£ç›˜é™åˆ¶
            'queue_index_embed_messages': True,  # åµŒå…¥æ¶ˆæ¯åˆ°ç´¢å¼•
            'lazy_queue_persistent': False  # ç¦ç”¨æ‡’é˜Ÿåˆ—æŒä¹…åŒ–
        }
        
        print(f"å†…å­˜ä¼˜åŒ–: é¢„è®¡æå‡ {target_improvement * 100:.0f}% æ€§èƒ½")
        return settings
    
    def _optimize_cpu(self, target_improvement: float) -> Dict[str, Any]:
        """CPUä¼˜åŒ–"""
        settings = {
            'process_limit': 1000,  # å¢åŠ è¿›ç¨‹é™åˆ¶
            'max_connections': 2000,  # å¢åŠ è¿æ¥é™åˆ¶
            'heartbeat': 30,  # å»¶é•¿å¿ƒè·³é—´éš”
            'connection_backlog': 50,  # å¢åŠ è¿æ¥ç§¯å‹
            'channel_max': 1000,  # å¢åŠ é€šé“é™åˆ¶
            'use_cpu_quota': False  # ç¦ç”¨CPUé…é¢
        }
        
        print(f"CPUä¼˜åŒ–: é¢„è®¡æå‡ {target_improvement * 100:.0f}% æ€§èƒ½")
        return settings
    
    def _optimize_disk(self, target_improvement: float) -> Dict[str, Any]:
        """ç£ç›˜ä¼˜åŒ–"""
        settings = {
            'disk_free_limit': 1000000000,  # 1GBç£ç›˜é™åˆ¶
            'disk_monitor_interval': 5000,  # 5ç§’ç›‘æ§é—´éš”
            'queue_index_embed_messages': False,  # ä¸åµŒå…¥æ¶ˆæ¯
            'msg_store_file_size': 16777216,  # 16MBæ–‡ä»¶å¤§å°
            'lazy_queue_persistent': True,  # å¯ç”¨æ‡’é˜Ÿåˆ—
            'lazy_queue_use_disk': True  # ä½¿ç”¨ç£ç›˜å­˜å‚¨
        }
        
        print(f"ç£ç›˜ä¼˜åŒ–: é¢„è®¡æå‡ {target_improvement * 100:.0f}% æ€§èƒ½")
        return settings
    
    def _optimize_network(self, target_improvement: float) -> Dict[str, Any]:
        """ç½‘ç»œä¼˜åŒ–"""
        settings = {
            'network_frame_max': 131072,  # 128KBæœ€å¤§å¸§
            'network_handshake_timeout': 10000,  # 10ç§’æ¡æ‰‹è¶…æ—¶
            'network_server_properties': {
                'capabilities': ['connection.blocked', 'authentication_failure_close'],
                'product': 'RabbitMQ',
                'version': '3.8.0',
                'platform': 'Erlang/OTP',
                'copyright': 'Copyright (C) 2007-2023 Pivotal Software, Inc.',
                'information': 'Licensed under the MPL 2.0. Website: https://rabbitmq.com'
            }
        }
        
        print(f"ç½‘ç»œä¼˜åŒ–: é¢„è®¡æå‡ {target_improvement * 100:.0f}% æ€§èƒ½")
        return settings
    
    def _optimize_queues(self, target_improvement: float) -> Dict[str, Any]:
        """é˜Ÿåˆ—ä¼˜åŒ–"""
        settings = {
            'default_queue_type': 'classic',  # ä½¿ç”¨ç»å…¸é˜Ÿåˆ—
            'queue_master_locator': 'client-local',  # å®¢æˆ·ç«¯æœ¬åœ°å®šä½
            'mirroring_sync_batch_size': 100,  # é•œåƒåŒæ­¥æ‰¹å¤§å°
            'classic_queue_mirroring_sync_timeout': 60000,  # 60ç§’åŒæ­¥è¶…æ—¶
            'lazy_queue_threshold': 10000,  # 10000æ¡æ¶ˆæ¯å¯ç”¨æ‡’é˜Ÿåˆ—
            'dead_letter_exchange': 'dlx',  # å¯ç”¨æ­»ä¿¡äº¤æ¢
            'dead_letter_routing_key': '#'  # æ­»ä¿¡è·¯ç”±é”®
        }
        
        print(f"é˜Ÿåˆ—ä¼˜åŒ–: é¢„è®¡æå‡ {target_improvement * 100:.0f}% æ€§èƒ½")
        return settings
    
    def _optimize_connections(self, target_improvement: float) -> Dict[str, Any]:
        """è¿æ¥ä¼˜åŒ–"""
        settings = {
            'connection_max_channels': 500,  # æœ€å¤§é€šé“æ•°
            'channel_keepalive_duration': 2000,  # 2ç§’é€šé“ä¿æ´»
            'heartbeat_timeout': 30,  # 30ç§’å¿ƒè·³è¶…æ—¶
            'connection_timeout': 30000,  # 30ç§’è¿æ¥è¶…æ—¶
            'channel_flow_control': True,  # å¯ç”¨é€šé“æµæ§åˆ¶
            'channel_operation_timeout': 15000  # 15ç§’æ“ä½œè¶…æ—¶
        }
        
        print(f"è¿æ¥ä¼˜åŒ–: é¢„è®¡æå‡ {target_improvement * 100:.0f}% æ€§èƒ½")
        return settings
    
    def _balance_cluster_load(self, target_improvement: float) -> Dict[str, Any]:
        """å¹³è¡¡é›†ç¾¤è´Ÿè½½"""
        settings = {
            'queue_leader_locator': 'min-masters',  # æœ€å°‘ä¸»èŠ‚ç‚¹
            'classic_queue_mirroring_master_policy': 'exactly',
            'mirroring_parameters': 'queues with policy',
            'cluster_formation_target': 3,  # ç›®æ ‡3èŠ‚ç‚¹é›†ç¾¤
            'force_peer_down_on_failed_health_check': True,  # å¥åº·æ£€æŸ¥å¤±è´¥æ—¶å¼ºåˆ¶ä¸‹çº¿
            'health_check_timeout': 30000  # 30ç§’å¥åº·æ£€æŸ¥è¶…æ—¶
        }
        
        print(f"è´Ÿè½½å‡è¡¡: é¢„è®¡æå‡ {target_improvement * 100:.0f}% æ€§èƒ½")
        return settings
    
    def _collect_cluster_metrics(self) -> ClusterMetrics:
        """æ”¶é›†é›†ç¾¤æŒ‡æ ‡"""
        # æ¨¡æ‹Ÿæ”¶é›†æŒ‡æ ‡
        return ClusterMetrics(
            timestamp=time.time(),
            total_nodes=len(self.node_configs),
            running_nodes=len(self.node_configs),
            total_queues=100,
            total_connections=500,
            total_channels=1000,
            total_messages=10000,
            ready_messages=8000,
            unacked_messages=2000,
            memory_usage_bytes=2 * 1024 * 1024 * 1024,  # 2GB
            disk_usage_bytes=20 * 1024 * 1024 * 1024,  # 20GB
            cpu_usage_percent=45.5,
            network_io_mbps=100.0,
            cluster_load=0.65,
            queue_depth_avg=100.0,
            message_rate_in=5000.0,
            message_rate_out=4800.0
        )
    
    def _calculate_improvement(self, before: ClusterMetrics, after: ClusterMetrics) -> float:
        """è®¡ç®—æ”¹è¿›å¹…åº¦"""
        # åŸºäºååé‡æ”¹è¿›è®¡ç®—
        throughput_improvement = (after.message_rate_in - before.message_rate_in) / before.message_rate_in
        
        # åŸºäºå»¶è¿Ÿæ”¹è¿›è®¡ç®—ï¼ˆå»¶è¿Ÿé™ä½æ˜¯æ”¹è¿›ï¼‰
        latency_improvement = (before.cpu_usage_percent - after.cpu_usage_percent) / 100.0
        
        # ç»¼åˆè¯„åˆ†
        overall_improvement = (throughput_improvement + latency_improvement) / 2
        
        return max(0.0, overall_improvement)
    
    def get_optimization_history(self) -> List[OptimizationResult]:
        """è·å–ä¼˜åŒ–å†å²"""
        return self.optimization_history
    
    def generate_optimization_report(self) -> str:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        if not self.optimization_history:
            return "æ²¡æœ‰ä¼˜åŒ–å†å²è®°å½•"
        
        report = []
        report.append("# RabbitMQ é›†ç¾¤ä¼˜åŒ–æŠ¥å‘Š")
        report.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        report.append("## ä¼˜åŒ–å†å²")
        for result in self.optimization_history:
            report.append(f"### {result.optimization_type.title()}ä¼˜åŒ–")
            report.append(f"- æ—¶é—´: {datetime.fromtimestamp(result.timestamp).strftime('%H:%M:%S')}")
            report.append(f"- æ€§èƒ½æå‡: {result.improvement_percent:.1%}")
            report.append(f"- ååé‡æå‡: {result.performance_gain:.0f} æ¶ˆæ¯/ç§’")
            report.append(f"- åº”ç”¨è®¾ç½®: {len(result.applied_settings)} é¡¹")
            report.append("")
        
        # ç»Ÿè®¡ä¿¡æ¯
        if self.optimization_history:
            total_improvements = [r.improvement_percent for r in self.optimization_history]
            avg_improvement = sum(total_improvements) / len(total_improvements)
            max_improvement = max(total_improvements)
            
            report.append("## ä¼˜åŒ–ç»Ÿè®¡")
            report.append(f"- æ€»ä¼˜åŒ–æ¬¡æ•°: {len(self.optimization_history)}")
            report.append(f"- å¹³å‡æ€§èƒ½æå‡: {avg_improvement:.1%}")
            report.append(f"- æœ€å¤§æ€§èƒ½æå‡: {max_improvement:.1%}")
        
        return "\n".join(report)


class ClusterBenchmarker:
    """é›†ç¾¤åŸºå‡†æµ‹è¯•å™¨"""
    
    def __init__(self, cluster_optimizer: ClusterOptimizer):
        self.cluster_optimizer = cluster_optimizer
        self.test_results = []
    
    def run_cluster_benchmark(self,
                            test_type: str = "throughput",
                            duration: int = 60,
                            message_count: int = 10000,
                            message_size: int = 1024,
                            concurrent_producers: int = 10,
                            concurrent_consumers: int = 10) -> Dict[str, Any]:
        """è¿è¡Œé›†ç¾¤åŸºå‡†æµ‹è¯•"""
        print(f"å¼€å§‹é›†ç¾¤åŸºå‡†æµ‹è¯•:")
        print(f"  æµ‹è¯•ç±»å‹: {test_type}")
        print(f"  æŒç»­æ—¶é—´: {duration}ç§’")
        print(f"  æ¶ˆæ¯æ•°é‡: {message_count}")
        print(f"  æ¶ˆæ¯å¤§å°: {message_size}å­—èŠ‚")
        print(f"  å¹¶å‘ç”Ÿäº§è€…: {concurrent_producers}")
        print(f"  å¹¶å‘æ¶ˆè´¹è€…: {concurrent_consumers}")
        print()
        
        start_time = time.time()
        metrics_collection = []
        
        # æ¨¡æ‹ŸåŸºå‡†æµ‹è¯•
        def collect_metrics():
            end_time = start_time + duration
            while time.time() < end_time:
                metrics = self._simulate_cluster_metrics()
                metrics_collection.append(metrics)
                time.sleep(1)  # æ¯ç§’æ”¶é›†ä¸€æ¬¡
        
        # å¯åŠ¨æŒ‡æ ‡æ”¶é›†
        metrics_thread = threading.Thread(target=collect_metrics)
        metrics_thread.start()
        
        # æ¨¡æ‹Ÿæµ‹è¯•è´Ÿè½½
        self._simulate_test_load(
            test_type, message_count, message_size,
            concurrent_producers, concurrent_consumers
        )
        
        # ç­‰å¾…æŒ‡æ ‡æ”¶é›†å®Œæˆ
        metrics_thread.join()
        
        # åˆ†æç»“æœ
        result = self._analyze_benchmark_results(metrics_collection, duration, test_type)
        
        print("âœ… é›†ç¾¤åŸºå‡†æµ‹è¯•å®Œæˆ:")
        print(f"  æ€»è€—æ—¶: {duration}ç§’")
        print(f"  å¹³å‡ååé‡: {result['avg_throughput']:.2f} æ¶ˆæ¯/ç§’")
        print(f"  å³°å€¼ååé‡: {result['peak_throughput']:.2f} æ¶ˆæ¯/ç§’")
        print(f"  å¹³å‡å»¶è¿Ÿ: {result['avg_latency']:.4f} ç§’")
        print(f"  95%å»¶è¿Ÿ: {result['latency_p95']:.4f} ç§’")
        print(f"  é”™è¯¯ç‡: {result['error_rate']:.2%}")
        print(f"  CPUä½¿ç”¨ç‡: {result['avg_cpu_usage']:.1f}%")
        print(f"  å†…å­˜ä½¿ç”¨ç‡: {result['avg_memory_usage']:.1f}%")
        print()
        
        self.test_results.append(result)
        return result
    
    def _simulate_cluster_metrics(self) -> Dict[str, float]:
        """æ¨¡æ‹Ÿé›†ç¾¤æŒ‡æ ‡"""
        import random
        
        return {
            'timestamp': time.time(),
            'throughput_in': random.uniform(4500, 5500),
            'throughput_out': random.uniform(4400, 5400),
            'latency': random.uniform(0.05, 0.15),
            'cpu_usage': random.uniform(40, 60),
            'memory_usage': random.uniform(60, 80),
            'disk_usage': random.uniform(30, 50),
            'connection_count': random.uniform(450, 550),
            'channel_count': random.uniform(900, 1100),
            'queue_count': 100,
            'message_count': random.uniform(9500, 10500)
        }
    
    def _simulate_test_load(self, 
                          test_type: str,
                          message_count: int,
                          message_size: int,
                          concurrent_producers: int,
                          concurrent_consumers: int):
        """æ¨¡æ‹Ÿæµ‹è¯•è´Ÿè½½"""
        import random
        import threading
        
        def producer():
            messages_per_producer = message_count // concurrent_producers
            for i in range(messages_per_producer):
                # æ¨¡æ‹Ÿå‘é€å»¶è¿Ÿ
                time.sleep(random.uniform(0.01, 0.05))
                
                # æ¨¡æ‹Ÿä¸åŒæµ‹è¯•ç±»å‹çš„è´Ÿè½½æ¨¡å¼
                if test_type == "burst":
                    if i % 10 == 0:  # æ¯10æ¡æ¶ˆæ¯çˆ†å‘
                        time.sleep(random.uniform(0.1, 0.3))
                elif test_type == "sustained":
                    time.sleep(0.02)  # æŒç»­è´Ÿè½½
                elif test_type == "high_throughput":
                    time.sleep(random.uniform(0.005, 0.01))  # é«˜ååé‡
        
        def consumer():
            # æ¨¡æ‹Ÿæ¶ˆè´¹å»¶è¿Ÿ
            for i in range(message_count // concurrent_consumers):
                time.sleep(random.uniform(0.01, 0.03))
        
        threads = []
        
        # å¯åŠ¨ç”Ÿäº§è€…çº¿ç¨‹
        for i in range(concurrent_producers):
            thread = threading.Thread(target=producer)
            threads.append(thread)
            thread.start()
        
        # å¯åŠ¨æ¶ˆè´¹è€…çº¿ç¨‹
        for i in range(concurrent_consumers):
            thread = threading.Thread(target=consumer)
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
    
    def _analyze_benchmark_results(self, 
                                 metrics_collection: List[Dict[str, float]], 
                                 duration: int,
                                 test_type: str) -> Dict[str, Any]:
        """åˆ†æåŸºå‡†æµ‹è¯•ç»“æœ"""
        if not metrics_collection:
            return {}
        
        # è®¡ç®—å¹³å‡å€¼
        throughputs_in = [m['throughput_in'] for m in metrics_collection]
        throughputs_out = [m['throughput_out'] for m in metrics_collection]
        latencies = [m['latency'] for m in metrics_collection]
        cpu_usages = [m['cpu_usage'] for m in metrics_collection]
        memory_usages = [m['memory_usage'] for m in metrics_collection]
        
        result = {
            'test_type': test_type,
            'duration': duration,
            'avg_throughput': statistics.mean(throughputs_in),
            'peak_throughput': max(throughputs_in),
            'min_throughput': min(throughputs_in),
            'avg_latency': statistics.mean(latencies),
            'latency_p95': self._calculate_percentile(latencies, 95),
            'latency_p99': self._calculate_percentile(latencies, 99),
            'avg_cpu_usage': statistics.mean(cpu_usages),
            'max_cpu_usage': max(cpu_usages),
            'avg_memory_usage': statistics.mean(memory_usages),
            'max_memory_usage': max(memory_usages),
            'error_rate': 0.01,  # å‡è®¾1%é”™è¯¯ç‡
            'total_messages': sum(throughputs_in) * duration,
            'stability_score': self._calculate_stability_score(throughputs_in)
        }
        
        return result
    
    def _calculate_percentile(self, values: List[float], percentile: int) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        sorted_values = sorted(values)
        index = int(len(sorted_values) * percentile / 100)
        return sorted_values[min(index, len(sorted_values) - 1)]
    
    def _calculate_stability_score(self, throughputs: List[float]) -> float:
        """è®¡ç®—ç¨³å®šæ€§è¯„åˆ†"""
        if not throughputs:
            return 0.0
        
        mean_throughput = statistics.mean(throughputs)
        variance = statistics.variance(throughputs)
        
        # ç¨³å®šæ€§è¯„åˆ†ï¼šæ–¹å·®è¶Šå°åˆ†æ•°è¶Šé«˜
        stability_score = max(0, 100 - (variance / mean_throughput) * 10)
        return min(100, stability_score)
    
    def compare_optimizations(self, 
                            before_optimization: List[OptimizationType],
                            after_optimization: List[OptimizationType]) -> Dict[str, Any]:
        """å¯¹æ¯”ä¼˜åŒ–æ•ˆæœ"""
        print("å¼€å§‹ä¼˜åŒ–å‰åå¯¹æ¯”æµ‹è¯•...")
        
        # ä¼˜åŒ–å‰æµ‹è¯•
        print("æµ‹è¯•ä¼˜åŒ–å‰æ€§èƒ½...")
        before_results = []
        for opt_type in before_optimization:
            result = self.cluster_optimizer.optimize_cluster(opt_type, apply_settings=False)
            benchmark_result = self.run_cluster_benchmark("throughput", 30, 5000)
            before_results.append({
                'optimization': opt_type.value,
                'benchmark': benchmark_result
            })
        
        # ä¼˜åŒ–åæµ‹è¯•
        print("æµ‹è¯•ä¼˜åŒ–åæ€§èƒ½...")
        after_results = []
        for opt_type in after_optimization:
            result = self.cluster_optimizer.optimize_cluster(opt_type, apply_settings=True)
            benchmark_result = self.run_cluster_benchmark("throughput", 30, 5000)
            after_results.append({
                'optimization': opt_type.value,
                'benchmark': benchmark_result
            })
        
        # å¯¹æ¯”åˆ†æ
        comparison = self._analyze_optimization_comparison(before_results, after_results)
        
        print("âœ… ä¼˜åŒ–å¯¹æ¯”æµ‹è¯•å®Œæˆ:")
        for opt_name, metrics in comparison.items():
            print(f"  {opt_name}:")
            print(f"    ååé‡æå‡: {metrics['throughput_improvement']:.1%}")
            print(f"    å»¶è¿Ÿæ”¹å–„: {metrics['latency_improvement']:.1%}")
            print(f"    CPUä¼˜åŒ–: {metrics['cpu_optimization']:.1f}%")
        
        return comparison
    
    def _analyze_optimization_comparison(self, 
                                       before_results: List[Dict[str, Any]],
                                       after_results: List[Dict[str, Any]]) -> Dict[str, Dict[str, float]]:
        """åˆ†æä¼˜åŒ–å¯¹æ¯”"""
        comparison = {}
        
        for i, (before, after) in enumerate(zip(before_results, after_results)):
            opt_name = after['optimization']
            
            before_benchmark = before['benchmark']
            after_benchmark = after['benchmark']
            
            # è®¡ç®—å„é¡¹æŒ‡æ ‡æ”¹è¿›
            throughput_improvement = (
                (after_benchmark['avg_throughput'] - before_benchmark['avg_throughput']) 
                / before_benchmark['avg_throughput']
            )
            
            latency_improvement = (
                (before_benchmark['avg_latency'] - after_benchmark['avg_latency'])
                / before_benchmark['avg_latency']
            )
            
            cpu_optimization = before_benchmark['avg_cpu_usage'] - after_benchmark['avg_cpu_usage']
            
            comparison[opt_name] = {
                'throughput_improvement': throughput_improvement,
                'latency_improvement': latency_improvement,
                'cpu_optimization': cpu_optimization
            }
        
        return comparison


class ClusterOptimizationDemo:
    """é›†ç¾¤ä¼˜åŒ–æ¼”ç¤º"""
    
    def __init__(self):
        self.cluster_optimizer = ClusterOptimizer()
        self.cluster_benchmarker = ClusterBenchmarker(self.cluster_optimizer)
        self._setup_demo_cluster()
    
    def _setup_demo_cluster(self):
        """è®¾ç½®æ¼”ç¤ºé›†ç¾¤"""
        # åˆ›å»ºæ¼”ç¤ºèŠ‚ç‚¹
        nodes = [
            NodeConfig("node1", "rabbitmq-1.example.com", 5672, 
                      cpu_cores=8, memory_gb=16, disk_gb=200, role="disc"),
            NodeConfig("node2", "rabbitmq-2.example.com", 5672, 
                      cpu_cores=8, memory_gb=16, disk_gb=200, role="disc"),
            NodeConfig("node3", "rabbitmq-3.example.com", 5672, 
                      cpu_cores=4, memory_gb=8, disk_gb=100, role="ram"),
            NodeConfig("node4", "rabbitmq-4.example.com", 5672, 
                      cpu_cores=4, memory_gb=8, disk_gb=100, role="ram")
        ]
        
        for node in nodes:
            self.cluster_optimizer.add_node(node)
        
        print(f"âœ… æ¼”ç¤ºé›†ç¾¤å·²è®¾ç½®: {len(nodes)} ä¸ªèŠ‚ç‚¹")
        print()
    
    def demonstrate_cluster_analysis(self):
        """æ¼”ç¤ºé›†ç¾¤åˆ†æ"""
        print("=== é›†ç¾¤çŠ¶æ€åˆ†ææ¼”ç¤º ===")
        print()
        
        # åˆ†æå½“å‰çŠ¶æ€
        analysis = self.cluster_optimizer.analyze_current_state()
        
        print("ğŸ“Š é›†ç¾¤ä¿¡æ¯:")
        cluster_info = analysis['cluster_info']
        print(f"  æ€»èŠ‚ç‚¹æ•°: {cluster_info['total_nodes']}")
        print(f"  è§’è‰²åˆ†å¸ƒ: {cluster_info['roles']}")
        
        print("\nğŸ’» èµ„æºåˆ†å¸ƒ:")
        resources = cluster_info['resource_distribution']
        print(f"  CPUåˆ†å¸ƒ: {resources['cpu_distribution']}")
        print(f"  å†…å­˜åˆ†å¸ƒ: {resources['memory_distribution']} GB")
        print(f"  å¹³å‡CPU/èŠ‚ç‚¹: {resources['avg_cpu_per_node']:.1f}")
        print(f"  å¹³å‡å†…å­˜/èŠ‚ç‚¹: {resources['avg_memory_per_node']:.1f} GB")
        
        print("\nğŸŒ ç½‘ç»œæ‹“æ‰‘:")
        topology = cluster_info['network_topology']
        print(f"  ç½‘ç»œç±»å‹: {topology['network_types']}")
        print(f"  æ··åˆç½‘ç»œ: {topology['mixed_networks']}")
        
        print("\nğŸš€ æ€§èƒ½åŸºçº¿:")
        performance = analysis['performance_baseline']
        print(f"  ä¼°ç®—ååé‡: {performance['estimated_throughput']:.0f} æ¶ˆæ¯/ç§’")
        print(f"  ä¼°ç®—å»¶è¿Ÿ: {performance['estimated_latency']:.4f} ç§’")
        print(f"  æœ€å¤§å®¹é‡: {performance['max_capacity']['max_safe_capacity']:,} æ¶ˆæ¯")
        
        print("\nğŸ’¡ ä¼˜åŒ–å»ºè®®:")
        recommendations = analysis['recommendations']
        for i, rec in enumerate(recommendations, 1):
            print(f"  {i}. {rec}")
        
        print()
        return analysis
    
    def demonstrate_optimization_strategies(self):
        """æ¼”ç¤ºä¼˜åŒ–ç­–ç•¥"""
        print("=== é›†ç¾¤ä¼˜åŒ–ç­–ç•¥æ¼”ç¤º ===")
        print()
        
        optimization_types = [
            OptimizationType.THROUGHPUT,
            OptimizationType.LATENCY,
            OptimizationType.MEMORY,
            OptimizationType.BALANCED
        ]
        
        results = []
        
        for opt_type in optimization_types:
            print(f"æ‰§è¡Œ {opt_type.value} ä¼˜åŒ–...")
            result = self.cluster_optimizer.optimize_cluster(opt_type)
            results.append(result)
        
        # æ˜¾ç¤ºä¼˜åŒ–å†å²
        print("ğŸ“ˆ ä¼˜åŒ–å†å²:")
        history = self.cluster_optimizer.get_optimization_history()
        for result in history:
            print(f"  {result.optimization_type}: {result.improvement_percent:.1%} æå‡")
        
        print()
        return results
    
    def demonstrate_benchmark_testing(self):
        """æ¼”ç¤ºåŸºå‡†æµ‹è¯•"""
        print("=== é›†ç¾¤åŸºå‡†æµ‹è¯•æ¼”ç¤º ===")
        print()
        
        test_types = ["throughput", "latency", "burst"]
        all_results = []
        
        for test_type in test_types:
            print(f"è¿è¡Œ {test_type} æµ‹è¯•...")
            result = self.cluster_benchmarker.run_cluster_benchmark(
                test_type=test_type,
                duration=30,  # 30ç§’æµ‹è¯•
                message_count=5000,
                message_size=1024,
                concurrent_producers=5,
                concurrent_consumers=5
            )
            all_results.append(result)
        
        # åˆ†ææµ‹è¯•ç»“æœ
        print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
        for result in all_results:
            print(f"  {result['test_type']} æµ‹è¯•:")
            print(f"    å¹³å‡ååé‡: {result['avg_throughput']:.0f} æ¶ˆæ¯/ç§’")
            print(f"    å¹³å‡å»¶è¿Ÿ: {result['avg_latency']:.4f} ç§’")
            print(f"    ç¨³å®šæ€§è¯„åˆ†: {result['stability_score']:.1f}/100")
        
        print()
        return all_results
    
    def demonstrate_optimization_comparison(self):
        """æ¼”ç¤ºä¼˜åŒ–å¯¹æ¯”"""
        print("=== ä¼˜åŒ–å‰åå¯¹æ¯”æ¼”ç¤º ===")
        print()
        
        before_types = [OptimizationType.MEMORY]
        after_types = [OptimizationType.THROUGHPUT, OptimizationType.LATENCY]
        
        comparison = self.cluster_benchmarker.compare_optimizations(
            before_optimization=before_types,
            after_optimization=after_types
        )
        
        print("âœ… ä¼˜åŒ–å¯¹æ¯”å®Œæˆ")
        print()
        return comparison
    
    def demonstrate_complete_workflow(self):
        """æ¼”ç¤ºå®Œæ•´å·¥ä½œæµç¨‹"""
        print("ğŸš€ RabbitMQ é›†ç¾¤ä¼˜åŒ–å®Œæ•´æµç¨‹æ¼”ç¤º")
        print("=" * 50)
        print()
        
        try:
            # 1. é›†ç¾¤åˆ†æ
            analysis = self.demonstrate_cluster_analysis()
            
            # 2. ä¼˜åŒ–ç­–ç•¥æ¼”ç¤º
            optimization_results = self.demonstrate_optimization_strategies()
            
            # 3. åŸºå‡†æµ‹è¯•æ¼”ç¤º
            benchmark_results = self.demonstrate_benchmark_testing()
            
            # 4. ä¼˜åŒ–å¯¹æ¯”æ¼”ç¤º
            comparison_results = self.demonstrate_optimization_comparison()
            
            # 5. ç”ŸæˆæŠ¥å‘Š
            report = self.cluster_optimizer.generate_optimization_report()
            print("ğŸ“‹ ä¼˜åŒ–æŠ¥å‘Š:")
            print(report)
            
            # 6. æä¾›æœ€ç»ˆå»ºè®®
            print("\nğŸ¯ æœ€ç»ˆä¼˜åŒ–å»ºè®®:")
            if benchmark_results:
                best_test = max(benchmark_results, key=lambda r: r['stability_score'])
                print(f"  æœ€ä½³ç¨³å®šæ€§æµ‹è¯•: {best_test['test_type']} (è¯„åˆ†: {best_test['stability_score']:.1f})")
            
            if optimization_results:
                best_optimization = max(optimization_results, key=lambda r: r.improvement_percent)
                print(f"  æœ€ä½³ä¼˜åŒ–ç­–ç•¥: {best_optimization.optimization_type} (æå‡: {best_optimization.improvement_percent:.1%})")
            
            print("\nğŸ‰ é›†ç¾¤ä¼˜åŒ–æ¼”ç¤ºå®Œæˆ!")
            
        except KeyboardInterrupt:
            print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    # è¿è¡Œé›†ç¾¤ä¼˜åŒ–æ¼”ç¤º
    demo = ClusterOptimizationDemo()
    demo.demonstrate_complete_workflow()