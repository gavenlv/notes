#!/usr/bin/env python3
"""
ç¬¬8ç« ï¼šæ€§èƒ½ç›‘æ§ä¸è°ƒä¼˜ç¤ºä¾‹
 RabbitMQ æ€§èƒ½ç›‘æ§ã€åŸºå‡†æµ‹è¯•å’Œå®æ—¶è°ƒä¼˜å·¥å…·
"""

import time
import threading
import json
import asyncio
import statistics
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from enum import Enum
import heapq
import time
import threading
from collections import deque, defaultdict
import logging


class MetricType(Enum):
    """æŒ‡æ ‡ç±»å‹"""
    COUNTER = "counter"
    GAUGE = "gauge"
    HISTOGRAM = "histogram"
    TIMER = "timer"


class AlertLevel(Enum):
    """å‘Šè­¦çº§åˆ«"""
    INFO = "info"
    WARNING = "warning"
    CRITICAL = "critical"


@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ ‡"""
    name: str
    value: float
    metric_type: MetricType
    timestamp: float
    tags: Dict[str, str] = None
    
    def __post_init__(self):
        if self.tags is None:
            self.tags = {}


@dataclass
class AlertRule:
    """å‘Šè­¦è§„åˆ™"""
    name: str
    metric_name: str
    condition: str  # ">", "<", ">=", "<=", "==", "!="
    threshold: float
    level: AlertLevel
    description: str
    enabled: bool = True


@dataclass
class Alert:
    """å‘Šè­¦"""
    rule_name: str
    metric_name: str
    value: float
    threshold: float
    level: AlertLevel
    message: str
    timestamp: float
    resolved: bool = False


class PerformanceCounter:
    """æ€§èƒ½è®¡æ•°å™¨"""
    
    def __init__(self, name: str):
        self.name = name
        self.value = 0
        self._lock = threading.Lock()
    
    def increment(self, amount: float = 1):
        """å¢åŠ è®¡æ•°å™¨"""
        with self._lock:
            self.value += amount
    
    def decrement(self, amount: float = 1):
        """å‡å°‘è®¡æ•°å™¨"""
        with self._lock:
            self.value -= amount
    
    def reset(self):
        """é‡ç½®è®¡æ•°å™¨"""
        with self._lock:
            self.value = 0
    
    def get_value(self) -> float:
        """è·å–å½“å‰å€¼"""
        with self._lock:
            return self.value


class PerformanceGauge:
    """æ€§èƒ½ä»ªè¡¨"""
    
    def __init__(self, name: str):
        self.name = name
        self.value = 0.0
        self._lock = threading.Lock()
    
    def set(self, value: float):
        """è®¾ç½®å€¼"""
        with self._lock:
            self.value = value
    
    def get_value(self) -> float:
        """è·å–å½“å‰å€¼"""
        with self._lock:
            return self.value


class PerformanceHistogram:
    """æ€§èƒ½ç›´æ–¹å›¾"""
    
    def __init__(self, name: str, buckets: List[float] = None):
        self.name = name
        self.count = 0
        self.sum = 0.0
        self.buckets = buckets or [0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1.0, 2.5, 5.0, 7.5, 10.0]
        self.bucket_counts = {bucket: 0 for bucket in self.buckets}
        self.max_value = 0.0
        self._lock = threading.Lock()
    
    def observe(self, value: float):
        """è®°å½•è§‚æµ‹å€¼"""
        with self._lock:
            self.count += 1
            self.sum += value
            self.max_value = max(self.max_value, value)
            
            # æ›´æ–°æ¡¶è®¡æ•°
            for bucket in self.buckets:
                if value <= bucket:
                    self.bucket_counts[bucket] += 1
    
    def get_quantile(self, quantile: float) -> float:
        """è·å–åˆ†ä½æ•°"""
        with self._lock:
            if self.count == 0:
                return 0.0
            
            # ç®€åŒ–å®ç°ï¼Œè¿”å›ç™¾åˆ†ä½æ•°
            sorted_values = []
            # è¿™é‡Œåº”è¯¥æœ‰å®Œæ•´çš„æ•°æ®ç‚¹å­˜å‚¨ï¼Œç®€åŒ–å¤„ç†
            if quantile <= 0.5:
                return self.max_value * quantile * 2
            else:
                return self.max_value
    
    def get_stats(self) -> Dict[str, float]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            if self.count == 0:
                return {
                    'count': 0,
                    'sum': 0.0,
                    'avg': 0.0,
                    'max': 0.0
                }
            
            return {
                'count': self.count,
                'sum': self.sum,
                'avg': self.sum / self.count,
                'max': self.max_value
            }


class PerformanceTimer:
    """æ€§èƒ½è®¡æ—¶å™¨"""
    
    def __init__(self, name: str):
        self.name = name
        self.histogram = PerformanceHistogram(name)
        self._lock = threading.Lock()
    
    def time_function(self, func: Callable, *args, **kwargs):
        """è®¡æ—¶æ‰§è¡Œå‡½æ•°"""
        start_time = time.perf_counter()
        try:
            result = func(*args, **kwargs)
            elapsed = time.perf_counter() - start_time
            self.histogram.observe(elapsed)
            return result
        except Exception as e:
            elapsed = time.perf_counter() - start_time
            self.histogram.observe(elapsed)
            raise e
    
    def time_context(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨è®¡æ—¶"""
        return TimerContext(self.histogram)


class TimerContext:
    """è®¡æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self, histogram: PerformanceHistogram):
        self.histogram = histogram
        self.start_time = None
    
    def __enter__(self):
        self.start_time = time.perf_counter()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        elapsed = time.perf_counter() - self.start_time
        self.histogram.observe(elapsed)


class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        self.counters = {}
        self.gauges = {}
        self.histograms = {}
        self.timers = {}
        self._lock = threading.Lock()
        
        # å®æ—¶æ•°æ®
        self.current_metrics = {}
        self.metric_history = defaultdict(deque)
        
    def get_counter(self, name: str) -> PerformanceCounter:
        """è·å–æˆ–åˆ›å»ºè®¡æ•°å™¨"""
        with self._lock:
            if name not in self.counters:
                self.counters[name] = PerformanceCounter(name)
            return self.counters[name]
    
    def get_gauge(self, name: str) -> PerformanceGauge:
        """è·å–æˆ–åˆ›å»ºä»ªè¡¨"""
        with self._lock:
            if name not in self.gauges:
                self.gauges[name] = PerformanceGauge(name)
            return self.gauges[name]
    
    def get_histogram(self, name: str, buckets: List[float] = None) -> PerformanceHistogram:
        """è·å–æˆ–åˆ›å»ºç›´æ–¹å›¾"""
        with self._lock:
            if name not in self.histograms:
                self.histograms[name] = PerformanceHistogram(name, buckets)
            return self.histograms[name]
    
    def get_timer(self, name: str) -> PerformanceTimer:
        """è·å–æˆ–åˆ›å»ºè®¡æ—¶å™¨"""
        with self._lock:
            if name not in self.timers:
                self.timers[name] = PerformanceTimer(name)
            return self.timers[name]
    
    def record_metric(self, metric: PerformanceMetric):
        """è®°å½•æŒ‡æ ‡"""
        with self._lock:
            self.current_metrics[metric.name] = metric
            # ä¿æŒå†å²æ•°æ®ï¼ˆæœ€è¿‘100ä¸ªæ•°æ®ç‚¹ï¼‰
            history = self.metric_history[metric.name]
            history.append(metric)
            if len(history) > 100:
                history.popleft()
    
    def get_current_metrics(self) -> Dict[str, PerformanceMetric]:
        """è·å–å½“å‰æŒ‡æ ‡"""
        with self._lock:
            return self.current_metrics.copy()
    
    def get_metric_history(self, name: str, limit: int = 100) -> List[PerformanceMetric]:
        """è·å–æŒ‡æ ‡å†å²"""
        with self._lock:
            history = self.metric_history[name]
            return list(history)[-limit:]
    
    def get_all_stats(self) -> Dict[str, Any]:
        """è·å–æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        with self._lock:
            # è®¡æ•°å™¨ç»Ÿè®¡
            for name, counter in self.counters.items():
                stats[name] = {
                    'type': 'counter',
                    'value': counter.get_value()
                }
            
            # ä»ªè¡¨ç»Ÿè®¡
            for name, gauge in self.gauges.items():
                stats[name] = {
                    'type': 'gauge',
                    'value': gauge.get_value()
                }
            
            # ç›´æ–¹å›¾ç»Ÿè®¡
            for name, histogram in self.histograms.items():
                stats[name] = {
                    'type': 'histogram',
                    'stats': histogram.get_stats()
                }
            
            # è®¡æ—¶å™¨ç»Ÿè®¡
            for name, timer in self.timers.items():
                stats[name] = {
                    'type': 'timer',
                    'stats': timer.histogram.get_stats()
                }
        
        return stats


class AlertEngine:
    """å‘Šè­¦å¼•æ“"""
    
    def __init__(self):
        self.rules: List[AlertRule] = []
        self.active_alerts: List[Alert] = []
        self.alert_history: List[Alert] = []
        self._lock = threading.Lock()
    
    def add_rule(self, rule: AlertRule):
        """æ·»åŠ å‘Šè­¦è§„åˆ™"""
        with self._lock:
            self.rules.append(rule)
    
    def remove_rule(self, rule_name: str):
        """ç§»é™¤å‘Šè­¦è§„åˆ™"""
        with self._lock:
            self.rules = [r for r in self.rules if r.name != rule_name]
    
    def evaluate_rules(self, metrics: Dict[str, PerformanceMetric]) -> List[Alert]:
        """è¯„ä¼°å‘Šè­¦è§„åˆ™"""
        new_alerts = []
        
        with self._lock:
            for rule in self.rules:
                if not rule.enabled:
                    continue
                
                if rule.metric_name not in metrics:
                    continue
                
                metric_value = metrics[rule.metric_name].value
                triggered = False
                
                if rule.condition == ">" and metric_value > rule.threshold:
                    triggered = True
                elif rule.condition == "<" and metric_value < rule.threshold:
                    triggered = True
                elif rule.condition == ">=" and metric_value >= rule.threshold:
                    triggered = True
                elif rule.condition == "<=" and metric_value <= rule.threshold:
                    triggered = True
                elif rule.condition == "==" and metric_value == rule.threshold:
                    triggered = True
                elif rule.condition == "!=" and metric_value != rule.threshold:
                    triggered = True
                
                if triggered:
                    alert = Alert(
                        rule_name=rule.name,
                        metric_name=rule.metric_name,
                        value=metric_value,
                        threshold=rule.threshold,
                        level=rule.level,
                        message=f"{rule.name}: {rule.metric_name} {rule.condition} {rule.threshold}, å½“å‰å€¼: {metric_value}",
                        timestamp=time.time(),
                        resolved=False
                    )
                    new_alerts.append(alert)
        
        # æ·»åŠ åˆ°å‘Šè­¦åˆ—è¡¨
        if new_alerts:
            with self._lock:
                self.active_alerts.extend(new_alerts)
                self.alert_history.extend(new_alerts)
        
        return new_alerts
    
    def resolve_alert(self, alert_id: str):
        """è§£å†³å‘Šè­¦"""
        with self._lock:
            for alert in self.active_alerts:
                if alert.rule_name == alert_id:
                    alert.resolved = True
            self.active_alerts = [a for a in self.active_alerts if not a.resolved]
    
    def get_active_alerts(self) -> List[Alert]:
        """è·å–æ´»è·ƒå‘Šè­¦"""
        with self._lock:
            return [a for a in self.active_alerts if not a.resolved]


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self, interval: float = 1.0):
        self.interval = interval
        self.collector = MetricsCollector()
        self.alert_engine = AlertEngine()
        self.monitoring = False
        self.monitor_thread = None
        
        # ç›‘æ§å›è°ƒå‡½æ•°
        self.monitor_callbacks = []
        
        # é»˜è®¤å‘Šè­¦è§„åˆ™
        self._setup_default_alerts()
    
    def _setup_default_alerts(self):
        """è®¾ç½®é»˜è®¤å‘Šè­¦è§„åˆ™"""
        default_rules = [
            AlertRule(
                name="high_cpu_usage",
                metric_name="system.cpu.usage",
                condition=">",
                threshold=80.0,
                level=AlertLevel.WARNING,
                description="CPUä½¿ç”¨ç‡è¿‡é«˜"
            ),
            AlertRule(
                name="high_memory_usage",
                metric_name="system.memory.usage_percent",
                condition=">",
                threshold=85.0,
                level=AlertLevel.WARNING,
                description="å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜"
            ),
            AlertRule(
                name="slow_message_processing",
                metric_name="rabbitmq.message.process_time",
                condition=">",
                threshold=1.0,
                level=AlertLevel.WARNING,
                description="æ¶ˆæ¯å¤„ç†æ—¶é—´è¿‡é•¿"
            ),
            AlertRule(
                name="high_queue_length",
                metric_name="rabbitmq.queue.length",
                condition=">",
                threshold=1000,
                level=AlertLevel.CRITICAL,
                description="é˜Ÿåˆ—é•¿åº¦è¿‡é«˜"
            )
        ]
        
        for rule in default_rules:
            self.alert_engine.add_rule(rule)
    
    def add_monitor_callback(self, callback: Callable[[Dict[str, Any]], None]):
        """æ·»åŠ ç›‘æ§å›è°ƒå‡½æ•°"""
        self.monitor_callbacks.append(callback)
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.monitoring:
            return
        
        self.monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                self._collect_system_metrics()
                
                # æ”¶é›†åº”ç”¨æŒ‡æ ‡
                self._collect_application_metrics()
                
                # è¯„ä¼°å‘Šè­¦è§„åˆ™
                current_metrics = self.collector.get_current_metrics()
                alerts = self.alert_engine.evaluate_rules(current_metrics)
                
                # è§¦å‘å›è°ƒå‡½æ•°
                if self.monitor_callbacks:
                    monitor_data = {
                        'timestamp': time.time(),
                        'metrics': current_metrics,
                        'alerts': alerts,
                        'stats': self.collector.get_all_stats()
                    }
                    
                    for callback in self.monitor_callbacks:
                        try:
                            callback(monitor_data)
                        except Exception as e:
                            logging.error(f"ç›‘æ§å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")
                
                time.sleep(self.interval)
                
            except Exception as e:
                logging.error(f"ç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                time.sleep(self.interval)
    
    def _collect_system_metrics(self):
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        try:
            import psutil
            
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=0.1)
            self.collector.record_metric(PerformanceMetric(
                name="system.cpu.usage",
                value=cpu_percent,
                metric_type=MetricType.GAUGE,
                timestamp=time.time(),
                tags={"component": "system"}
            ))
            
            # å†…å­˜ä½¿ç”¨ç‡
            memory = psutil.virtual_memory()
            self.collector.record_metric(PerformanceMetric(
                name="system.memory.usage_percent",
                value=memory.percent,
                metric_type=MetricType.GAUGE,
                timestamp=time.time(),
                tags={"component": "system"}
            ))
            
            # ç£ç›˜ä½¿ç”¨ç‡
            disk = psutil.disk_usage('/')
            disk_percent = (disk.used / disk.total) * 100
            self.collector.record_metric(PerformanceMetric(
                name="system.disk.usage_percent",
                value=disk_percent,
                metric_type=MetricType.GAUGE,
                timestamp=time.time(),
                tags={"component": "system"}
            ))
            
            # ç½‘ç»œI/O
            net_io = psutil.net_io_counters()
            if net_io:
                self.collector.record_metric(PerformanceMetric(
                    name="system.network.bytes_sent",
                    value=net_io.bytes_sent,
                    metric_type=MetricType.COUNTER,
                    timestamp=time.time(),
                    tags={"component": "system"}
                ))
                
                self.collector.record_metric(PerformanceMetric(
                    name="system.network.bytes_recv",
                    value=net_io.bytes_recv,
                    metric_type=MetricType.COUNTER,
                    timestamp=time.time(),
                    tags={"component": "system"}
                ))
        
        except ImportError:
            # å¦‚æœæ²¡æœ‰psutilï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            import random
            self.collector.record_metric(PerformanceMetric(
                name="system.cpu.usage",
                value=random.uniform(20, 80),
                metric_type=MetricType.GAUGE,
                timestamp=time.time(),
                tags={"component": "system"}
            ))
    
    def _collect_application_metrics(self):
        """æ”¶é›†åº”ç”¨æŒ‡æ ‡"""
        # è¿™é‡Œåº”è¯¥æ”¶é›†RabbitMQç›¸å…³æŒ‡æ ‡
        # ç®€åŒ–å®ç°ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        
        import random
        
        # æ¶ˆæ¯å¤„ç†æ—¶é—´
        process_time = random.uniform(0.1, 2.0)
        self.collector.record_metric(PerformanceMetric(
            name="rabbitmq.message.process_time",
            value=process_time,
            metric_type=MetricType.TIMER,
            timestamp=time.time(),
            tags={"component": "rabbitmq"}
        ))
        
        # é˜Ÿåˆ—é•¿åº¦
        queue_length = random.randint(100, 2000)
        self.collector.record_metric(PerformanceMetric(
            name="rabbitmq.queue.length",
            value=queue_length,
            metric_type=MetricType.GAUGE,
            timestamp=time.time(),
            tags={"component": "rabbitmq"}
        ))
        
        # è¿æ¥æ•°
        connection_count = random.randint(10, 100)
        self.collector.record_metric(PerformanceMetric(
            name="rabbitmq.connections.count",
            value=connection_count,
            metric_type=MetricType.GAUGE,
            timestamp=time.time(),
            tags={"component": "rabbitmq"}
        ))


class BenchmarkRunner:
    """åŸºå‡†æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self, monitor: PerformanceMonitor):
        self.monitor = monitor
        self.results = {}
    
    def run_throughput_benchmark(self, duration: int = 60, message_size: int = 1024) -> Dict[str, Any]:
        """è¿è¡Œååé‡åŸºå‡†æµ‹è¯•"""
        print(f"å¼€å§‹ååé‡åŸºå‡†æµ‹è¯•ï¼ŒæŒç»­æ—¶é—´: {duration}ç§’ï¼Œæ¶ˆæ¯å¤§å°: {message_size}å­—èŠ‚")
        
        start_time = time.time()
        message_count = 0
        timer = self.monitor.collector.get_timer("benchmark.throughput")
        
        # ç”Ÿæˆå¹¶å¤„ç†æ¶ˆæ¯çš„æ¨¡æ‹Ÿå‡½æ•°
        def process_message():
            nonlocal message_count
            # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†
            time.sleep(0.001)  # 1mså¤„ç†æ—¶é—´
            with timer.time_context():
                # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†å·¥ä½œ
                data = "x" * message_size
                processed_data = data.upper()
                message_count += 1
                return processed_data
        
        # è¿è¡ŒåŸºå‡†æµ‹è¯•
        end_time = start_time + duration
        while time.time() < end_time:
            try:
                process_message()
            except Exception as e:
                print(f"æ¶ˆæ¯å¤„ç†é”™è¯¯: {e}")
        
        total_time = time.time() - start_time
        throughput = message_count / total_time
        
        results = {
            'duration': total_time,
            'total_messages': message_count,
            'throughput': throughput,
            'message_size': message_size,
            'avg_processing_time': timer.histogram.get_stats()['avg']
        }
        
        print(f"ååé‡åŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"  æ€»æ¶ˆæ¯æ•°: {message_count}")
        print(f"  æ€»æ—¶é—´: {total_time:.2f}ç§’")
        print(f"  ååé‡: {throughput:.2f}æ¶ˆæ¯/ç§’")
        print(f"  å¹³å‡å¤„ç†æ—¶é—´: {timer.histogram.get_stats()['avg']:.4f}ç§’")
        
        return results
    
    def run_latency_benchmark(self, test_count: int = 1000) -> Dict[str, Any]:
        """è¿è¡Œå»¶è¿ŸåŸºå‡†æµ‹è¯•"""
        print(f"å¼€å§‹å»¶è¿ŸåŸºå‡†æµ‹è¯•ï¼Œæµ‹è¯•æ¬¡æ•°: {test_count}")
        
        latencies = []
        timer = self.monitor.collector.get_timer("benchmark.latency")
        
        # å»¶è¿Ÿæµ‹è¯•å‡½æ•°
        def measure_latency():
            with timer.time_context():
                # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†
                start = time.perf_counter()
                time.sleep(0.01)  # 10msåŸºå‡†å»¶è¿Ÿ
                end = time.perf_counter()
                latency = end - start
                latencies.append(latency)
        
        # è¿è¡Œå»¶è¿Ÿæµ‹è¯•
        for i in range(test_count):
            if i % 100 == 0:
                print(f"è¿›åº¦: {i}/{test_count}")
            measure_latency()
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        latencies.sort()
        count = len(latencies)
        
        results = {
            'test_count': count,
            'min_latency': min(latencies),
            'max_latency': max(latencies),
            'avg_latency': statistics.mean(latencies),
            'median_latency': statistics.median(latencies),
            'p95_latency': latencies[int(count * 0.95)],
            'p99_latency': latencies[int(count * 0.99)]
        }
        
        print(f"å»¶è¿ŸåŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"  æœ€å°å»¶è¿Ÿ: {results['min_latency']:.4f}ç§’")
        print(f"  æœ€å¤§å»¶è¿Ÿ: {results['max_latency']:.4f}ç§’")
        print(f"  å¹³å‡å»¶è¿Ÿ: {results['avg_latency']:.4f}ç§’")
        print(f"  ä¸­ä½æ•°å»¶è¿Ÿ: {results['median_latency']:.4f}ç§’")
        print(f"  95%å»¶è¿Ÿ: {results['p95_latency']:.4f}ç§’")
        print(f"  99%å»¶è¿Ÿ: {results['p99_latency']:.4f}ç§’")
        
        return results
    
    def run_concurrent_benchmark(self, concurrent_threads: int = 10, duration: int = 30) -> Dict[str, Any]:
        """è¿è¡Œå¹¶å‘åŸºå‡†æµ‹è¯•"""
        print(f"å¼€å§‹å¹¶å‘åŸºå‡†æµ‹è¯•ï¼Œå¹¶å‘çº¿ç¨‹æ•°: {concurrent_threads}ï¼ŒæŒç»­æ—¶é—´: {duration}ç§’")
        
        results = {
            'concurrent_threads': concurrent_threads,
            'duration': duration,
            'thread_results': []
        }
        
        def worker_thread(thread_id: int):
            thread_results = {
                'thread_id': thread_id,
                'messages_processed': 0,
                'start_time': time.time(),
                'errors': 0
            }
            
            timer = self.monitor.collector.get_timer(f"benchmark.concurrent.{thread_id}")
            
            end_time = thread_results['start_time'] + duration
            while time.time() < end_time:
                try:
                    with timer.time_context():
                        # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†
                        time.sleep(0.005)  # 5mså¤„ç†æ—¶é—´
                        thread_results['messages_processed'] += 1
                except Exception as e:
                    thread_results['errors'] += 1
            
            thread_results['end_time'] = time.time()
            thread_results['total_time'] = thread_results['end_time'] - thread_results['start_time']
            thread_results['throughput'] = thread_results['messages_processed'] / thread_results['total_time']
            
            return thread_results
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        threads = []
        for i in range(concurrent_threads):
            thread = threading.Thread(target=lambda: results['thread_results'].append(worker_thread(i)))
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_messages = sum(r['messages_processed'] for r in results['thread_results'])
        total_time = duration
        overall_throughput = total_messages / total_time
        
        # è®¡ç®—å»¶è¿Ÿç»Ÿè®¡
        all_latencies = []
        for i in range(concurrent_threads):
            timer = self.monitor.collector.get_timer(f"benchmark.concurrent.{i}")
            stats = timer.histogram.get_stats()
            # ä¼°ç®—å»¶è¿Ÿåˆ†å¸ƒ
            all_latencies.extend([stats['avg']] * int(stats['count'] / concurrent_threads))
        
        results.update({
            'total_messages': total_messages,
            'overall_throughput': overall_throughput,
            'avg_latency': statistics.mean(all_latencies) if all_latencies else 0,
            'thread_stats': results['thread_results']
        })
        
        print(f"å¹¶å‘åŸºå‡†æµ‹è¯•ç»“æœ:")
        print(f"  æ€»æ¶ˆæ¯æ•°: {total_messages}")
        print(f"  æ€»ä½“ååé‡: {overall_throughput:.2f}æ¶ˆæ¯/ç§’")
        print(f"  å¹³å‡å»¶è¿Ÿ: {results['avg_latency']:.4f}ç§’")
        print(f"  å„çº¿ç¨‹ç»Ÿè®¡:")
        for thread_result in results['thread_results']:
            print(f"    çº¿ç¨‹{thread_result['thread_id']}: {thread_result['messages_processed']}æ¶ˆæ¯, "
                  f"{thread_result['throughput']:.2f}æ¶ˆæ¯/ç§’")
        
        return results


class AutoTuningManager:
    """è‡ªåŠ¨è°ƒä¼˜ç®¡ç†å™¨"""
    
    def __init__(self, monitor: PerformanceMonitor):
        self.monitor = monitor
        self.tuning_rules = []
        self.current_config = {}
        self.auto_tuning_enabled = False
        
    def enable_auto_tuning(self, enabled: bool = True):
        """å¯ç”¨æˆ–ç¦ç”¨è‡ªåŠ¨è°ƒä¼˜"""
        self.auto_tuning_enabled = enabled
    
    def add_tuning_rule(self, condition: Dict[str, Any], action: Callable):
        """æ·»åŠ è°ƒä¼˜è§„åˆ™"""
        self.tuning_rules.append({
            'condition': condition,
            'action': action
        })
    
    def analyze_and_tune(self):
        """åˆ†æå½“å‰æ€§èƒ½å¹¶è°ƒä¼˜"""
        if not self.auto_tuning_enabled:
            return
        
        metrics = self.monitor.collector.get_current_metrics()
        
        for rule in self.tuning_rules:
            if self._evaluate_condition(rule['condition'], metrics):
                try:
                    rule['action'](metrics)
                except Exception as e:
                    print(f"è°ƒä¼˜æ“ä½œå¤±è´¥: {e}")
    
    def _evaluate_condition(self, condition: Dict[str, Any], metrics: Dict[str, PerformanceMetric]) -> bool:
        """è¯„ä¼°æ¡ä»¶"""
        metric_name = condition['metric']
        operator = condition['operator']
        threshold = condition['threshold']
        
        if metric_name not in metrics:
            return False
        
        value = metrics[metric_name].value
        
        if operator == '>' and value > threshold:
            return True
        elif operator == '<' and value < threshold:
            return True
        elif operator == '>=' and value >= threshold:
            return True
        elif operator == '<=' and value <= threshold:
            return True
        elif operator == '==' and value == threshold:
            return True
        elif operator == '!=' and value != threshold:
            return True
        
        return False
    
    def apply_rabbitmq_optimizations(self, metrics: Dict[str, PerformanceMetric]):
        """åº”ç”¨RabbitMQä¼˜åŒ–"""
        print("æ­£åœ¨åº”ç”¨RabbitMQè‡ªåŠ¨ä¼˜åŒ–...")
        
        # æ ¹æ®æŒ‡æ ‡è°ƒæ•´é…ç½®
        cpu_usage = metrics.get('system.cpu.usage', PerformanceMetric('dummy', 0, MetricType.GAUGE, 0)).value
        memory_usage = metrics.get('system.memory.usage_percent', PerformanceMetric('dummy', 0, MetricType.GAUGE, 0)).value
        
        if cpu_usage > 80:
            print("æ£€æµ‹åˆ°é«˜CPUä½¿ç”¨ç‡ï¼Œå»ºè®®:")
            print("  - å‡å°‘å¹¶å‘è¿æ¥æ•°")
            print("  - è°ƒæ•´é˜Ÿåˆ—æ¶ˆè´¹è€…æ•°é‡")
            print("  - è€ƒè™‘å¢åŠ èŠ‚ç‚¹")
        
        if memory_usage > 85:
            print("æ£€æµ‹åˆ°é«˜å†…å­˜ä½¿ç”¨ç‡ï¼Œå»ºè®®:")
            print("  - é™ä½é˜Ÿåˆ—æ¶ˆæ¯TTL")
            print("  - å‡å°‘æ¶ˆæ¯ç§¯å‹")
            print("  - è°ƒæ•´å†…å­˜é™åˆ¶å‚æ•°")


class PerformanceMonitoringDemo:
    """æ€§èƒ½ç›‘æ§æ¼”ç¤º"""
    
    def __init__(self):
        self.monitor = PerformanceMonitor(interval=1.0)
        self.benchmark_runner = BenchmarkRunner(self.monitor)
        self.auto_tuning = AutoTuningManager(self.monitor)
        
        # è®¾ç½®ç›‘æ§å›è°ƒ
        self.monitor.add_monitor_callback(self._monitor_callback)
        
        # æ·»åŠ é»˜è®¤è°ƒä¼˜è§„åˆ™
        self._setup_default_tuning_rules()
    
    def _setup_default_tuning_rules(self):
        """è®¾ç½®é»˜è®¤è°ƒä¼˜è§„åˆ™"""
        # é«˜CPUä½¿ç”¨ç‡è°ƒä¼˜è§„åˆ™
        self.auto_tuning.add_tuning_rule(
            condition={
                'metric': 'system.cpu.usage',
                'operator': '>',
                'threshold': 80.0
            },
            action=self.auto_tuning.apply_rabbitmq_optimizations
        )
        
        # é«˜å†…å­˜ä½¿ç”¨ç‡è°ƒä¼˜è§„åˆ™
        self.auto_tuning.add_tuning_rule(
            condition={
                'metric': 'system.memory.usage_percent',
                'operator': '>',
                'threshold': 85.0
            },
            action=self.auto_tuning.apply_rabbitmq_optimizations
        )
    
    def _monitor_callback(self, monitor_data: Dict[str, Any]):
        """ç›‘æ§å›è°ƒå‡½æ•°"""
        timestamp = datetime.fromtimestamp(monitor_data['timestamp'])
        alerts = monitor_data['alerts']
        
        if alerts:
            print(f"[{timestamp.strftime('%H:%M:%S')}] æ£€æµ‹åˆ°å‘Šè­¦:")
            for alert in alerts:
                print(f"  - {alert.level.value.upper()}: {alert.message}")
        
        # è‡ªåŠ¨è°ƒä¼˜
        if self.auto_tuning.auto_tuning_enabled:
            self.auto_tuning.analyze_and_tune()
    
    def demonstrate_basic_monitoring(self):
        """æ¼”ç¤ºåŸºç¡€ç›‘æ§åŠŸèƒ½"""
        print("=== åŸºç¡€æ€§èƒ½ç›‘æ§æ¼”ç¤º ===")
        
        # æ¨¡æ‹Ÿåº”ç”¨æŒ‡æ ‡
        import random
        
        print("å¯åŠ¨ç›‘æ§ç³»ç»Ÿ...")
        self.monitor.start_monitoring()
        
        try:
            print("è¿è¡Œç›‘æ§30ç§’...")
            time.sleep(30)
        except KeyboardInterrupt:
            print("ç›‘æ§ä¸­æ–­")
        finally:
            print("åœæ­¢ç›‘æ§ç³»ç»Ÿ...")
            self.monitor.stop_monitoring()
        
        # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
        stats = self.monitor.collector.get_all_stats()
        print("\nğŸ“Š æ€§èƒ½ç»Ÿè®¡ç»“æœ:")
        for metric_name, metric_data in stats.items():
            print(f"\n{metric_name}:")
            if metric_data['type'] == 'counter':
                print(f"  æ•°å€¼: {metric_data['value']}")
            elif metric_data['type'] == 'gauge':
                print(f"  æ•°å€¼: {metric_data['value']}")
            elif metric_data['type'] in ['histogram', 'timer']:
                metric_stats = metric_data['stats']
                print(f"  è®¡æ•°: {metric_stats['count']}")
                print(f"  å¹³å‡å€¼: {metric_stats['avg']:.4f}ç§’")
                print(f"  æœ€å¤§å€¼: {metric_stats['max']:.4f}ç§’")
        
        # æ˜¾ç¤ºæ´»è·ƒå‘Šè­¦
        active_alerts = self.monitor.alert_engine.get_active_alerts()
        if active_alerts:
            print(f"\nğŸš¨ æ´»è·ƒå‘Šè­¦ ({len(active_alerts)}ä¸ª):")
            for alert in active_alerts:
                print(f"  - {alert.level.value.upper()}: {alert.message}")
        
        print()
    
    def demonstrate_benchmark_testing(self):
        """æ¼”ç¤ºåŸºå‡†æµ‹è¯•"""
        print("=== æ€§èƒ½åŸºå‡†æµ‹è¯•æ¼”ç¤º ===")
        
        # ååé‡æµ‹è¯•
        print("\n1. ååé‡åŸºå‡†æµ‹è¯•:")
        throughput_results = self.benchmark_runner.run_throughput_benchmark(
            duration=10,  # 10ç§’æµ‹è¯•
            message_size=1024
        )
        
        # å»¶è¿Ÿæµ‹è¯•
        print("\n2. å»¶è¿ŸåŸºå‡†æµ‹è¯•:")
        latency_results = self.benchmark_runner.run_latency_benchmark(
            test_count=100  # 100æ¬¡æµ‹è¯•
        )
        
        # å¹¶å‘æµ‹è¯•
        print("\n3. å¹¶å‘åŸºå‡†æµ‹è¯•:")
        concurrent_results = self.benchmark_runner.run_concurrent_benchmark(
            concurrent_threads=5,  # 5ä¸ªå¹¶å‘çº¿ç¨‹
            duration=10
        )
        
        # ä¿å­˜ç»“æœ
        self.benchmark_runner.results = {
            'throughput': throughput_results,
            'latency': latency_results,
            'concurrent': concurrent_results
        }
        
        print("\nâœ… åŸºå‡†æµ‹è¯•å®Œæˆ")
        print()
    
    def demonstrate_auto_tuning(self):
        """æ¼”ç¤ºè‡ªåŠ¨è°ƒä¼˜"""
        print("=== è‡ªåŠ¨è°ƒä¼˜æ¼”ç¤º ===")
        
        # å¯ç”¨è‡ªåŠ¨è°ƒä¼˜
        print("å¯ç”¨è‡ªåŠ¨è°ƒä¼˜åŠŸèƒ½...")
        self.auto_tuning.enable_auto_tuning(True)
        
        # å¯åŠ¨ç›‘æ§
        self.monitor.start_monitoring()
        
        try:
            print("è¿è¡Œè‡ªåŠ¨è°ƒä¼˜æµ‹è¯•30ç§’...")
            
            # æ¨¡æ‹Ÿè´Ÿè½½å˜åŒ–
            import random
            for i in range(30):
                # éšæœºæ”¹å˜è´Ÿè½½æƒ…å†µ
                cpu_load = random.uniform(70, 95)  # æ¨¡æ‹Ÿé«˜CPUè´Ÿè½½
                memory_load = random.uniform(75, 90)  # æ¨¡æ‹Ÿé«˜å†…å­˜è´Ÿè½½
                
                self.monitor.collector.record_metric(PerformanceMetric(
                    name="system.cpu.usage",
                    value=cpu_load,
                    metric_type=MetricType.GAUGE,
                    timestamp=time.time()
                ))
                
                self.monitor.collector.record_metric(PerformanceMetric(
                    name="system.memory.usage_percent",
                    value=memory_load,
                    metric_type=MetricType.GAUGE,
                    timestamp=time.time()
                ))
                
                time.sleep(1)
        
        except KeyboardInterrupt:
            print("è‡ªåŠ¨è°ƒä¼˜æµ‹è¯•ä¸­æ–­")
        finally:
            self.monitor.stop_monitoring()
        
        print("âœ… è‡ªåŠ¨è°ƒä¼˜æ¼”ç¤ºå®Œæˆ")
        print()
    
    def demonstrate_alert_system(self):
        """æ¼”ç¤ºå‘Šè­¦ç³»ç»Ÿ"""
        print("=== å‘Šè­¦ç³»ç»Ÿæ¼”ç¤º ===")
        
        # æ·»åŠ è‡ªå®šä¹‰å‘Šè­¦è§„åˆ™
        custom_rule = AlertRule(
            name="test_high_cpu",
            metric_name="system.cpu.usage",
            condition=">",
            threshold=90.0,
            level=AlertLevel.CRITICAL,
            description="æµ‹è¯•ç”¨CPUå‘Šè­¦"
        )
        
        self.monitor.alert_engine.add_rule(custom_rule)
        
        # å¯åŠ¨ç›‘æ§
        self.monitor.start_monitoring()
        
        try:
            print("ç”Ÿæˆæµ‹è¯•å‘Šè­¦åœºæ™¯...")
            import random
            
            # æ¨¡æ‹Ÿé«˜CPUä½¿ç”¨ç‡è§¦å‘å‘Šè­¦
            for i in range(20):
                cpu_usage = random.uniform(85, 98)  # æ¨¡æ‹Ÿé«˜CPUä½¿ç”¨
                
                self.monitor.collector.record_metric(PerformanceMetric(
                    name="system.cpu.usage",
                    value=cpu_usage,
                    metric_type=MetricType.GAUGE,
                    timestamp=time.time()
                ))
                
                time.sleep(1)
        
        except KeyboardInterrupt:
            print("å‘Šè­¦æµ‹è¯•ä¸­æ–­")
        finally:
            self.monitor.stop_monitoring()
        
        # æ˜¾ç¤ºå‘Šè­¦ç»“æœ
        active_alerts = self.monitor.alert_engine.get_active_alerts()
        print(f"\nğŸ“¢ æ´»è·ƒå‘Šè­¦ ({len(active_alerts)}ä¸ª):")
        for alert in active_alerts:
            print(f"  - {alert.level.value.upper()}: {alert.message}")
        
        print("âœ… å‘Šè­¦ç³»ç»Ÿæ¼”ç¤ºå®Œæˆ")
        print()


if __name__ == "__main__":
    # è¿è¡Œæ€§èƒ½ç›‘æ§æ¼”ç¤º
    demo = PerformanceMonitoringDemo()
    
    print("ğŸ”§ RabbitMQ æ€§èƒ½ç›‘æ§ä¸è°ƒä¼˜ç³»ç»Ÿ")
    print("=" * 50)
    print()
    
    try:
        # 1. åŸºç¡€ç›‘æ§æ¼”ç¤º
        demo.demonstrate_basic_monitoring()
        
        # 2. åŸºå‡†æµ‹è¯•æ¼”ç¤º
        demo.demonstrate_benchmark_testing()
        
        # 3. è‡ªåŠ¨è°ƒä¼˜æ¼”ç¤º
        demo.demonstrate_auto_tuning()
        
        # 4. å‘Šè­¦ç³»ç»Ÿæ¼”ç¤º
        demo.demonstrate_alert_system()
        
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆ!")
        
    except KeyboardInterrupt:
        print("\nç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nç¨‹åºæ‰§è¡Œé”™è¯¯: {e}")
    finally:
        # ç¡®ä¿ç›‘æ§åœæ­¢
        demo.monitor.stop_monitoring()