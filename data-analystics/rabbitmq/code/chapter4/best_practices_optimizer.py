#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¬¬4ç« ï¼šæ¶ˆæ¯ç¡®è®¤æœ€ä½³å®è·µå’Œæ€§èƒ½ä¼˜åŒ–æ¼”ç¤º
å±•ç¤ºå®é™…ç”Ÿäº§ç¯å¢ƒä¸­çš„ä¼˜åŒ–ç­–ç•¥å’Œç›‘æ§æ–¹æ³•
"""

import pika
import time
import uuid
import threading
import json
import queue
import statistics
import psutil
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from enum import Enum
from collections import defaultdict, deque
import logging

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    timestamp: float
    cpu_percent: float
    memory_mb: float
    queue_length: int
    throughput: float
    latency_ms: float
    error_rate: float

class OptimizerLevel(Enum):
    """ä¼˜åŒ–çº§åˆ«"""
    BASIC = "basic"
    INTERMEDIATE = "intermediate" 
    ADVANCED = "advanced"
    PRODUCTION = "production"

class BackoffStrategy(Enum):
    """é‡è¯•ç­–ç•¥"""
    EXPONENTIAL = "exponential"
    LINEAR = "linear"
    FIXED = "fixed"
    IMMEDIATE = "immediate"

class MessageProcessor:
    """æ¶ˆæ¯å¤„ç†å™¨"""
    
    def __init__(self, processor_id: str, complexity: int = 1):
        self.processor_id = processor_id
        self.complexity = complexity
        self.processed_count = 0
        self.error_count = 0
        self.processing_times = deque(maxlen=1000)
        self.lock = threading.Lock()
    
    def process(self, message: Dict) -> Tuple[bool, float]:
        """å¤„ç†æ¶ˆæ¯"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹Ÿå¤æ‚å¤„ç†é€»è¾‘
            for _ in range(self.complexity):
                # CPUå¯†é›†å‹æ“ä½œ
                result = sum(i * i for i in range(100))
                
                # å†…å­˜æ“ä½œ
                temp_data = [0] * 1000
                temp_data.clear()
                
                # I/Oæ“ä½œæ¨¡æ‹Ÿ
                time.sleep(0.0001)
            
            processing_time = time.time() - start_time
            
            # æ¨¡æ‹Ÿéšæœºé”™è¯¯
            if self.processed_count % 17 == 0:
                raise Exception("éšæœºå¤„ç†é”™è¯¯")
            
            with self.lock:
                self.processed_count += 1
                self.processing_times.append(processing_time)
                return True, processing_time
                
        except Exception as e:
            with self.lock:
                self.error_count += 1
                return False, time.time() - start_time
    
    def get_metrics(self) -> Dict:
        """è·å–å¤„ç†å™¨æŒ‡æ ‡"""
        with self.lock:
            avg_time = statistics.mean(self.processing_times) if self.processing_times else 0
            error_rate = (self.error_count / max(1, self.processed_count + self.error_count)) * 100
            
            return {
                'processor_id': self.processor_id,
                'processed_count': self.processed_count,
                'error_count': self.error_count,
                'avg_processing_time': avg_time,
                'error_rate': error_rate,
                'complexity': self.complexity
            }

class SystemMonitor:
    """ç³»ç»Ÿç›‘æ§å™¨"""
    
    def __init__(self, interval: float = 1.0):
        self.interval = interval
        self.metrics = deque(maxlen=3600)  # å­˜å‚¨1å°æ—¶çš„æ•°æ®
        self.is_monitoring = False
        self.monitor_thread = None
        self.lock = threading.Lock()
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        self.is_monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitor_loop)
        self.monitor_thread.start()
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
    
    def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.is_monitoring:
            try:
                metrics = PerformanceMetrics(
                    timestamp=time.time(),
                    cpu_percent=psutil.cpu_percent(),
                    memory_mb=psutil.virtual_memory().used / 1024 / 1024,
                    queue_length=0,  # ç”±å¤–éƒ¨è®¾ç½®
                    throughput=0,    # ç”±å¤–éƒ¨è®¾ç½®
                    latency_ms=0,    # ç”±å¤–éƒ¨è®¾ç½®
                    error_rate=0     # ç”±å¤–éƒ¨è®¾ç½®
                )
                
                with self.lock:
                    self.metrics.append(metrics)
                
                time.sleep(self.interval)
                
            except Exception as e:
                logging.error(f"ç›‘æ§é”™è¯¯: {e}")
                time.sleep(self.interval)
    
    def add_metrics(self, queue_length: int, throughput: float, latency_ms: float, error_rate: float):
        """æ·»åŠ æŒ‡æ ‡"""
        if self.metrics:
            with self.lock:
                last_metrics = self.metrics[-1]
                updated_metrics = PerformanceMetrics(
                    timestamp=time.time(),
                    cpu_percent=last_metrics.cpu_percent,
                    memory_mb=last_metrics.memory_mb,
                    queue_length=queue_length,
                    throughput=throughput,
                    latency_ms=latency_ms,
                    error_rate=error_rate
                )
                self.metrics.append(updated_metrics)
    
    def get_recent_metrics(self, duration_minutes: int = 5) -> List[PerformanceMetrics]:
        """è·å–æœ€è¿‘çš„æŒ‡æ ‡"""
        cutoff_time = time.time() - (duration_minutes * 60)
        
        with self.lock:
            return [m for m in self.metrics if m.timestamp >= cutoff_time]
    
    def print_performance_report(self):
        """æ‰“å°æ€§èƒ½æŠ¥å‘Š"""
        recent_metrics = self.get_recent_metrics()
        
        if not recent_metrics:
            return
        
        cpu_values = [m.cpu_percent for m in recent_metrics]
        memory_values = [m.memory_mb for m in recent_metrics]
        throughput_values = [m.throughput for m in recent_metrics]
        latency_values = [m.latency_ms for m in recent_metrics]
        error_rate_values = [m.error_rate for m in recent_metrics]
        
        print(f"\nğŸ“Š ç³»ç»Ÿæ€§èƒ½æŠ¥å‘Š (æœ€è¿‘ {len(recent_metrics)} ç§’):")
        print(f"  CPUä½¿ç”¨ç‡: {statistics.mean(cpu_values):.1f}% (æœ€å¤§: {max(cpu_values):.1f}%)")
        print(f"  å†…å­˜ä½¿ç”¨: {statistics.mean(memory_values):.0f}MB (æœ€å¤§: {max(memory_values):.0f}MB)")
        print(f"  å¹³å‡ååé‡: {statistics.mean(throughput_values):.2f} æ¶ˆæ¯/ç§’")
        print(f"  å¹³å‡å»¶è¿Ÿ: {statistics.mean(latency_values):.2f}ms")
        print(f"  å¹³å‡é”™è¯¯ç‡: {statistics.mean(error_rate_values):.2f}%")

class OptimizedMessageConsumer:
    """ä¼˜åŒ–çš„æ¶ˆæ¯æ¶ˆè´¹è€…"""
    
    def __init__(self, queue_name: str, processor_count: int = 4, 
                 prefetch_count: int = 50, auto_scale: bool = True):
        self.queue_name = queue_name
        self.processor_count = processor_count
        self.prefetch_count = prefetch_count
        self.auto_scale = auto_scale
        
        self.connection_params = pika.ConnectionParameters(
            host='localhost',
            port=5672,
            heartbeat=30,
            connection_attempts=3
        )
        
        self.processors = [
            MessageProcessor(f"processor_{i}", complexity=2) 
            for i in range(processor_count)
        ]
        
        self.message_queue = queue.Queue(maxsize=1000)
        self.is_running = False
        self.consumer_threads = []
        self.processor_threads = []
        
        # æ€§èƒ½ç»Ÿè®¡
        self.total_processed = 0
        self.total_errors = 0
        self.lock = threading.Lock()
    
    def _get_connection(self):
        """è·å–è¿æ¥"""
        return pika.BlockingConnection(self.connection_params)
    
    def _adaptive_prefetch(self):
        """è‡ªé€‚åº”é¢„å–"""
        recent_metrics = [
            p.get_metrics()['avg_processing_time'] 
            for p in self.processors
        ]
        
        if not recent_metrics:
            return self.prefetch_count
        
        avg_processing_time = statistics.mean(recent_metrics)
        
        # æ ¹æ®å¤„ç†æ—¶é—´åŠ¨æ€è°ƒæ•´é¢„å–æ•°é‡
        if avg_processing_time > 0.1:  # å¤„ç†æ—¶é—´è¶…è¿‡100ms
            return max(10, self.prefetch_count // 2)
        elif avg_processing_time < 0.01:  # å¤„ç†æ—¶é—´å°‘äº10ms
            return min(100, self.prefetch_count * 2)
        else:
            return self.prefetch_count
    
    def _auto_scaling(self):
        """è‡ªåŠ¨æ‰©ç¼©å®¹"""
        if not self.auto_scale:
            return
        
        avg_error_rate = statistics.mean([
            p.get_metrics()['error_rate'] 
            for p in self.processors
        ])
        
        avg_processing_time = statistics.mean([
            p.get_metrics()['avg_processing_time'] 
            for p in self.processors
        ])
        
        # å¦‚æœé”™è¯¯ç‡è¿‡é«˜æˆ–å¤„ç†æ—¶é—´è¿‡é•¿ï¼Œæ·»åŠ å¤„ç†å™¨
        if avg_error_rate > 10 or avg_processing_time > 0.2:
            if len(self.processors) < 8:  # æœ€å¤§8ä¸ªå¤„ç†å™¨
                new_processor = MessageProcessor(
                    f"processor_{len(self.processors)}", 
                    complexity=1  # æ–°å¤„ç†å™¨å¤æ‚åº¦è¾ƒä½
                )
                self.processors.append(new_processor)
                
                # å¯åŠ¨æ–°çš„å¤„ç†å™¨çº¿ç¨‹
                processor_thread = threading.Thread(
                    target=self._processor_worker, 
                    args=(new_processor,)
                )
                processor_thread.start()
                self.processor_threads.append(processor_thread)
                
                print(f"ğŸ”§ è‡ªåŠ¨æ‰©å®¹ï¼šæ·»åŠ å¤„ç†å™¨ {new_processor.processor_id}")
    
    def _consumer_worker(self, connection):
        """æ¶ˆè´¹è€…å·¥ä½œçº¿ç¨‹"""
        channel = connection.channel()
        
        # è®¾ç½®é¢„å–
        current_prefetch = self._adaptive_prefetch()
        channel.basic_qos(prefetch_count=current_prefetch)
        
        def callback(ch, method, properties, body):
            try:
                message = json.loads(body.decode())
                
                # æ£€æŸ¥é˜Ÿåˆ—å¤§å°
                if self.message_queue.qsize() > 800:
                    print("âš ï¸ é˜Ÿåˆ—æ¥è¿‘æ»¡è½½ï¼Œå‡æ…¢æ¶ˆè´¹é€Ÿåº¦")
                    time.sleep(0.1)
                
                # å°†æ¶ˆæ¯æ”¾å…¥å¤„ç†é˜Ÿåˆ—
                self.message_queue.put((message, method, properties), timeout=1.0)
                
                # è‡ªåŠ¨æ‰©ç¼©å®¹æ£€æŸ¥
                if self.total_processed % 100 == 0:
                    self._auto_scaling()
                
            except queue.Full:
                print("âŒ å¤„ç†é˜Ÿåˆ—å·²æ»¡ï¼Œæ¶ˆæ¯å¯èƒ½è¢«é‡å¤æŠ•é€’")
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
            except Exception as e:
                print(f"âŒ æ¥æ”¶æ¶ˆæ¯å¤±è´¥: {e}")
                ch.basic_nack(delivery_tag=method.delivery_tag, requeue=True)
        
        try:
            channel.basic_consume(
                queue=self.queue_name,
                on_message_callback=callback,
                auto_ack=False
            )
            
            # å¤„ç†æ¶ˆæ¯äº‹ä»¶
            while self.is_running:
                connection.process_data_events(time_limit=1.0)
                
        except Exception as e:
            print(f"âŒ æ¶ˆè´¹è€…å·¥ä½œçº¿ç¨‹é”™è¯¯: {e}")
        finally:
            if channel.is_open:
                channel.close()
    
    def _processor_worker(self, processor: MessageProcessor):
        """å¤„ç†å™¨å·¥ä½œçº¿ç¨‹"""
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—è·å–æ¶ˆæ¯
                message, method, properties = self.message_queue.get(timeout=1.0)
                
                # å¤„ç†æ¶ˆæ¯
                success, processing_time = processor.process(message)
                
                with self.lock:
                    if success:
                        self.total_processed += 1
                    else:
                        self.total_errors += 1
                
                # ç¡®è®¤æ¶ˆæ¯
                try:
                    if success:
                        # æ¨¡æ‹Ÿå»¶è¿Ÿç¡®è®¤ä»¥ä¼˜åŒ–æ€§èƒ½
                        time.sleep(0.0001)
                        # è¿™é‡Œéœ€è¦è®¿é—®è¿æ¥ï¼Œä½†åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸­éœ€è¦ç‰¹æ®Šå¤„ç†
                        # å®é™…å®ç°ä¸­åº”è¯¥é€šè¿‡å›è°ƒæˆ–æ¶ˆæ¯ä¼ é€’æ¥ç¡®è®¤
                    
                except Exception as e:
                    print(f"âŒ æ¶ˆæ¯ç¡®è®¤å¤±è´¥: {e}")
                
                self.message_queue.task_done()
                
            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ å¤„ç†å™¨ {processor.processor_id} é”™è¯¯: {e}")
    
    def start(self):
        """å¯åŠ¨æ¶ˆè´¹è€…"""
        self.is_running = True
        
        # å¯åŠ¨å¤„ç†å™¨çº¿ç¨‹
        for processor in self.processors:
            thread = threading.Thread(target=self._processor_worker, args=(processor,))
            thread.start()
            self.processor_threads.append(thread)
        
        # å¯åŠ¨æ¶ˆè´¹è€…çº¿ç¨‹
        def consumer_wrapper():
            while self.is_running:
                try:
                    connection = self._get_connection()
                    self._consumer_worker(connection)
                except Exception as e:
                    print(f"âŒ è¿æ¥é”™è¯¯: {e}")
                    time.sleep(5)  # ç­‰å¾…é‡è¿
        
        consumer_thread = threading.Thread(target=consumer_wrapper)
        consumer_thread.start()
        self.consumer_threads.append(consumer_thread)
        
        print(f"ğŸš€ å¯åŠ¨ä¼˜åŒ–çš„æ¶ˆæ¯æ¶ˆè´¹è€…ï¼Œé˜Ÿåˆ—: {self.queue_name}")
    
    def stop(self):
        """åœæ­¢æ¶ˆè´¹è€…"""
        self.is_running = False
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹ç»“æŸ
        for thread in self.consumer_threads + self.processor_threads:
            if thread.is_alive():
                thread.join(timeout=5)
        
        print("â¹ï¸ ä¼˜åŒ–çš„æ¶ˆæ¯æ¶ˆè´¹è€…å·²åœæ­¢")
    
    def get_performance_metrics(self) -> Dict:
        """è·å–æ€§èƒ½æŒ‡æ ‡"""
        with self.lock:
            error_rate = (self.total_errors / max(1, self.total_processed + self.total_errors)) * 100
        
        # å¤„ç†å™¨ç»Ÿè®¡
        processor_stats = [p.get_metrics() for p in self.processors]
        
        return {
            'total_processed': self.total_processed,
            'total_errors': self.total_errors,
            'error_rate': error_rate,
            'queue_size': self.message_queue.qsize(),
            'processor_count': len(self.processors),
            'prefetch_count': self.prefetch_count,
            'processor_stats': processor_stats
        }

class BestPracticesDemo:
    """æœ€ä½³å®è·µæ¼”ç¤º"""
    
    def __init__(self):
        self.monitor = SystemMonitor(interval=2.0)
        self.consumers = {}
        self.connection_params = pika.ConnectionParameters(
            host='localhost',
            port=5672,
            heartbeat=30
        )
    
    def setup_optimized_queues(self):
        """è®¾ç½®ä¼˜åŒ–çš„é˜Ÿåˆ—"""
        connection = pika.BlockingConnection(self.connection_params)
        channel = connection.channel()
        
        # åˆ›å»ºä¼˜åŒ–é˜Ÿåˆ—
        queues = [
            {
                'name': 'optimized_queue',
                'args': {
                    'x-max-length': 10000,          # æœ€å¤§é˜Ÿåˆ—é•¿åº¦
                    'x-overflow': 'reject-publish', # æº¢å‡ºç­–ç•¥
                    'x-dead-letter-exchange': 'dlx_optimized',
                    'x-dead-letter-routing-key': 'dead_letter_optimized'
                }
            },
            {
                'name': 'high_priority_queue',
                'args': {
                    'x-max-priority': 10,           # æœ€å¤§ä¼˜å…ˆçº§
                    'x-max-length': 5000,           # æœ€å¤§é˜Ÿåˆ—é•¿åº¦
                    'x-message-ttl': 3600000        # 1å°æ—¶TTL
                }
            }
        ]
        
        # åˆ›å»ºæ­»ä¿¡äº¤æ¢æœº
        channel.exchange_declare(
            exchange='dlx_optimized',
            exchange_type='direct',
            durable=True
        )
        
        channel.queue_declare(
            queue='dead_letter_optimized',
            durable=True
        )
        
        channel.queue_bind(
            exchange='dlx_optimized',
            queue='dead_letter_optimized',
            routing_key='dead_letter_optimized'
        )
        
        # åˆ›å»ºé˜Ÿåˆ—
        for queue_config in queues:
            try:
                channel.queue_declare(
                    queue=queue_config['name'],
                    durable=True,
                    arguments=queue_config['args']
                )
                print(f"âœ… åˆ›å»ºé˜Ÿåˆ—: {queue_config['name']}")
            except Exception as e:
                print(f"âŒ åˆ›å»ºé˜Ÿåˆ—å¤±è´¥ {queue_config['name']}: {e}")
        
        connection.close()
    
    def demo_basic_optimization(self):
        """åŸºç¡€ä¼˜åŒ–æ¼”ç¤º"""
        print("\nğŸ”§ åŸºç¡€ä¼˜åŒ–æ¼”ç¤º")
        print("-" * 40)
        
        # åˆ›å»ºæ¶ˆè´¹è€…
        consumer = OptimizedMessageConsumer(
            queue_name='optimized_queue',
            processor_count=3,
            prefetch_count=20,
            auto_scale=False
        )
        
        self.consumers['basic'] = consumer
        consumer.start()
        
        # å‘é€æµ‹è¯•æ¶ˆæ¯
        connection = pika.BlockingConnection(self.connection_params)
        channel = connection.channel()
        
        print("ğŸ“¤ å‘é€æµ‹è¯•æ¶ˆæ¯...")
        for i in range(100):
            message = {
                'id': str(uuid.uuid4()),
                'sequence': i,
                'content': f'åŸºç¡€ä¼˜åŒ–æµ‹è¯•æ¶ˆæ¯ {i}',
                'priority': i % 5
            }
            
            properties = pika.BasicProperties(
                priority=message['priority'],
                delivery_mode=2,
                message_id=message['id']
            )
            
            channel.basic_publish(
                exchange='',
                routing_key='optimized_queue',
                body=json.dumps(message),
                properties=properties
            )
        
        connection.close()
        
        # ç›‘æ§å¤„ç†è¿‡ç¨‹
        print("ğŸ“Š ç›‘æ§å¤„ç†è¿‡ç¨‹...")
        for i in range(30):
            time.sleep(2)
            
            metrics = consumer.get_performance_metrics()
            self.monitor.add_metrics(
                queue_length=metrics['queue_size'],
                throughput=metrics['total_processed'],
                latency_ms=0,  # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´ç²¾ç¡®çš„å»¶è¿Ÿæµ‹é‡
                error_rate=metrics['error_rate']
            )
            
            print(f"  è¿›åº¦: å¤„ç† {metrics['total_processed']}, é”™è¯¯ {metrics['total_errors']}, "
                  f"é˜Ÿåˆ— {metrics['queue_size']}")
        
        consumer.stop()
        self.monitor.print_performance_report()
    
    def demo_advanced_optimization(self):
        """é«˜çº§ä¼˜åŒ–æ¼”ç¤º"""
        print("\nğŸš€ é«˜çº§ä¼˜åŒ–æ¼”ç¤º")
        print("-" * 40)
        
        # åˆ›å»ºæ¶ˆè´¹è€…
        consumer = OptimizedMessageConsumer(
            queue_name='optimized_queue',
            processor_count=4,
            prefetch_count=50,
            auto_scale=True
        )
        
        self.consumers['advanced'] = consumer
        consumer.start()
        
        # å‘é€å¤§é‡æµ‹è¯•æ¶ˆæ¯
        connection = pika.BlockingConnection(self.connection_params)
        channel = connection.channel()
        
        print("ğŸ“¤ å‘é€å¤§é‡æµ‹è¯•æ¶ˆæ¯...")
        for i in range(500):
            message = {
                'id': str(uuid.uuid4()),
                'sequence': i,
                'content': f'é«˜çº§ä¼˜åŒ–æµ‹è¯•æ¶ˆæ¯ {i}',
                'data': 'x' * 1000  # å¢åŠ æ¶ˆæ¯å¤§å°
            }
            
            channel.basic_publish(
                exchange='',
                routing_key='optimized_queue',
                body=json.dumps(message)
            )
        
        connection.close()
        
        # ç›‘æ§å¤„ç†è¿‡ç¨‹
        print("ğŸ“Š ç›‘æ§é«˜çº§ä¼˜åŒ–è¿‡ç¨‹...")
        for i in range(60):
            time.sleep(2)
            
            metrics = consumer.get_performance_metrics()
            
            # æ·»åŠ å¤„ç†å™¨æŒ‡æ ‡
            total_avg_time = statistics.mean([
                p['avg_processing_time'] 
                for p in metrics['processor_stats']
            ])
            
            self.monitor.add_metrics(
                queue_length=metrics['queue_size'],
                throughput=metrics['total_processed'],
                latency_ms=total_avg_time * 1000,
                error_rate=metrics['error_rate']
            )
            
            if i % 5 == 0:  # æ¯10ç§’æ‰“å°ä¸€æ¬¡
                print(f"  å¤„ç†å™¨æ•°é‡: {metrics['processor_count']}, "
                      f"å¤„ç†æ•°: {metrics['total_processed']}, "
                      f"é”™è¯¯ç‡: {metrics['error_rate']:.1f}%")
        
        consumer.stop()
        self.monitor.print_performance_report()
    
    def demo_production_patterns(self):
        """ç”Ÿäº§ç¯å¢ƒæ¨¡å¼æ¼”ç¤º"""
        print("\nğŸ­ ç”Ÿäº§ç¯å¢ƒæ¨¡å¼æ¼”ç¤º")
        print("-" * 40)
        
        # å¯åŠ¨ç³»ç»Ÿç›‘æ§
        self.monitor.start_monitoring()
        
        # åˆ›å»ºå¤šä¸ªæ¶ˆè´¹è€…
        consumers = []
        for i in range(3):
            consumer = OptimizedMessageConsumer(
                queue_name=f'pattern_queue_{i}',
                processor_count=2,
                prefetch_count=30,
                auto_scale=True
            )
            consumers.append(consumer)
            consumer.start()
            self.consumers[f'pattern_{i}'] = consumer
        
        # å‘é€ä¸åŒç±»å‹çš„æ¶ˆæ¯
        connection = pika.BlockingConnection(self.connection_params)
        channel = connection.channel()
        
        print("ğŸ“¤ å‘é€ä¸åŒç±»å‹çš„æ¶ˆæ¯...")
        
        for i in range(300):
            # åˆ›å»ºä¸åŒå¤æ‚åº¦çš„æ¶ˆæ¯
            if i % 3 == 0:
                # ç®€å•æ¶ˆæ¯
                message = {'type': 'simple', 'id': i, 'data': 'x' * 100}
            elif i % 3 == 1:
                # ä¸­ç­‰æ¶ˆæ¯
                message = {'type': 'medium', 'id': i, 'data': 'x' * 500}
            else:
                # å¤æ‚æ¶ˆæ¯
                message = {'type': 'complex', 'id': i, 'data': 'x' * 1000}
            
            # å‘é€åˆ°ä¸åŒé˜Ÿåˆ—
            queue_name = f'pattern_queue_{i % 3}'
            channel.basic_publish(
                exchange='',
                routing_key=queue_name,
                body=json.dumps(message)
            )
        
        connection.close()
        
        # ç›‘æ§æ‰€æœ‰æ¶ˆè´¹è€…
        print("ğŸ“Š ç›‘æ§ç”Ÿäº§ç¯å¢ƒæ¨¡å¼...")
        for i in range(45):
            time.sleep(3)
            
            total_processed = 0
            total_errors = 0
            total_queue_size = 0
            
            for consumer in consumers:
                metrics = consumer.get_performance_metrics()
                total_processed += metrics['total_processed']
                total_errors += metrics['total_errors']
                total_queue_size += metrics['queue_size']
            
            total_error_rate = (total_errors / max(1, total_processed + total_errors)) * 100
            
            self.monitor.add_metrics(
                queue_length=total_queue_size,
                throughput=total_processed,
                latency_ms=0,
                error_rate=total_error_rate
            )
            
            if i % 3 == 0:  # æ¯9ç§’æ‰“å°ä¸€æ¬¡
                print(f"  æ€»å¤„ç†: {total_processed}, æ€»é”™è¯¯: {total_errors}, "
                      f"æ€»é˜Ÿåˆ—: {total_queue_size}")
        
        # åœæ­¢æ‰€æœ‰æ¶ˆè´¹è€…
        for consumer in consumers:
            consumer.stop()
        
        # åœæ­¢ç›‘æ§
        self.monitor.stop_monitoring()
        self.monitor.print_performance_report()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        print("\nğŸ§¹ æ¸…ç†èµ„æº...")
        
        # åœæ­¢æ‰€æœ‰æ¶ˆè´¹è€…
        for name, consumer in self.consumers.items():
            try:
                consumer.stop()
            except:
                pass
        
        # æ¸…ç†é˜Ÿåˆ—
        try:
            connection = pika.BlockingConnection(self.connection_params)
            channel = connection.channel()
            
            queues_to_clean = [
                'optimized_queue', 'high_priority_queue',
                'pattern_queue_0', 'pattern_queue_1', 'pattern_queue_2',
                'dead_letter_optimized'
            ]
            
            for queue_name in queues_to_clean:
                try:
                    channel.queue_delete(queue=queue_name)
                except:
                    pass
            
            try:
                channel.exchange_delete(exchange='dlx_optimized')
            except:
                pass
            
            connection.close()
            
        except Exception as e:
            print(f"âš ï¸ æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        
        print("âœ… èµ„æºæ¸…ç†å®Œæˆ")
    
    def run_comprehensive_demo(self):
        """è¿è¡Œç»¼åˆæ¼”ç¤º"""
        print("ğŸ† æ¶ˆæ¯ç¡®è®¤æœ€ä½³å®è·µå’Œæ€§èƒ½ä¼˜åŒ–æ¼”ç¤º")
        print("=" * 60)
        
        try:
            # è®¾ç½®é˜Ÿåˆ—
            self.setup_optimized_queues()
            
            # è¿è¡Œå„ç§ä¼˜åŒ–æ¼”ç¤º
            self.demo_basic_optimization()
            self.demo_advanced_optimization()
            self.demo_production_patterns()
            
            # ç”Ÿæˆä¼˜åŒ–å»ºè®®
            self.generate_optimization_recommendations()
            
        except KeyboardInterrupt:
            print("\nâ¹ï¸ æ¼”ç¤ºè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\nâŒ æ¼”ç¤ºæ‰§è¡Œå¤±è´¥: {e}")
        finally:
            self.cleanup()
    
    def generate_optimization_recommendations(self):
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        print("\n" + "=" * 60)
        print("ğŸ’¡ æ¶ˆæ¯ç¡®è®¤å’ŒæŒä¹…åŒ–ä¼˜åŒ–å»ºè®®")
        print("=" * 60)
        
        recommendations = {
            "æ€§èƒ½ä¼˜åŒ–": [
                "ä½¿ç”¨åˆç†çš„æ‰‹åŠ¨ç¡®è®¤æ¨¡å¼ï¼Œæé«˜æ¶ˆæ¯å¯é æ€§",
                "æ ¹æ®å¤„ç†èƒ½åŠ›è°ƒæ•´prefetch_countï¼Œé¿å…é˜Ÿåˆ—è¿‡è½½",
                "å®æ–½æ‰¹å¤„ç†ç¡®è®¤ï¼Œå‡å°‘ç½‘ç»œå¼€é”€",
                "ä½¿ç”¨æŒä¹…åŒ–é˜Ÿåˆ—å’Œæ¶ˆæ¯ï¼Œä½†æ³¨æ„æ€§èƒ½å½±å“",
                "è€ƒè™‘æ¶ˆæ¯å‹ç¼©ä»¥å‡å°‘ç½‘ç»œä¼ è¾“"
            ],
            "å¯é æ€§ä¿è¯": [
                "å¯ç”¨æ¶ˆæ¯ç¡®è®¤æœºåˆ¶ï¼Œé¿å…æ¶ˆæ¯ä¸¢å¤±",
                "ä½¿ç”¨æ­»ä¿¡é˜Ÿåˆ—å¤„ç†å¤±è´¥æ¶ˆæ¯",
                "å®æ–½é‡è¯•æœºåˆ¶å’ŒæŒ‡æ•°é€€é¿",
                "ç›‘æ§é˜Ÿåˆ—é•¿åº¦å’Œæ¶ˆæ¯ç§¯å‹",
                "è®¾ç½®åˆç†çš„æ¶ˆæ¯TTL"
            ],
            "æ‰©å±•æ€§è®¾è®¡": [
                "è®¾è®¡æ°´å¹³æ‰©å±•çš„æ¶ˆè´¹æ¨¡å¼",
                "ä½¿ç”¨å¤šé˜Ÿåˆ—åˆ†å‘æ¶ˆæ¯",
                "å®æ–½åŠ¨æ€è´Ÿè½½å‡è¡¡",
                "è€ƒè™‘æ¶ˆæ¯åˆ†åŒºå’Œé¡ºåºæ€§",
                "ç›‘æ§å’Œè‡ªåŠ¨æ‰©ç¼©å®¹"
            ],
            "è¿ç»´ç›‘æ§": [
                "ç›‘æ§CPUã€å†…å­˜å’Œç½‘ç»œä½¿ç”¨",
                "è·Ÿè¸ªæ¶ˆæ¯å¤„ç†å»¶è¿Ÿå’Œååé‡",
                "è®°å½•é”™è¯¯ç‡å’Œå¤±è´¥åŸå› ",
                "ç›‘æ§é˜Ÿåˆ—å¥åº·çŠ¶æ€",
                "è®¾ç½®å‘Šè­¦å’Œé€šçŸ¥æœºåˆ¶"
            ]
        }
        
        for category, items in recommendations.items():
            print(f"\nğŸ“Œ {category}:")
            for i, item in enumerate(items, 1):
                print(f"  {i}. {item}")

def main():
    """ä¸»å‡½æ•°"""
    print("âš¡ æ¶ˆæ¯ç¡®è®¤æœ€ä½³å®è·µå’Œæ€§èƒ½ä¼˜åŒ–æ¼”ç¤º")
    print("ç¡®ä¿RabbitMQæœåŠ¡æ­£åœ¨è¿è¡Œ...")
    
    try:
        demo = BestPracticesDemo()
        demo.run_comprehensive_demo()
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºæ‰§è¡Œå¤±è´¥: {e}")
        print("è¯·ç¡®ä¿:")
        print("1. RabbitMQæœåŠ¡æ­£åœ¨è¿è¡Œ")
        print("2. å¯ä»¥è¿æ¥åˆ° localhost:5672")
        print("3. å·²å®‰è£…ä¾èµ–: pip install pika psutil")

if __name__ == "__main__":
    main()