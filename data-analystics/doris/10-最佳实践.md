# 第10章 Doris最佳实践

## 学习目标

- 掌握Doris架构设计与规划的最佳实践
- 学会Doris数据建模与表设计的最佳方法
- 了解Doris性能调优的最佳策略
- 掌握Doris运维管理的最佳实践
- 学会Doris应用开发的最佳技巧

## 1. 架构设计与规划

### 1.1 集群规划

#### 1.1.1 节点规划原则

1. **FE节点规划**
   - 生产环境至少部署3个FE节点，实现高可用
   - FE节点建议配置：8核CPU、32GB内存、SSD硬盘
   - FE节点不要与BE节点部署在同一台机器上
   - FE节点元数据存储建议使用高性能SSD

2. **BE节点规划**
   - BE节点数量根据数据量和查询并发决定
   - BE节点建议配置：16核CPU、64GB内存、SSD/HDD混合存储
   - BE节点磁盘建议使用RAID 10提高性能和可靠性
   - BE节点内存建议配置为数据量的1/4到1/3

3. **Broker节点规划**
   - Broker节点用于外部数据源访问
   - 建议每个BE节点部署一个Broker
   - Broker节点不需要高性能硬件

#### 1.1.2 网络规划

1. **网络隔离**
   - FE与BE之间使用内部网络
   - 客户端访问使用外部网络
   - 不同网络区域之间配置防火墙规则

2. **网络带宽**
   - FE与BE之间建议万兆网络
   - BE与外部存储之间建议万兆网络
   - 客户端访问根据查询量确定带宽

#### 1.1.3 存储规划

1. **存储类型选择**
   - 热数据使用SSD存储
   - 温数据使用高性能HDD存储
   - 冷数据使用大容量HDD存储

2. **存储容量规划**
   - 原始数据量的3-5倍
   - 预留30%的空间用于数据压缩和中间结果
   - 考虑数据增长率和保留周期

### 1.2 高可用架构

#### 1.2.1 FE高可用

```sql
-- FE高可用配置
-- 在fe.conf中配置
priority_networks = 10.0.0.0/8
meta_dir = /data/doris/meta
edit_log_port = 9010
edit_log_port = 9010
http_port = 8030
query_port = 9030
```

#### 1.2.2 BE高可用

```sql
-- BE高可用配置
-- 在be.conf中配置
priority_networks = 10.0.0.0/8
storage_root_path = /data/doris/storage,medium:hdd
heartbeat_service_thread_count = 1
create_tablet_worker_count = 3
default_rowset_type = beta
```

#### 1.2.3 数据备份策略

```sql
-- 创建备份仓库
CREATE REPOSITORY `backup_repo`
WITH BROKER `broker_name`
ON LOCATION `s3://doris-backup/backup`
PROPERTIES (
    "aws_s3_endpoint" = "s3.amazonaws.com",
    "aws_s3_access_key" = "your_access_key",
    "aws_s3_secret_key" = "your_secret_key"
);

-- 创建备份任务
CREATE BACKUP `backup_job`
FROM database_name
TO `backup_repo`
PROPERTIES (
    "type" = "FULL",
    "timeout" = "3600"
);

-- 恢复数据
RESTORE `restore_job`
FROM `backup_repo`
PROPERTIES (
    "type" = "FULL",
    "timeout" = "3600"
);
```

## 2. 数据建模与表设计

### 2.1 数据模型选择

#### 2.1.1 Duplicate模型

**适用场景**：
- 日志数据、行为数据等不需要去重的场景
- 需要保留原始数据的场景
- 数据量较大且查询较少的场景

**最佳实践**：
```sql
-- 日志表设计
CREATE TABLE app_logs (
    log_time DATETIME,
    app_name VARCHAR(50),
    instance_id VARCHAR(50),
    level VARCHAR(20),
    message TEXT
)
DUPLICATE KEY(log_time, app_name, instance_id, level)
PARTITION BY RANGE(log_time) (
    PARTITION p20231101 VALUES LESS THAN ("2023-11-02"),
    PARTITION p20231102 VALUES LESS THAN ("2023-11-03")
)
DISTRIBUTED BY HASH(app_name) BUCKETS 32
PROPERTIES (
    "compression" = "LZ4",
    "bloom_filter_columns" = "app_name, level"
);
```

#### 2.1.2 Aggregate模型

**适用场景**：
- 需要预聚合的场景
- 报表类数据
- 指标统计类数据

**最佳实践**：
```sql
-- 订单统计表设计
CREATE TABLE order_stats (
    order_date DATE,
    user_id BIGINT,
    region VARCHAR(50),
    order_count INT SUM DEFAULT "0",
    order_amount DECIMAL(18, 2) SUM DEFAULT "0",
    max_order_amount DECIMAL(18, 2) MAX DEFAULT "0",
    min_order_amount DECIMAL(18, 2) MIN DEFAULT "0"
)
AGGREGATE KEY(order_date, user_id, region)
PARTITION BY RANGE(order_date) (
    PARTITION p202311 VALUES LESS THAN ("2023-12-01")
)
DISTRIBUTED BY HASH(user_id) BUCKETS 32
PROPERTIES (
    "compression" = "LZ4",
    "bloom_filter_columns" = "user_id, region"
);
```

#### 2.1.3 Unique模型

**适用场景**：
- 需要唯一键的场景
- 用户维度数据
- 商品维度数据

**最佳实践**：
```sql
-- 用户表设计
CREATE TABLE users (
    user_id BIGINT,
    user_name VARCHAR(50),
    email VARCHAR(100),
    phone VARCHAR(20),
    gender VARCHAR(10),
    age INT,
    city VARCHAR(50),
    registration_time DATETIME,
    last_login_time DATETIME
)
UNIQUE KEY(user_id)
DISTRIBUTED BY HASH(user_id) BUCKETS 16
PROPERTIES (
    "compression" = "LZ4",
    "bloom_filter_columns" = "user_id"
);
```

### 2.2 分区设计

#### 2.2.1 分区策略

1. **时间分区**
   - 按天、周、月分区
   - 适用于时间序列数据
   - 便于数据生命周期管理

2. **范围分区**
   - 按数值范围分区
   - 适用于有明显分布特征的数据

3. **列表分区**
   - 按枚举值分区
   - 适用于基数较低的维度

#### 2.2.2 分区最佳实践

```sql
-- 动态分区配置
CREATE TABLE dynamic_partition_table (
    event_time DATETIME,
    user_id BIGINT,
    event_type VARCHAR(20),
    event_value INT
)
DUPLICATE KEY(event_time, user_id, event_type)
PARTITION BY RANGE(event_time) ()
DISTRIBUTED BY HASH(user_id) BUCKETS 32
PROPERTIES (
    "dynamic_partition.enable" = "true",
    "dynamic_partition.time_unit" = "DAY",
    "dynamic_partition.start" = "-30",
    "dynamic_partition.end" = "7",
    "dynamic_partition.prefix" = "p",
    "dynamic_partition.buckets" = "32"
);

-- 分区管理
-- 添加分区
ALTER TABLE table_name ADD PARTITION p20231201 VALUES LESS THAN ("2023-12-02");

-- 删除分区
ALTER TABLE table_name DROP PARTITION p20231101;

-- 修改分区属性
ALTER TABLE table_name MODIFY PARTITION p20231101 SET ("replication_num" = "3");
```

### 2.3 分桶设计

#### 2.3.1 分桶策略

1. **分桶键选择**
   - 选择高基数的列作为分桶键
   - 选择经常作为JOIN条件的列
   - 选择经常作为WHERE条件的列

2. **分桶数量**
   - 每个分桶大小建议在100MB-1GB之间
   - 分桶数量建议为BE节点数量的整数倍
   - 避免过多小分桶或过少大分桶

#### 2.3.2 分桶最佳实践

```sql
-- 分桶设计示例
CREATE TABLE bucket_example (
    user_id BIGINT,
    item_id BIGINT,
    category_id INT,
    action_time DATETIME,
    action_type VARCHAR(20),
    action_value DECIMAL(18, 2)
)
DUPLICATE KEY(user_id, item_id, action_time)
PARTITION BY RANGE(action_time) (
    PARTITION p202311 VALUES LESS THAN ("2023-12-01")
)
DISTRIBUTED BY HASH(user_id, item_id) BUCKETS 32
PROPERTIES (
    "compression" = "LZ4",
    "bloom_filter_columns" = "user_id, item_id"
);
```

### 2.4 列设计

#### 2.4.1 列类型选择

1. **数值类型**
   - 整数类型根据范围选择TINYINT、SMALLINT、INT、BIGINT
   - 浮点数根据精度选择FLOAT、DOUBLE、DECIMAL

2. **字符串类型**
   - 固定长度字符串使用CHAR
   - 变长字符串使用VARCHAR
   - 长文本使用STRING

3. **时间类型**
   - 日期使用DATE
   - 时间使用DATETIME
   - 时间戳使用DATETIME

#### 2.4.2 列设计最佳实践

```sql
-- 列设计示例
CREATE TABLE column_example (
    id BIGINT COMMENT '主键ID',
    user_id BIGINT COMMENT '用户ID',
    order_id BIGINT COMMENT '订单ID',
    product_id BIGINT COMMENT '商品ID',
    quantity INT COMMENT '数量',
    price DECIMAL(18, 2) COMMENT '价格',
    total_amount DECIMAL(18, 2) COMMENT '总金额',
    order_status VARCHAR(20) COMMENT '订单状态',
    payment_method VARCHAR(20) COMMENT '支付方式',
    order_time DATETIME COMMENT '下单时间',
    payment_time DATETIME COMMENT '支付时间',
    delivery_time DATETIME COMMENT '发货时间',
    finish_time DATETIME COMMENT '完成时间',
    create_time DATETIME COMMENT '创建时间',
    update_time DATETIME COMMENT '更新时间'
)
DUPLICATE KEY(id, user_id, order_id)
PARTITION BY RANGE(order_time) (
    PARTITION p202311 VALUES LESS THAN ("2023-12-01")
)
DISTRIBUTED BY HASH(user_id) BUCKETS 32
PROPERTIES (
    "compression" = "LZ4",
    "bloom_filter_columns" = "user_id, order_id, product_id"
);
```

## 3. 性能调优

### 3.1 查询优化

#### 3.1.1 查询重写

1. **避免SELECT ***
   - 只查询需要的列
   - 减少数据传输量

2. **合理使用WHERE条件**
   - 将过滤条件放在WHERE子句中
   - 避免在WHERE子句中使用函数

3. **合理使用JOIN**
   - 使用小表驱动大表
   - 确保JOIN键类型一致
   - 使用分桶键作为JOIN键

#### 3.1.2 查询优化示例

```sql
-- 优化前
SELECT * FROM orders o JOIN users u ON o.user_id = u.id WHERE DATE(o.order_time) = '2023-11-01';

-- 优化后
SELECT o.order_id, o.user_id, o.order_amount, u.user_name 
FROM orders o JOIN users u ON o.user_id = u.id 
WHERE o.order_time >= '2023-11-01 00:00:00' AND o.order_time < '2023-11-02 00:00:00';
```

#### 3.1.3 物化视图优化

```sql
-- 创建物化视图
CREATE MATERIALIZED VIEW order_daily_stats AS
SELECT 
    DATE(order_time) AS order_date,
    user_id,
    COUNT(*) AS order_count,
    SUM(order_amount) AS total_amount
FROM orders 
GROUP BY DATE(order_time), user_id;

-- 查询重写
SELECT order_date, SUM(order_count) AS total_orders, SUM(total_amount) AS total_amount
FROM order_daily_stats 
WHERE order_date >= '2023-11-01' AND order_date <= '2023-11-30'
GROUP BY order_date;
```

### 3.2 索引优化

#### 3.2.1 前缀索引

```sql
-- 创建表时指定前缀索引
CREATE TABLE prefix_index_example (
    user_id BIGINT,
    user_name VARCHAR(50),
    email VARCHAR(100),
    phone VARCHAR(20),
    address VARCHAR(200)
)
DUPLICATE KEY(user_id, user_name)
DISTRIBUTED BY HASH(user_id) BUCKETS 16
PROPERTIES (
    "compression" = "LZ4",
    "bloom_filter_columns" = "user_id, user_name",
    "prefix_length" = "10"
);
```

#### 3.2.2 布隆过滤器

```sql
-- 创建表时指定布隆过滤器
CREATE TABLE bloom_filter_example (
    user_id BIGINT,
    item_id BIGINT,
    category_id INT,
    action_time DATETIME,
    action_type VARCHAR(20)
)
DUPLICATE KEY(user_id, item_id, action_time)
DISTRIBUTED BY HASH(user_id) BUCKETS 32
PROPERTIES (
    "compression" = "LZ4",
    "bloom_filter_columns" = "user_id, item_id, category_id"
);
```

#### 3.2.3 位图索引

```sql
-- 创建位图索引
CREATE BITMAP INDEX idx_gender ON users (gender);
CREATE BITMAP INDEX idx_city ON users (city);
CREATE BITMAP INDEX idx_status ON orders (order_status);
```

#### 3.2.4 倒排索引

```sql
-- 创建倒排索引
CREATE INVERTED INDEX idx_content ON articles (content);
CREATE INVERTED INDEX idx_tags ON articles (tags);
```

### 3.3 参数调优

#### 3.3.1 FE参数调优

```properties
# fe.conf
# 元数据缓存大小
meta_cache_size = 10737418240

# 查询缓存大小
query_cache_size = 10737418240

# 最大连接数
max_connection = 4096

# 查询超时时间
query_timeout = 300

# 物化视图重写开关
enable_materialized_view_rewrite = true
```

#### 3.3.2 BE参数调优

```properties
# be.conf
# 内存限制
memory_limit = 80%

# 存储介质配置
storage_flood_stage_usage_percent = 85
storage_flood_stage_left_capacity_bytes = 1073741824

# 写入线程数
write_buffer_size = 104857600

# 压缩配置
chunk_size = 1024
compression = "LZ4"
```

#### 3.3.3 查询参数调优

```sql
-- 设置查询参数
SET exec_mem_limit = 8589934592;
SET batch_size = 4096;
SET parallel_fragment_exec_instance_num = 8;
SET enable_vectorized_engine = true;
SET enable_pipeline_engine = true;
```

## 4. 运维管理

### 4.1 监控与告警

#### 4.1.1 集群监控指标

1. **FE监控指标**
   - FE节点状态
   - 元数据大小
   - 查询数量
   - 连接数量

2. **BE监控指标**
   - BE节点状态
   - 磁盘使用率
   - 内存使用率
   - CPU使用率
   - 查询延迟
   - 导入速度

#### 4.1.2 监控实现

```sql
-- 创建监控表
CREATE TABLE cluster_metrics (
    metric_time DATETIME,
    node_type VARCHAR(10),
    node_name VARCHAR(100),
    metric_name VARCHAR(100),
    metric_value DOUBLE,
    metric_unit VARCHAR(20)
)
DUPLICATE KEY(metric_time, node_type, node_name, metric_name)
PARTITION BY RANGE(metric_time) (
    PARTITION p202311 VALUES LESS THAN ("2023-12-01")
)
DISTRIBUTED BY HASH(node_name) BUCKETS 16
PROPERTIES (
    "compression" = "LZ4"
);

-- 插入监控数据
INSERT INTO cluster_metrics
SELECT 
    NOW() AS metric_time,
    'BE' AS node_type,
    name AS node_name,
    'disk_usage' AS metric_name,
    used_disk / total_disk AS metric_value,
    '%' AS metric_unit
FROM information_schema.be_tablets;
```

### 4.2 数据生命周期管理

#### 4.2.1 数据分区管理

```sql
-- 自动创建分区
ALTER TABLE table_name SET (
    "dynamic_partition.enable" = "true",
    "dynamic_partition.time_unit" = "DAY",
    "dynamic_partition.start" = "-30",
    "dynamic_partition.end" = "7",
    "dynamic_partition.prefix" = "p"
);

-- 自动删除分区
ALTER TABLE table_name SET (
    "dynamic_partition.enable" = "true",
    "dynamic_partition.time_unit" = "DAY",
    "dynamic_partition.start" = "-30",
    "dynamic_partition.end" = "7",
    "dynamic_partition.prefix" = "p"
);

-- 手动删除分区
ALTER TABLE table_name DROP PARTITION p20231101;
```

#### 4.2.2 数据压缩与清理

```sql
-- 手动触发压缩
ALTER TABLE table_name COMPACT;

-- 查看压缩状态
SHOW COMPACTION FROM table_name;

-- 清理过期数据
DELETE FROM table_name WHERE event_time < '2023-01-01';
```

### 4.3 备份与恢复

#### 4.3.1 备份策略

1. **全量备份**
   - 定期进行全量备份
   - 保留多个备份版本
   - 备份到异地存储

2. **增量备份**
   - 基于全量备份进行增量备份
   - 减少备份时间和存储空间

#### 4.3.2 备份实现

```sql
-- 创建备份仓库
CREATE REPOSITORY `backup_repo`
WITH BROKER `broker_name`
ON LOCATION `s3://doris-backup/backup`
PROPERTIES (
    "aws_s3_endpoint" = "s3.amazonaws.com",
    "aws_s3_access_key" = "your_access_key",
    "aws_s3_secret_key" = "your_secret_key"
);

-- 创建备份任务
CREATE BACKUP `backup_job_20231101`
FROM database_name
TO `backup_repo`
PROPERTIES (
    "type" = "FULL",
    "timeout" = "3600"
);

-- 查看备份状态
SHOW BACKUP FROM `backup_repo`;

-- 恢复数据
RESTORE `restore_job_20231101`
FROM `backup_repo`
PROPERTIES (
    "type" = "FULL",
    "timeout" = "3600"
);
```

## 5. 应用开发

### 5.1 数据导入最佳实践

#### 5.1.1 导入方式选择

1. **Stream Load**
   - 适用于小批量数据导入
   - 实时性要求高的场景
   - 单次导入数据量建议在100MB以内

2. **Broker Load**
   - 适用于大批量数据导入
   - 历史数据迁移
   - 单次导入数据量建议在GB级别

3. **Routine Load**
   - 适用于实时数据导入
   - Kafka、Pulsar等消息队列数据
   - 持续性数据导入

#### 5.1.2 导入优化

```bash
# Stream Load优化
curl --location-trusted -u root: \
    -H "column_separator:," \
    -H "columns:col1,col2,col3" \
    -H "load_to_single_partition:true" \
    -H "strict_mode:false" \
    -H "timezone:Asia/Shanghai" \
    -T data.csv \
    http://fe_host:http_port/api/db/table/_stream_load
```

```sql
-- Broker Load优化
LOAD LABEL db.table_label
(
    DATA INFILE("hdfs://namenode:port/path/to/data")
    INTO TABLE table_name
    FORMAT AS "csv"
    (col1, col2, col3)
    SET col4 = col1 + col2
)
WITH BROKER broker_name
(
    "username" = "user",
    "password" = "password"
)
PROPERTIES
(
    "timeout" = "3600",
    "max_filter_ratio" = "0.1"
);
```

### 5.2 查询开发最佳实践

#### 5.2.1 查询设计原则

1. **减少数据扫描量**
   - 使用分区裁剪
   - 使用列裁剪
   - 使用索引

2. **优化JOIN操作**
   - 使用分桶键作为JOIN键
   - 确保JOIN键类型一致
   - 使用小表驱动大表

3. **合理使用聚合**
   - 预聚合常用指标
   - 使用物化视图
   - 避免重复计算

#### 5.2.2 查询优化示例

```sql
-- 优化前
SELECT 
    u.user_id,
    u.user_name,
    COUNT(o.order_id) AS order_count,
    SUM(o.order_amount) AS total_amount
FROM users u
LEFT JOIN orders o ON u.user_id = o.user_id
WHERE u.registration_time >= '2023-01-01'
GROUP BY u.user_id, u.user_name;

-- 优化后
-- 创建物化视图
CREATE MATERIALIZED VIEW user_order_stats AS
SELECT 
    user_id,
    COUNT(order_id) AS order_count,
    SUM(order_amount) AS total_amount
FROM orders 
GROUP BY user_id;

-- 查询重写
SELECT 
    u.user_id,
    u.user_name,
    COALESCE(s.order_count, 0) AS order_count,
    COALESCE(s.total_amount, 0) AS total_amount
FROM users u
LEFT JOIN user_order_stats s ON u.user_id = s.user_id
WHERE u.registration_time >= '2023-01-01';
```

### 5.3 应用集成

#### 5.3.1 JDBC集成

```java
// JDBC连接示例
Class.forName("com.mysql.jdbc.Driver");
Connection conn = DriverManager.getConnection(
    "jdbc:mysql://fe_host:query_port/db?useUnicode=true&characterEncoding=utf8", 
    "user", 
    "password");

// 执行查询
Statement stmt = conn.createStatement();
ResultSet rs = stmt.executeQuery("SELECT * FROM table_name LIMIT 10");

// 处理结果
while (rs.next()) {
    System.out.println(rs.getString("column_name"));
}

// 关闭连接
rs.close();
stmt.close();
conn.close();
```

#### 5.3.2 Python集成

```python
# Python连接示例
import pymysql

# 创建连接
conn = pymysql.connect(
    host='fe_host',
    port=9030,
    user='user',
    password='password',
    database='db'
)

# 创建游标
cursor = conn.cursor()

# 执行查询
cursor.execute("SELECT * FROM table_name LIMIT 10")

# 获取结果
results = cursor.fetchall()

# 处理结果
for row in results:
    print(row)

# 关闭连接
cursor.close()
conn.close()
```

## 6. 本章小结

本章详细介绍了Doris的最佳实践，包括架构设计与规划、数据建模与表设计、性能调优、运维管理和应用开发等方面。通过遵循这些最佳实践，可以构建高性能、高可用、易维护的Doris系统。

### 6.1 关键要点

1. **架构规划**：合理规划FE、BE节点数量和配置
2. **数据建模**：根据业务特点选择合适的数据模型
3. **性能优化**：通过查询优化、索引优化和参数调优提升性能
4. **运维管理**：建立完善的监控、备份和恢复机制
5. **应用开发**：遵循数据导入和查询开发的最佳实践

### 6.2 最佳实践总结

1. 集群规划要考虑业务增长和扩展性
2. 数据模型选择要基于业务特点和查询模式
3. 分区和分桶设计要考虑数据分布和查询模式
4. 索引设计要基于查询条件和频率
5. 查询优化要减少数据扫描量和计算量
6. 运维管理要建立完善的监控和告警体系
7. 数据导入要选择合适的导入方式和优化策略
8. 应用集成要使用合适的连接方式和参数

## 7. 延伸阅读

- [Doris官方文档-最佳实践](https://doris.apache.org/docs/dev/best-practice/)
- [Doris官方文档-性能调优](https://doris.apache.org/docs/dev/admin-manual/config/)
- [Doris官方文档-运维管理](https://doris.apache.org/docs/dev/admin-manual/)

## 8. 实践练习

1. 设计一个电商平台的Doris架构
2. 优化一个复杂查询的性能
3. 设计一个高可用的Doris集群
4. 实现一个自动化的备份恢复方案
5. 开发一个Doris数据导入工具
6. 构建一个Doris监控告警系统
7. 设计一个Doris应用集成方案