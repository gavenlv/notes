# 第7章 数据源管理与资源中心

## 7.1 数据源管理

### 7.1.1 数据源概述

数据源是DolphinScheduler中用于连接各种数据存储系统的配置，支持多种数据库和数据存储类型。

#### 7.1.1.1 支持的数据源类型

1. **关系型数据库**
   - MySQL
   - PostgreSQL
   - Oracle
   - SQL Server
   - ClickHouse

2. **大数据存储**
   - Hive
   - HBase
   - Phoenix

3. **NoSQL数据库**
   - MongoDB
   - Redis

4. **数据仓库**
   - Amazon Redshift
   - Google BigQuery
   - Snowflake

5. **其他数据源**
   - FTP/SFTP
   - HTTP API

#### 7.1.1.2 数据源配置模型

```java
// 数据源基础模型
public abstract class DataSource {
    protected int id;
    protected String name;
    protected String type;
    protected String description;
    protected String connectionParams;
    protected int userId;
    protected Date createTime;
    protected Date updateTime;
    
    // 抽象方法：测试连接
    public abstract Connection testConnection() throws SQLException;
    
    // 抽象方法：获取连接
    public abstract Connection getConnection() throws SQLException;
    
    // 抽象方法：验证配置
    public abstract ValidationResult validateConfiguration();
}

// MySQL数据源
public class MySQLDataSource extends DataSource {
    private String host;
    private int port;
    private String database;
    private String username;
    private String password;
    private String jdbcUrl;
    private String driverClass;
    
    @Override
    public Connection testConnection() throws SQLException {
        try {
            Class.forName(driverClass);
            Connection connection = DriverManager.getConnection(jdbcUrl, username, password);
            // 执行简单查询验证连接
            try (Statement stmt = connection.createStatement();
                 ResultSet rs = stmt.executeQuery("SELECT 1")) {
                if (rs.next() && rs.getInt(1) == 1) {
                    return connection;
                }
            }
            connection.close();
            throw new SQLException("Connection test failed");
        } catch (ClassNotFoundException e) {
            throw new SQLException("MySQL driver not found", e);
        }
    }
    
    @Override
    public Connection getConnection() throws SQLException {
        try {
            Class.forName(driverClass);
            return DriverManager.getConnection(jdbcUrl, username, password);
        } catch (ClassNotFoundException e) {
            throw new SQLException("MySQL driver not found", e);
        }
    }
    
    @Override
    public ValidationResult validateConfiguration() {
        ValidationResult result = new ValidationResult();
        
        // 验证主机名
        if (host == null || host.trim().isEmpty()) {
            result.addError("Host is required");
        }
        
        // 验证端口
        if (port <= 0 || port > 65535) {
            result.addError("Invalid port number");
        }
        
        // 验证数据库名
        if (database == null || database.trim().isEmpty()) {
            result.addError("Database name is required");
        }
        
        // 验证用户名
        if (username == null || username.trim().isEmpty()) {
            result.addError("Username is required");
        }
        
        return result;
    }
}

// Hive数据源
public class HiveDataSource extends DataSource {
    private String metastoreUris;
    private String auth;
    private String principal;
    private String krb5Conf;
    private String jdbcUrl;
    private String driverClass;
    
    @Override
    public Connection testConnection() throws SQLException {
        try {
            Class.forName(driverClass);
            Connection connection = DriverManager.getConnection(jdbcUrl);
            
            // 执行简单查询验证连接
            try (Statement stmt = connection.createStatement();
                 ResultSet rs = stmt.executeQuery("SELECT 1")) {
                if (rs.next() && rs.getInt(1) == 1) {
                    return connection;
                }
            }
            connection.close();
            throw new SQLException("Connection test failed");
        } catch (ClassNotFoundException e) {
            throw new SQLException("Hive driver not found", e);
        }
    }
    
    @Override
    public Connection getConnection() throws SQLException {
        try {
            Class.forName(driverClass);
            return DriverManager.getConnection(jdbcUrl);
        } catch (ClassNotFoundException e) {
            throw new SQLException("Hive driver not found", e);
        }
    }
    
    @Override
    public ValidationResult validateConfiguration() {
        ValidationResult result = new ValidationResult();
        
        // 验证Metastore URIs
        if (metastoreUris == null || metastoreUris.trim().isEmpty()) {
            result.addError("Metastore URIs is required");
        }
        
        // 验证认证方式
        if (auth != null) {
            if ("KERBEROS".equals(auth) && (principal == null || krb5Conf == null)) {
                result.addError("Principal and Krb5 conf are required for Kerberos authentication");
            }
        }
        
        return result;
    }
}
```

### 7.1.2 数据源管理API

#### 7.1.2.1 数据源CRUD操作

```java
// 数据源管理服务
@RestController
@RequestMapping("/v1/datasources")
public class DataSourceController {
    
    @Autowired
    private DataSourceService dataSourceService;
    
    // 创建数据源
    @PostMapping
    public Result<DataSourceDetail> createDataSource(@RequestBody DataSourceCreateRequest request) {
        try {
            DataSourceDetail dataSource = dataSourceService.createDataSource(request);
            return Result.success(dataSource);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 获取数据源详情
    @GetMapping("/{id}")
    public Result<DataSourceDetail> getDataSource(@PathVariable int id) {
        try {
            DataSourceDetail dataSource = dataSourceService.getDataSource(id);
            return Result.success(dataSource);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 更新数据源
    @PutMapping("/{id}")
    public Result<DataSourceDetail> updateDataSource(@PathVariable int id, 
                                                    @RequestBody DataSourceUpdateRequest request) {
        try {
            DataSourceDetail dataSource = dataSourceService.updateDataSource(id, request);
            return Result.success(dataSource);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 删除数据源
    @DeleteMapping("/{id}")
    public Result deleteDataSource(@PathVariable int id) {
        try {
            dataSourceService.deleteDataSource(id);
            return Result.success();
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 测试数据源连接
    @PostMapping("/{id}/test")
    public Result testDataSourceConnection(@PathVariable int id) {
        try {
            ConnectionTestResult result = dataSourceService.testConnection(id);
            return Result.success(result);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 获取数据源列表
    @GetMapping
    public Result<PageInfo<DataSourceSummary>> listDataSources(
            @RequestParam(value = "type", required = false) String type,
            @RequestParam(value = "name", required = false) String name,
            @RequestParam(value = "page", defaultValue = "1") int page,
            @RequestParam(value = "size", defaultValue = "20") int size) {
        try {
            DataSourceQuery query = new DataSourceQuery(type, name);
            PageInfo<DataSourceSummary> pageInfo = dataSourceService.listDataSources(query, page, size);
            return Result.success(pageInfo);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
}

// 数据源服务实现
@Service
public class DataSourceServiceImpl implements DataSourceService {
    
    @Autowired
    private DataSourceDao dataSourceDao;
    
    @Autowired
    private DataSourceFactory dataSourceFactory;
    
    @Override
    @Transactional
    public DataSourceDetail createDataSource(DataSourceCreateRequest request) {
        // 1. 验证请求参数
        validateCreateRequest(request);
        
        // 2. 创建数据源对象
        DataSource dataSource = dataSourceFactory.createDataSource(request.getType(), request);
        
        // 3. 验证数据源配置
        ValidationResult validation = dataSource.validateConfiguration();
        if (!validation.isValid()) {
            throw new IllegalArgumentException("Invalid data source configuration: " 
                                             + validation.getErrors());
        }
        
        // 4. 测试连接
        try {
            Connection connection = dataSource.testConnection();
            if (connection != null) {
                connection.close();
            }
        } catch (SQLException e) {
            throw new RuntimeException("Failed to connect to data source: " + e.getMessage(), e);
        }
        
        // 5. 加密敏感信息
        encryptSensitiveInformation(dataSource);
        
        // 6. 保存数据源
        int id = dataSourceDao.save(dataSource);
        
        // 7. 返回详情
        return getDataSource(id);
    }
    
    @Override
    public ConnectionTestResult testConnection(int id) {
        DataSource dataSource = dataSourceDao.findById(id);
        if (dataSource == null) {
            throw new RuntimeException("Data source not found");
        }
        
        long startTime = System.currentTimeMillis();
        try {
            Connection connection = dataSource.testConnection();
            if (connection != null) {
                connection.close();
            }
            
            long duration = System.currentTimeMillis() - startTime;
            return ConnectionTestResult.success(duration);
        } catch (SQLException e) {
            long duration = System.currentTimeMillis() - startTime;
            return ConnectionTestResult.failed(e.getMessage(), duration);
        }
    }
    
    // 加密敏感信息
    private void encryptSensitiveInformation(DataSource dataSource) {
        // 这里应该使用加密算法加密密码等敏感信息
        // 简化实现，实际应使用更安全的加密方式
        String connectionParams = dataSource.getConnectionParams();
        if (connectionParams != null) {
            // 加密连接参数中的敏感信息
            String encryptedParams = encryptParams(connectionParams);
            dataSource.setConnectionParams(encryptedParams);
        }
    }
}
```

### 7.1.3 连接池管理

#### 7.1.3.1 连接池实现

```java
// 数据源连接池管理
public class DataSourceConnectionPoolManager {
    
    private Map<Integer, DataSourceConnectionPool> pools = new ConcurrentHashMap<>();
    
    // 获取或创建连接池
    public DataSourceConnectionPool getConnectionPool(int dataSourceId) {
        return pools.computeIfAbsent(dataSourceId, id -> {
            DataSource dataSource = dataSourceDao.findById(id);
            return createConnectionPool(dataSource);
        });
    }
    
    // 创建连接池
    private DataSourceConnectionPool createConnectionPool(DataSource dataSource) {
        DataSourceConnectionPool pool = new DataSourceConnectionPool();
        
        // 设置数据源连接配置
        HikariConfig config = new HikariConfig();
        config.setJdbcUrl(dataSource.getJdbcUrl());
        config.setUsername(dataSource.getUsername());
        config.setPassword(dataSource.getPassword());
        config.setDriverClassName(dataSource.getDriverClass());
        
        // 连接池参数配置
        config.setMaximumPoolSize(dataSource.getMaxPoolSize() > 0 ? dataSource.getMaxPoolSize() : 10);
        config.setMinimumIdle(dataSource.getMinPoolSize() > 0 ? dataSource.getMinPoolSize() : 2);
        config.setConnectionTimeout(dataSource.getConnectionTimeout() > 0 ? 
                                  dataSource.getConnectionTimeout() : 30000);
        config.setIdleTimeout(dataSource.getIdleTimeout() > 0 ? dataSource.getIdleTimeout() : 600000);
        config.setMaxLifetime(dataSource.getMaxLifetime() > 0 ? dataSource.getMaxLifetime() : 1800000);
        
        // 性能优化配置
        config.setLeakDetectionThreshold(dataSource.getLeakDetectionThreshold() > 0 ? 
                                        dataSource.getLeakDetectionThreshold() : 0);
        config.setValidationTimeout(dataSource.getValidationTimeout() > 0 ? 
                                  dataSource.getValidationTimeout() : 5000);
        config.setConnectionTestQuery(dataSource.getConnectionTestQuery() != null ? 
                                      dataSource.getConnectionTestQuery() : "SELECT 1");
        
        // 创建连接池
        HikariDataSource hikariDataSource = new HikariDataSource(config);
        
        // 设置连接池状态监控
        setupPoolMonitoring(dataSourceId, hikariDataSource);
        
        pool.setHikariDataSource(hikariDataSource);
        pool.setDataSourceId(dataSourceId);
        
        return pool;
    }
    
    // 设置连接池监控
    private void setupPoolMonitoring(int dataSourceId, HikariDataSource hikariDataSource) {
        // 定期收集连接池指标
        ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor();
        scheduler.scheduleAtFixedRate(() -> {
            try {
                HikariPoolMXBean poolProxy = hikariDataSource.getHikariPoolMXBean();
                
                // 记录连接池状态
                ConnectionPoolStats stats = new ConnectionPoolStats();
                stats.setDataSourceId(dataSourceId);
                stats.setTotalConnections(poolProxy.getTotalConnections());
                stats.setActiveConnections(poolProxy.getActiveConnections());
                stats.setIdleConnections(poolProxy.getIdleConnections());
                stats.setWaitingThreads(poolProxy.getThreadsAwaitingConnection());
                stats.setTimestamp(new Date());
                
                // 保存指标到数据库或监控系统
                saveConnectionPoolStats(stats);
                
                // 检查连接池健康状态
                checkConnectionPoolHealth(dataSourceId, stats);
            } catch (Exception e) {
                logger.error("Failed to collect connection pool metrics for data source: " + 
                            dataSourceId, e);
            }
        }, 30, 30, TimeUnit.SECONDS); // 每30秒收集一次指标
    }
    
    // 检查连接池健康状态
    private void checkConnectionPoolHealth(int dataSourceId, ConnectionPoolStats stats) {
        // 检查连接池使用率
        double usageRatio = (double) stats.getActiveConnections() / stats.getTotalConnections();
        
        // 如果使用率过高，发送告警
        if (usageRatio > 0.8) {
            alertService.sendConnectionPoolHighUsageAlert(dataSourceId, usageRatio);
        }
        
        // 检查等待线程数
        if (stats.getWaitingThreads() > 5) {
            alertService.sendConnectionPoolWaitingThreadAlert(dataSourceId, stats.getWaitingThreads());
        }
    }
}
```

#### 7.1.3.2 连接池配置

```java
// 连接池配置
public class ConnectionPoolConfig {
    private int maxPoolSize = 10;              // 最大连接数
    private int minPoolSize = 2;               // 最小连接数
    private long connectionTimeout = 30000;     // 连接超时时间(毫秒)
    private long idleTimeout = 600000;          // 空闲超时时间(毫秒)
    private long maxLifetime = 1800000;         // 连接最大生命周期(毫秒)
    private long leakDetectionThreshold = 0;    // 连接泄漏检测阈值(毫秒)，0表示不检测
    private long validationTimeout = 5000;       // 连接验证超时时间(毫秒)
    private String connectionTestQuery = "SELECT 1"; // 连接测试查询
    
    // 根据数据源类型优化配置
    public static ConnectionPoolConfig optimizeForDataSourceType(String type) {
        ConnectionPoolConfig config = new ConnectionPoolConfig();
        
        switch (type) {
            case "MYSQL":
                config.setMaxPoolSize(20);
                config.setConnectionTimeout(20000);
                config.setIdleTimeout(300000);
                config.setMaxLifetime(1200000);
                break;
                
            case "ORACLE":
                config.setMaxPoolSize(15);
                config.setConnectionTimeout(30000);
                config.setIdleTimeout(600000);
                config.setMaxLifetime(1800000);
                break;
                
            case "HIVE":
                config.setMaxPoolSize(10);
                config.setConnectionTimeout(60000);
                config.setIdleTimeout(900000);
                config.setMaxLifetime(3600000);
                break;
                
            case "CLICKHOUSE":
                config.setMaxPoolSize(30);
                config.setConnectionTimeout(15000);
                config.setIdleTimeout(300000);
                config.setMaxLifetime(900000);
                break;
        }
        
        return config;
    }
}
```

## 7.2 资源中心

### 7.2.1 资源中心概述

资源中心是DolphinScheduler中用于管理任务执行过程中需要的文件、脚本和配置的地方，支持上传、下载、版本管理和权限控制。

#### 7.2.1.1 资源类型

1. **脚本文件**
   - Shell脚本
   - Python脚本
   - SQL脚本
   - 其他执行脚本

2. **配置文件**
   - 配置文件
   - 属性文件
   - XML/JSON/YAML文件

3. **依赖文件**
   - JAR包
   - Python包
   - 数据文件
   - 模型文件

4. **其他资源**
   - 图片
   - 文档
   - 模板文件

### 7.2.2 资源管理

#### 7.2.2.1 资源上传

```java
// 资源上传服务
@RestController
@RequestMapping("/v1/resources")
public class ResourceController {
    
    @Autowired
    private ResourceService resourceService;
    
    // 上传文件资源
    @PostMapping("/upload")
    public Result<ResourceDetail> uploadResource(@RequestParam("file") MultipartFile file,
                                                @RequestParam(value = "description", required = false) String description,
                                                @RequestParam(value = "pid", defaultValue = "0") int pid) {
        try {
            ResourceUploadRequest request = new ResourceUploadRequest();
            request.setFile(file);
            request.setDescription(description);
            request.setPid(pid);
            
            ResourceDetail resource = resourceService.uploadResource(request);
            return Result.success(resource);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 上传UDF资源
    @PostMapping("/udf")
    public Result<UDFResourceDetail> uploadUDFResource(@RequestParam("file") MultipartFile file,
                                                       @RequestParam(value = "description", required = false) String description,
                                                       @RequestParam("type") String type,
                                                       @RequestParam("className") String className,
                                                       @RequestParam(value = "jarName", required = false) String jarName) {
        try {
            UDFResourceUploadRequest request = new UDFResourceUploadRequest();
            request.setFile(file);
            request.setDescription(description);
            request.setType(type);
            request.setClassName(className);
            request.setJarName(jarName);
            
            UDFResourceDetail resource = resourceService.uploadUDFResource(request);
            return Result.success(resource);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 创建文件夹
    @PostMapping("/folder")
    public Result<ResourceDetail> createFolder(@RequestBody ResourceCreateFolderRequest request) {
        try {
            ResourceDetail resource = resourceService.createFolder(request);
            return Result.success(resource);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
}

// 资源服务实现
@Service
public class ResourceServiceImpl implements ResourceService {
    
    @Autowired
    private ResourceDao resourceDao;
    
    @Autowired
    private ResourceStorageService storageService;
    
    @Autowired
    private ResourceVersionService versionService;
    
    @Override
    @Transactional
    public ResourceDetail uploadResource(ResourceUploadRequest request) {
        // 1. 验证请求
        validateUploadRequest(request);
        
        // 2. 检查文件名是否已存在
        checkFileNameExistence(request);
        
        // 3. 上传文件到存储
        String storagePath = storageService.storeFile(request.getFile());
        
        // 4. 创建资源记录
        Resource resource = new Resource();
        resource.setFullName(request.getFile().getOriginalFilename());
        resource.setFileName(request.getFile().getOriginalFilename());
        resource.setDirectory(false);
        resource.setSize(request.getFile().getSize());
        resource.setDescription(request.getDescription());
        resource.setPid(request.getPid());
        resource.setFullName(getFullName(request.getPid(), request.getFile().getOriginalFilename()));
        resource.setCreateTime(new Date());
        resource.setUpdateTime(new Date());
        resource.setType(getResourceType(request.getFile().getOriginalFilename()));
        
        // 5. 保存资源记录
        int resourceId = resourceDao.save(resource);
        
        // 6. 创建版本记录
        versionService.createVersion(resourceId, 1, storagePath, 
                                   "Initial upload", request.getCurrentUser());
        
        // 7. 返回详情
        return getResource(resourceId);
    }
    
    // 获取资源类型
    private String getResourceType(String fileName) {
        String extension = getFileExtension(fileName);
        switch (extension.toLowerCase()) {
            case "sh":
                return "SHELL";
            case "py":
                return "PYTHON";
            case "sql":
                return "SQL";
            case "jar":
                return "JAR";
            case "zip":
            case "tar":
            case "gz":
                return "ARCHIVE";
            default:
                return "FILE";
        }
    }
    
    // 获取文件扩展名
    private String getFileExtension(String fileName) {
        int lastDotIndex = fileName.lastIndexOf('.');
        if (lastDotIndex > 0 && lastDotIndex < fileName.length() - 1) {
            return fileName.substring(lastDotIndex + 1);
        }
        return "";
    }
    
    // 获取完整路径
    private String getFullName(int pid, String fileName) {
        if (pid == 0) {
            return fileName;
        }
        
        Resource parent = resourceDao.findById(pid);
        if (parent == null) {
            return fileName;
        }
        
        return parent.getFullName() + "/" + fileName;
    }
}
```

#### 7.2.2.2 资源版本管理

```java
// 资源版本管理
@Service
public class ResourceVersionServiceImpl implements ResourceVersionService {
    
    @Autowired
    private ResourceVersionDao resourceVersionDao;
    
    @Autowired
    private ResourceDao resourceDao;
    
    @Override
    @Transactional
    public ResourceVersion createVersion(int resourceId, int versionNumber, 
                                         String storagePath, String description, String createUser) {
        // 1. 检查资源是否存在
        Resource resource = resourceDao.findById(resourceId);
        if (resource == null) {
            throw new RuntimeException("Resource not found");
        }
        
        // 2. 创建版本记录
        ResourceVersion version = new ResourceVersion();
        version.setResourceId(resourceId);
        version.setVersionNumber(versionNumber);
        version.setStoragePath(storagePath);
        version.setDescription(description);
        version.setCreateUser(createUser);
        version.setCreateTime(new Date());
        
        // 3. 保存版本记录
        int versionId = resourceVersionDao.save(version);
        
        // 4. 更新资源当前版本
        resource.setVersionNumber(versionNumber);
        resource.setUpdateTime(new Date());
        resourceDao.update(resource);
        
        // 5. 返回版本详情
        return getVersion(versionId);
    }
    
    @Override
    @Transactional
    public ResourceVersion updateResource(int resourceId, MultipartFile file, 
                                         String description, String updateUser) {
        // 1. 获取资源信息
        Resource resource = resourceDao.findById(resourceId);
        if (resource == null) {
            throw new RuntimeException("Resource not found");
        }
        
        // 2. 上传新文件
        String storagePath = storageService.storeFile(file);
        
        // 3. 获取下一个版本号
        int nextVersion = resource.getVersionNumber() + 1;
        
        // 4. 创建新版本
        ResourceVersion version = createVersion(resourceId, nextVersion, storagePath, 
                                               description, updateUser);
        
        // 5. 更新资源信息
        resource.setSize(file.getSize());
        resource.setUpdateTime(new Date());
        resourceDao.update(resource);
        
        return version;
    }
    
    @Override
    public List<ResourceVersion> getVersionHistory(int resourceId) {
        return resourceVersionDao.findByResourceId(resourceId);
    }
    
    @Override
    public ResourceVersion revertToVersion(int resourceId, int versionNumber, String updateUser) {
        // 1. 检查版本是否存在
        ResourceVersion version = resourceVersionDao.findByResourceIdAndVersionNumber(resourceId, versionNumber);
        if (version == null) {
            throw new RuntimeException("Version not found");
        }
        
        // 2. 获取资源信息
        Resource resource = resourceDao.findById(resourceId);
        if (resource == null) {
            throw new RuntimeException("Resource not found");
        }
        
        // 3. 复制旧版本的文件
        String newStoragePath = storageService.copyFile(version.getStoragePath());
        
        // 4. 创建新版本（实际上是一个恢复版本）
        int nextVersion = resource.getVersionNumber() + 1;
        String description = String.format("Revert to version %d", versionNumber);
        ResourceVersion newVersion = createVersion(resourceId, nextVersion, newStoragePath, 
                                                 description, updateUser);
        
        return newVersion;
    }
}
```

#### 7.2.2.3 资源权限管理

```java
// 资源权限管理
@Service
public class ResourcePermissionServiceImpl implements ResourcePermissionService {
    
    @Autowired
    private ResourcePermissionDao resourcePermissionDao;
    
    @Autowired
    private UserDao userDao;
    
    @Override
    public boolean hasPermission(int userId, int resourceId, ResourcePermission permission) {
        // 1. 检查用户是否是资源创建者
        Resource resource = resourceDao.findById(resourceId);
        if (resource != null && resource.getUserId() == userId) {
            return true; // 资源创建者拥有所有权限
        }
        
        // 2. 检查用户是否有直接权限
        ResourcePermission userPermission = resourcePermissionDao.findByUserIdAndResourceId(userId, resourceId);
        if (userPermission != null && checkPermission(userPermission, permission)) {
            return true;
        }
        
        // 3. 检查用户是否有组权限
        User user = userDao.findById(userId);
        if (user != null) {
            for (int groupId : user.getGroupIds()) {
                ResourcePermission groupPermission = resourcePermissionDao
                    .findByGroupIdAndResourceId(groupId, resourceId);
                if (groupPermission != null && checkPermission(groupPermission, permission)) {
                    return true;
                }
            }
        }
        
        // 4. 检查父目录权限
        if (resource != null && resource.getPid() > 0) {
            return hasPermission(userId, resource.getPid(), permission);
        }
        
        return false;
    }
    
    @Override
    @Transactional
    public void grantPermission(GrantResourcePermissionRequest request) {
        // 1. 验证请求
        validateGrantPermissionRequest(request);
        
        // 2. 检查权限授权者是否有权限
        if (!hasPermission(request.getGrantorId(), request.getResourceId(), ResourcePermission.MANAGE)) {
            throw new SecurityException("No permission to grant permissions");
        }
        
        // 3. 创建权限记录
        ResourcePermission permission = new ResourcePermission();
        permission.setResourceId(request.getResourceId());
        permission.setPermission(request.getPermission().getCode());
        
        if (request.getUserId() > 0) {
            permission.setUserId(request.getUserId());
        } else if (request.getGroupId() > 0) {
            permission.setGroupId(request.getGroupId());
        }
        
        permission.setCreateUser(request.getGrantorId());
        permission.setCreateTime(new Date());
        
        resourcePermissionDao.save(permission);
    }
    
    @Override
    @Transactional
    public void revokePermission(RevokeResourcePermissionRequest request) {
        // 1. 验证请求
        validateRevokePermissionRequest(request);
        
        // 2. 检查权限撤销者是否有权限
        if (!hasPermission(request.getRevokerId(), request.getResourceId(), ResourcePermission.MANAGE)) {
            throw new SecurityException("No permission to revoke permissions");
        }
        
        // 3. 删除权限记录
        if (request.getUserId() > 0) {
            resourcePermissionDao.deleteByUserIdAndResourceId(request.getUserId(), 
                                                              request.getResourceId());
        } else if (request.getGroupId() > 0) {
            resourcePermissionDao.deleteByGroupIdAndResourceId(request.getGroupId(), 
                                                               request.getResourceId());
        }
    }
    
    // 检查权限
    private boolean checkPermission(ResourcePermission grantedPermission, 
                                   ResourcePermission requiredPermission) {
        // 如果被授予的权限级别大于等于所需权限级别
        return grantedPermission.getPermission() >= requiredPermission.getCode();
    }
}
```

### 7.2.3 资源存储

#### 7.2.3.1 存储抽象层

```java
// 资源存储服务接口
public interface ResourceStorageService {
    
    // 存储文件
    String storeFile(MultipartFile file) throws IOException;
    
    // 存储文件流
    String storeFile(String fileName, InputStream inputStream, long size) throws IOException;
    
    // 获取文件
    InputStream getFile(String storagePath) throws IOException;
    
    // 复制文件
    String copyFile(String sourcePath) throws IOException;
    
    // 删除文件
    void deleteFile(String storagePath) throws IOException;
    
    // 检查文件是否存在
    boolean fileExists(String storagePath);
    
    // 获取文件大小
    long getFileSize(String storagePath) throws IOException;
}

// 本地文件系统实现
@Service
@ConditionalOnProperty(name = "dolphinscheduler.resource.storage.type", havingValue = "local")
public class LocalResourceStorageServiceImpl implements ResourceStorageService {
    
    @Value("${dolphinscheduler.resource.storage.local.basePath:/tmp/dolphinscheduler}")
    private String basePath;
    
    @PostConstruct
    public void init() {
        // 确保基础路径存在
        File baseDir = new File(basePath);
        if (!baseDir.exists()) {
            baseDir.mkdirs();
        }
    }
    
    @Override
    public String storeFile(MultipartFile file) throws IOException {
        String fileName = generateStoragePath(file.getOriginalFilename());
        String filePath = basePath + File.separator + fileName;
        
        File dest = new File(filePath);
        dest.getParentFile().mkdirs();
        
        file.transferTo(dest);
        
        return fileName;
    }
    
    @Override
    public String storeFile(String fileName, InputStream inputStream, long size) throws IOException {
        String storagePath = generateStoragePath(fileName);
        String filePath = basePath + File.separator + storagePath;
        
        File dest = new File(filePath);
        dest.getParentFile().mkdirs();
        
        try (FileOutputStream fos = new FileOutputStream(dest)) {
            IOUtils.copy(inputStream, fos);
        }
        
        return storagePath;
    }
    
    @Override
    public InputStream getFile(String storagePath) throws IOException {
        String filePath = basePath + File.separator + storagePath;
        return new FileInputStream(filePath);
    }
    
    @Override
    public String copyFile(String sourcePath) throws IOException {
        String targetPath = generateStoragePath(extractFileName(sourcePath));
        String sourceFilePath = basePath + File.separator + sourcePath;
        String targetFilePath = basePath + File.separator + targetPath;
        
        File targetDir = new File(targetFilePath).getParentFile();
        if (!targetDir.exists()) {
            targetDir.mkdirs();
        }
        
        Files.copy(new File(sourceFilePath).toPath(), new File(targetFilePath).toPath());
        
        return targetPath;
    }
    
    @Override
    public void deleteFile(String storagePath) throws IOException {
        String filePath = basePath + File.separator + storagePath;
        Files.deleteIfExists(new File(filePath).toPath());
    }
    
    @Override
    public boolean fileExists(String storagePath) {
        String filePath = basePath + File.separator + storagePath;
        return new File(filePath).exists();
    }
    
    @Override
    public long getFileSize(String storagePath) throws IOException {
        String filePath = basePath + File.separator + storagePath;
        return new File(filePath).length();
    }
    
    // 生成存储路径
    private String generateStoragePath(String originalFileName) {
        SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy/MM/dd/HH");
        String datePath = dateFormat.format(new Date());
        
        // 生成唯一文件名
        String fileName = UUID.randomUUID().toString();
        String extension = getFileExtension(originalFileName);
        if (!extension.isEmpty()) {
            fileName += "." + extension;
        }
        
        return datePath + File.separator + fileName;
    }
    
    // 提取文件名
    private String extractFileName(String storagePath) {
        int lastSlashIndex = storagePath.lastIndexOf(File.separator);
        if (lastSlashIndex >= 0 && lastSlashIndex < storagePath.length() - 1) {
            return storagePath.substring(lastSlashIndex + 1);
        }
        return storagePath;
    }
    
    // 获取文件扩展名
    private String getFileExtension(String fileName) {
        int lastDotIndex = fileName.lastIndexOf('.');
        if (lastDotIndex > 0 && lastDotIndex < fileName.length() - 1) {
            return fileName.substring(lastDotIndex + 1);
        }
        return "";
    }
}

// HDFS实现
@Service
@ConditionalOnProperty(name = "dolphinscheduler.resource.storage.type", havingValue = "hdfs")
public class HdfsResourceStorageServiceImpl implements ResourceStorageService {
    
    @Value("${dolphinscheduler.resource.storage.hdfs.basePath:/dolphinscheduler}")
    private String basePath;
    
    @Value("${dolphinscheduler.resource.storage.hdfs.defaultFS}")
    private String defaultFS;
    
    private FileSystem fileSystem;
    
    @PostConstruct
    public void init() throws IOException {
        Configuration conf = new Configuration();
        conf.set("fs.defaultFS", defaultFS);
        this.fileSystem = FileSystem.get(conf);
        
        // 确保基础路径存在
        Path baseDir = new Path(basePath);
        if (!fileSystem.exists(baseDir)) {
            fileSystem.mkdirs(baseDir);
        }
    }
    
    @Override
    public String storeFile(MultipartFile file) throws IOException {
        String storagePath = generateStoragePath(file.getOriginalFilename());
        Path hdfsPath = new Path(basePath + "/" + storagePath);
        
        try (InputStream inputStream = file.getInputStream()) {
            fileSystem.copyFromLocalFile(false, true, 
                new Path(file.getOriginalFilename()), hdfsPath);
        }
        
        return storagePath;
    }
    
    @Override
    public String storeFile(String fileName, InputStream inputStream, long size) throws IOException {
        String storagePath = generateStoragePath(fileName);
        Path hdfsPath = new Path(basePath + "/" + storagePath);
        
        try (FSDataOutputStream outputStream = fileSystem.create(hdfsPath)) {
            IOUtils.copy(inputStream, outputStream);
        }
        
        return storagePath;
    }
    
    @Override
    public InputStream getFile(String storagePath) throws IOException {
        Path hdfsPath = new Path(basePath + "/" + storagePath);
        return fileSystem.open(hdfsPath);
    }
    
    @Override
    public String copyFile(String sourcePath) throws IOException {
        String targetPath = generateStoragePath(extractFileName(sourcePath));
        Path sourceHdfsPath = new Path(basePath + "/" + sourcePath);
        Path targetHdfsPath = new Path(basePath + "/" + targetPath);
        
        FileUtil.copy(fileSystem, sourceHdfsPath, fileSystem, targetHdfsPath, false, 
                     fileSystem.getConf());
        
        return targetPath;
    }
    
    @Override
    public void deleteFile(String storagePath) throws IOException {
        Path hdfsPath = new Path(basePath + "/" + storagePath);
        fileSystem.delete(hdfsPath, false);
    }
    
    @Override
    public boolean fileExists(String storagePath) throws IOException {
        Path hdfsPath = new Path(basePath + "/" + storagePath);
        return fileSystem.exists(hdfsPath);
    }
    
    @Override
    public long getFileSize(String storagePath) throws IOException {
        Path hdfsPath = new Path(basePath + "/" + storagePath);
        return fileSystem.getFileStatus(hdfsPath).getLen();
    }
    
    // 其他辅助方法...
}
```

## 7.3 UDF函数管理

### 7.3.1 UDF概述

UDF（User-Defined Function，用户自定义函数）是扩展DolphinScheduler SQL功能的重要机制，允许用户自定义函数来处理复杂的数据转换逻辑。

### 7.3.2 UDF类型

1. **UDF**：标量函数，对单行数据产生单值结果
2. **UDTF**：表值函数，对单行数据产生多行结果
3. **UDAF**：聚合函数，对多行数据聚合产生单值结果

### 7.3.3 UDF管理实现

#### 7.3.3.1 UDF注册与管理

```java
// UDF管理控制器
@RestController
@RequestMapping("/v1/udfs")
public class UDFController {
    
    @Autowired
    private UDFService udfService;
    
    // 注册UDF
    @PostMapping("/register")
    public Result<UDFDetail> registerUDF(@RequestBody UDFRegisterRequest request) {
        try {
            UDFDetail udf = udfService.registerUDF(request);
            return Result.success(udf);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 更新UDF
    @PutMapping("/{id}")
    public Result<UDFDetail> updateUDF(@PathVariable int id, @RequestBody UDFUpdateRequest request) {
        try {
            UDFDetail udf = udfService.updateUDF(id, request);
            return Result.success(udf);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 删除UDF
    @DeleteMapping("/{id}")
    public Result deleteUDF(@PathVariable int id) {
        try {
            udfService.deleteUDF(id);
            return Result.success();
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 获取UDF详情
    @GetMapping("/{id}")
    public Result<UDFDetail> getUDF(@PathVariable int id) {
        try {
            UDFDetail udf = udfService.getUDF(id);
            return Result.success(udf);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 获取UDF列表
    @GetMapping
    public Result<PageInfo<UDFSummary>> listUDFs(
            @RequestParam(value = "type", required = false) String type,
            @RequestParam(value = "name", required = false) String name,
            @RequestParam(value = "page", defaultValue = "1") int page,
            @RequestParam(value = "size", defaultValue = "20") int size) {
        try {
            UDFQuery query = new UDFQuery(type, name);
            PageInfo<UDFSummary> pageInfo = udfService.listUDFs(query, page, size);
            return Result.success(pageInfo);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
    
    // 测试UDF
    @PostMapping("/{id}/test")
    public Result<UDFTestResult> testUDF(@PathVariable int id, 
                                         @RequestBody UDFTestRequest request) {
        try {
            UDFTestResult result = udfService.testUDF(id, request);
            return Result.success(result);
        } catch (Exception e) {
            return Result.error(e.getMessage());
        }
    }
}

// UDF服务实现
@Service
public class UDFServiceImpl implements UDFService {
    
    @Autowired
    private UDFDao udfDao;
    
    @Autowired
    private ResourceService resourceService;
    
    @Autowired
    private UDFClassLoaderManager classLoaderManager;
    
    @Override
    @Transactional
    public UDFDetail registerUDF(UDFRegisterRequest request) {
        // 1. 验证请求
        validateRegisterRequest(request);
        
        // 2. 上传UDF资源
        ResourceDetail resource = uploadUDFResource(request);
        
        // 3. 加载UDF类并验证
        validateUDFClass(resource);
        
        // 4. 创建UDF记录
        UDF udf = new UDF();
        udf.setName(request.getName());
        udf.setDescription(request.getDescription());
        udf.setType(request.getType());
        udf.setClassName(request.getClassName());
        udf.setResourceId(resource.getId());
        udf.setJarName(resource.getFileName());
        udf.setUserId(request.getUserId());
        udf.setCreateTime(new Date());
        udf.setUpdateTime(new Date());
        udf.setStatus(UDFStatus.ENABLED);
        
        // 5. 保存UDF记录
        int udfId = udfDao.save(udf);
        
        // 6. 注册UDF到引擎
        registerUDFToEngine(udfId);
        
        // 7. 返回详情
        return getUDF(udfId);
    }
    
    // 上传UDF资源
    private ResourceDetail uploadUDFResource(UDFRegisterRequest request) {
        try {
            UDFResourceUploadRequest resourceRequest = new UDFResourceUploadRequest();
            resourceRequest.setFile(request.getFile());
            resourceRequest.setDescription("UDF resource for " + request.getName());
            resourceRequest.setType("JAR");
            resourceRequest.setClassName(request.getClassName());
            
            return resourceService.uploadUDFResource(resourceRequest);
        } catch (Exception e) {
            throw new RuntimeException("Failed to upload UDF resource", e);
        }
    }
    
    // 验证UDF类
    private void validateUDFClass(ResourceDetail resource) {
        try {
            // 1. 加载资源
            ClassLoader classLoader = classLoaderManager.getClassLoader(resource.getId());
            
            // 2. 加载UDF类
            String className = extractClassName(resource);
            Class<?> udfClass = classLoader.loadClass(className);
            
            // 3. 验证类结构
            validateUDFClassStructure(udfClass);
            
            // 4. 创建实例并测试
            Object udfInstance = udfClass.getDeclaredConstructor().newInstance();
            testUDFInstance(udfInstance);
            
        } catch (Exception e) {
            throw new RuntimeException("UDF class validation failed: " + e.getMessage(), e);
        }
    }
    
    // 验证UDF类结构
    private void validateUDFClassStructure(Class<?> udfClass) {
        // 检查是否继承或实现了适当的基类/接口
        boolean validUDF = false;
        
        for (Class<?> iface : udfClass.getInterfaces()) {
            if (iface.getName().equals("org.apache.hadoop.hive.ql.exec.UDF") ||
                iface.getName().equals("org.apache.hadoop.hive.ql.udf.generic.GenericUDF")) {
                validUDF = true;
                break;
            }
        }
        
        if (!validUDF) {
            throw new RuntimeException("Class must implement UDF interface");
        }
        
        // 检查是否有必要的注解
        if (!udfClass.isAnnotationPresent(UDFDescription.class)) {
            throw new RuntimeException("Class must have @UDFDescription annotation");
        }
    }
    
    // 测试UDF实例
    private void testUDFInstance(Object udfInstance) {
        try {
            // 这里可以根据UDF类型进行不同的测试
            // 简化实现，实际应该根据UDF类型调用不同的测试方法
            
            // 检查是否有evaluate方法
            Method evaluateMethod = findEvaluateMethod(udfInstance.getClass());
            if (evaluateMethod == null) {
                throw new RuntimeException("UDF class must have evaluate method");
            }
            
        } catch (Exception e) {
            throw new RuntimeException("UDF instance test failed: " + e.getMessage(), e);
        }
    }
    
    // 查找evaluate方法
    private Method findEvaluateMethod(Class<?> udfClass) {
        for (Method method : udfClass.getMethods()) {
            if ("evaluate".equals(method.getName())) {
                return method;
            }
        }
        return null;
    }
    
    // 注册UDF到引擎
    private void registerUDFToEngine(int udfId) {
        UDF udf = udfDao.findById(udfId);
        if (udf == null) {
            throw new RuntimeException("UDF not found");
        }
        
        try {
            // 1. 获取资源
            Resource resource = resourceService.getResource(udf.getResourceId());
            
            // 2. 加载类
            ClassLoader classLoader = classLoaderManager.getClassLoader(resource.getId());
            Class<?> udfClass = classLoader.loadClass(udf.getClassName());
            
            // 3. 注册UDF
            UDFRegistry.registerFunction(udf.getName(), udfClass);
            
        } catch (Exception e) {
            throw new RuntimeException("Failed to register UDF to engine: " + e.getMessage(), e);
        }
    }
    
    @Override
    @Transactional
    public UDFTestResult testUDF(int id, UDFTestRequest request) {
        // 1. 获取UDF信息
        UDF udf = udfDao.findById(id);
        if (udf == null) {
            throw new RuntimeException("UDF not found");
        }
        
        // 2. 获取资源
        Resource resource = resourceService.getResource(udf.getResourceId());
        
        try {
            // 3. 加载类
            ClassLoader classLoader = classLoaderManager.getClassLoader(resource.getId());
            Class<?> udfClass = classLoader.loadClass(udf.getClassName());
            
            // 4. 创建实例
            Object udfInstance = udfClass.getDeclaredConstructor().newInstance();
            
            // 5. 调用测试方法
            Object result = callEvaluateMethod(udfInstance, request.getTestInputs());
            
            // 6. 构建测试结果
            UDFTestResult testResult = new UDFTestResult();
            testResult.setSuccess(true);
            testResult.setResult(result);
            testResult.setMessage("UDF test completed successfully");
            
            return testResult;
            
        } catch (Exception e) {
            UDFTestResult testResult = new UDFTestResult();
            testResult.setSuccess(false);
            testResult.setMessage("UDF test failed: " + e.getMessage());
            
            return testResult;
        }
    }
    
    // 调用evaluate方法
    private Object callEvaluateMethod(Object udfInstance, List<Object> testInputs) throws Exception {
        Method evaluateMethod = findEvaluateMethod(udfInstance.getClass());
        if (evaluateMethod == null) {
            throw new RuntimeException("evaluate method not found");
        }
        
        // 准备参数
        Object[] args = testInputs.toArray();
        
        // 调用方法
        return evaluateMethod.invoke(udfInstance, args);
    }
}
```

#### 7.3.3.2 UDF类加载管理

```java
// UDF类加载管理器
@Service
public class UDFClassLoaderManager {
    
    private Map<Integer, ChildFirstClassLoader> classLoaders = new ConcurrentHashMap<>();
    
    @Autowired
    private ResourceService resourceService;
    
    public ClassLoader getClassLoader(int resourceId) {
        return classLoaders.computeIfAbsent(resourceId, id -> {
            try {
                // 1. 获取资源信息
                Resource resource = resourceService.getResource(id);
                if (resource == null) {
                    throw new RuntimeException("Resource not found");
                }
                
                // 2. 获取资源文件
                InputStream inputStream = resourceService.getFile(resource.getVersionStoragePath());
                
                // 3. 创建临时文件
                File tempFile = createTempFile(resource.getFileName());
                
                // 4. 复制资源到临时文件
                copyToFile(inputStream, tempFile);
                
                // 5. 创建类加载器
                URL jarUrl = tempFile.toURI().toURL();
                return new ChildFirstClassLoader(new URL[]{jarUrl}, 
                                               getClass().getClassLoader());
                
            } catch (Exception e) {
                throw new RuntimeException("Failed to create class loader", e);
            }
        });
    }
    
    // 创建临时文件
    private File createTempFile(String fileName) throws IOException {
        String prefix = fileName.substring(0, fileName.lastIndexOf('.'));
        String suffix = fileName.substring(fileName.lastIndexOf('.'));
        
        File tempFile = File.createTempFile(prefix, suffix);
        tempFile.deleteOnExit();
        
        return tempFile;
    }
    
    // 复制流到文件
    private void copyToFile(InputStream inputStream, File file) throws IOException {
        try (FileOutputStream fos = new FileOutputStream(file)) {
            IOUtils.copy(inputStream, fos);
        }
    }
    
    // 刷新类加载器
    public void refreshClassLoader(int resourceId) {
        ChildFirstClassLoader oldClassLoader = classLoaders.remove(resourceId);
        if (oldClassLoader != null) {
            try {
                oldClassLoader.close();
            } catch (IOException e) {
                logger.warn("Failed to close class loader", e);
            }
        }
    }
    
    // 清理所有类加载器
    @PreDestroy
    public void cleanup() {
        for (Map.Entry<Integer, ChildFirstClassLoader> entry : classLoaders.entrySet()) {
            try {
                entry.getValue().close();
            } catch (IOException e) {
                logger.warn("Failed to close class loader for resource: " + entry.getKey(), e);
            }
        }
        classLoaders.clear();
    }
}

// 子优先类加载器
public class ChildFirstClassLoader extends URLClassLoader {
    
    public ChildFirstClassLoader(URL[] urls, ClassLoader parent) {
        super(urls, parent);
    }
    
    @Override
    protected Class<?> loadClass(String name, boolean resolve) throws ClassNotFoundException {
        // 1. 检查类是否已经加载
        Class<?> loadedClass = findLoadedClass(name);
        if (loadedClass != null) {
            return loadedClass;
        }
        
        // 2. 尝试从当前类加载器加载（子优先）
        try {
            return findClass(name);
        } catch (ClassNotFoundException e) {
            // 忽略，继续从父类加载器加载
        }
        
        // 3. 从父类加载器加载
        return super.loadClass(name, resolve);
    }
}
```

## 7.4 实践案例

### 7.4.1 数据源管理最佳实践

#### 7.4.1.1 场景描述

一个大型企业有多个数据源，需要统一管理和监控，确保数据源连接的稳定性和安全性。

#### 7.4.1.2 数据源管理方案

```java
// 数据源管理最佳实践
public class DataSourceManagementBestPractices {
    
    // 设置数据源生命周期管理
    public void setupDataSourceLifecycleManagement() {
        // 1. 设置数据源连接池监控
        setupConnectionPoolMonitoring();
        
        // 2. 设置数据源健康检查
        setupHealthCheck();
        
        // 3. 设置数据源连接泄露检测
        setupLeakDetection();
        
        // 4. 设置数据源故障转移
        setupFailover();
    }
    
    // 设置连接池监控
    private void setupConnectionPoolMonitoring() {
        // 1. 设置指标收集
        MetricsCollector metricsCollector = new MetricsCollector();
        
        // 2. 注册连接池指标
        DataSourceMetricsRegistry registry = new DataSourceMetricsRegistry();
        registry.registerMetric("total_connections", metricsCollector::getTotalConnections);
        registry.registerMetric("active_connections", metricsCollector::getActiveConnections);
        registry.registerMetric("idle_connections", metricsCollector::getIdleConnections);
        registry.registerMetric("waiting_threads", metricsCollector::getWaitingThreads);
        
        // 3. 设置定期报告
        ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor();
        scheduler.scheduleAtFixedRate(() -> {
            try {
                // 收集指标
                Map<String, Object> metrics = registry.collectAll();
                
                // 发送到监控系统
                monitoringService.sendMetrics(metrics);
                
                // 检查告警条件
                checkAlertConditions(metrics);
            } catch (Exception e) {
                logger.error("Failed to collect connection pool metrics", e);
            }
        }, 0, 30, TimeUnit.SECONDS);
    }
    
    // 设置健康检查
    private void setupHealthCheck() {
        DataSourceHealthChecker healthChecker = new DataSourceHealthChecker();
        
        // 1. 设置检查间隔
        healthChecker.setCheckInterval(60000); // 1分钟
        
        // 2. 设置检查超时
        healthChecker.setCheckTimeout(5000); // 5秒
        
        // 3. 设置检查查询
        healthChecker.setCheckQuery("SELECT 1");
        
        // 4. 设置失败阈值
        healthChecker.setFailureThreshold(3); // 连续3次失败则标记为不健康
        
        // 5. 设置健康状态变化监听器
        healthChecker.addHealthStatusListener((dataSourceId, healthy, message) -> {
            if (!healthy) {
                alertService.sendDataSourceUnhealthyAlert(dataSourceId, message);
                
                // 尝试恢复数据源
                dataSourceRecoveryService.attemptRecovery(dataSourceId);
            } else {
                // 数据源恢复健康
                alertService.sendDataSourceRecoveredAlert(dataSourceId);
            }
        });
        
        // 6. 启动健康检查
        healthChecker.start();
    }
    
    // 设置连接泄露检测
    private void setupLeakDetection() {
        ConnectionLeakDetector leakDetector = new ConnectionLeakDetector();
        
        // 1. 设置检测阈值
        leakDetector.setLeakThreshold(300000); // 5分钟
        
        // 2. 设置检测间隔
        leakDetector.setDetectionInterval(120000); // 2分钟
        
        // 3. 设置泄露处理策略
        leakDetector.setLeakHandler(leakInfo -> {
            // 记录泄露信息
            logger.error("Connection leak detected", leakInfo);
            
            // 发送告警
            alertService.sendConnectionLeakAlert(leakInfo);
            
            // 强制关闭泄露的连接
            try {
                leakInfo.getConnection().close();
            } catch (SQLException e) {
                logger.error("Failed to close leaked connection", e);
            }
        });
        
        // 4. 启动泄露检测
        leakDetector.start();
    }
    
    // 设置故障转移
    private void setupFailover() {
        DataSourceFailoverManager failoverManager = new DataSourceFailoverManager();
        
        // 1. 设置故障检测
        failoverManager.setFailureDetector((dataSourceId) -> {
            try {
                Connection connection = dataSourceService.getConnection(dataSourceId);
                if (connection != null) {
                    connection.close();
                    return true;
                }
            } catch (Exception e) {
                logger.warn("Data source connection failed", e);
            }
            return false;
        });
        
        // 2. 设置故障恢复
        failoverManager.setRecoveryHandler((dataSourceId) -> {
            // 1. 重置连接池
            dataSourceService.resetConnectionPool(dataSourceId);
            
            // 2. 测试连接
            ConnectionTestResult result = dataSourceService.testConnection(dataSourceId);
            
            // 3. 如果恢复成功，发送通知
            if (result.isSuccess()) {
                alertService.sendDataSourceRecoveredAlert(dataSourceId);
                return true;
            }
            
            return false;
        });
        
        // 3. 设置故障转移策略
        failoverManager.setFailoverStrategy((primaryDataSourceId) -> {
            // 获取备用数据源
            List<DataSourceDetail> standbyDataSources = dataSourceService
                .getStandbyDataSources(primaryDataSourceId);
            
            if (!standbyDataSources.isEmpty()) {
                // 选择第一个可用的备用数据源
                for (DataSourceDetail standby : standbyDataSources) {
                    ConnectionTestResult result = dataSourceService.testConnection(standby.getId());
                    if (result.isSuccess()) {
                        return standby.getId();
                    }
                }
            }
            
            return -1; // 没有可用的备用数据源
        });
        
        // 4. 启动故障转移管理
        failoverManager.start();
    }
}
```

### 7.4.2 资源中心实现

#### 7.4.2.1 场景描述

实现一个高效的资源中心，支持文件上传、版本管理和权限控制。

#### 7.4.2.2 资源中心实现

```java
// 高效资源中心实现
public class EfficientResourceCenter {
    
    // 实现文件分片上传
    public ChunkedUploadResponse uploadFileInChunks(ChunkedUploadRequest request) {
        // 1. 初始化上传
        if (request.getChunkIndex() == 1) {
            // 创建上传会话
            UploadSession session = createUploadSession(request);
            
            // 保存第一块数据
            saveChunk(session, request);
            
            // 如果只有一块，完成上传
            if (request.getTotalChunks() == 1) {
                return completeUpload(session);
            }
            
            return new ChunkedUploadResponse(session.getSessionId(), 
                                            "Chunk uploaded successfully", 
                                            false);
        } else {
            // 获取上传会话
            UploadSession session = getUploadSession(request.getSessionId());
            if (session == null) {
                throw new RuntimeException("Upload session not found");
            }
            
            // 保存分块数据
            saveChunk(session, request);
            
            // 检查是否所有分块都已上传
            if (session.getUploadedChunks().size() >= request.getTotalChunks()) {
                // 合并分块
                mergeChunks(session);
                
                // 完成上传
                return completeUpload(session);
            }
            
            return new ChunkedUploadResponse(session.getSessionId(), 
                                            "Chunk uploaded successfully", 
                                            false);
        }
    }
    
    // 创建上传会话
    private UploadSession createUploadSession(ChunkedUploadRequest request) {
        UploadSession session = new UploadSession();
        session.setSessionId(generateSessionId());
        session.setFileName(request.getFileName());
        session.setTotalSize(request.getTotalSize());
        session.setTotalChunks(request.getTotalChunks());
        session.setChunkSize(request.getChunkSize());
        session.setUploadedChunks(new HashSet<>());
        session.setUploadStartTime(new Date());
        session.setUserId(request.getUserId());
        
        uploadSessionDao.save(session);
        
        return session;
    }
    
    // 保存分块
    private void saveChunk(UploadSession session, ChunkedUploadRequest request) {
        String chunkPath = getChunkPath(session, request.getChunkIndex());
        
        try (InputStream inputStream = request.getChunkData();
             FileOutputStream outputStream = new FileOutputStream(chunkPath)) {
            IOUtils.copy(inputStream, outputStream);
        } catch (IOException e) {
            throw new RuntimeException("Failed to save chunk", e);
        }
        
        // 记录已上传的分块
        session.getUploadedChunks().add(request.getChunkIndex());
        session.setLastUploadTime(new Date());
        
        uploadSessionDao.update(session);
    }
    
    // 合并分块
    private void mergeChunks(UploadSession session) {
        String mergedPath = getMergedPath(session);
        
        try (FileOutputStream outputStream = new FileOutputStream(mergedPath)) {
            for (int i = 1; i <= session.getTotalChunks(); i++) {
                String chunkPath = getChunkPath(session, i);
                
                try (FileInputStream inputStream = new FileInputStream(chunkPath)) {
                    IOUtils.copy(inputStream, outputStream);
                }
                
                // 删除分块文件
                Files.deleteIfExists(Paths.get(chunkPath));
            }
        } catch (IOException e) {
            throw new RuntimeException("Failed to merge chunks", e);
        }
        
        // 设置合并后的文件路径
        session.setMergedFilePath(mergedPath);
        uploadSessionDao.update(session);
    }
    
    // 完成上传
    private ChunkedUploadResponse completeUpload(UploadSession session) {
        // 1. 保存文件到存储系统
        String storagePath;
        try (FileInputStream inputStream = new FileInputStream(session.getMergedFilePath())) {
            storagePath = resourceStorageService.storeFile(session.getFileName(), 
                                                          inputStream, 
                                                          session.getTotalSize());
        } catch (IOException e) {
            throw new RuntimeException("Failed to store merged file", e);
        }
        
        // 2. 创建资源记录
        Resource resource = new Resource();
        resource.setFullName(session.getFileName());
        resource.setFileName(session.getFileName());
        resource.setDirectory(false);
        resource.setSize(session.getTotalSize());
        resource.setType(getResourceType(session.getFileName()));
        resource.setPid(request.getPid());
        resource.setUserId(session.getUserId());
        resource.setCreateTime(new Date());
        resource.setUpdateTime(new Date());
        
        // 3. 保存资源记录
        int resourceId = resourceDao.save(resource);
        
        // 4. 创建版本记录
        ResourceVersion version = new ResourceVersion();
        version.setResourceId(resourceId);
        version.setVersionNumber(1);
        version.setStoragePath(storagePath);
        version.setDescription("Initial upload via chunked upload");
        version.setCreateUser(session.getUserId());
        version.setCreateTime(new Date());
        
        resourceVersionDao.save(version);
        
        // 5. 清理上传会话
        cleanupUploadSession(session);
        
        // 6. 返回结果
        ChunkedUploadResponse response = new ChunkedUploadResponse(session.getSessionId(), 
                                                                 "Upload completed", 
                                                                 true);
        response.setResourceId(resourceId);
        
        return response;
    }
}
```

## 7.5 小结

本章详细介绍了DolphinScheduler的数据源管理与资源中心：

1. **数据源管理**：多种数据源类型、连接池管理和权限控制
2. **资源中心**：文件上传、版本管理和权限控制
3. **UDF函数管理**：UDF注册、测试和类加载管理
4. **实践案例**：数据源管理最佳实践和资源中心实现

通过本章的学习，您应该能够：

- 管理多种类型的数据源
- 实现高效的资源中心
- 开发和使用UDF函数
- 设计健壮的数据源连接池
- 实现文件分片上传和版本控制

在下一章中，我们将介绍DolphinScheduler的API使用与扩展开发。