# 第5章 工作流设计与任务配置

## 5.1 DAG工作流设计

### 5.1.1 DAG基本概念

DAG（Directed Acyclic Graph，有向无环图）是DolphinScheduler中工作流的基本表示形式，用于描述任务之间的依赖关系。

#### 5.1.1.1 DAG特性

1. **有向性**：边有方向，表示任务的执行顺序
2. **无环性**：不存在循环依赖，确保工作流能够结束
3. **连通性**：所有任务通过依赖关系连接
4. **可并行性**：无依赖关系的任务可以并行执行

#### 5.1.1.2 DAG表示方法

```java
// DAG节点定义
public class DAGNode {
    private String nodeId;           // 节点ID
    private String nodeName;         // 节点名称
    private String taskType;         // 任务类型
    private TaskParams taskParams;   // 任务参数
    private List<String> predecessors; // 前驱节点
    private List<String> successors;   // 后继节点
    
    // 添加前驱节点
    public void addPredecessor(String nodeId) {
        if (predecessors == null) {
            predecessors = new ArrayList<>();
        }
        predecessors.add(nodeId);
    }
    
    // 添加后继节点
    public void addSuccessor(String nodeId) {
        if (successors == null) {
            successors = new ArrayList<>();
        }
        successors.add(nodeId);
    }
}

// DAG图定义
public class DAG {
    private Map<String, DAGNode> nodes; // 节点集合
    
    public DAG() {
        this.nodes = new HashMap<>();
    }
    
    // 添加节点
    public void addNode(DAGNode node) {
        nodes.put(node.getNodeId(), node);
    }
    
    // 添加边
    public void addEdge(String fromNodeId, String toNodeId) {
        DAGNode fromNode = nodes.get(fromNodeId);
        DAGNode toNode = nodes.get(toNodeId);
        
        fromNode.addSuccessor(toNodeId);
        toNode.addPredecessor(fromNodeId);
    }
    
    // 拓扑排序
    public List<String> topologicalSort() {
        List<String> result = new ArrayList<>();
        Map<String, Integer> inDegree = new HashMap<>();
        
        // 计算入度
        for (DAGNode node : nodes.values()) {
            inDegree.put(node.getNodeId(), 0);
        }
        for (DAGNode node : nodes.values()) {
            if (node.getSuccessors() != null) {
                for (String successorId : node.getSuccessors()) {
                    inDegree.put(successorId, inDegree.get(successorId) + 1);
                }
            }
        }
        
        // 找到所有入度为0的节点
        Queue<String> queue = new LinkedList<>();
        for (Map.Entry<String, Integer> entry : inDegree.entrySet()) {
            if (entry.getValue() == 0) {
                queue.offer(entry.getKey());
            }
        }
        
        // 拓扑排序
        while (!queue.isEmpty()) {
            String nodeId = queue.poll();
            result.add(nodeId);
            
            DAGNode node = nodes.get(nodeId);
            if (node.getSuccessors() != null) {
                for (String successorId : node.getSuccessors()) {
                    inDegree.put(successorId, inDegree.get(successorId) - 1);
                    if (inDegree.get(successorId) == 0) {
                        queue.offer(successorId);
                    }
                }
            }
        }
        
        // 检查是否有环
        if (result.size() != nodes.size()) {
            throw new RuntimeException("DAG contains cycle");
        }
        
        return result;
    }
}
```

### 5.1.2 DAG设计原则

#### 5.1.2.1 设计原则

1. **单一职责**：每个工作流应该有明确的业务目标
2. **模块化设计**：将复杂工作流拆分为多个子工作流
3. **合理并行**：识别可以并行执行的任务
4. **避免过长链路**：避免创建过长的任务依赖链
5. **错误处理**：为关键任务设计错误处理机制

#### 5.1.2.2 最佳实践

```java
// DAG设计最佳实践
public class DAGEstablisher {
    
    // 创建ETL工作流
    public DAG createETLDAG() {
        DAG dag = new DAG();
        
        // 1. 数据抽取节点
        DAGNode extractNode = new DAGNode();
        extractNode.setNodeId("extract_data");
        extractNode.setNodeName("数据抽取");
        extractNode.setTaskType("SQL");
        dag.addNode(extractNode);
        
        // 2. 数据清洗节点
        DAGNode cleanNode = new DAGNode();
        cleanNode.setNodeId("clean_data");
        cleanNode.setNodeName("数据清洗");
        cleanNode.setTaskType("SHELL");
        dag.addNode(cleanNode);
        
        // 3. 数据转换节点
        DAGNode transformNode = new DAGNode();
        transformNode.setNodeId("transform_data");
        transformNode.setNodeName("数据转换");
        transformNode.setTaskType("PYTHON");
        dag.addNode(transformNode);
        
        // 4. 数据加载节点
        DAGNode loadNode = new DAGNode();
        loadNode.setNodeId("load_data");
        loadNode.setNodeName("数据加载");
        loadNode.setTaskType("SQL");
        dag.addNode(loadNode);
        
        // 5. 设置依赖关系
        dag.addEdge("extract_data", "clean_data");
        dag.addEdge("clean_data", "transform_data");
        dag.addEdge("transform_data", "load_data");
        
        return dag;
    }
    
    // 创建并行处理工作流
    public DAG createParallelDAG() {
        DAG dag = new DAG();
        
        // 1. 开始节点
        DAGNode startNode = new DAGNode();
        startNode.setNodeId("start");
        startNode.setNodeName("开始");
        startNode.setTaskType("SHELL");
        dag.addNode(startNode);
        
        // 2. 并行处理节点A
        DAGNode processA = new DAGNode();
        processA.setNodeId("process_a");
        processA.setNodeName("处理A");
        processA.setTaskType("SQL");
        dag.addNode(processA);
        
        // 3. 并行处理节点B
        DAGNode processB = new DAGNode();
        processB.setNodeId("process_b");
        processB.setNodeName("处理B");
        processB.setTaskType("SHELL");
        dag.addNode(processB);
        
        // 4. 汇总节点
        DAGNode mergeNode = new DAGNode();
        mergeNode.setNodeId("merge");
        mergeNode.setNodeName("汇总");
        mergeNode.setTaskType("PYTHON");
        dag.addNode(mergeNode);
        
        // 5. 设置依赖关系
        dag.addEdge("start", "process_a");
        dag.addEdge("start", "process_b");
        dag.addEdge("process_a", "merge");
        dag.addEdge("process_b", "merge");
        
        return dag;
    }
}
```

### 5.1.3 DAG验证与优化

#### 5.1.3.1 DAG验证

```java
// DAG验证器
public class DAGValidator {
    
    // 验证DAG的有效性
    public ValidationResult validate(DAG dag) {
        ValidationResult result = new ValidationResult();
        
        // 1. 检查是否有环
        if (hasCycle(dag)) {
            result.addError("DAG contains cycle");
        }
        
        // 2. 检查孤立节点
        List<String> isolatedNodes = findIsolatedNodes(dag);
        if (!isolatedNodes.isEmpty()) {
            result.addError("Found isolated nodes: " + isolatedNodes);
        }
        
        // 3. 检查不可达节点
        List<String> unreachableNodes = findUnreachableNodes(dag);
        if (!unreachableNodes.isEmpty()) {
            result.addError("Found unreachable nodes: " + unreachableNodes);
        }
        
        // 4. 检查资源分配
        checkResourceAllocation(dag, result);
        
        return result;
    }
    
    // 检查是否有环
    private boolean hasCycle(DAG dag) {
        Set<String> visited = new HashSet<>();
        Set<String> recursionStack = new HashSet<>();
        
        for (DAGNode node : dag.getNodes().values()) {
            if (hasCycleUtil(node, dag, visited, recursionStack)) {
                return true;
            }
        }
        
        return false;
    }
    
    // 检查环的递归方法
    private boolean hasCycleUtil(DAGNode node, DAG dag, Set<String> visited, 
                                Set<String> recursionStack) {
        String nodeId = node.getNodeId();
        
        if (recursionStack.contains(nodeId)) {
            return true;
        }
        
        if (visited.contains(nodeId)) {
            return false;
        }
        
        visited.add(nodeId);
        recursionStack.add(nodeId);
        
        List<String> successors = node.getSuccessors();
        if (successors != null) {
            for (String successorId : successors) {
                DAGNode successor = dag.getNode(successorId);
                if (hasCycleUtil(successor, dag, visited, recursionStack)) {
                    return true;
                }
            }
        }
        
        recursionStack.remove(nodeId);
        return false;
    }
    
    // 检查资源分配
    private void checkResourceAllocation(DAG dag, ValidationResult result) {
        // 计算同时运行的最大任务数
        int maxConcurrentTasks = calculateMaxConcurrentTasks(dag);
        
        // 检查是否超过租户资源限制
        Tenant tenant = getCurrentTenant();
        if (maxConcurrentTasks > tenant.getMaxRunningJobs()) {
            result.addWarning("Maximum concurrent tasks (" + maxConcurrentTasks + 
                            ") exceeds tenant limit (" + tenant.getMaxRunningJobs() + ")");
        }
    }
}
```

#### 5.1.3.2 DAG优化

```java
// DAG优化器
public class DAGOptimizer {
    
    // 优化DAG结构
    public DAG optimize(DAG dag) {
        // 1. 合并连续的同类任务
        dag = mergeConsecutiveSameTypeTasks(dag);
        
        // 2. 识别并创建并行执行机会
        dag = identifyParallelOpportunities(dag);
        
        // 3. 减少不必要的依赖
        dag = reduceUnnecessaryDependencies(dag);
        
        // 4. 添加合适的重试机制
        dag = addRetryMechanisms(dag);
        
        return dag;
    }
    
    // 合并连续的同类任务
    private DAG mergeConsecutiveSameTypeTasks(DAG dag) {
        Map<String, DAGNode> nodes = dag.getNodes();
        List<String> nodesToRemove = new ArrayList<>();
        
        // 查找可以合并的连续任务
        for (DAGNode node : nodes.values()) {
            if (canMergeWithSuccessor(node, dag)) {
                String successorId = node.getSuccessors().get(0);
                DAGNode successor = nodes.get(successorId);
                
                // 合并任务参数
                mergeTaskParams(node, successor);
                
                // 更新后继关系
                node.setSuccessors(successor.getSuccessors());
                
                // 标记要删除的节点
                nodesToRemove.add(successorId);
            }
        }
        
        // 删除合并的节点
        for (String nodeId : nodesToRemove) {
            dag.removeNode(nodeId);
        }
        
        return dag;
    }
    
    // 识别并行执行机会
    private DAG identifyParallelOpportunities(DAG dag) {
        // 分析DAG结构，识别可以并行执行的任务
        // 这里简化实现，实际算法会更复杂
        return dag;
    }
    
    // 减少不必要的依赖
    private DAG reduceUnnecessaryDependencies(DAG dag) {
        // 分析依赖关系，移除传递依赖中的冗余边
        return dag;
    }
    
    // 添加重试机制
    private DAG addRetryMechanisms(DAG dag) {
        // 为关键任务添加重试机制
        for (DAGNode node : dag.getNodes().values()) {
            if (isCriticalTask(node)) {
                TaskParams params = node.getTaskParams();
                params.setMaxRetryTimes(3);
                params.setRetryInterval(60); // 60秒
            }
        }
        
        return dag;
    }
}
```

## 5.2 任务类型详解

### 5.2.1 Shell任务

#### 5.2.1.1 Shell任务概述

Shell任务是DolphinScheduler中最基础的任务类型，用于执行Shell脚本或命令。

#### 5.2.1.2 Shell任务配置

```json
{
  "taskType": "SHELL",
  "taskParams": {
    "rawScript": "#!/bin/bash\n# 数据抽取脚本\nsource /opt/dolphinscheduler/env.sh\n\n# 抽取订单数据\nsqoop import \\\n  --connect jdbc:mysql://db.example.com/orders \\\n  --username $DB_USER \\\n  --password $DB_PASSWORD \\\n  --table orders \\\n  --target-dir /data/orders/$(date +%Y%m%d) \\\n  --as-avrodatafile \\\n  --m 4\n\n# 校验抽取结果\nif [ $? -eq 0 ]; then\n  echo \"数据抽取成功\"\n  exit 0\nelse\n  echo \"数据抽取失败\"\n  exit 1\nfi",
    "localParams": [
      {
        "prop": "DB_USER",
        "direct": "IN",
        "type": "VARCHAR",
        "value": "${db.user}"
      },
      {
        "prop": "DB_PASSWORD",
        "direct": "IN",
        "type": "VARCHAR",
        "value": "${db.password}"
      }
    ]
  }
}
```

#### 5.2.1.3 Shell任务最佳实践

```java
// Shell任务最佳实践
public class ShellTaskBestPractices {
    
    // 创建健壮的Shell任务
    public String createRobustShellScript() {
        StringBuilder script = new StringBuilder();
        
        // 1. 设置错误处理
        script.append("#!/bin/bash\n");
        script.append("set -euo pipefail\n");  // 遇到错误立即退出
        script.append("IFS=$'\\n\\t'\n");       // 设置内部字段分隔符
        
        // 2. 日志函数
        script.append("\n# 日志函数\n");
        script.append("log() {\n");
        script.append("  echo \"[$(date +'%Y-%m-%d %H:%M:%S')] $1\"\n");
        script.append("}\n");
        
        // 3. 错误处理函数
        script.append("\n# 错误处理函数\n");
        script.append("handle_error() {\n");
        script.append("  local line_no=$1\n");
        script.append("  log \"Error occurred in line $line_no\"\n");
        script.append("  exit 1\n");
        script.append("}\n");
        script.append("trap 'handle_error $LINENO' ERR\n");
        
        // 4. 主逻辑
        script.append("\n# 主逻辑\n");
        script.append("log \"Starting data extraction\"\n");
        script.append("# 业务逻辑\n");
        script.append("log \"Data extraction completed\"\n");
        
        return script.toString();
    }
    
    // 参数验证
    public String addParameterValidation() {
        StringBuilder script = new StringBuilder();
        
        script.append("# 参数验证\n");
        script.append("if [ -z \"${DB_USER:-}\" ]; then\n");
        script.append("  echo \"Error: DB_USER is required\"\n");
        script.append("  exit 1\n");
        script.append("fi\n");
        
        script.append("if [ -z \"${DB_PASSWORD:-}\" ]; then\n");
        script.append("  echo \"Error: DB_PASSWORD is required\"\n");
        script.append("  exit 1\n");
        script.append("fi\n");
        
        return script.toString();
    }
}
```

### 5.2.2 SQL任务

#### 5.2.2.1 SQL任务概述

SQL任务用于执行数据库查询，支持多种数据库类型。

#### 5.2.2.2 SQL任务配置

```json
{
  "taskType": "SQL",
  "taskParams": {
    "type": "MYSQL",
    "datasource": 1,
    "sql": "-- 数据清洗：清除重复订单\nDELETE o1 FROM orders o1\nINNER JOIN orders o2\nWHERE o1.order_id > o2.order_id\nAND o1.customer_id = o2.customer_id\nAND o1.order_date = o2.order_date\nAND o1.total_amount = o2.total_amount\nAND o1.order_date >= '${start_date}'\nAND o1.order_date <= '${end_date}';\n\n-- 数据聚合：计算月度销售额\nINSERT INTO monthly_sales (year, month, customer_id, total_amount)\nSELECT \n  YEAR(order_date) AS year,\n  MONTH(order_date) AS month,\n  customer_id,\n  SUM(total_amount) AS total_amount\nFROM orders\nWHERE order_date >= '${start_date}'\nAND order_date <= '${end_date}'\nGROUP BY YEAR(order_date), MONTH(order_date), customer_id\nON DUPLICATE KEY UPDATE total_amount = VALUES(total_amount);",
    "udfs": "",
    "showType": "TABLE",
    "connParams": "useUnicode=true&characterEncoding=UTF-8",
    "preStatements": [
      "SET SESSION sql_mode = 'STRICT_TRANS_TABLES'"
    ],
    "postStatements": [
      "COMMIT"
    ],
    "localParams": [
      {
        "prop": "start_date",
        "direct": "IN",
        "type": "VARCHAR",
        "value": "${bizDate}"
      },
      {
        "prop": "end_date",
        "direct": "IN",
        "type": "VARCHAR",
        "value": "${bizDate}"
      }
    ]
  }
}
```

#### 5.2.2.3 SQL任务最佳实践

```java
// SQL任务最佳实践
public class SQLTaskBestPractices {
    
    // 创建高性能SQL任务
    public String createOptimizedSQL() {
        StringBuilder sql = new StringBuilder();
        
        // 1. 使用事务
        sql.append("BEGIN;\n\n");
        
        // 2. 设置会话参数
        sql.append("-- 设置会话参数\n");
        sql.append("SET SESSION innodb_lock_wait_timeout = 60;\n");
        sql.append("SET SESSION sql_mode = 'STRICT_TRANS_TABLES';\n\n");
        
        // 3. 使用临时表
        sql.append("-- 创建临时表\n");
        sql.append("CREATE TEMPORARY TABLE temp_orders AS\n");
        sql.append("SELECT * FROM orders WHERE order_date >= '${start_date}';\n\n");
        
        // 4. 添加索引
        sql.append("-- 添加临时表索引\n");
        sql.append("CREATE INDEX idx_temp_order_date ON temp_orders(order_date);\n");
        sql.append("CREATE INDEX idx_temp_customer_id ON temp_orders(customer_id);\n\n");
        
        // 5. 业务逻辑
        sql.append("-- 业务逻辑\n");
        sql.append("INSERT INTO monthly_sales (year, month, customer_id, total_amount)\n");
        sql.append("SELECT \n");
        sql.append("  YEAR(order_date) AS year,\n");
        sql.append("  MONTH(order_date) AS month,\n");
        sql.append("  customer_id,\n");
        sql.append("  SUM(total_amount) AS total_amount\n");
        sql.append("FROM temp_orders\n");
        sql.append("GROUP BY YEAR(order_date), MONTH(order_date), customer_id;\n\n");
        
        // 6. 提交事务
        sql.append("COMMIT;\n");
        
        return sql.toString();
    }
    
    // SQL安全性验证
    public boolean validateSQLSecurity(String sql) {
        // 检查危险操作
        String[] dangerousKeywords = {
            "DROP DATABASE", "DROP TABLE", "TRUNCATE", 
            "DELETE FROM", "UPDATE", "INSERT INTO"
        };
        
        String upperSQL = sql.toUpperCase();
        for (String keyword : dangerousKeywords) {
            if (upperSQL.contains(keyword)) {
                // 这里可以添加更细致的检查
                return false;
            }
        }
        
        return true;
    }
}
```

### 5.2.3 Python任务

#### 5.2.3.1 Python任务概述

Python任务用于执行Python脚本，支持数据处理、机器学习等复杂任务。

#### 5.2.3.2 Python任务配置

```json
{
  "taskType": "PYTHON",
  "taskParams": {
    "rawScript": "import pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport sys\nimport os\n\n# 添加自定义库路径\nsys.path.append('/opt/dolphinscheduler/pylibs')\nfrom utils.data_processor import DataProcessor\nfrom utils.logger import setup_logger\n\n# 设置日志\nlogger = setup_logger('data_transform')\n\ndef main():\n    try:\n        # 获取参数\n        input_path = '${input_path}'\n        output_path = '${output_path}'\n        process_date = '${process_date}'\n        \n        logger.info(f\"Starting data transformation for date: {process_date}\")\n        \n        # 读取数据\n        logger.info(f\"Reading data from {input_path}\")\n        df = pd.read_csv(input_path)\n        \n        # 数据清洗\n        logger.info(\"Cleaning data\")\n        processor = DataProcessor()\n        clean_df = processor.clean_data(df)\n        \n        # 数据转换\n        logger.info(\"Transforming data\")\n        transformed_df = processor.transform_data(clean_df)\n        \n        # 数据聚合\n        logger.info(\"Aggregating data\")\n        aggregated_df = processor.aggregate_data(transformed_df)\n        \n        # 保存结果\n        logger.info(f\"Saving data to {output_path}\")\n        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n        aggregated_df.to_csv(output_path, index=False)\n        \n        logger.info(\"Data transformation completed successfully\")\n        return 0\n        \n    except Exception as e:\n        logger.error(f\"Error in data transformation: {str(e)}\")\n        return 1\n\nif __name__ == \"__main__\":\n    sys.exit(main())",
    "localParams": [
      {
        "prop": "input_path",
        "direct": "IN",
        "type": "VARCHAR",
        "value": "/data/input/orders_${bizDate}.csv"
      },
      {
        "prop": "output_path",
        "direct": "IN",
        "type": "VARCHAR",
        "value": "/data/output/daily_summary_${bizDate}.csv"
      },
      {
        "prop": "process_date",
        "direct": "IN",
        "type": "VARCHAR",
        "value": "${bizDate}"
      }
    ]
  }
}
```

### 5.2.4 条件分支任务

#### 5.2.4.1 条件分支概述

条件分支任务用于根据条件执行不同的后续任务。

#### 5.2.4.2 条件分支配置

```json
{
  "taskType": "CONDITIONS",
  "taskParams": {
    "conditionResult": {
      "successNode": [
        "success_task"
      ],
      "failedNode": [
        "failed_task"
      ]
    },
    "dependence": {
      "relation": "AND",
      "dependTaskList": [
        {
          "relation": "AND",
          "dependItemList": [
            {
              "regx": "SUCCESS",
              "depTaskCode": "data_validation",
              "status": "SUCCESS"
            },
            {
              "regx": "records_processed",
              "depTaskCode": "data_process",
              "status": "SUCCESS"
            }
          ]
        }
      ]
    },
    "localParams": [
      {
        "prop": "success_count_threshold",
        "direct": "IN",
        "type": "INTEGER",
        "value": "1000"
      }
    ]
  }
}
```

#### 5.2.4.3 复杂条件判断

```java
// 复杂条件判断实现
public class ComplexConditionEvaluator {
    
    // 评估条件
    public boolean evaluateCondition(TaskInstance taskInstance, List<TaskInstance> upstreamTasks) {
        // 1. 获取条件配置
        Map<String, Object> conditionConfig = getConditionConfig(taskInstance);
        
        // 2. 收集上游任务状态和结果
        Map<String, TaskResult> taskResults = collectTaskResults(upstreamTasks);
        
        // 3. 评估条件
        return evaluateExpression(conditionConfig, taskResults);
    }
    
    // 评估表达式
    private boolean evaluateExpression(Map<String, Object> conditionConfig, 
                                      Map<String, TaskResult> taskResults) {
        String expression = (String) conditionConfig.get("expression");
        
        // 简单实现：支持基本逻辑运算
        if (expression.contains("AND")) {
            String[] subExpressions = expression.split("AND");
            for (String subExpr : subExpressions) {
                if (!evaluateSubExpression(subExpr.trim(), taskResults)) {
                    return false;
                }
            }
            return true;
        } else if (expression.contains("OR")) {
            String[] subExpressions = expression.split("OR");
            for (String subExpr : subExpressions) {
                if (evaluateSubExpression(subExpr.trim(), taskResults)) {
                    return true;
                }
            }
            return false;
        } else {
            return evaluateSubExpression(expression, taskResults);
        }
    }
    
    // 评估子表达式
    private boolean evaluateSubExpression(String subExpr, Map<String, TaskResult> taskResults) {
        // 解析子表达式
        // 示例格式：task_name.SUCCESS.count > 1000
        String[] parts = subExpr.split("\\s+");
        if (parts.length < 3) {
            return false;
        }
        
        String[] taskParts = parts[0].split("\\.");
        if (taskParts.length < 2) {
            return false;
        }
        
        String taskName = taskParts[0];
        String status = taskParts[1];
        String operator = parts[1];
        Object expectedValue = parseValue(parts[2]);
        
        // 获取任务结果
        TaskResult result = taskResults.get(taskName);
        if (result == null) {
            return false;
        }
        
        // 评估条件
        if ("SUCCESS".equals(status)) {
            if (">".equals(operator)) {
                return result.getProcessCount() > ((Number) expectedValue).intValue();
            } else if ("<".equals(operator)) {
                return result.getProcessCount() < ((Number) expectedValue).intValue();
            } else if ("=".equals(operator)) {
                return result.getProcessCount() == ((Number) expectedValue).intValue();
            }
        }
        
        return false;
    }
}
```

### 5.2.5 子工作流任务

#### 5.2.5.1 子工作流概述

子工作流任务用于嵌套执行其他工作流，实现工作流的复用和模块化。

#### 5.2.5.2 子工作流配置

```json
{
  "taskType": "SUB_PROCESS",
  "taskParams": {
    "processDefinitionId": 456,
    "releaseState": "ONLINE",
    "globalParams": [
      {
        "prop": "input_date",
        "direct": "IN",
        "type": "VARCHAR",
        "value": "${bizDate}"
      },
      {
        "prop": "batch_id",
        "direct": "IN",
        "type": "VARCHAR",
        "value": "${batch_id}"
      }
    ],
    "localParams": [
      {
        "prop": "output_path",
        "direct": "OUT",
        "type": "VARCHAR",
        "value": ""
      }
    ]
  }
}
```

#### 5.2.5.3 子工作流最佳实践

```java
// 子工作流最佳实践
public class SubWorkflowBestPractices {
    
    // 创建模块化子工作流
    public WorkflowDefinition createDataQualityModule() {
        WorkflowDefinition workflow = new WorkflowDefinition();
        workflow.setName("数据质量检查模块");
        workflow.setDescription("通用数据质量检查模块");
        
        // 1. 数据完整性检查任务
        TaskDefinition completenessTask = new TaskDefinition();
        completenessTask.setName("数据完整性检查");
        completenessTask.setTaskType("PYTHON");
        completenessTask.setPosition(new Position(100, 100));
        
        // 2. 数据一致性检查任务
        TaskDefinition consistencyTask = new TaskDefinition();
        consistencyTask.setName("数据一致性检查");
        consistencyTask.setTaskType("SQL");
        consistencyTask.setPosition(new Position(300, 100));
        
        // 3. 数据准确性检查任务
        TaskDefinition accuracyTask = new TaskDefinition();
        accuracyTask.setName("数据准确性检查");
        accuracyTask.setTaskType("SHELL");
        accuracyTask.setPosition(new Position(500, 100));
        
        // 4. 设置任务依赖
        TaskDependency dependency1 = new TaskDependency();
        dependency1.setPreTaskCode(completenessTask.getTaskCode());
        dependency1.setPostTaskCode(consistencyTask.getTaskCode());
        
        TaskDependency dependency2 = new TaskDependency();
        dependency2.setPreTaskCode(consistencyTask.getTaskCode());
        dependency2.setPostTaskCode(accuracyTask.getTaskCode());
        
        // 添加任务和依赖
        workflow.addTask(completenessTask);
        workflow.addTask(consistencyTask);
        workflow.addTask(accuracyTask);
        workflow.addDependency(dependency1);
        workflow.addDependency(dependency2);
        
        return workflow;
    }
    
    // 参数传递设计
    public void designParameterPassing() {
        // 父工作流向子工作流传递参数
        Map<String, Object> parentParams = new HashMap<>();
        parentParams.put("input_table", "orders");
        parentParams.put("check_date", "${bizDate}");
        parentParams.put("quality_threshold", 0.95);
        
        // 子工作流参数
        Map<String, Object> childParams = new HashMap<>();
        childParams.put("table_name", "${input_table}");
        childParams.put("check_date", "${check_date}");
        childParams.put("threshold", "${quality_threshold}");
        
        // 子工作流返回参数
        Map<String, Object> returnParams = new HashMap<>();
        returnParams.put("quality_score", "${quality_score}");
        returnParams.put("error_count", "${error_count}");
        
        // 参数映射
        Map<String, String> paramMapping = new HashMap<>();
        paramMapping.put("quality_score", "data_quality_score");
        paramMapping.put("error_count", "data_error_count");
    }
}
```

## 5.3 参数传递机制

### 5.3.1 参数类型与作用域

#### 5.3.1.1 参数类型

1. **全局参数**：工作流级别的参数，对工作流内所有任务可见
2. **局部参数**：任务级别的参数，只在特定任务内可见
3. **系统参数**：系统预定义参数，如系统时间、工作流实例ID等
4. **时间参数**：与时间相关的参数，如${bizDate}、${currentTime}等

#### 5.3.1.2 参数作用域

```java
// 参数作用域管理
public class ParameterScopeManager {
    
    // 解析工作流参数
    public Map<String, Object> resolveWorkflowParameters(ProcessInstance processInstance) {
        Map<String, Object> parameters = new HashMap<>();
        
        // 1. 添加系统参数
        addSystemParameters(parameters, processInstance);
        
        // 2. 添加时间参数
        addTimeParameters(parameters, processInstance);
        
        // 3. 添加全局参数
        addGlobalParameters(parameters, processInstance);
        
        // 4. 参数值替换
        substituteParameterValues(parameters);
        
        return parameters;
    }
    
    // 解析任务参数
    public Map<String, Object> resolveTaskParameters(TaskInstance taskInstance, 
                                                   Map<String, Object> workflowParams) {
        Map<String, Object> parameters = new HashMap<>();
        
        // 1. 继承工作流参数
        parameters.putAll(workflowParams);
        
        // 2. 添加任务局部参数
        addTaskParameters(parameters, taskInstance);
        
        // 3. 处理上游传递的参数
        handleUpstreamParameters(parameters, taskInstance);
        
        // 4. 参数值替换
        substituteParameterValues(parameters);
        
        return parameters;
    }
    
    // 添加系统参数
    private void addSystemParameters(Map<String, Object> parameters, ProcessInstance processInstance) {
        parameters.put("system.date", new Date());
        parameters.put("system.user", processInstance.getExecutorName());
        parameters.put("system.workflow.id", processInstance.getId());
        parameters.put("system.workflow.name", processInstance.getName());
    }
    
    // 添加时间参数
    private void addTimeParameters(Map<String, Object> parameters, ProcessInstance processInstance) {
        Date scheduleTime = processInstance.getScheduleTime();
        if (scheduleTime != null) {
            Calendar cal = Calendar.getInstance();
            cal.setTime(scheduleTime);
            
            // 业务日期（通常是前一天）
            cal.add(Calendar.DAY_OF_MONTH, -1);
            String bizDate = new SimpleDateFormat("yyyyMMdd").format(cal.getTime());
            parameters.put("bizDate", bizDate);
            
            // 业务月份
            String bizMonth = new SimpleDateFormat("yyyyMM").format(cal.getTime());
            parameters.put("bizMonth", bizMonth);
            
            // 业务年份
            String bizYear = new SimpleDateFormat("yyyy").format(cal.getTime());
            parameters.put("bizYear", bizYear);
        }
    }
    
    // 参数值替换
    private void substituteParameterValues(Map<String, Object> parameters) {
        for (Map.Entry<String, Object> entry : parameters.entrySet()) {
            String value = entry.getValue().toString();
            
            // 替换参数引用
            String replacedValue = replaceParameterReferences(value, parameters);
            
            entry.setValue(replacedValue);
        }
    }
    
    // 替换参数引用
    private String replaceParameterReferences(String value, Map<String, Object> parameters) {
        Pattern pattern = Pattern.compile("\\$\\{(\\w+)\\}");
        Matcher matcher = pattern.matcher(value);
        
        StringBuffer result = new StringBuffer();
        while (matcher.find()) {
            String paramName = matcher.group(1);
            Object paramValue = parameters.get(paramName);
            
            if (paramValue != null) {
                matcher.appendReplacement(result, paramValue.toString());
            }
        }
        matcher.appendTail(result);
        
        return result.toString();
    }
}
```

### 5.3.2 参数传递机制

#### 5.3.2.1 上游任务参数传递

```java
// 上游任务参数传递
public class UpstreamParameterPassing {
    
    // 收集上游任务输出参数
    public Map<String, Object> collectUpstreamParameters(TaskInstance currentTask) {
        Map<String, Object> upstreamParams = new HashMap<>();
        
        // 1. 获取所有上游任务
        List<TaskInstance> upstreamTasks = getUpstreamTasks(currentTask);
        
        // 2. 收集上游任务的输出参数
        for (TaskInstance upstreamTask : upstreamTasks) {
            Map<String, Object> outputParams = getTaskOutputParameters(upstreamTask);
            
            // 3. 添加前缀以避免参数名冲突
            String prefix = upstreamTask.getName() + ".";
            for (Map.Entry<String, Object> entry : outputParams.entrySet()) {
                upstreamParams.put(prefix + entry.getKey(), entry.getValue());
            }
        }
        
        return upstreamParams;
    }
    
    // 获取任务输出参数
    private Map<String, Object> getTaskOutputParameters(TaskInstance task) {
        Map<String, Object> outputParams = new HashMap<>();
        
        // 从任务执行结果中提取输出参数
        TaskExecutionResult result = getTaskExecutionResult(task);
        
        // 解析输出日志
        String outputLog = result.getOutputLog();
        Map<String, String> extractedParams = extractParametersFromLog(outputLog);
        
        outputParams.putAll(extractedParams);
        
        // 添加标准输出参数
        outputParams.put("exit_code", result.getExitCode());
        outputParams.put("start_time", result.getStartTime());
        outputParams.put("end_time", result.getEndTime());
        outputParams.put("duration", result.getDuration());
        outputParams.put("process_count", result.getProcessCount());
        
        return outputParams;
    }
    
    // 从日志中提取参数
    private Map<String, String> extractParametersFromLog(String log) {
        Map<String, String> extractedParams = new HashMap<>();
        
        // 查找输出参数格式: DS_OUTPUT_PARAM_NAME=value
        Pattern pattern = Pattern.compile("DS_OUTPUT_(\\w+)=(\\S+)");
        Matcher matcher = pattern.matcher(log);
        
        while (matcher.find()) {
            String paramName = matcher.group(1);
            String paramValue = matcher.group(2);
            extractedParams.put(paramName, paramValue);
        }
        
        return extractedParams;
    }
}
```

#### 5.3.2.2 跨工作流参数传递

```java
// 跨工作流参数传递
public class CrossWorkflowParameterPassing {
    
    // 保存工作流输出参数
    public void saveWorkflowOutputParameters(ProcessInstance processInstance) {
        Map<String, Object> outputParams = collectWorkflowOutputParameters(processInstance);
        
        // 1. 保存到数据库
        WorkflowOutputParameters params = new WorkflowOutputParameters();
        params.setProcessInstanceId(processInstance.getId());
        params.setParametersJson(JsonUtils.toJsonString(outputParams));
        params.setCreateTime(new Date());
        
        workflowOutputParametersDao.save(params);
        
        // 2. 保存到缓存（供其他工作流快速访问）
        String cacheKey = "workflow_output_" + processInstance.getId();
        cacheService.set(cacheKey, outputParams, 24 * 3600); // 缓存24小时
    }
    
    // 获取上游工作流输出参数
    public Map<String, Object> getUpstreamWorkflowParameters(ProcessInstance processInstance) {
        Map<String, Object> upstreamParams = new HashMap<>();
        
        // 1. 获取所有上游工作流实例
        List<ProcessInstance> upstreamWorkflows = getUpstreamWorkflows(processInstance);
        
        // 2. 收集上游工作流输出参数
        for (ProcessInstance upstreamWorkflow : upstreamWorkflows) {
            Map<String, Object> outputParams = getWorkflowOutputParameters(upstreamWorkflow.getId());
            
            // 3. 添加前缀以避免参数名冲突
            String prefix = upstreamWorkflow.getName() + ".";
            for (Map.Entry<String, Object> entry : outputParams.entrySet()) {
                upstreamParams.put(prefix + entry.getKey(), entry.getValue());
            }
        }
        
        return upstreamParams;
    }
    
    // 从缓存获取工作流输出参数
    private Map<String, Object> getWorkflowOutputParameters(Long processInstanceId) {
        // 1. 尝试从缓存获取
        String cacheKey = "workflow_output_" + processInstanceId;
        Map<String, Object> cachedParams = cacheService.get(cacheKey);
        if (cachedParams != null) {
            return cachedParams;
        }
        
        // 2. 从数据库获取
        WorkflowOutputParameters params = workflowOutputParametersDao
            .findByProcessInstanceId(processInstanceId);
        if (params != null) {
            Map<String, Object> dbParams = JsonUtils.parseObject(params.getParametersJson(), 
                new TypeReference<Map<String, Object>>() {});
            
            // 3. 放入缓存
            cacheService.set(cacheKey, dbParams, 24 * 3600);
            
            return dbParams;
        }
        
        return new HashMap<>();
    }
}
```

### 5.3.3 参数高级特性

#### 5.3.3.1 参数加密

```java
// 参数加密
public class ParameterEncryption {
    
    // 加密敏感参数
    public String encryptParameter(String value) {
        try {
            // 使用AES加密
            Cipher cipher = Cipher.getInstance("AES/CBC/PKCS5Padding");
            SecretKeySpec secretKey = new SecretKeySpec(getEncryptionKey(), "AES");
            IvParameterSpec ivParameterSpec = new IvParameterSpec(getInitializationVector());
            
            cipher.init(Cipher.ENCRYPT_MODE, secretKey, ivParameterSpec);
            
            byte[] encryptedBytes = cipher.doFinal(value.getBytes(StandardCharsets.UTF_8));
            
            // Base64编码
            return Base64.getEncoder().encodeToString(encryptedBytes);
        } catch (Exception e) {
            throw new RuntimeException("Failed to encrypt parameter", e);
        }
    }
    
    // 解密敏感参数
    public String decryptParameter(String encryptedValue) {
        try {
            // Base64解码
            byte[] encryptedBytes = Base64.getDecoder().decode(encryptedValue);
            
            // 使用AES解密
            Cipher cipher = Cipher.getInstance("AES/CBC/PKCS5Padding");
            SecretKeySpec secretKey = new SecretKeySpec(getEncryptionKey(), "AES");
            IvParameterSpec ivParameterSpec = new IvParameterSpec(getInitializationVector());
            
            cipher.init(Cipher.DECRYPT_MODE, secretKey, ivParameterSpec);
            
            byte[] decryptedBytes = cipher.doFinal(encryptedBytes);
            
            return new String(decryptedBytes, StandardCharsets.UTF_8);
        } catch (Exception e) {
            throw new RuntimeException("Failed to decrypt parameter", e);
        }
    }
    
    // 获取加密密钥
    private byte[] getEncryptionKey() {
        String key = System.getProperty("dolphinscheduler.param.encryption.key");
        if (key == null) {
            key = "default-encryption-key-16-bytes"; // 默认密钥，实际应从安全配置中获取
        }
        return key.getBytes(StandardCharsets.UTF_8);
    }
    
    // 获取初始化向量
    private byte[] getInitializationVector() {
        String iv = System.getProperty("dolphinscheduler.param.encryption.iv");
        if (iv == null) {
            iv = "default-iv-16-bytes"; // 默认IV，实际应从安全配置中获取
        }
        return iv.getBytes(StandardCharsets.UTF_8);
    }
}
```

#### 5.3.3.2 参数验证

```java
// 参数验证
public class ParameterValidator {
    
    // 验证参数
    public ValidationResult validateParameters(Map<String, Object> parameters, 
                                             List<ParameterRule> rules) {
        ValidationResult result = new ValidationResult();
        
        for (ParameterRule rule : rules) {
            String paramName = rule.getParamName();
            Object paramValue = parameters.get(paramName);
            
            // 1. 检查必填参数
            if (rule.isRequired() && paramValue == null) {
                result.addError(paramName + " is required");
                continue;
            }
            
            // 2. 检查参数类型
            if (paramValue != null && !validateParameterType(paramValue, rule.getType())) {
                result.addError(paramName + " should be of type " + rule.getType());
                continue;
            }
            
            // 3. 检查参数值范围
            if (paramValue != null && !validateParameterValue(paramValue, rule)) {
                result.addError(paramName + " value is invalid: " + paramValue);
            }
            
            // 4. 自定义验证规则
            if (paramValue != null && rule.getValidator() != null) {
                if (!rule.getValidator().validate(paramValue)) {
                    result.addError(paramName + " failed custom validation");
                }
            }
        }
        
        return result;
    }
    
    // 验证参数类型
    private boolean validateParameterType(Object value, String expectedType) {
        switch (expectedType.toUpperCase()) {
            case "STRING":
                return value instanceof String;
            case "INTEGER":
                return value instanceof Integer || (value instanceof String && ((String) value).matches("-?\\d+"));
            case "DECIMAL":
                return value instanceof Double || value instanceof Float || 
                       (value instanceof String && ((String) value).matches("-?\\d+(\\.\\d+)?"));
            case "BOOLEAN":
                return value instanceof Boolean || 
                       (value instanceof String && ("true".equalsIgnoreCase((String) value) || 
                                                  "false".equalsIgnoreCase((String) value)));
            case "DATE":
                return value instanceof Date || 
                       (value instanceof String && isValidDateString((String) value));
            default:
                return true;
        }
    }
    
    // 验证参数值范围
    private boolean validateParameterValue(Object value, ParameterRule rule) {
        // 检查最小值
        if (rule.getMinValue() != null) {
            if (value instanceof Number && ((Number) value).doubleValue() < rule.getMinValue()) {
                return false;
            }
        }
        
        // 检查最大值
        if (rule.getMaxValue() != null) {
            if (value instanceof Number && ((Number) value).doubleValue() > rule.getMaxValue()) {
                return false;
            }
        }
        
        // 检查允许的值列表
        if (rule.getAllowedValues() != null && !rule.getAllowedValues().isEmpty()) {
            return rule.getAllowedValues().contains(value.toString());
        }
        
        // 检查正则表达式
        if (rule.getRegex() != null && !rule.getRegex().isEmpty()) {
            return value.toString().matches(rule.getRegex());
        }
        
        return true;
    }
}

// 参数规则定义
public class ParameterRule {
    private String paramName;
    private String type;
    private boolean required;
    private Double minValue;
    private Double maxValue;
    private List<String> allowedValues;
    private String regex;
    private ParameterValidator customValidator;
    
    // 自定义验证器接口
    public interface ParameterValidator {
        boolean validate(Object value);
    }
}
```

## 5.4 实践案例

### 5.4.1 数据ETL工作流设计

#### 5.4.1.1 场景描述

设计一个完整的数据ETL工作流，包括数据抽取、清洗、转换和加载。

#### 5.4.1.2 工作流设计

```java
// 数据ETL工作流设计
public class ETLWorkflowDesigner {
    
    public WorkflowDefinition createETLWorkflow() {
        WorkflowDefinition workflow = new WorkflowDefinition();
        workflow.setName("订单数据ETL流程");
        workflow.setDescription("从源系统抽取订单数据，经过清洗和转换后加载到数据仓库");
        
        // 1. 数据抽取任务
        TaskDefinition extractTask = createExtractTask();
        
        // 2. 数据质量检查任务
        TaskDefinition qualityCheckTask = createQualityCheckTask();
        
        // 3. 数据清洗任务
        TaskDefinition cleanTask = createCleanTask();
        
        // 4. 数据转换任务
        TaskDefinition transformTask = createTransformTask();
        
        // 5. 数据加载任务
        TaskDefinition loadTask = createLoadTask();
        
        // 6. 设置任务位置
        extractTask.setPosition(new Position(100, 100));
        qualityCheckTask.setPosition(new Position(300, 100));
        cleanTask.setPosition(new Position(500, 100));
        transformTask.setPosition(new Position(700, 100));
        loadTask.setPosition(new Position(900, 100));
        
        // 7. 设置任务依赖
        setupTaskDependencies(workflow, extractTask, qualityCheckTask, cleanTask, 
                             transformTask, loadTask);
        
        // 8. 添加全局参数
        addGlobalParameters(workflow);
        
        return workflow;
    }
    
    // 创建数据抽取任务
    private TaskDefinition createExtractTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("数据抽取");
        task.setTaskType("SHELL");
        task.setTaskParams(createExtractTaskParams());
        return task;
    }
    
    // 创建数据质量检查任务
    private TaskDefinition createQualityCheckTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("数据质量检查");
        task.setTaskType("PYTHON");
        task.setTaskParams(createQualityCheckTaskParams());
        return task;
    }
    
    // 创建数据清洗任务
    private TaskDefinition createCleanTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("数据清洗");
        task.setTaskType("SQL");
        task.setTaskParams(createCleanTaskParams());
        return task;
    }
    
    // 创建数据转换任务
    private TaskDefinition createTransformTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("数据转换");
        task.setTaskType("PYTHON");
        task.setTaskParams(createTransformTaskParams());
        return task;
    }
    
    // 创建数据加载任务
    private TaskDefinition createLoadTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("数据加载");
        task.setTaskType("SQL");
        task.setTaskParams(createLoadTaskParams());
        return task;
    }
    
    // 设置任务依赖
    private void setupTaskDependencies(WorkflowDefinition workflow, 
                                       TaskDefinition extractTask,
                                       TaskDefinition qualityCheckTask,
                                       TaskDefinition cleanTask,
                                       TaskDefinition transformTask,
                                       TaskDefinition loadTask) {
        // 顺序依赖：extract -> qualityCheck -> clean -> transform -> load
        addDependency(workflow, extractTask, qualityCheckTask);
        addDependency(workflow, qualityCheckTask, cleanTask);
        addDependency(workflow, cleanTask, transformTask);
        addDependency(workflow, transformTask, loadTask);
    }
    
    // 添加任务依赖
    private void addDependency(WorkflowDefinition workflow, 
                              TaskDefinition preTask, TaskDefinition postTask) {
        workflow.addTask(preTask);
        workflow.addTask(postTask);
        
        TaskDependency dependency = new TaskDependency();
        dependency.setPreTaskCode(preTask.getTaskCode());
        dependency.setPostTaskCode(postTask.getTaskCode());
        
        workflow.addDependency(dependency);
    }
    
    // 添加全局参数
    private void addGlobalParameters(WorkflowDefinition workflow) {
        List<GlobalParam> globalParams = new ArrayList<>();
        
        GlobalParam bizDate = new GlobalParam();
        bizDate.setProp("bizDate");
        bizDate.setDirect("IN");
        bizDate.setType("VARCHAR");
        bizDate.setValue("${system.biz.date}");
        globalParams.add(bizDate);
        
        GlobalParam sourceDb = new GlobalParam();
        sourceDb.setProp("sourceDb");
        sourceDb.setDirect("IN");
        sourceDb.setType("VARCHAR");
        sourceDb.setValue("orders_db");
        globalParams.add(sourceDb);
        
        GlobalParam targetDb = new GlobalParam();
        targetDb.setProp("targetDb");
        targetDb.setDirect("IN");
        targetDb.setType("VARCHAR");
        targetDb.setValue("datawarehouse");
        globalParams.add(targetDb);
        
        workflow.setGlobalParams(globalParams);
    }
}
```

### 5.4.2 机器学习工作流设计

#### 5.4.2.1 场景描述

设计一个机器学习工作流，包括数据准备、特征工程、模型训练和模型评估。

#### 5.4.2.2 工作流设计

```java
// 机器学习工作流设计
public class MLWorkflowDesigner {
    
    public WorkflowDefinition createMLWorkflow() {
        WorkflowDefinition workflow = new WorkflowDefinition();
        workflow.setName("机器学习模型训练流程");
        workflow.setDescription("数据准备、特征工程、模型训练和评估的完整流程");
        
        // 1. 数据准备任务
        TaskDefinition dataPrepTask = createDataPreparationTask();
        
        // 2. 特征工程任务
        TaskDefinition featureEngTask = createFeatureEngineeringTask();
        
        // 3. 模型训练任务
        TaskDefinition modelTrainingTask = createModelTrainingTask();
        
        // 4. 模型评估任务
        TaskDefinition modelEvalTask = createModelEvaluationTask();
        
        // 5. 条件判断任务
        TaskDefinition conditionTask = createConditionTask();
        
        // 6. 模型部署任务
        TaskDefinition modelDeployTask = createModelDeploymentTask();
        
        // 7. 设置任务位置
        dataPrepTask.setPosition(new Position(100, 100));
        featureEngTask.setPosition(new Position(300, 100));
        modelTrainingTask.setPosition(new Position(500, 100));
        modelEvalTask.setPosition(new Position(700, 100));
        conditionTask.setPosition(new Position(900, 100));
        modelDeployTask.setPosition(new Position(1100, 100));
        
        // 8. 设置任务依赖
        setupTaskDependencies(workflow, dataPrepTask, featureEngTask, modelTrainingTask, 
                             modelEvalTask, conditionTask, modelDeployTask);
        
        return workflow;
    }
    
    // 创建数据准备任务
    private TaskDefinition createDataPreparationTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("数据准备");
        task.setTaskType("PYTHON");
        task.setTaskParams(createDataPrepTaskParams());
        return task;
    }
    
    // 创建特征工程任务
    private TaskDefinition createFeatureEngineeringTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("特征工程");
        task.setTaskType("PYTHON");
        task.setTaskParams(createFeatureEngTaskParams());
        return task;
    }
    
    // 创建模型训练任务
    private TaskDefinition createModelTrainingTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("模型训练");
        task.setTaskType("PYTHON");
        task.setTaskParams(createModelTrainingTaskParams());
        return task;
    }
    
    // 创建模型评估任务
    private TaskDefinition createModelEvaluationTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("模型评估");
        task.setTaskType("PYTHON");
        task.setTaskParams(createModelEvalTaskParams());
        return task;
    }
    
    // 创建条件判断任务
    private TaskDefinition createConditionTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("模型质量判断");
        task.setTaskType("CONDITIONS");
        task.setTaskParams(createConditionTaskParams());
        return task;
    }
    
    // 创建模型部署任务
    private TaskDefinition createModelDeploymentTask() {
        TaskDefinition task = new TaskDefinition();
        task.setName("模型部署");
        task.setTaskType("SHELL");
        task.setTaskParams(createModelDeployTaskParams());
        return task;
    }
}
```

## 5.5 小结

本章详细介绍了DolphinScheduler的工作流设计与任务配置：

1. **DAG工作流设计**：DAG的基本概念、设计原则和验证优化方法
2. **任务类型详解**：Shell、SQL、Python、条件分支、子工作流等任务类型的配置和最佳实践
3. **参数传递机制**：参数类型、作用域、传递方式和高级特性
4. **实践案例**：数据ETL和机器学习工作流的设计示例

通过本章的学习，您应该能够：

- 理解DAG的概念和设计原则
- 掌握各种任务类型的配置方法
- 了解参数传递机制和高级特性
- 设计和实现复杂的工作流

在下一章中，我们将详细介绍任务调度与监控，包括定时调度、优先级设置、失败重试、补数机制等内容。