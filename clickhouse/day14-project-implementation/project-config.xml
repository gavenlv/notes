<?xml version="1.0"?>
<!-- ClickHouse Day 14: 项目实战配置文件 -->
<!-- 实时数据分析平台生产环境配置 -->
<yandex>
    <!-- ================================ -->
    <!-- 集群配置 -->
    <!-- ================================ -->
    <clickhouse_remote_servers>
        <analytics_cluster>
            <!-- 分片1 -->
            <shard>
                <weight>1</weight>
                <internal_replication>true</internal_replication>
                <replica>
                    <host>ch-shard1-replica1</host>
                    <port>9000</port>
                    <user>cluster_user</user>
                    <password>Cluster@2024</password>
                    <secure>1</secure>
                </replica>
                <replica>
                    <host>ch-shard1-replica2</host>
                    <port>9000</port>
                    <user>cluster_user</user>
                    <password>Cluster@2024</password>
                    <secure>1</secure>
                </replica>
            </shard>
            
            <!-- 分片2 -->
            <shard>
                <weight>1</weight>
                <internal_replication>true</internal_replication>
                <replica>
                    <host>ch-shard2-replica1</host>
                    <port>9000</port>
                    <user>cluster_user</user>
                    <password>Cluster@2024</password>
                    <secure>1</secure>
                </replica>
                <replica>
                    <host>ch-shard2-replica2</host>
                    <port>9000</port>
                    <user>cluster_user</user>
                    <password>Cluster@2024</password>
                    <secure>1</secure>
                </replica>
            </shard>
            
            <!-- 分片3 -->
            <shard>
                <weight>1</weight>
                <internal_replication>true</internal_replication>
                <replica>
                    <host>ch-shard3-replica1</host>
                    <port>9000</port>
                    <user>cluster_user</user>
                    <password>Cluster@2024</password>
                    <secure>1</secure>
                </replica>
                <replica>
                    <host>ch-shard3-replica2</host>
                    <port>9000</port>
                    <user>cluster_user</user>
                    <password>Cluster@2024</password>
                    <secure>1</secure>
                </replica>
            </shard>
        </analytics_cluster>
        
        <!-- 只读集群用于分析查询 -->
        <analytics_readonly_cluster>
            <shard>
                <replica>
                    <host>ch-readonly-1</host>
                    <port>9000</port>
                    <user>readonly_user</user>
                    <password>ReadOnly@2024</password>
                </replica>
                <replica>
                    <host>ch-readonly-2</host>
                    <port>9000</port>
                    <user>readonly_user</user>
                    <password>ReadOnly@2024</password>
                </replica>
            </shard>
        </analytics_readonly_cluster>
    </clickhouse_remote_servers>

    <!-- ================================ -->
    <!-- ZooKeeper配置 -->
    <!-- ================================ -->
    <zookeeper>
        <node>
            <host>zk-1.analytics.local</host>
            <port>2181</port>
        </node>
        <node>
            <host>zk-2.analytics.local</host>
            <port>2181</port>
        </node>
        <node>
            <host>zk-3.analytics.local</host>
            <port>2181</port>
        </node>
        <session_timeout_ms>30000</session_timeout_ms>
        <operation_timeout_ms>10000</operation_timeout_ms>
        <root>/clickhouse/analytics</root>
        <identity>analytics:Analytics@ZK2024</identity>
    </zookeeper>

    <!-- ================================ -->
    <!-- 宏定义 -->
    <!-- ================================ -->
    <macros>
        <cluster>analytics_cluster</cluster>
        <shard>01</shard>
        <replica>replica-1</replica>
        <layer>production</layer>
    </macros>

    <!-- ================================ -->
    <!-- 网络配置 -->
    <!-- ================================ -->
    <listen_host>0.0.0.0</listen_host>
    <http_port>8123</http_port>
    <tcp_port>9000</tcp_port>
    <mysql_port>9004</mysql_port>
    <postgresql_port>9005</postgresql_port>
    
    <!-- HTTPS配置 -->
    <https_port>8443</https_port>
    <tcp_port_secure>9440</tcp_port_secure>
    
    <!-- 互联端口 -->
    <interserver_http_port>9009</interserver_http_port>
    <interserver_https_port>9010</interserver_https_port>

    <!-- ================================ -->
    <!-- SSL/TLS配置 -->
    <!-- ================================ -->
    <openSSL>
        <server>
            <certificateFile>/etc/clickhouse-server/ssl/server.crt</certificateFile>
            <privateKeyFile>/etc/clickhouse-server/ssl/server.key</privateKeyFile>
            <dhParamsFile>/etc/clickhouse-server/ssl/dhparam.pem</dhParamsFile>
            <verificationMode>relaxed</verificationMode>
            <loadDefaultCAFile>true</loadDefaultCAFile>
            <cacheSessions>true</cacheSessions>
            <disableProtocols>sslv2,sslv3</disableProtocols>
            <preferServerCiphers>true</preferServerCiphers>
        </server>
        <client>
            <loadDefaultCAFile>true</loadDefaultCAFile>
            <cacheSessions>true</cacheSessions>
            <disableProtocols>sslv2,sslv3</disableProtocols>
            <preferServerCiphers>true</preferServerCiphers>
            <verificationMode>relaxed</verificationMode>
            <invalidCertificateHandler>
                <name>RejectCertificateHandler</name>
            </invalidCertificateHandler>
        </client>
    </openSSL>

    <!-- ================================ -->
    <!-- 存储配置 -->
    <!-- ================================ -->
    <storage_configuration>
        <disks>
            <!-- 高速SSD存储 -->
            <hot_ssd>
                <type>local</type>
                <path>/var/lib/clickhouse/hot/</path>
                <keep_free_space_bytes>10737418240</keep_free_space_bytes>
            </hot_ssd>
            
            <!-- 普通SSD存储 -->
            <warm_ssd>
                <type>local</type>
                <path>/var/lib/clickhouse/warm/</path>
                <keep_free_space_bytes>5368709120</keep_free_space_bytes>
            </warm_ssd>
            
            <!-- HDD冷存储 -->
            <cold_hdd>
                <type>local</type>
                <path>/var/lib/clickhouse/cold/</path>
                <keep_free_space_bytes>2147483648</keep_free_space_bytes>
            </cold_hdd>
            
            <!-- S3存储 -->
            <s3_archive>
                <type>s3</type>
                <endpoint>https://s3.amazonaws.com/analytics-backup/</endpoint>
                <access_key_id>AKIAIOSFODNN7EXAMPLE</access_key_id>
                <secret_access_key>wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY</secret_access_key>
                <region>us-east-1</region>
                <use_environment_credentials>false</use_environment_credentials>
                <header>Content-Type: application/octet-stream</header>
                <server_side_encryption_customer_key_base64>your-base64-encoded-key</server_side_encryption_customer_key_base64>
            </s3_archive>
            
            <!-- HDFS存储 -->
            <hdfs_archive>
                <type>hdfs</type>
                <endpoint>hdfs://namenode:9000/clickhouse/</endpoint>
                <min_bytes_for_seek>1048576</min_bytes_for_seek>
            </hdfs_archive>
        </disks>

        <policies>
            <!-- 实时数据存储策略 -->
            <realtime_policy>
                <volumes>
                    <hot>
                        <disk>hot_ssd</disk>
                        <max_data_part_size_bytes>1073741824</max_data_part_size_bytes>
                    </hot>
                    <warm>
                        <disk>warm_ssd</disk>
                        <max_data_part_size_bytes>10737418240</max_data_part_size_bytes>
                    </warm>
                    <cold>
                        <disk>cold_hdd</disk>
                    </cold>
                </volumes>
                <move_factor>0.1</move_factor>
                <prefer_not_to_merge>false</prefer_not_to_merge>
            </realtime_policy>
            
            <!-- 归档数据存储策略 -->
            <archive_policy>
                <volumes>
                    <archive>
                        <disk>s3_archive</disk>
                    </archive>
                </volumes>
            </archive_policy>
            
            <!-- 混合存储策略 -->
            <hybrid_policy>
                <volumes>
                    <hot>
                        <disk>hot_ssd</disk>
                        <max_data_part_size_bytes>536870912</max_data_part_size_bytes>
                    </hot>
                    <warm>
                        <disk>warm_ssd</disk>
                        <max_data_part_size_bytes>5368709120</max_data_part_size_bytes>
                    </warm>
                    <cold>
                        <disk>cold_hdd</disk>
                        <max_data_part_size_bytes>21474836480</max_data_part_size_bytes>
                    </cold>
                    <archive>
                        <disk>s3_archive</disk>
                    </archive>
                </volumes>
                <move_factor>0.2</move_factor>
            </hybrid_policy>
        </policies>
    </storage_configuration>

    <!-- ================================ -->
    <!-- 内存配置 -->
    <!-- ================================ -->
    <max_server_memory_usage>0</max_server_memory_usage>
    <max_server_memory_usage_to_ram_ratio>0.8</max_server_memory_usage_to_ram_ratio>
    <max_memory_usage>20000000000</max_memory_usage>
    <max_memory_usage_for_user>15000000000</max_memory_usage_for_user>
    <max_memory_usage_for_all_queries>25000000000</max_memory_usage_for_all_queries>

    <!-- 缓存配置 -->
    <mark_cache_size>10737418240</mark_cache_size>
    <uncompressed_cache_size>21474836480</uncompressed_cache_size>
    <compiled_expression_cache_size>268435456</compiled_expression_cache_size>
    <query_cache_size>5368709120</query_cache_size>

    <!-- ================================ -->
    <!-- 线程池配置 -->
    <!-- ================================ -->
    <max_concurrent_queries>200</max_concurrent_queries>
    <max_concurrent_insert_queries>50</max_concurrent_insert_queries>
    <max_concurrent_select_queries>150</max_concurrent_select_queries>
    
    <!-- 后台处理线程 -->
    <background_pool_size>32</background_pool_size>
    <background_merges_mutations_concurrency_ratio>4</background_merges_mutations_concurrency_ratio>
    <background_schedule_pool_size>128</background_schedule_pool_size>
    <background_fetches_pool_size>16</background_fetches_pool_size>
    <background_move_pool_size>8</background_move_pool_size>
    <background_common_pool_size>16</background_common_pool_size>

    <!-- ================================ -->
    <!-- 查询处理配置 -->
    <!-- ================================ -->
    <max_execution_time>300</max_execution_time>
    <max_query_size>268435456</max_query_size>
    <max_ast_depth>1000</max_ast_depth>
    <max_ast_elements>50000</max_ast_elements>
    <max_expanded_ast_elements>500000</max_expanded_ast_elements>
    
    <!-- 分布式查询配置 -->
    <distributed_connections_pool_size>1024</distributed_connections_pool_size>
    <distributed_ddl_task_timeout>300</distributed_ddl_task_timeout>
    <distributed_ddl_output_mode>throw</distributed_ddl_output_mode>

    <!-- ================================ -->
    <!-- 数据处理配置 -->
    <!-- ================================ -->
    <max_table_size_to_drop>0</max_table_size_to_drop>
    <max_partition_size_to_drop>0</max_partition_size_to_drop>
    
    <!-- 插入配置 -->
    <max_insert_block_size>1048576</max_insert_block_size>
    <min_insert_block_size_rows>1048576</min_insert_block_size_rows>
    <min_insert_block_size_bytes>268435456</min_insert_block_size_bytes>
    <max_insert_threads>16</max_insert_threads>
    
    <!-- 合并配置 -->
    <merge_tree>
        <max_suspicious_broken_parts>10</max_suspicious_broken_parts>
        <parts_to_delay_insert>300</parts_to_delay_insert>
        <parts_to_throw_insert>600</parts_to_throw_insert>
        <max_delay_to_insert>1</max_delay_to_insert>
        <max_parts_in_total>100000</max_parts_in_total>
        <max_bytes_to_merge_at_min_space_in_pool>1073741824</max_bytes_to_merge_at_min_space_in_pool>
        <max_bytes_to_merge_at_max_space_in_pool>161061273600</max_bytes_to_merge_at_max_space_in_pool>
        <merge_max_block_size>8192</merge_max_block_size>
        <max_part_loading_threads>16</max_part_loading_threads>
        <max_part_removal_threads>16</max_part_removal_threads>
        <concurrent_part_removal_threshold>100</concurrent_part_removal_threshold>
    </merge_tree>

    <!-- ================================ -->
    <!-- 网络和连接配置 -->
    <!-- ================================ -->
    <max_connections>2048</max_connections>
    <keep_alive_timeout>30</keep_alive_timeout>
    <listen_backlog>4096</listen_backlog>
    <max_open_files>1048576</max_open_files>
    
    <!-- TCP配置 -->
    <tcp_keep_alive_timeout>7200</tcp_keep_alive_timeout>
    <tcp_with_proxy_protocol>false</tcp_with_proxy_protocol>
    
    <!-- HTTP配置 -->
    <http_receive_timeout>300</http_receive_timeout>
    <http_send_timeout>300</http_send_timeout>
    <add_http_cors_header>true</add_http_cors_header>

    <!-- ================================ -->
    <!-- 压缩配置 -->
    <!-- ================================ -->
    <compression>
        <case>
            <method>zstd</method>
            <level>3</level>
            <min_part_size>10485760</min_part_size>
            <min_part_size_ratio>0.01</min_part_size_ratio>
        </case>
        <case>
            <method>lz4hc</method>
            <level>9</level>
            <min_part_size>1048576</min_part_size>
            <min_part_size_ratio>0.005</min_part_size_ratio>
        </case>
    </compression>

    <!-- ================================ -->
    <!-- 日志配置 -->
    <!-- ================================ -->
    <logger>
        <level>information</level>
        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
        <size>1000M</size>
        <count>10</count>
        <console>false</console>
        <formatting>
            <type>json</type>
            <names>
                <date_time>timestamp</date_time>
                <thread_name>thread</thread_name>
                <thread_id>thread_id</thread_id>
                <level>level</level>
                <query_id>query_id</query_id>
                <logger_name>logger</logger_name>
                <message>message</message>
                <source_file>source_file</source_file>
                <source_line>source_line</source_line>
            </names>
        </formatting>
    </logger>

    <!-- 查询日志 -->
    <query_log>
        <database>system</database>
        <table>query_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <ttl>event_date + INTERVAL 30 DAY DELETE</ttl>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <max_size_rows>1048576</max_size_rows>
        <reserved_size_rows>8192</reserved_size_rows>
        <buffer_size_rows_flush_threshold>524288</buffer_size_rows_flush_threshold>
        <flush_on_crash>false</flush_on_crash>
    </query_log>

    <!-- 查询线程日志 -->
    <query_thread_log>
        <database>system</database>
        <table>query_thread_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <ttl>event_date + INTERVAL 30 DAY DELETE</ttl>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <max_size_rows>1048576</max_size_rows>
    </query_thread_log>

    <!-- 部分日志 -->
    <part_log>
        <database>system</database>
        <table>part_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <ttl>event_date + INTERVAL 30 DAY DELETE</ttl>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <max_size_rows>1048576</max_size_rows>
    </part_log>

    <!-- 文本日志 -->
    <text_log>
        <database>system</database>
        <table>text_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <ttl>event_date + INTERVAL 7 DAY DELETE</ttl>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <max_size_rows>1048576</max_size_rows>
        <level>information</level>
    </text_log>

    <!-- 指标日志 -->
    <metric_log>
        <database>system</database>
        <table>metric_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <ttl>event_date + INTERVAL 30 DAY DELETE</ttl>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <collect_interval_milliseconds>1000</collect_interval_milliseconds>
        <max_size_rows>1048576</max_size_rows>
    </metric_log>

    <!-- 异步指标日志 -->
    <asynchronous_metric_log>
        <database>system</database>
        <table>asynchronous_metric_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <ttl>event_date + INTERVAL 30 DAY DELETE</ttl>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <max_size_rows>1048576</max_size_rows>
    </asynchronous_metric_log>

    <!-- 跟踪日志 -->
    <trace_log>
        <database>system</database>
        <table>trace_log</table>
        <partition_by>toYYYYMM(event_date)</partition_by>
        <ttl>event_date + INTERVAL 7 DAY DELETE</ttl>
        <flush_interval_milliseconds>7500</flush_interval_milliseconds>
        <max_size_rows>1048576</max_size_rows>
    </trace_log>

    <!-- ================================ -->
    <!-- 安全配置 -->
    <!-- ================================ -->
    <interserver_http_credentials>
        <user>interserver</user>
        <password>InterServer@2024</password>
    </interserver_http_credentials>

    <!-- 访问控制 -->
    <access_control_path>/var/lib/clickhouse/access/</access_control_path>
    <user_directories>
        <users_xml>
            <path>/etc/clickhouse-server/users.xml</path>
        </users_xml>
        <local_directory>
            <path>/var/lib/clickhouse/access/</path>
        </local_directory>
    </user_directories>

    <!-- ================================ -->
    <!-- Kafka配置 -->
    <!-- ================================ -->
    <kafka>
        <debug>cgrp,topic,fetch</debug>
        <auto_offset_reset>earliest</auto_offset_reset>
        <statistics_interval_ms>3000</statistics_interval_ms>
        <max_poll_interval_ms>300000</max_poll_interval_ms>
        <session_timeout_ms>30000</session_timeout_ms>
        <heartbeat_interval_ms>3000</heartbeat_interval_ms>
        <commit_every_batch_consumed>1</commit_every_batch_consumed>
        <max_rows_per_message>1</max_rows_per_message>
    </kafka>

    <!-- ================================ -->
    <!-- 监控配置 -->
    <!-- ================================ -->
    <prometheus>
        <endpoint>/metrics</endpoint>
        <port>9363</port>
        <metrics>true</metrics>
        <events>true</events>
        <asynchronous_metrics>true</asynchronous_metrics>
        <status_info>true</status_info>
    </prometheus>

    <!-- ================================ -->
    <!-- 性能优化配置 -->
    <!-- ================================ -->
    <profiles>
        <default>
            <max_memory_usage>20000000000</max_memory_usage>
            <use_uncompressed_cache>1</use_uncompressed_cache>
            <load_balancing>random</load_balancing>
            <max_execution_time>300</max_execution_time>
            <max_rows_to_read>1000000000</max_rows_to_read>
            <max_bytes_to_read>100000000000</max_bytes_to_read>
            <max_result_rows>1000000</max_result_rows>
            <max_result_bytes>1000000000</max_result_bytes>
            <result_overflow_mode>throw</result_overflow_mode>
            <max_execution_time>300</max_execution_time>
            <min_execution_speed>1000000</min_execution_speed>
            <timeout_before_checking_execution_speed>10</timeout_before_checking_execution_speed>
            <max_columns_to_read>1000</max_columns_to_read>
            <max_temporary_columns>1000</max_temporary_columns>
            <max_temporary_non_const_columns>1000</max_temporary_non_const_columns>
            <max_subquery_depth>100</max_subquery_depth>
            <max_pipeline_depth>1000</max_pipeline_depth>
            <max_ast_depth>1000</max_ast_depth>
            <max_ast_elements>50000</max_ast_elements>
            <max_expanded_ast_elements>500000</max_expanded_ast_elements>
            <readonly>0</readonly>
            <max_rows_in_set>0</max_rows_in_set>
            <max_bytes_in_set>0</max_bytes_in_set>
            <set_overflow_mode>throw</set_overflow_mode>
            <max_rows_in_join>0</max_rows_in_join>
            <max_bytes_in_join>0</max_bytes_in_join>
            <join_overflow_mode>throw</join_overflow_mode>
            <max_rows_to_transfer>0</max_rows_to_transfer>
            <max_bytes_to_transfer>0</max_bytes_to_transfer>
            <transfer_overflow_mode>throw</transfer_overflow_mode>
            <max_rows_in_distinct>0</max_rows_in_distinct>
            <max_bytes_in_distinct>0</max_bytes_in_distinct>
            <distinct_overflow_mode>throw</distinct_overflow_mode>
            <max_memory_usage_for_user>0</max_memory_usage_for_user>
            <max_memory_usage_for_all_queries>0</max_memory_usage_for_all_queries>
            <max_network_bandwidth>0</max_network_bandwidth>
            <max_network_bytes>0</max_network_bytes>
            <max_network_bandwidth_for_user>0</max_network_bandwidth_for_user>
            <max_network_bandwidth_for_all_users>0</max_network_bandwidth_for_all_users>
            <force_index_by_date>0</force_index_by_date>
            <force_primary_key>0</force_primary_key>
            <max_threads>16</max_threads>
            <max_insert_block_size>1048576</max_insert_block_size>
            <min_insert_block_size_rows>1048576</min_insert_block_size_rows>
            <min_insert_block_size_bytes>268435456</min_insert_block_size_bytes>
            <max_block_size>65536</max_block_size>
            <max_insert_threads>16</max_insert_threads>
            <max_final_threads>16</max_final_threads>
            <max_distributed_connections>1024</max_distributed_connections>
            <skip_unavailable_shards>0</skip_unavailable_shards>
            <distributed_group_by_no_merge>0</distributed_group_by_no_merge>
            <merge_tree_max_rows_to_use_cache>128</merge_tree_max_rows_to_use_cache>
            <merge_tree_max_bytes_to_use_cache>1024</merge_tree_max_bytes_to_use_cache>
            <merge_tree_min_rows_for_concurrent_read>20480</merge_tree_min_rows_for_concurrent_read>
            <merge_tree_min_bytes_for_concurrent_read>24576</merge_tree_min_bytes_for_concurrent_read>
            <max_bytes_before_external_group_by>20000000000</max_bytes_before_external_group_by>
            <max_bytes_before_external_sort>20000000000</max_bytes_before_external_sort>
            <group_by_two_level_threshold>100000</group_by_two_level_threshold>
            <group_by_two_level_threshold_bytes>50000000</group_by_two_level_threshold_bytes>
            <distributed_aggregation_memory_efficient>1</distributed_aggregation_memory_efficient>
            <aggregation_memory_efficient_merge_threads>16</aggregation_memory_efficient_merge_threads>
            <max_parallel_replicas>1</max_parallel_replicas>
            <parallel_replicas_count>0</parallel_replicas_count>
            <parallel_replica_offset>0</parallel_replica_offset>
            <compile>1</compile>
            <compile_expressions>1</compile_expressions>
            <min_count_to_compile>3</min_count_to_compile>
            <min_count_to_compile_expression>3</min_count_to_compile_expression>
            <optimize_skip_unused_shards>1</optimize_skip_unused_shards>
            <optimize_throw_if_noop>1</optimize_throw_if_noop>
            <query_profiler_real_time_period_ns>1000000000</query_profiler_real_time_period_ns>
            <query_profiler_cpu_time_period_ns>1000000000</query_profiler_cpu_time_period_ns>
            <allow_introspection_functions>1</allow_introspection_functions>
        </default>

        <readonly>
            <readonly>1</readonly>
            <max_memory_usage>10000000000</max_memory_usage>
            <max_execution_time>60</max_execution_time>
            <max_rows_to_read>100000000</max_rows_to_read>
            <max_bytes_to_read>10000000000</max_bytes_to_read>
        </readonly>

        <analytics>
            <max_memory_usage>30000000000</max_memory_usage>
            <max_execution_time>600</max_execution_time>
            <max_threads>32</max_threads>
            <max_rows_to_read>10000000000</max_rows_to_read>
            <max_bytes_to_read>1000000000000</max_bytes_to_read>
            <optimize_skip_unused_shards>1</optimize_skip_unused_shards>
            <distributed_aggregation_memory_efficient>1</distributed_aggregation_memory_efficient>
        </analytics>
    </profiles>

    <!-- ================================ -->
    <!-- 用户配置 -->
    <!-- ================================ -->
    <users>
        <default>
            <password></password>
            <networks>
                <ip>::/0</ip>
            </networks>
            <profile>default</profile>
            <quota>default</quota>
        </default>

        <analytics_user>
            <password_sha256_hex>e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855</password_sha256_hex>
            <networks>
                <ip>10.0.0.0/8</ip>
                <ip>172.16.0.0/12</ip>
                <ip>192.168.0.0/16</ip>
            </networks>
            <profile>analytics</profile>
            <quota>analytics_quota</quota>
            <databases>
                <analytics>
                    <tables>
                        <user_events>
                            <filter>user_id != 0</filter>
                        </user_events>
                    </tables>
                </analytics>
            </databases>
        </analytics_user>

        <readonly_user>
            <password_sha256_hex>5e884898da28047151d0e56f8dc6292773603d0d6aabbdd62a11ef721d1542d8</password_sha256_hex>
            <networks>
                <ip>10.0.0.0/8</ip>
            </networks>
            <profile>readonly</profile>
            <quota>readonly_quota</quota>
        </readonly_user>
    </users>

    <!-- ================================ -->
    <!-- 配额配置 -->
    <!-- ================================ -->
    <quotas>
        <default>
            <interval>
                <duration>3600</duration>
                <queries>0</queries>
                <errors>0</errors>
                <result_rows>0</result_rows>
                <read_rows>0</read_rows>
                <execution_time>0</execution_time>
            </interval>
        </default>

        <analytics_quota>
            <interval>
                <duration>3600</duration>
                <queries>1000</queries>
                <errors>100</errors>
                <result_rows>1000000000</result_rows>
                <read_rows>10000000000</read_rows>
                <execution_time>36000</execution_time>
            </interval>
        </analytics_quota>

        <readonly_quota>
            <interval>
                <duration>3600</duration>
                <queries>100</queries>
                <errors>10</errors>
                <result_rows>10000000</result_rows>
                <read_rows>100000000</read_rows>
                <execution_time>3600</execution_time>
            </interval>
        </readonly_quota>
    </quotas>

    <!-- ================================ -->
    <!-- 数据字典配置 -->
    <!-- ================================ -->
    <dictionaries_config>/etc/clickhouse-server/config.d/*_dictionary.xml</dictionaries_config>

    <!-- ================================ -->
    <!-- 格式配置 -->
    <!-- ================================ -->
    <format_schema_path>/var/lib/clickhouse/format_schemas/</format_schema_path>

    <!-- ================================ -->
    <!-- 自定义设置 -->
    <!-- ================================ -->
    <custom_settings_prefixes>analytics_</custom_settings_prefixes>

    <!-- ================================ -->
    <!-- 临时数据配置 -->
    <!-- ================================ -->
    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
    <tmp_policy>default_move_factor</tmp_policy>

    <!-- ================================ -->
    <!-- 用户文件配置 -->
    <!-- ================================ -->
    <user_files_path>/var/lib/clickhouse/user_files/</user_files_path>

    <!-- ================================ -->
    <!-- 分布式DDL配置 -->
    <!-- ================================ -->
    <distributed_ddl>
        <path>/clickhouse/task_queue/ddl</path>
        <profile>default</profile>
        <pool_size>1</pool_size>
        <max_tasks_in_queue>1000</max_tasks_in_queue>
        <task_max_lifetime>604800</task_max_lifetime>
        <cleanup_delay_period>60</cleanup_delay_period>
        <max_pushed_ddl_entry_size>1048576</max_pushed_ddl_entry_size>
    </distributed_ddl>

    <!-- ================================ -->
    <!-- 其他配置 -->
    <!-- ================================ -->
    <builtin_dictionaries_reload_interval>3600</builtin_dictionaries_reload_interval>
    <max_session_timeout>3600</max_session_timeout>
    <default_session_timeout>60</default_session_timeout>
    <disable_internal_dns_cache>1</disable_internal_dns_cache>
    <dns_cache_update_period>15</dns_cache_update_period>

    <!-- 地理数据库配置 -->
    <path_to_regions_hierarchy_file>/opt/geo/regions_hierarchy.txt</path_to_regions_hierarchy_file>
    <path_to_regions_names_files>/opt/geo/</path_to_regions_names_files>

    <!-- 时区配置 -->
    <timezone>Asia/Shanghai</timezone>

    <!-- 崩溃报告 -->
    <send_crash_reports>
        <enabled>false</enabled>
        <anonymize>false</anonymize>
        <endpoint>https://6f33034cfe684dd7a3ab9875e57b1c8d@o388870.ingest.sentry.io/5226277</endpoint>
    </send_crash_reports>

</yandex> 