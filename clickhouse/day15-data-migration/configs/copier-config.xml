<?xml version="1.0"?>
<clickhouse>
    <!-- ClickHouse Copier配置文件 -->
    <!-- 用于从3分片2副本集群迁移到1分片2副本集群 -->
    
    <!-- 集群配置 -->
    <remote_servers>
        <!-- 源集群：3分片2副本 -->
        <source_cluster>
            <shard>
                <replica>
                    <host>10.0.1.1</host>
                    <port>9000</port>
                    <user>default</user>
                    <password></password>
                </replica>
                <replica>
                    <host>10.0.1.2</host>
                    <port>9000</port>
                    <user>default</user>
                    <password></password>
                </replica>
            </shard>
            <shard>
                <replica>
                    <host>10.0.1.3</host>
                    <port>9000</port>
                    <user>default</user>
                    <password></password>
                </replica>
                <replica>
                    <host>10.0.1.4</host>
                    <port>9000</port>
                    <user>default</user>
                    <password></password>
                </replica>
            </shard>
            <shard>
                <replica>
                    <host>10.0.1.5</host>
                    <port>9000</port>
                    <user>default</user>
                    <password></password>
                </replica>
                <replica>
                    <host>10.0.1.6</host>
                    <port>9000</port>
                    <user>default</user>
                    <password></password>
                </replica>
            </shard>
        </source_cluster>

        <!-- 目标集群：1分片2副本 -->
        <target_cluster>
            <shard>
                <replica>
                    <host>10.0.2.1</host><!-- 临时使用不同IP进行迁移 -->
                    <port>9000</port>
                    <user>default</user>
                    <password></password>
                </replica>
                <replica>
                    <host>10.0.2.2</host><!-- 临时使用不同IP进行迁移 -->
                    <port>9000</port>
                    <user>default</user>
                    <password></password>
                </replica>
            </shard>
        </target_cluster>
    </remote_servers>

    <!-- ZooKeeper配置 -->
    <zookeeper>
        <node>
            <host>10.0.1.10</host>
            <port>2181</port>
        </node>
        <node>
            <host>10.0.1.11</host>
            <port>2181</port>
        </node>
        <node>
            <host>10.0.1.12</host>
            <port>2181</port>
        </node>
    </zookeeper>

    <!-- Copier全局设置 -->
    <max_workers>8</max_workers>
    <settings_pull>
        <max_execution_time>7200</max_execution_time><!-- 2小时 -->
        <max_memory_usage>10737418240</max_memory_usage><!-- 10GB -->
        <max_bytes_before_external_group_by>8589934592</max_bytes_before_external_group_by><!-- 8GB -->
        <max_bytes_before_external_sort>8589934592</max_bytes_before_external_sort><!-- 8GB -->
        <max_block_size>65536</max_block_size>
        <preferred_block_size_bytes>1048576</preferred_block_size_bytes><!-- 1MB -->
        <max_insert_block_size>1048576</max_insert_block_size><!-- 1M rows -->
        <min_insert_block_size_rows>262144</min_insert_block_size_rows><!-- 256K rows -->
        <min_insert_block_size_bytes>268435456</min_insert_block_size_bytes><!-- 256MB -->
        <max_threads>16</max_threads>
        <load_balancing>random</load_balancing>
    </settings_pull>
    
    <settings_push>
        <max_execution_time>7200</max_execution_time><!-- 2小时 -->
        <max_memory_usage>10737418240</max_memory_usage><!-- 10GB -->
        <max_insert_block_size>1048576</max_insert_block_size><!-- 1M rows -->
        <min_insert_block_size_rows>262144</min_insert_block_size_rows><!-- 256K rows -->
        <min_insert_block_size_bytes>268435456</min_insert_block_size_bytes><!-- 256MB -->
        <max_threads>16</max_threads>
        <insert_distributed_sync>1</insert_distributed_sync>
        <fsync_metadata>1</fsync_metadata>
    </settings_push>

    <!-- 需要复制的表配置 -->
    <tables>
        <!-- 示例表1：用户行为表 -->
        <user_events>
            <cluster_pull>source_cluster</cluster_pull>
            <database_pull>analytics</database_pull>
            <table_pull>user_events</table_pull>
            
            <cluster_push>target_cluster</cluster_push>
            <database_push>analytics</database_push>
            <table_push>user_events</table_push>
            
            <!-- 目标表引擎定义 -->
            <engine>
                ENGINE = ReplicatedMergeTree('/clickhouse/tables/{cluster}-{shard}/user_events', '{replica}')
                PARTITION BY toYYYYMM(event_date)
                ORDER BY (user_id, event_date, event_time)
                SAMPLE BY intHash32(user_id)
                SETTINGS index_granularity = 8192
            </engine>
            
            <!-- 分片键：随机分布 -->
            <sharding_key>rand()</sharding_key>
            
            <!-- 数据过滤条件（可选） -->
            <where_condition>event_date >= '2024-01-01'</where_condition>
            
            <!-- 启用数据压缩 -->
            <settings>
                <compress>1</compress>
                <extremes>1</extremes>
            </settings>
        </user_events>

        <!-- 示例表2：订单表 -->
        <orders>
            <cluster_pull>source_cluster</cluster_pull>
            <database_pull>ecommerce</database_pull>
            <table_pull>orders</table_pull>
            
            <cluster_push>target_cluster</cluster_push>
            <database_push>ecommerce</database_push>
            <table_push>orders</table_push>
            
            <engine>
                ENGINE = ReplicatedMergeTree('/clickhouse/tables/{cluster}-{shard}/orders', '{replica}')
                PARTITION BY toYYYYMM(order_date)
                ORDER BY (customer_id, order_date, order_id)
                SETTINGS index_granularity = 8192
            </engine>
            
            <sharding_key>rand()</sharding_key>
            
            <!-- 只迁移最近一年的数据 -->
            <where_condition>order_date >= today() - INTERVAL 365 DAY</where_condition>
        </orders>

        <!-- 示例表3：产品表 -->
        <products>
            <cluster_pull>source_cluster</cluster_pull>
            <database_pull>ecommerce</database_pull>
            <table_pull>products</table_pull>
            
            <cluster_push>target_cluster</cluster_push>
            <database_push>ecommerce</database_push>
            <table_push>products</table_push>
            
            <engine>
                ENGINE = ReplicatedMergeTree('/clickhouse/tables/{cluster}-{shard}/products', '{replica}')
                ORDER BY product_id
                SETTINGS index_granularity = 8192
            </engine>
            
            <sharding_key>rand()</sharding_key>
        </products>

        <!-- 示例表4：日志表 -->
        <access_logs>
            <cluster_pull>source_cluster</cluster_pull>
            <database_pull>logs</database_pull>
            <table_pull>access_logs</table_pull>
            
            <cluster_push>target_cluster</cluster_push>
            <database_push>logs</database_push>
            <table_push>access_logs</table_push>
            
            <engine>
                ENGINE = ReplicatedMergeTree('/clickhouse/tables/{cluster}-{shard}/access_logs', '{replica}')
                PARTITION BY toYYYYMMDD(timestamp)
                ORDER BY (timestamp, ip, user_agent)
                TTL timestamp + INTERVAL 90 DAY DELETE
                SETTINGS index_granularity = 8192
            </engine>
            
            <sharding_key>rand()</sharding_key>
            
            <!-- 只迁移最近30天的日志 -->
            <where_condition>timestamp >= today() - INTERVAL 30 DAY</where_condition>
        </access_logs>
    </tables>

    <!-- 任务配置 -->
    <task_zookeeper_path>/clickhouse/copier/migration_3s_to_1s</task_zookeeper_path>
    
    <!-- 状态更新间隔 -->
    <status_update_interval>10</status_update_interval>
    
    <!-- 日志配置 -->
    <logger>
        <level>debug</level>
        <log>/var/log/clickhouse-copier/copier.log</log>
        <errorlog>/var/log/clickhouse-copier/copier.err.log</errorlog>
        <size>1000M</size>
        <count>5</count>
    </logger>
</clickhouse> 