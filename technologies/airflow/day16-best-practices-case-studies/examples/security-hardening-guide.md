# Apache Airflow å®‰å…¨åŠ å›ºæŒ‡å—

## 1. æ¦‚è¿°

### 1.1 ç›®çš„
æœ¬æ–‡æ¡£æ—¨åœ¨ä¸ºApache Airflowç”Ÿäº§ç¯å¢ƒæä¾›å…¨é¢çš„å®‰å…¨åŠ å›ºæŒ‡å—ï¼Œç¡®ä¿ç³»ç»Ÿåœ¨é¢å¯¹å„ç§å®‰å…¨å¨èƒæ—¶èƒ½å¤Ÿä¿æŒç¨³å®šã€å¯é å’Œå®‰å…¨çš„è¿è¡Œã€‚

### 1.2 é€‚ç”¨èŒƒå›´
æœ¬æŒ‡å—é€‚ç”¨äºæ‰€æœ‰è¿è¡ŒApache Airflowçš„ç¯å¢ƒï¼ŒåŒ…æ‹¬å¼€å‘ã€æµ‹è¯•ã€é¢„ç”Ÿäº§å’Œç”Ÿäº§ç¯å¢ƒã€‚

### 1.3 å®‰å…¨åŸåˆ™
- **æœ€å°æƒé™åŸåˆ™**: ç”¨æˆ·å’Œç³»ç»Ÿç»„ä»¶åªåº”æ‹¥æœ‰å®Œæˆå…¶ä»»åŠ¡æ‰€éœ€çš„æœ€å°æƒé™
- **çºµæ·±é˜²å¾¡**: é‡‡ç”¨å¤šå±‚å®‰å…¨é˜²æŠ¤æœºåˆ¶
- **å®‰å…¨é»˜è®¤é…ç½®**: ç³»ç»Ÿé»˜è®¤é…ç½®åº”ä¼˜å…ˆè€ƒè™‘å®‰å…¨æ€§
- **æŒç»­ç›‘æ§**: å®æ–½æŒç»­çš„å®‰å…¨ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶
- **å®šæœŸå®¡è®¡**: å®šæœŸè¿›è¡Œå®‰å…¨å®¡è®¡å’Œæ¼æ´æ‰«æ

## 2. èº«ä»½è®¤è¯å’Œæˆæƒ

### 2.1 èº«ä»½è®¤è¯é…ç½®
```yaml
# èº«ä»½è®¤è¯é…ç½®ç¤ºä¾‹
auth_config:
  # OAuth2é…ç½®
  oauth2:
    enabled: true
    provider: auth0
    domain: airflow.company.com
    client_id: airflow-client-id
    client_secret_secret: airflow/oauth2-client-secret
    
    # ç”¨æˆ·æ˜ å°„
    user_mapping:
      - email_domain: company.com
        role: User
      - email: admin@company.com
        role: Admin
      - email: ops@company.com
        role: Op
        
  # LDAPé…ç½®
  ldap:
    enabled: true
    uri: ldaps://ldap.company.com:636
    bind_user: cn=airflow,ou=services,dc=company,dc=com
    bind_password_secret: airflow/ldap-bind-password
    
    # ç”¨æˆ·æœç´¢é…ç½®
    user_search:
      base: ou=people,dc=company,dc=com
      filter: (memberOf=cn=airflow-users,ou=groups,dc=company,dc=com)
      
    # ç»„æœç´¢é…ç½®
    group_search:
      base: ou=groups,dc=company,dc=com
      filter: (member=cn={0},ou=people,dc=company,dc=com)
      
    # è§’è‰²æ˜ å°„
    role_mapping:
      admin: cn=airflow-admins,ou=groups,dc=company,dc=com
      user: cn=airflow-users,ou=groups,dc=company,dc=com
      viewer: cn=airflow-viewers,ou=groups,dc=company,dc=com
      
  # SAMLé…ç½®
  saml:
    enabled: false
    metadata_url: https://sso.company.com/saml/metadata
    entity_id: airflow.company.com
    acs_url: https://airflow.company.com/complete/saml/
    
    # å±æ€§æ˜ å°„
    attributes:
      username: email
      email: email
      firstname: givenName
      lastname: surname
      role: role
```

### 2.2 åŸºäºè§’è‰²çš„è®¿é—®æ§åˆ¶(RBAC)
```python
# rbac_config.py
from airflow.models import DagBag
from airflow.security import permissions
from airflow.www.security import AirflowSecurityManager

class CustomSecurityManager(AirflowSecurityManager):
    def init_role(self, role_name, perms):
        """åˆå§‹åŒ–è§’è‰²æƒé™"""
        role = self.find_role(role_name)
        if not role:
            role = self.add_role(role_name)
            
        role.permissions = perms
        self.update_role(role_name, role)
        
    def init_roles(self):
        """åˆå§‹åŒ–æ‰€æœ‰è§’è‰²"""
        # ç®¡ç†å‘˜è§’è‰² - æ‹¥æœ‰æ‰€æœ‰æƒé™
        admin_perms = [
            permissions.ACTION_CAN_READ,
            permissions.ACTION_CAN_EDIT,
            permissions.ACTION_CAN_DELETE,
            permissions.RESOURCE_DAG,
            permissions.RESOURCE_TASK_INSTANCE,
            permissions.RESOURCE_USER,
            permissions.RESOURCE_CONNECTION,
            permissions.RESOURCE_VARIABLE,
            permissions.RESOURCE_POOL,
            permissions.RESOURCE_DAG_RUN,
            permissions.RESOURCE_IMPORT_ERROR,
            permissions.RESOURCE_JOB,
            permissions.RESOURCE_AUDIT_LOG,
            permissions.RESOURCE_TASK_RESCHEDULE,
            permissions.RESOURCE_TRIGGER,
            permissions.RESOURCE_XCOM,
        ]
        
        # å¼€å‘è€…è§’è‰² - å¯ä»¥è¯»å†™è‡ªå·±çš„DAG
        developer_perms = [
            permissions.ACTION_CAN_READ,
            permissions.ACTION_CAN_EDIT,
            permissions.RESOURCE_DAG,
            permissions.RESOURCE_TASK_INSTANCE,
            permissions.RESOURCE_DAG_RUN,
            permissions.RESOURCE_XCOM,
        ]
        
        # è¿ç»´è§’è‰² - å¯ä»¥ç®¡ç†ä»»åŠ¡å®ä¾‹å’Œè¿æ¥
        ops_perms = [
            permissions.ACTION_CAN_READ,
            permissions.ACTION_CAN_EDIT,
            permissions.RESOURCE_TASK_INSTANCE,
            permissions.RESOURCE_CONNECTION,
            permissions.RESOURCE_VARIABLE,
            permissions.RESOURCE_POOL,
            permissions.RESOURCE_DAG_RUN,
            permissions.RESOURCE_JOB,
        ]
        
        # æŸ¥çœ‹è€…è§’è‰² - åªè¯»æƒé™
        viewer_perms = [
            permissions.ACTION_CAN_READ,
            permissions.RESOURCE_DAG,
            permissions.RESOURCE_TASK_INSTANCE,
            permissions.RESOURCE_DAG_RUN,
            permissions.RESOURCE_JOB,
        ]
        
        # åˆå§‹åŒ–è§’è‰²
        self.init_role("Admin", admin_perms)
        self.init_role("Developer", developer_perms)
        self.init_role("Ops", ops_perms)
        self.init_role("Viewer", viewer_perms)
        
    def is_user_dag_owner(self, user, dag_id):
        """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºDAGæ‰€æœ‰è€…"""
        # ä»ç”¨æˆ·å±æ€§æˆ–å¤–éƒ¨ç³»ç»Ÿè·å–DAGæ‰€æœ‰æƒä¿¡æ¯
        user_dags = self.get_user_dags(user)
        return dag_id in user_dags
        
    def get_user_dags(self, user):
        """è·å–ç”¨æˆ·æ‹¥æœ‰çš„DAGåˆ—è¡¨"""
        # è¿™é‡Œå¯ä»¥é›†æˆå¤–éƒ¨ç³»ç»Ÿå¦‚LDAPæˆ–æ•°æ®åº“æ¥è·å–DAGæ‰€æœ‰æƒ
        # ç¤ºä¾‹å®ç°
        if hasattr(user, 'dag_ownerships'):
            return user.dag_ownerships
        return []

# è‡ªå®šä¹‰æƒé™æ£€æŸ¥
def check_dag_permission(user, dag_id, action):
    """æ£€æŸ¥ç”¨æˆ·å¯¹ç‰¹å®šDAGçš„æƒé™"""
    # è·å–DAGæ‰€æœ‰è€…
    dag_bag = DagBag()
    dag = dag_bag.get_dag(dag_id)
    
    if not dag:
        return False
        
    # æ£€æŸ¥ç”¨æˆ·è§’è‰²
    user_roles = [role.name for role in user.roles]
    
    # ç®¡ç†å‘˜æ‹¥æœ‰æ‰€æœ‰æƒé™
    if "Admin" in user_roles:
        return True
        
    # å¼€å‘è€…åªèƒ½æ“ä½œè‡ªå·±æ‹¥æœ‰çš„DAG
    if "Developer" in user_roles:
        if action in [permissions.ACTION_CAN_READ, permissions.ACTION_CAN_EDIT]:
            return is_user_dag_owner(user, dag_id)
        return False
        
    # è¿ç»´å¯ä»¥æ“ä½œæ‰€æœ‰ä»»åŠ¡å®ä¾‹
    if "Ops" in user_roles:
        if action in [permissions.ACTION_CAN_READ, permissions.ACTION_CAN_EDIT]:
            return True
        return False
        
    # æŸ¥çœ‹è€…åªèƒ½è¯»å–
    if "Viewer" in user_roles:
        return action == permissions.ACTION_CAN_READ
        
    return False
```

### 2.3 ç”¨æˆ·å’Œç»„ç®¡ç†
```bash
#!/bin/bash
# user_management.sh

# åˆ›å»ºAirflowç”¨æˆ·ç»„
create_airflow_groups() {
    echo "Creating Airflow user groups..."
    
    # åˆ›å»ºç®¡ç†å‘˜ç»„
    ldapadd -x -D "cn=admin,dc=company,dc=com" -W << EOF
dn: cn=airflow-admins,ou=groups,dc=company,dc=com
objectClass: groupOfNames
cn: airflow-admins
member: cn=admin,ou=people,dc=company,dc=com
EOF

    # åˆ›å»ºå¼€å‘è€…ç»„
    ldapadd -x -D "cn=admin,dc=company,dc=com" -W << EOF
dn: cn=airflow-developers,ou=groups,dc=company,dc=com
objectClass: groupOfNames
cn: airflow-developers
member: cn=dev1,ou=people,dc=company,dc=com
member: cn=dev2,ou=people,dc=company,dc=com
EOF

    # åˆ›å»ºè¿ç»´ç»„
    ldapadd -x -D "cn=admin,dc=company,dc=com" -W << EOF
dn: cn=airflow-ops,ou=groups,dc=company,dc=com
objectClass: groupOfNames
cn: airflow-ops
member: cn=ops1,ou=people,dc=company,dc=com
EOF

    # åˆ›å»ºæŸ¥çœ‹è€…ç»„
    ldapadd -x -D "cn=admin,dc=company,dc=com" -W << EOF
dn: cn=airflow-viewers,ou=groups,dc=company,dc=com
objectClass: groupOfNames
cn: airflow-viewers
member: cn=viewer1,ou=people,dc=company,dc=com
EOF
}

# ç®¡ç†ç”¨æˆ·æƒé™
manage_user_permissions() {
    local username=$1
    local role=$2
    
    echo "Managing permissions for user: $username, role: $role"
    
    case $role in
        "admin")
            ldapmodify -x -D "cn=admin,dc=company,dc=com" -W << EOF
dn: cn=airflow-admins,ou=groups,dc=company,dc=com
changetype: modify
add: member
member: cn=$username,ou=people,dc=company,dc=com
EOF
            ;;
        "developer")
            ldapmodify -x -D "cn=admin,dc=company,dc=com" -W << EOF
dn: cn=airflow-developers,ou=groups,dc=company,dc=com
changetype: modify
add: member
member: cn=$username,ou=people,dc=company,dc=com
EOF
            ;;
        "ops")
            ldapmodify -x -D "cn=admin,dc=company,dc=com" -W << EOF
dn: cn=airflow-ops,ou=groups,dc=company,dc=com
changetype: modify
add: member
member: cn=$username,ou=people,dc=company,dc=com
EOF
            ;;
        "viewer")
            ldapmodify -x -D "cn=admin,dc=company,dc=com" -W << EOF
dn: cn=airflow-viewers,ou=groups,dc=company,dc=com
changetype: modify
add: member
member: cn=$username,ou=people,dc=company,dc=com
EOF
            ;;
        *)
            echo "Unknown role: $role"
            return 1
            ;;
    esac
}
```

## 3. æ•°æ®ä¿æŠ¤

### 3.1 æ•°æ®åŠ å¯†
```yaml
# æ•°æ®åŠ å¯†é…ç½®
data_encryption:
  # é™æ€æ•°æ®åŠ å¯†
  at_rest_encryption:
    # æ•°æ®åº“åŠ å¯†
    database_encryption:
      enabled: true
      method: TDE  # Transparent Data Encryption
      key_management: vault
      
    # æ–‡ä»¶ç³»ç»ŸåŠ å¯†
    filesystem_encryption:
      enabled: true
      method: LUKS
      key_management: vault
      
    # å¯¹è±¡å­˜å‚¨åŠ å¯†
    object_storage_encryption:
      enabled: true
      method: SSE  # Server-Side Encryption
      key_management: kms
      
  # ä¼ è¾“æ•°æ®åŠ å¯†
  in_transit_encryption:
    # TLSé…ç½®
    tls:
      enabled: true
      protocol: TLSv1.3
      cipher_suites:
        - TLS_AES_256_GCM_SHA384
        - TLS_CHACHA20_POLY1305_SHA256
        - TLS_AES_128_GCM_SHA256
        
      # è¯ä¹¦ç®¡ç†
      certificate_management:
        provider: vault
        certificate_secret: airflow/tls-certificate
        private_key_secret: airflow/tls-private-key
        ca_certificate_secret: airflow/ca-certificate
        
  # åº”ç”¨å±‚åŠ å¯†
  application_encryption:
    # Fernetå¯†é’¥é…ç½®
    fernet_key:
      enabled: true
      key_rotation_interval: 90  # å¤©
      key_storage: vault
      key_secret: airflow/fernet-key
      
    # è¿æ¥ä¿¡æ¯åŠ å¯†
    connection_encryption:
      enabled: true
      method: fernet
      sensitive_fields:
        - password
        - extra
        - schema
```

### 3.2 å¯†é’¥ç®¡ç†
```python
# key_management.py
import os
import base64
import hashlib
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
import hvac  # HashiCorp Vaultå®¢æˆ·ç«¯

class KeyManager:
    def __init__(self, vault_url, vault_token):
        self.vault_client = hvac.Client(url=vault_url, token=vault_token)
        
    def generate_fernet_key(self):
        """ç”ŸæˆFernetå¯†é’¥"""
        return Fernet.generate_key()
        
    def rotate_fernet_key(self, current_key_secret_path):
        """è½®æ¢Fernetå¯†é’¥"""
        # è·å–å½“å‰å¯†é’¥
        current_key = self.get_secret(current_key_secret_path)
        
        # ç”Ÿæˆæ–°å¯†é’¥
        new_key = self.generate_fernet_key()
        
        # å°†æ–°å¯†é’¥å­˜å‚¨åˆ°Vault
        self.store_secret(current_key_secret_path, new_key.decode())
        
        # å¯é€‰ï¼šå°†æ—§å¯†é’¥å­˜å‚¨åˆ°å†å²è®°å½•ä¸­
        self.store_secret(f"{current_key_secret_path}/history/{int(time.time())}", 
                         current_key)
        
        return new_key
        
    def get_secret(self, secret_path):
        """ä»Vaultè·å–å¯†é’¥"""
        try:
            secret = self.vault_client.secrets.kv.v2.read_secret_version(
                path=secret_path
            )
            return secret['data']['data']['value']
        except Exception as e:
            raise Exception(f"Failed to get secret from Vault: {str(e)}")
            
    def store_secret(self, secret_path, secret_value):
        """å°†å¯†é’¥å­˜å‚¨åˆ°Vault"""
        try:
            self.vault_client.secrets.kv.v2.create_or_update_secret(
                path=secret_path,
                secret=dict(value=secret_value)
            )
        except Exception as e:
            raise Exception(f"Failed to store secret to Vault: {str(e)}")
            
    def encrypt_data(self, data, key_secret_path):
        """ä½¿ç”¨Vaultä¸­çš„å¯†é’¥åŠ å¯†æ•°æ®"""
        key = self.get_secret(key_secret_path)
        fernet = Fernet(key.encode())
        return fernet.encrypt(data.encode())
        
    def decrypt_data(self, encrypted_data, key_secret_path):
        """ä½¿ç”¨Vaultä¸­çš„å¯†é’¥è§£å¯†æ•°æ®"""
        key = self.get_secret(key_secret_path)
        fernet = Fernet(key.encode())
        return fernet.decrypt(encrypted_data).decode()

# ä½¿ç”¨ç¤ºä¾‹
def secure_connection_config(connection_config):
    """å®‰å…¨åœ°å¤„ç†è¿æ¥é…ç½®"""
    key_manager = KeyManager(
        vault_url=os.environ.get('VAULT_ADDR'),
        vault_token=os.environ.get('VAULT_TOKEN')
    )
    
    # åŠ å¯†æ•æ„Ÿå­—æ®µ
    encrypted_password = key_manager.encrypt_data(
        connection_config['password'],
        'airflow/connection-password'
    )
    
    # å­˜å‚¨åŠ å¯†åçš„é…ç½®
    secure_config = connection_config.copy()
    secure_config['password'] = encrypted_password.decode()
    
    return secure_config
```

### 3.3 æ•æ„Ÿä¿¡æ¯ä¿æŠ¤
```bash
#!/bin/bash
# sensitive_data_protection.sh

# ä¿æŠ¤ç¯å¢ƒå˜é‡
protect_environment_variables() {
    echo "Protecting environment variables..."
    
    # ä½¿ç”¨envsubstæ›¿æ¢æ•æ„Ÿå˜é‡
    envsubst < airflow-template.cfg > airflow.cfg
    
    # è®¾ç½®æ–‡ä»¶æƒé™
    chmod 600 airflow.cfg
    
    # éªŒè¯æ•æ„Ÿä¿¡æ¯å·²è¢«æ›¿æ¢
    if grep -q "\${" airflow.cfg; then
        echo "Warning: Unresolved environment variables found in config"
        return 1
    fi
}

# ä¿æŠ¤é…ç½®æ–‡ä»¶
protect_config_files() {
    local config_dir="/opt/airflow/config"
    
    echo "Protecting configuration files..."
    
    # è®¾ç½®ç›®å½•æƒé™
    chown -R airflow:airflow $config_dir
    chmod 700 $config_dir
    
    # è®¾ç½®æ–‡ä»¶æƒé™
    find $config_dir -type f -exec chmod 600 {} \;
    
    # éªŒè¯æƒé™è®¾ç½®
    for file in $(find $config_dir -type f); do
        perms=$(stat -c %a $file)
        if [ "$perms" != "600" ]; then
            echo "Warning: Incorrect permissions on $file: $perms"
        fi
    done
}

# ä¿æŠ¤æ—¥å¿—æ–‡ä»¶
protect_log_files() {
    local log_dir="/opt/airflow/logs"
    
    echo "Protecting log files..."
    
    # è®¾ç½®æ—¥å¿—ç›®å½•æƒé™
    chown -R airflow:airflow $log_dir
    chmod 750 $log_dir
    
    # è®¾ç½®æ—¥å¿—æ–‡ä»¶æƒé™
    find $log_dir -type f -name "*.log" -exec chmod 640 {} \;
    
    # é…ç½®æ—¥å¿—è½®è½¬
    cat > /etc/logrotate.d/airflow << EOF
/opt/airflow/logs/*.log {
    daily
    rotate 30
    compress
    delaycompress
    missingok
    notifempty
    create 640 airflow airflow
    postrotate
        systemctl reload airflow-webserver > /dev/null 2>&1 || true
    endscript
}
EOF
}
```

## 4. ç½‘ç»œå®‰å…¨

### 4.1 ç½‘ç»œéš”ç¦»
```yaml
# ç½‘ç»œéš”ç¦»é…ç½®
network_isolation:
  # ç½‘ç»œåˆ†æ®µ
  network_segmentation:
    # ç®¡ç†ç½‘ç»œ
    management_network:
      cidr: 10.0.1.0/24
      allowed_services:
        - ssh
        - https
      ingress_rules:
        - source: 10.0.0.0/16
          protocol: tcp
          port: 22
        - source: 0.0.0.0/0
          protocol: tcp
          port: 443
          
    # æ•°æ®ç½‘ç»œ
    data_network:
      cidr: 10.0.2.0/24
      allowed_services:
        - postgresql
        - redis
      ingress_rules:
        - source: 10.0.1.0/24
          protocol: tcp
          port: 5432
        - source: 10.0.1.0/24
          protocol: tcp
          port: 6379
          
    # åº”ç”¨ç½‘ç»œ
    application_network:
      cidr: 10.0.3.0/24
      allowed_services:
        - http
        - https
      ingress_rules:
        - source: 0.0.0.0/0
          protocol: tcp
          port: 8080
        - source: 10.0.1.0/24
          protocol: tcp
          ports: [8080, 8793]
          
  # é˜²ç«å¢™è§„åˆ™
  firewall_rules:
    # Webserveré˜²ç«å¢™
    webserver_firewall:
      enabled: true
      rules:
        - name: allow_https
          direction: ingress
          action: allow
          protocol: tcp
          port: 443
          source: 0.0.0.0/0
          
        - name: allow_internal
          direction: ingress
          action: allow
          protocol: tcp
          ports: [8080, 8793]
          source: 10.0.0.0/16
          
        - name: deny_all_other
          direction: ingress
          action: deny
          protocol: any
          port: any
          source: 0.0.0.0/0
          
    # æ•°æ®åº“é˜²ç«å¢™
    database_firewall:
      enabled: true
      rules:
        - name: allow_postgresql
          direction: ingress
          action: allow
          protocol: tcp
          port: 5432
          source: 10.0.0.0/16
          
        - name: allow_redis
          direction: ingress
          action: allow
          protocol: tcp
          port: 6379
          source: 10.0.0.0/16
          
        - name: deny_all_other
          direction: ingress
          action: deny
          protocol: any
          port: any
          source: 0.0.0.0/0
```

### 4.2 å…¥ä¾µæ£€æµ‹å’Œé˜²æŠ¤
```python
# intrusion_detection.py
import logging
import re
import time
from datetime import datetime, timedelta
import requests
from elasticsearch import Elasticsearch

class IntrusionDetector:
    def __init__(self, es_host, es_port):
        self.es = Elasticsearch([{'host': es_host, 'port': es_port}])
        self.logger = logging.getLogger(__name__)
        self.suspicious_patterns = [
            r"DROP\s+TABLE",
            r"DELETE\s+FROM",
            r"INSERT\s+INTO",
            r"UPDATE\s+\w+\s+SET",
            r"UNION\s+SELECT",
            r"1=1",
            r"OR\s+1=1",
            r"';\s*--",
            r"';\s*DROP",
            r"';\s*DELETE",
        ]
        
    def analyze_logs(self, log_file):
        """åˆ†ææ—¥å¿—æ–‡ä»¶ä¸­çš„å¯ç–‘æ´»åŠ¨"""
        suspicious_activities = []
        
        with open(log_file, 'r') as f:
            for line_num, line in enumerate(f, 1):
                # æ£€æŸ¥å¯ç–‘æ¨¡å¼
                for pattern in self.suspicious_patterns:
                    if re.search(pattern, line, re.IGNORECASE):
                        suspicious_activities.append({
                            'line_number': line_num,
                            'content': line.strip(),
                            'pattern': pattern,
                            'timestamp': datetime.now().isoformat()
                        })
                        
                # æ£€æŸ¥å¼‚å¸¸è®¿é—®é¢‘ç‡
                if self.check_access_frequency(line):
                    suspicious_activities.append({
                        'line_number': line_num,
                        'content': line.strip(),
                        'pattern': 'high_frequency_access',
                        'timestamp': datetime.now().isoformat()
                    })
                    
        return suspicious_activities
        
    def check_access_frequency(self, log_line):
        """æ£€æŸ¥è®¿é—®é¢‘ç‡æ˜¯å¦å¼‚å¸¸"""
        # è§£ææ—¥å¿—è¡Œä¸­çš„IPåœ°å€å’Œæ—¶é—´æˆ³
        ip_match = re.search(r'(\d+\.\d+\.\d+\.\d+)', log_line)
        if not ip_match:
            return False
            
        ip = ip_match.group(1)
        
        # æŸ¥è¯¢æœ€è¿‘1åˆ†é’Ÿå†…è¯¥IPçš„è®¿é—®æ¬¡æ•°
        query = {
            "query": {
                "bool": {
                    "must": [
                        {"term": {"ip": ip}},
                        {"range": {
                            "@timestamp": {
                                "gte": "now-1m",
                                "lt": "now"
                            }
                        }}
                    ]
                }
            }
        }
        
        try:
            result = self.es.search(index="airflow-logs-*", body=query)
            hit_count = result['hits']['total']['value']
            
            # å¦‚æœ1åˆ†é’Ÿå†…è®¿é—®è¶…è¿‡100æ¬¡ï¼Œè®¤ä¸ºæ˜¯å¼‚å¸¸
            return hit_count > 100
        except Exception as e:
            self.logger.error(f"Failed to check access frequency: {str(e)}")
            return False
            
    def block_ip(self, ip_address):
        """é˜»æ­¢å¯ç–‘IPåœ°å€"""
        try:
            # ä½¿ç”¨iptablesé˜»æ­¢IP
            result = subprocess.run([
                'iptables', '-A', 'INPUT', '-s', ip_address, '-j', 'DROP'
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                self.logger.info(f"Successfully blocked IP: {ip_address}")
                return True
            else:
                self.logger.error(f"Failed to block IP {ip_address}: {result.stderr}")
                return False
        except Exception as e:
            self.logger.error(f"Error blocking IP {ip_address}: {str(e)}")
            return False
            
    def generate_alert(self, activities):
        """ç”Ÿæˆå®‰å…¨å‘Šè­¦"""
        if not activities:
            return
            
        alert_message = f"""
Security Alert: Suspicious Activities Detected

Time: {datetime.now().isoformat()}
Activities:
"""
        
        for activity in activities[:10]:  # é™åˆ¶æ˜¾ç¤ºå‰10ä¸ªæ´»åŠ¨
            alert_message += f"""
- Line {activity['line_number']}: {activity['content']}
  Pattern: {activity['pattern']}
  Time: {activity['timestamp']}
"""
            
        # å‘é€å‘Šè­¦åˆ°Slack
        self.send_slack_alert(alert_message)
        
        # å‘é€å‘Šè­¦é‚®ä»¶
        self.send_email_alert(alert_message)
        
    def send_slack_alert(self, message):
        """å‘é€Slackå‘Šè­¦"""
        try:
            webhook_url = os.environ.get('SLACK_WEBHOOK_URL')
            if not webhook_url:
                return
                
            payload = {
                "channel": "#security-alerts",
                "username": "Airflow Security Monitor",
                "text": f"ğŸš¨ *Security Alert*\n\n{message}",
                "icon_emoji": ":rotating_light:"
            }
            
            requests.post(webhook_url, json=payload)
        except Exception as e:
            self.logger.error(f"Failed to send Slack alert: {str(e)}")
            
    def send_email_alert(self, message):
        """å‘é€é‚®ä»¶å‘Šè­¦"""
        try:
            import smtplib
            from email.mime.text import MIMEText
            
            smtp_server = os.environ.get('SMTP_SERVER')
            smtp_port = int(os.environ.get('SMTP_PORT', 587))
            sender_email = os.environ.get('SENDER_EMAIL')
            receiver_emails = os.environ.get('RECEIVER_EMAILS', '').split(',')
            
            if not all([smtp_server, sender_email, receiver_emails]):
                return
                
            msg = MIMEText(message)
            msg['Subject'] = 'Airflow Security Alert'
            msg['From'] = sender_email
            msg['To'] = ', '.join(receiver_emails)
            
            server = smtplib.SMTP(smtp_server, smtp_port)
            server.starttls()
            server.login(sender_email, os.environ.get('EMAIL_PASSWORD'))
            server.send_message(msg)
            server.quit()
            
        except Exception as e:
            self.logger.error(f"Failed to send email alert: {str(e)}")

# ä½¿ç”¨ç¤ºä¾‹
def monitor_airflow_security():
    """ç›‘æ§Airflowå®‰å…¨"""
    detector = IntrusionDetector('elasticsearch.company.com', 9200)
    
    # åˆ†æWebserveræ—¥å¿—
    webserver_activities = detector.analyze_logs('/var/log/airflow/webserver.log')
    
    # åˆ†æScheduleræ—¥å¿—
    scheduler_activities = detector.analyze_logs('/var/log/airflow/scheduler.log')
    
    # åˆå¹¶æ‰€æœ‰å¯ç–‘æ´»åŠ¨
    all_activities = webserver_activities + scheduler_activities
    
    # ç”Ÿæˆå‘Šè­¦
    if all_activities:
        detector.generate_alert(all_activities)
        
        # é˜»æ­¢æ¶æ„IP
        for activity in all_activities:
            ip_match = re.search(r'(\d+\.\d+\.\d+\.\d+)', activity['content'])
            if ip_match:
                detector.block_ip(ip_match.group(1))
```

### 4.3 DDoSé˜²æŠ¤
```yaml
# DDoSé˜²æŠ¤é…ç½®
ddos_protection:
  # AWS Shieldé…ç½®
  aws_shield:
    enabled: true
    protection_level: advanced
    protected_resources:
      - load_balancer: airflow-web-lb
      - cloudfront_distribution: airflow-cdn
      
    # é˜²æŠ¤è§„åˆ™
    protection_rules:
      - name: rate_limiting
        type: rate_based
        limit: 1000  # æ¯5åˆ†é’Ÿè¯·æ±‚æ•°
        period: 300  # 5åˆ†é’Ÿ
        action: block
        
      - name: geographic_blocking
        type: geographic
        blocked_countries:
          - CN
          - RU
          - KP
        action: block
        
      - name: ip_reputation
        type: ip_reputation
        reputation_lists:
          - spamhaus
          - abusech
        action: block
        
  # Cloudflareé…ç½®
  cloudflare:
    enabled: true
    zone: airflow.company.com
    security_level: high
    challenge_ttl: 1800  # 30åˆ†é’Ÿ
    
    # é˜²ç«å¢™è§„åˆ™
    firewall_rules:
      - name: block_known_bad_ips
        expression: ip.src in $known_bad_ips
        action: block
        description: "Block known malicious IP addresses"
        
      - name: rate_limit_api
        expression: http.request.uri.path contains "/api/" and cf.bot_management.score < 30
        action: challenge
        description: "Rate limit API requests from low reputation clients"
        
      - name: block_sql_injection
        expression: http.request.body contains "union select" or http.request.body contains "drop table"
        action: block
        description: "Block SQL injection attempts"
        
    # WAFè§„åˆ™
    waf_rules:
      - name: owasp_top_10
        enabled: true
        ruleset: owasp_core_ruleset
        
      - name: custom_rules
        enabled: true
        rules:
          - id: 1001
            description: "Block excessive requests"
            expression: cf.rate_limiting.requests_per_minute > 1000
            action: block
            
          - id: 1002
            description: "Challenge suspicious user agents"
            expression: http.user_agent contains "bot" or http.user_agent contains "crawler"
            action: challenge
```

## 5. åº”ç”¨å®‰å…¨

### 5.1 DAGå®‰å…¨
```python
# dag_security.py
import os
import ast
import hashlib
from datetime import datetime
import yaml
from airflow.models import DagBag, DagModel
from airflow.utils.db import provide_session
from sqlalchemy.orm import Session

class DAGSecurityScanner:
    def __init__(self):
        self.dangerous_modules = {
            'os', 'subprocess', 'sys', 'importlib', 'exec', 'eval'
        }
        self.dangerous_functions = {
            'os.system', 'os.popen', 'subprocess.call', 'subprocess.run',
            'exec', 'eval', 'compile', 'open', 'file'
        }
        
    def scan_dag_file(self, file_path):
        """æ‰«æDAGæ–‡ä»¶çš„å®‰å…¨é—®é¢˜"""
        issues = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # è§£æPythonä»£ç 
            tree = ast.parse(content)
            
            # æ£€æŸ¥å¯¼å…¥è¯­å¥
            issues.extend(self._check_imports(tree, file_path))
            
            # æ£€æŸ¥å‡½æ•°è°ƒç”¨
            issues.extend(self._check_function_calls(tree, file_path))
            
            # æ£€æŸ¥å­—ç¬¦ä¸²æ‰§è¡Œ
            issues.extend(self._check_string_execution(tree, file_path))
            
            # è®¡ç®—æ–‡ä»¶å“ˆå¸Œå€¼ç”¨äºå®Œæ•´æ€§æ£€æŸ¥
            file_hash = hashlib.sha256(content.encode()).hexdigest()
            issues.append({
                'type': 'file_hash',
                'file': file_path,
                'hash': file_hash,
                'severity': 'info'
            })
            
        except SyntaxError as e:
            issues.append({
                'type': 'syntax_error',
                'file': file_path,
                'line': e.lineno,
                'message': str(e),
                'severity': 'critical'
            })
        except Exception as e:
            issues.append({
                'type': 'scan_error',
                'file': file_path,
                'message': str(e),
                'severity': 'high'
            })
            
        return issues
        
    def _check_imports(self, tree, file_path):
        """æ£€æŸ¥å¯¼å…¥è¯­å¥"""
        issues = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    if alias.name in self.dangerous_modules:
                        issues.append({
                            'type': 'dangerous_import',
                            'file': file_path,
                            'line': node.lineno,
                            'module': alias.name,
                            'severity': 'high'
                        })
            elif isinstance(node, ast.ImportFrom):
                if node.module in self.dangerous_modules:
                    issues.append({
                        'type': 'dangerous_import',
                        'file': file_path,
                        'line': node.lineno,
                        'module': node.module,
                        'severity': 'high'
                    })
                    
        return issues
        
    def _check_function_calls(self, tree, file_path):
        """æ£€æŸ¥å‡½æ•°è°ƒç”¨"""
        issues = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                # æ£€æŸ¥å‡½æ•°è°ƒç”¨
                if isinstance(node.func, ast.Name):
                    func_name = node.func.id
                    if func_name in self.dangerous_functions:
                        issues.append({
                            'type': 'dangerous_function',
                            'file': file_path,
                            'line': node.lineno,
                            'function': func_name,
                            'severity': 'high'
                        })
                elif isinstance(node.func, ast.Attribute):
                    # æ£€æŸ¥æ–¹æ³•è°ƒç”¨
                    attr_name = self._get_attribute_name(node.func)
                    if attr_name in self.dangerous_functions:
                        issues.append({
                            'type': 'dangerous_function',
                            'file': file_path,
                            'line': node.lineno,
                            'function': attr_name,
                            'severity': 'high'
                        })
                        
        return issues
        
    def _get_attribute_name(self, node):
        """è·å–å±æ€§åç§°"""
        if isinstance(node, ast.Attribute):
            return f"{self._get_attribute_name(node.value)}.{node.attr}"
        elif isinstance(node, ast.Name):
            return node.id
        else:
            return str(node)
            
    def _check_string_execution(self, tree, file_path):
        """æ£€æŸ¥å­—ç¬¦ä¸²æ‰§è¡Œ"""
        issues = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                if isinstance(node.func, ast.Name) and node.func.id in ['exec', 'eval']:
                    # æ£€æŸ¥exec/evalè°ƒç”¨
                    issues.append({
                        'type': 'string_execution',
                        'file': file_path,
                        'line': node.lineno,
                        'function': node.func.id,
                        'severity': 'critical'
                    })
                    
        return issues
        
    def scan_all_dags(self, dag_directory):
        """æ‰«ææ‰€æœ‰DAGæ–‡ä»¶"""
        all_issues = []
        
        for root, dirs, files in os.walk(dag_directory):
            for file in files:
                if file.endswith('.py') and file.startswith('dag'):
                    file_path = os.path.join(root, file)
                    issues = self.scan_dag_file(file_path)
                    all_issues.extend(issues)
                    
        return all_issues
        
    def generate_security_report(self, issues):
        """ç”Ÿæˆå®‰å…¨æŠ¥å‘Š"""
        report = {
            'scan_time': datetime.now().isoformat(),
            'total_files_scanned': len(set([issue['file'] for issue in issues])),
            'total_issues': len(issues),
            'critical_issues': len([i for i in issues if i['severity'] == 'critical']),
            'high_issues': len([i for i in issues if i['severity'] == 'high']),
            'medium_issues': len([i for i in issues if i['severity'] == 'medium']),
            'low_issues': len([i for i in issues if i['severity'] == 'low']),
            'issues_by_file': {},
            'issues_by_type': {}
        }
        
        # æŒ‰æ–‡ä»¶åˆ†ç»„é—®é¢˜
        for issue in issues:
            file = issue['file']
            if file not in report['issues_by_file']:
                report['issues_by_file'][file] = []
            report['issues_by_file'][file].append(issue)
            
            # æŒ‰ç±»å‹åˆ†ç»„é—®é¢˜
            issue_type = issue['type']
            if issue_type not in report['issues_by_type']:
                report['issues_by_type'][issue_type] = 0
            report['issues_by_type'][issue_type] += 1
            
        return report

# DAGæƒé™éªŒè¯è£…é¥°å™¨
def dag_owner_required(func):
    """DAGæ‰€æœ‰è€…æƒé™éªŒè¯è£…é¥°å™¨"""
    def wrapper(*args, **kwargs):
        from flask_login import current_user
        from airflow.models import DagModel
        
        # è·å–DAG ID
        dag_id = kwargs.get('dag_id') or args[0] if args else None
        if not dag_id:
            raise PermissionError("DAG ID is required")
            
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºDAGæ‰€æœ‰è€…
        dag = DagModel.get_dagmodel(dag_id)
        if not dag:
            raise ValueError(f"DAG {dag_id} not found")
            
        # è¿™é‡Œåº”è¯¥é›†æˆå®é™…çš„æ‰€æœ‰æƒæ£€æŸ¥é€»è¾‘
        # ä¾‹å¦‚ä»æ•°æ®åº“æˆ–LDAPè·å–DAGæ‰€æœ‰æƒä¿¡æ¯
        if not is_dag_owner(current_user, dag_id):
            raise PermissionError(f"User {current_user.username} is not owner of DAG {dag_id}")
            
        return func(*args, **kwargs)
    return wrapper

def is_dag_owner(user, dag_id):
    """æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸ºDAGæ‰€æœ‰è€…"""
    # å®é™…å®ç°åº”è¯¥æŸ¥è¯¢æ•°æ®åº“æˆ–å¤–éƒ¨ç³»ç»Ÿ
    # è¿™é‡Œæ˜¯ç¤ºä¾‹å®ç°
    dag_owners = {
        'example_dag': ['admin', 'dev1'],
        'finance_dag': ['finance_team'],
        'hr_dag': ['hr_team']
    }
    
    owners = dag_owners.get(dag_id, [])
    return user.username in owners or 'admin' in [role.name for role in user.roles]
```

### 5.2 ä»£ç å®¡æŸ¥æµç¨‹
```yaml
# ä»£ç å®¡æŸ¥æµç¨‹é…ç½®
code_review_process:
  # é¢„æäº¤æ£€æŸ¥
  pre_commit_hooks:
    - name: security_scan
      command: python dag_security.py scan --file {file}
      stages: [commit]
      
    - name: syntax_check
      command: python -m py_compile {file}
      stages: [commit]
      
    - name: style_check
      command: flake8 {file}
      stages: [commit]
      
  # åˆå¹¶è¯·æ±‚æ£€æŸ¥
  merge_request_checks:
    - name: full_security_scan
      command: python dag_security.py scan-all --directory dags/
      required: true
      
    - name: dependency_check
      command: safety check
      required: true
      
    - name: unit_tests
      command: pytest tests/
      required: true
      
    - name: integration_tests
      command: pytest tests/integration/
      required: false
      
  # è‡ªåŠ¨åŒ–å®‰å…¨æ‰«æ
  automated_scanning:
    # å®šæœŸæ‰«æ
    scheduled_scans:
      - name: daily_security_scan
        schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹
        command: python dag_security.py scan-all --directory dags/ --report security_report.json
        
      - name: weekly_dependency_check
        schedule: "0 3 * * 1"  # æ¯å‘¨ä¸€å‡Œæ™¨3ç‚¹
        command: safety check --full-report > dependency_report.txt
        
    # å®æ—¶ç›‘æ§
    real_time_monitoring:
      - name: file_integrity_monitoring
        command: python fim_monitor.py --directory dags/
        description: "ç›‘æ§DAGæ–‡ä»¶å®Œæ•´æ€§å˜åŒ–"
        
      - name: suspicious_activity_detection
        command: python intrusion_detection.py --log-dir /var/log/airflow/
        description: "æ£€æµ‹å¯ç–‘æ´»åŠ¨"
```

### 5.3 å®‰å…¨æµ‹è¯•
```python
# security_testing.py
import unittest
import tempfile
import os
from airflow.models import DagBag
from dag_security import DAGSecurityScanner

class SecurityTestCase(unittest.TestCase):
    def setUp(self):
        self.scanner = DAGSecurityScanner()
        self.test_dag_dir = tempfile.mkdtemp()
        
    def tearDown(self):
        import shutil
        shutil.rmtree(self.test_dag_dir)
        
    def test_dangerous_import_detection(self):
        """æµ‹è¯•å±é™©å¯¼å…¥æ£€æµ‹"""
        # åˆ›å»ºåŒ…å«å±é™©å¯¼å…¥çš„æµ‹è¯•DAG
        test_dag_content = '''
from airflow import DAG
from datetime import datetime
import os  # å±é™©å¯¼å…¥

dag = DAG('test_dag', start_date=datetime(2023, 1, 1))

def dangerous_task():
    os.system('ls -la')  # å±é™©å‡½æ•°è°ƒç”¨
'''
        
        test_file = os.path.join(self.test_dag_dir, 'dangerous_dag.py')
        with open(test_file, 'w') as f:
            f.write(test_dag_content)
            
        # æ‰«ææ–‡ä»¶
        issues = self.scanner.scan_dag_file(test_file)
        
        # éªŒè¯æ£€æµ‹åˆ°çš„é—®é¢˜
        dangerous_imports = [i for i in issues if i['type'] == 'dangerous_import']
        self.assertEqual(len(dangerous_imports), 1)
        self.assertEqual(dangerous_imports[0]['module'], 'os')
        
        dangerous_functions = [i for i in issues if i['type'] == 'dangerous_function']
        self.assertEqual(len(dangerous_functions), 1)
        self.assertEqual(dangerous_functions[0]['function'], 'os.system')
        
    def test_string_execution_detection(self):
        """æµ‹è¯•å­—ç¬¦ä¸²æ‰§è¡Œæ£€æµ‹"""
        # åˆ›å»ºåŒ…å«exec/evalçš„æµ‹è¯•DAG
        test_dag_content = '''
from airflow import DAG
from datetime import datetime

dag = DAG('test_dag', start_date=datetime(2023, 1, 1))

def unsafe_task():
    user_input = "print('hello')"
    exec(user_input)  # å±é™©å‡½æ•°è°ƒç”¨
    
    eval("1+1")  # å±é™©å‡½æ•°è°ƒç”¨
'''
        
        test_file = os.path.join(self.test_dag_dir, 'unsafe_dag.py')
        with open(test_file, 'w') as f:
            f.write(test_dag_content)
            
        # æ‰«ææ–‡ä»¶
        issues = self.scanner.scan_dag_file(test_file)
        
        # éªŒè¯æ£€æµ‹åˆ°çš„é—®é¢˜
        string_executions = [i for i in issues if i['type'] == 'string_execution']
        self.assertEqual(len(string_executions), 2)
        
        functions = [i['function'] for i in string_executions]
        self.assertIn('exec', functions)
        self.assertIn('eval', functions)
        
    def test_safe_dag_validation(self):
        """æµ‹è¯•å®‰å…¨DAGéªŒè¯"""
        # åˆ›å»ºå®‰å…¨çš„æµ‹è¯•DAG
        test_dag_content = '''
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

dag = DAG('safe_dag', start_date=datetime(2023, 1, 1))

task1 = BashOperator(
    task_id='print_date',
    bash_command='date',
    dag=dag
)
'''
        
        test_file = os.path.join(self.test_dag_dir, 'safe_dag.py')
        with open(test_file, 'w') as f:
            f.write(test_dag_content)
            
        # æ‰«ææ–‡ä»¶
        issues = self.scanner.scan_dag_file(test_file)
        
        # éªŒè¯æ²¡æœ‰æ£€æµ‹åˆ°å®‰å…¨é—®é¢˜
        security_issues = [i for i in issues 
                          if i['type'] in ['dangerous_import', 'dangerous_function', 'string_execution']]
        self.assertEqual(len(security_issues), 0)
        
    def test_dag_loading_security(self):
        """æµ‹è¯•DAGåŠ è½½å®‰å…¨æ€§"""
        # åˆ›å»ºæµ‹è¯•DAGåŒ…
        dagbag = DagBag(dag_folder=self.test_dag_dir, include_examples=False)
        
        # éªŒè¯DAGåŒ…åŠ è½½æˆåŠŸ
        self.assertFalse(dagbag.import_errors)
        
        # éªŒè¯DAGæ•°é‡
        self.assertGreaterEqual(len(dagbag.dags), 0)

if __name__ == '__main__':
    unittest.main()
```

## 6. ç›‘æ§å’Œå®¡è®¡

### 6.1 å®‰å…¨ç›‘æ§
```yaml
# å®‰å…¨ç›‘æ§é…ç½®
security_monitoring:
  # æ—¥å¿—ç›‘æ§
  log_monitoring:
    # æ–‡ä»¶å®Œæ•´æ€§ç›‘æ§
    file_integrity_monitoring:
      enabled: true
      directories:
        - /opt/airflow/dags/
        - /opt/airflow/config/
        - /opt/airflow/plugins/
      ignore_patterns:
        - "*.log"
        - "*.tmp"
      alert_threshold: 1  # ä»»ä½•å˜åŒ–éƒ½å‘Šè­¦
      
    # å®‰å…¨æ—¥å¿—ç›‘æ§
    security_log_monitoring:
      enabled: true
      log_files:
        - /var/log/airflow/webserver.log
        - /var/log/airflow/scheduler.log
        - /var/log/airflow/worker.log
      patterns:
        - "ERROR"
        - "WARNING"
        - "FAILED"
        - "denied"
        - "blocked"
      alert_threshold: 10  # 10æ¬¡åŒ¹é…å‘Šè­¦
      
  # è¡Œä¸ºç›‘æ§
  behavior_monitoring:
    # ç”¨æˆ·è¡Œä¸ºç›‘æ§
    user_behavior_monitoring:
      enabled: true
      metrics:
        - login_attempts
        - failed_logins
        - privilege_escalations
        - unusual_access_patterns
      baseline_period: 30  # å¤©
      
    # ç³»ç»Ÿè¡Œä¸ºç›‘æ§
    system_behavior_monitoring:
      enabled: true
      metrics:
        - cpu_usage
        - memory_usage
        - disk_io
        - network_traffic
      anomaly_threshold: 2.0  # 2å€æ ‡å‡†å·®
      
  # å‘Šè­¦é…ç½®
  alerting:
    # å‘Šè­¦çº§åˆ«
    alert_levels:
      critical:
        response_time: 5  # åˆ†é’Ÿ
        notification_channels:
          - sms
          - phone
          - email
          
      high:
        response_time: 30  # åˆ†é’Ÿ
        notification_channels:
          - email
          - slack
          
      medium:
        response_time: 2  # å°æ—¶
        notification_channels:
          - email
          
      low:
        response_time: 24  # å°æ—¶
        notification_channels:
          - email
          
    # å‘Šè­¦æŠ‘åˆ¶
    alert_suppression:
      enabled: true
      suppression_rules:
        - name: maintenance_window
          condition: time between 02:00-04:00
          suppress_alerts: true
          
        - name: known_patterns
          condition: alert_pattern in known_false_positives
          suppress_alerts: true
```

### 6.2 å®¡è®¡æ—¥å¿—
```python
# audit_logging.py
import logging
import json
from datetime import datetime
from functools import wraps
from flask import request, session
from airflow.models import Log
from airflow.utils.db import provide_session
from sqlalchemy.orm import Session

class AuditLogger:
    def __init__(self, log_level=logging.INFO):
        self.logger = logging.getLogger('airflow.audit')
        self.logger.setLevel(log_level)
        
        # é…ç½®å®¡è®¡æ—¥å¿—å¤„ç†å™¨
        handler = logging.FileHandler('/var/log/airflow/audit.log')
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        
    def log_event(self, event_type, user=None, resource=None, details=None):
        """è®°å½•å®¡è®¡äº‹ä»¶"""
        audit_event = {
            'timestamp': datetime.now().isoformat(),
            'event_type': event_type,
            'user': user or self._get_current_user(),
            'resource': resource,
            'details': details or {},
            'ip_address': self._get_client_ip(),
            'user_agent': request.headers.get('User-Agent') if request else None
        }
        
        self.logger.info(json.dumps(audit_event))
        
        # åŒæ—¶è®°å½•åˆ°æ•°æ®åº“
        self._log_to_database(audit_event)
        
    def _get_current_user(self):
        """è·å–å½“å‰ç”¨æˆ·"""
        try:
            if 'user' in session:
                return session['user'].username
            elif hasattr(request, 'user') and request.user:
                return request.user.username
        except:
            pass
        return 'anonymous'
        
    def _get_client_ip(self):
        """è·å–å®¢æˆ·ç«¯IP"""
        if request:
            return request.environ.get('HTTP_X_REAL_IP', request.remote_addr)
        return 'unknown'
        
    @provide_session
    def _log_to_database(self, event, session: Session = None):
        """è®°å½•åˆ°æ•°æ®åº“"""
        try:
            log_entry = Log(
                event=event['event_type'],
                task_instance=None,
                owner=event['user'],
                extra=json.dumps({
                    'resource': event['resource'],
                    'details': event['details'],
                    'ip_address': event['ip_address'],
                    'user_agent': event['user_agent']
                }),
                timestamp=datetime.fromisoformat(event['timestamp'])
            )
            session.add(log_entry)
            session.commit()
        except Exception as e:
            self.logger.error(f"Failed to log to database: {str(e)}")

# å®¡è®¡è£…é¥°å™¨
def audit_log(event_type, resource_extractor=None):
    """å®¡è®¡æ—¥å¿—è£…é¥°å™¨"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            audit_logger = AuditLogger()
            
            # æå–èµ„æºä¿¡æ¯
            resource = None
            if resource_extractor:
                try:
                    resource = resource_extractor(*args, **kwargs)
                except Exception as e:
                    audit_logger.logger.warning(f"Failed to extract resource: {str(e)}")
                    
            # è®°å½•å‡½æ•°è°ƒç”¨å‰äº‹ä»¶
            audit_logger.log_event(
                event_type=f"{event_type}_start",
                resource=resource,
                details={
                    'function': func.__name__,
                    'args': str(args)[:100],  # é™åˆ¶é•¿åº¦
                    'kwargs': str(kwargs)[:100]  # é™åˆ¶é•¿åº¦
                }
            )
            
            try:
                # æ‰§è¡Œå‡½æ•°
                result = func(*args, **kwargs)
                
                # è®°å½•æˆåŠŸäº‹ä»¶
                audit_logger.log_event(
                    event_type=f"{event_type}_success",
                    resource=resource,
                    details={
                        'function': func.__name__,
                        'result': str(result)[:100]  # é™åˆ¶é•¿åº¦
                    }
                )
                
                return result
            except Exception as e:
                # è®°å½•å¤±è´¥äº‹ä»¶
                audit_logger.log_event(
                    event_type=f"{event_type}_failure",
                    resource=resource,
                    details={
                        'function': func.__name__,
                        'error': str(e)
                    }
                )
                raise
                
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@audit_log('dag_deployment', lambda dag_id, *args, **kwargs: dag_id)
def deploy_dag(dag_id, dag_content):
    """éƒ¨ç½²DAG"""
    # DAGéƒ¨ç½²é€»è¾‘
    pass

@audit_log('user_login', lambda username, *args, **kwargs: username)
def user_login(username, password):
    """ç”¨æˆ·ç™»å½•"""
    # ç”¨æˆ·ç™»å½•é€»è¾‘
    pass
```

### 6.3 åˆè§„æ€§æ£€æŸ¥
```python
# compliance_check.py
import json
import yaml
from datetime import datetime, timedelta
from airflow.models import DagRun, TaskInstance, Log
from airflow.utils.state import State

class ComplianceChecker:
    def __init__(self, config_file):
        with open(config_file, 'r') as f:
            self.config = yaml.safe_load(f)
            
    def run_compliance_check(self):
        """è¿è¡Œåˆè§„æ€§æ£€æŸ¥"""
        report = {
            'check_time': datetime.now().isoformat(),
            'checks': {}
        }
        
        # è¿è¡Œå„é¡¹æ£€æŸ¥
        report['checks']['access_control'] = self._check_access_control()
        report['checks']['data_protection'] = self._check_data_protection()
        report['checks']['audit_logging'] = self._check_audit_logging()
        report['checks']['vulnerability_management'] = self._check_vulnerability_management()
        report['checks']['incident_response'] = self._check_incident_response()
        
        return report
        
    def _check_access_control(self):
        """æ£€æŸ¥è®¿é—®æ§åˆ¶åˆè§„æ€§"""
        findings = []
        
        # æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†RBAC
        if not self.config.get('rbac_enabled', False):
            findings.append({
                'issue': 'RBAC not enabled',
                'severity': 'high',
                'recommendation': 'Enable Role-Based Access Control'
            })
            
        # æ£€æŸ¥é»˜è®¤è´¦æˆ·
        default_accounts = self._find_default_accounts()
        if default_accounts:
            findings.append({
                'issue': f'Default accounts found: {default_accounts}',
                'severity': 'critical',
                'recommendation': 'Remove or secure default accounts'
            })
            
        return {
            'status': 'fail' if findings else 'pass',
            'findings': findings
        }
        
    def _check_data_protection(self):
        """æ£€æŸ¥æ•°æ®ä¿æŠ¤åˆè§„æ€§"""
        findings = []
        
        # æ£€æŸ¥é™æ€æ•°æ®åŠ å¯†
        if not self.config.get('encryption_at_rest', False):
            findings.append({
                'issue': 'Data at rest not encrypted',
                'severity': 'high',
                'recommendation': 'Enable encryption for data at rest'
            })
            
        # æ£€æŸ¥ä¼ è¾“æ•°æ®åŠ å¯†
        if not self.config.get('encryption_in_transit', False):
            findings.append({
                'issue': 'Data in transit not encrypted',
                'severity': 'high',
                'recommendation': 'Enable TLS encryption for all communications'
            })
            
        return {
            'status': 'fail' if findings else 'pass',
            'findings': findings
        }
        
    def _check_audit_logging(self):
        """æ£€æŸ¥å®¡è®¡æ—¥å¿—åˆè§„æ€§"""
        findings = []
        
        # æ£€æŸ¥å®¡è®¡æ—¥å¿—æ˜¯å¦å¯ç”¨
        if not self.config.get('audit_logging_enabled', False):
            findings.append({
                'issue': 'Audit logging not enabled',
                'severity': 'high',
                'recommendation': 'Enable comprehensive audit logging'
            })
            
        # æ£€æŸ¥æ—¥å¿—ä¿ç•™æœŸ
        retention_days = self.config.get('log_retention_days', 0)
        if retention_days < 90:
            findings.append({
                'issue': f'Log retention period too short: {retention_days} days',
                'severity': 'medium',
                'recommendation': 'Set log retention to at least 90 days'
            })
            
        return {
            'status': 'fail' if findings else 'pass',
            'findings': findings
        }
        
    def _check_vulnerability_management(self):
        """æ£€æŸ¥æ¼æ´ç®¡ç†åˆè§„æ€§"""
        findings = []
        
        # æ£€æŸ¥ä¸Šæ¬¡å®‰å…¨æ‰«ææ—¶é—´
        last_scan = self.config.get('last_security_scan')
        if last_scan:
            scan_date = datetime.fromisoformat(last_scan)
            if datetime.now() - scan_date > timedelta(days=30):
                findings.append({
                    'issue': 'Security scan overdue',
                    'severity': 'medium',
                    'recommendation': 'Run security scan'
                })
                
        return {
            'status': 'fail' if findings else 'pass',
            'findings': findings
        }
        
    def _check_incident_response(self):
        """æ£€æŸ¥äº‹ä»¶å“åº”åˆè§„æ€§"""
        findings = []
        
        # æ£€æŸ¥æ˜¯å¦æœ‰äº‹ä»¶å“åº”è®¡åˆ’
        if not self.config.get('incident_response_plan', False):
            findings.append({
                'issue': 'No incident response plan',
                'severity': 'high',
                'recommendation': 'Create and maintain incident response plan'
            })
            
        return {
            'status': 'fail' if findings else 'pass',
            'findings': findings
        }
        
    def _find_default_accounts(self):
        """æŸ¥æ‰¾é»˜è®¤è´¦æˆ·"""
        # è¿™é‡Œåº”è¯¥æŸ¥è¯¢å®é™…çš„ç”¨æˆ·æ•°æ®åº“
        # ç¤ºä¾‹å®ç°
        default_accounts = []
        # å®é™…å®ç°ä¼šæŸ¥è¯¢ç”¨æˆ·è¡¨
        return default_accounts

# åˆè§„æ€§é…ç½®ç¤ºä¾‹
compliance_config = {
    'rbac_enabled': True,
    'encryption_at_rest': True,
    'encryption_in_transit': True,
    'audit_logging_enabled': True,
    'log_retention_days': 365,
    'last_security_scan': '2023-06-15T10:30:00',
    'incident_response_plan': True
}

# ä¿å­˜é…ç½®
with open('compliance_config.yaml', 'w') as f:
    yaml.dump(compliance_config, f)
```

## 7. åº”æ€¥å“åº”

### 7.1 å®‰å…¨äº‹ä»¶å“åº”æµç¨‹
```mermaid
graph TD
    A[å®‰å…¨äº‹ä»¶æ£€æµ‹] --> B{æ˜¯å¦ç¡®è®¤äº‹ä»¶?}
    B -->|æ˜¯| C[å¯åŠ¨åº”æ€¥å“åº”]
    B -->|å¦| D[ç»§ç»­ç›‘æ§]
    C --> E[äº‹ä»¶è¯„ä¼°å’Œåˆ†ç±»]
    E --> F[é€šçŸ¥ç›¸å…³äººå‘˜]
    F --> G[éåˆ¶å’Œéš”ç¦»]
    G --> H[è°ƒæŸ¥å’Œåˆ†æ]
    H --> I[æ¸…é™¤å’Œæ¢å¤]
    I --> J[äº‹ååˆ†æå’Œæ”¹è¿›]
    J --> K[æ›´æ–°å®‰å…¨ç­–ç•¥]
```

### 7.2 åº”æ€¥å“åº”è„šæœ¬
```bash
#!/bin/bash
# incident_response.sh

# å®‰å…¨äº‹ä»¶å“åº”è„šæœ¬

# äº‹ä»¶æ£€æµ‹å‡½æ•°
detect_security_incident() {
    local log_file=$1
    local pattern=$2
    
    echo "Detecting security incident in $log_file with pattern: $pattern"
    
    # æœç´¢æ—¥å¿—ä¸­çš„å®‰å…¨äº‹ä»¶
    grep -i "$pattern" $log_file | while read line; do
        echo "Security incident detected: $line"
        # è§¦å‘å‘Šè­¦
        trigger_alert "Security incident detected: $line"
    done
}

# è§¦å‘å‘Šè­¦å‡½æ•°
trigger_alert() {
    local message=$1
    
    echo "Triggering security alert: $message"
    
    # å‘é€Slackå‘Šè­¦
    curl -X POST -H 'Content-type: application/json' \
         --data "{\"text\":\"ğŸš¨ Security Alert: $message\"}" \
         $SLACK_WEBHOOK_URL
         
    # å‘é€é‚®ä»¶å‘Šè­¦
    echo "$message" | mail -s "Security Alert" $ALERT_EMAIL
}

# éš”ç¦»å—æ„ŸæŸ“ç³»ç»Ÿ
isolate_system() {
    local system_ip=$1
    
    echo "Isolating system: $system_ip"
    
    # ä½¿ç”¨iptableséš”ç¦»ç³»ç»Ÿ
    iptables -A INPUT -s $system_ip -j DROP
    iptables -A OUTPUT -d $system_ip -j DROP
    
    echo "System $system_ip isolated"
}

# æ”¶é›†è¯æ®
collect_evidence() {
    local system_ip=$1
    local evidence_dir="/var/evidence/$(date +%Y%m%d_%H%M%S)"
    
    echo "Collecting evidence from system: $system_ip"
    
    # åˆ›å»ºè¯æ®ç›®å½•
    mkdir -p $evidence_dir
    
    # æ”¶é›†ç³»ç»Ÿä¿¡æ¯
    ssh $system_ip "ps aux" > $evidence_dir/processes.txt
    ssh $system_ip "netstat -tulpn" > $evidence_dir/network_connections.txt
    ssh $system_ip "ls -la /tmp" > $evidence_dir/temp_files.txt
    
    # æ”¶é›†æ—¥å¿—æ–‡ä»¶
    scp $system_ip:/var/log/airflow/*.log $evidence_dir/
    
    echo "Evidence collected in $evidence_dir"
}

# æ¸…é™¤æ¶æ„è½¯ä»¶
cleanup_malware() {
    local system_ip=$1
    
    echo "Cleaning up malware on system: $system_ip"
    
    # åœæ­¢AirflowæœåŠ¡
    ssh $system_ip "systemctl stop airflow-webserver airflow-scheduler"
    
    # åˆ é™¤å¯ç–‘æ–‡ä»¶
    ssh $system_ip "find /tmp -name '*.sh' -mtime -7 -delete"
    ssh $system_ip "find /opt/airflow/dags -name '*.py' -mtime -7 -exec grep -l 'os.system\|subprocess' {} \; | xargs rm -f"
    
    # é‡å¯æœåŠ¡
    ssh $system_ip "systemctl start airflow-webserver airflow-scheduler"
    
    echo "Malware cleanup completed on $system_ip"
}
```

é€šè¿‡å®æ–½æœ¬å®‰å…¨åŠ å›ºæŒ‡å—ï¼Œæ‚¨å¯ä»¥æ˜¾è‘—æé«˜Apache Airflowç¯å¢ƒçš„å®‰å…¨æ€§ï¼Œä¿æŠ¤ç³»ç»Ÿå…å—å„ç§å®‰å…¨å¨èƒã€‚è®°ä½å®‰å…¨æ˜¯ä¸€ä¸ªæŒç»­çš„è¿‡ç¨‹ï¼Œéœ€è¦å®šæœŸå®¡æŸ¥å’Œæ›´æ–°å®‰å…¨æªæ–½ã€‚