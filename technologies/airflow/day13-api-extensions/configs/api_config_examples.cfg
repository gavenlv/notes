[api]
# REST API配置
auth_backend = airflow.api.auth.backend.basic_auth
maximum_page_limit = 100
fallback_page_limit = 100

# 是否启用REST API
enable_experimental_api = False

[webserver]
# Web服务器配置
rbac = True

# API访问日志
access_logfile = /var/log/airflow/access.log
error_logfile = /var/log/airflow/error.log

# Web服务器安全配置
secure_mode = True
cookie_secure = True
cookie_httponly = True
cookie_samesite = Lax

# CSRF保护
wtf_csrf_enabled = True
wtf_csrf_time_limit = 3600

[core]
# 核心配置
default_timezone = utc

# 安全配置
fernet_key = your_fernet_key_here
secret_key = your_secret_key_here

# 数据库连接
sql_alchemy_conn = postgresql+psycopg2://airflow:airflow@localhost:5432/airflow

# 连接池配置
sql_alchemy_pool_enabled = True
sql_alchemy_pool_size = 5
sql_alchemy_max_overflow = 10

[logging]
# 日志配置
base_log_folder = /var/log/airflow
logging_level = INFO

# API请求日志
fab_logging_level = WARN

[celery]
# Celery配置（如果使用CeleryExecutor）
celery_app_name = airflow.executors.celery_executor
worker_concurrency = 16

# Redis或RabbitMQ连接
broker_url = redis://localhost:6379/0
result_backend = redis://localhost:6379/0

# SSL配置（如果需要）
# broker_use_ssl = True
# redis_backend_use_ssl = True

[smtp]
# SMTP配置（用于邮件通知）
smtp_host = smtp.gmail.com
smtp_starttls = True
smtp_ssl = False
smtp_port = 587
smtp_mail_from = airflow@example.com

[kerberos]
# Kerberos配置（如果使用Kerberos认证）
ccache = /var/run/airflow/airflow_krb5_ccache
principal = airflow/_HOST@EXAMPLE.COM

[github_enterprise]
# GitHub Enterprise配置（如果使用GitHub OAuth）
api_rev = v3

[oauth]
# OAuth配置（如果使用OAuth）
client_id = your_client_id
client_secret = your_client_secret
oauth_callback_url = http://localhost:8080/oauth/callback

[ldap]
# LDAP配置（如果使用LDAP认证）
uri = ldap://ldap.example.com
user_filter = objectClass=*
user_name_attr = uid
group_member_attr = memberOf
superuser_filter = memberOf=cn=airflow_admins,ou=groups,dc=example,dc=com
data_profiler_filter = memberOf=cn=airflow_users,ou=groups,dc=example,dc=com
bind_user = cn=airflow,ou=services,dc=example,dc=com
bind_password = your_bind_password
basedn = dc=example,dc=com
cacert = /etc/ssl/certs/ldap_ca.crt
search_scope = SUBTREE

[metrics]
# 指标配置（用于监控）
metrics_allow_list = 
metrics_block_list = 
stat_name_handler = 
statsd_on = False
statsd_host = localhost
statsd_port = 8125
statsd_prefix = airflow

[elasticsearch]
# Elasticsearch配置（如果使用ES进行日志存储）
elasticsearch_host = localhost:9200
elasticsearch_log_id_template = {dag_id}-{task_id}-{execution_date}-{try_number}
elasticsearch_end_of_log_mark = end_of_log

[elasticsearch_configs]
# Elasticsearch连接配置
use_ssl = False
verify_certs = True

[kubernetes]
# Kubernetes配置（如果在K8s环境中运行）
pod_template_file = /path/to/pod_template.yaml
worker_container_repository = apache/airflow
worker_container_tag = 2.5.0
namespace = airflow
delete_worker_pods = True
delete_worker_pods_on_failure = False
worker_pods_creation_batch_size = 1
multi_namespace_mode = False
in_cluster = True
kube_client_request_args = 
delete_option_kwargs = 

[secrets]
# 密钥管理配置
backend = airflow.providers.hashicorp.secrets.vault.VaultBackend
backend_kwargs = {"connections_path": "airflow/connections", "variables_path": "airflow/variables"}