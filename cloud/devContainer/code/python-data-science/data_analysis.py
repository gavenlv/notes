#!/usr/bin/env python3
"""
Pythonæ•°æ®ç§‘å­¦ç¯å¢ƒç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨DevContainerè¿›è¡Œæ•°æ®ç§‘å­¦å¼€å‘
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

def generate_sample_data():
    """ç”Ÿæˆç¤ºä¾‹æ•°æ®"""
    X, y = make_classification(
        n_samples=1000, 
        n_features=20, 
        n_informative=15, 
        n_redundant=5,
        random_state=42
    )
    
    # è½¬æ¢ä¸ºDataFrame
    feature_names = [f'feature_{i}' for i in range(X.shape[1])]
    df = pd.DataFrame(X, columns=feature_names)
    df['target'] = y
    
    return df, X, y

def perform_eda(df):
    """æ‰§è¡Œæ¢ç´¢æ€§æ•°æ®åˆ†æ"""
    print("=== æ•°æ®åŸºæœ¬ä¿¡æ¯ ===")
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    print("\nå‰5è¡Œæ•°æ®:")
    print(df.head())
    
    print("\n=== æ•°æ®ç»Ÿè®¡ä¿¡æ¯ ===")
    print(df.describe())
    
    print("\n=== ç¼ºå¤±å€¼æ£€æŸ¥ ===")
    print(df.isnull().sum())

def create_visualizations(df):
    """åˆ›å»ºå¯è§†åŒ–å›¾è¡¨"""
    # è®¾ç½®æ ·å¼
    plt.style.use('seaborn-v0_8')
    
    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    
    # 1. ç›®æ ‡å˜é‡åˆ†å¸ƒ
    df['target'].value_counts().plot(kind='bar', ax=axes[0, 0])
    axes[0, 0].set_title('ç›®æ ‡å˜é‡åˆ†å¸ƒ')
    axes[0, 0].set_xlabel('ç±»åˆ«')
    axes[0, 0].set_ylabel('æ•°é‡')
    
    # 2. ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾
    corr_matrix = df.corr()
    sns.heatmap(corr_matrix, ax=axes[0, 1], cmap='coolwarm', center=0)
    axes[0, 1].set_title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾')
    
    # 3. ä¸¤ä¸ªç‰¹å¾çš„å…³ç³»å›¾
    axes[1, 0].scatter(df['feature_0'], df['feature_1'], c=df['target'], alpha=0.6)
    axes[1, 0].set_title('ç‰¹å¾0 vs ç‰¹å¾1')
    axes[1, 0].set_xlabel('ç‰¹å¾0')
    axes[1, 0].set_ylabel('ç‰¹å¾1')
    
    # 4. ç®±çº¿å›¾
    df[['feature_0', 'feature_1', 'feature_2']].boxplot(ax=axes[1, 1])
    axes[1, 1].set_title('ç‰¹å¾åˆ†å¸ƒç®±çº¿å›¾')
    
    plt.tight_layout()
    plt.savefig('data_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

def train_model(X, y):
    """è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹"""
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # è®­ç»ƒæ¨¡å‹
    model = RandomForestClassifier(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # é¢„æµ‹
    y_pred = model.predict(X_test)
    
    # è¯„ä¼°
    print("=== æ¨¡å‹è¯„ä¼°ç»“æœ ===")
    print(classification_report(y_test, y_pred))
    
    # ç‰¹å¾é‡è¦æ€§
    feature_importance = pd.DataFrame({
        'feature': [f'feature_{i}' for i in range(X.shape[1])],
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print("\n=== ç‰¹å¾é‡è¦æ€§æ’å ===")
    print(feature_importance.head(10))
    
    return model, feature_importance

if __name__ == "__main__":
    print("ğŸš€ Pythonæ•°æ®ç§‘å­¦ç¯å¢ƒæ¼”ç¤º")
    print("=" * 50)
    
    # ç”Ÿæˆæ•°æ®
    df, X, y = generate_sample_data()
    
    # æ¢ç´¢æ€§æ•°æ®åˆ†æ
    perform_eda(df)
    
    # å¯è§†åŒ–
    print("\nğŸ“Š æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    create_visualizations(df)
    
    # æ¨¡å‹è®­ç»ƒ
    print("\nğŸ¤– æ­£åœ¨è®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹...")
    model, feature_importance = train_model(X, y)
    
    print("\nâœ… æ•°æ®ç§‘å­¦åˆ†æå®Œæˆï¼")
    print("ç”Ÿæˆçš„æ–‡ä»¶: data_analysis.png")